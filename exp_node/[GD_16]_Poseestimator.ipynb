{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [GD-16] 행동 스티커 만들기.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPII 데이터셋으로 Human Pose Estimation task를 수행.  \n",
    "StackedHourglass Network, simplebaseline 모델 사용.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 0. 라이브러리 로드."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras import Sequential\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models1')\n",
    "MODEL_PATH2 = os.path.join(PROJECT_PATH, 'models2')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 데이터셋 준비  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json 파싱하기  \n",
    "joints 가 우리가 label 로 사용할 keypoint 의 label   \n",
    "Joints순서:\n",
    "0 - 오른쪽 발목  \n",
    "1 - 오른쪽 무릎  \n",
    "2 - 오른쪽 엉덩이  \n",
    "3 - 왼쪽 엉덩이  \n",
    "4 - 왼쪽 무릎  \n",
    "5 - 왼쪽 발목  \n",
    "6 - 골반  \n",
    "7 - 가슴(흉부)  \n",
    "8 - 목  \n",
    "9 - 머리 위  \n",
    "10 - 오른쪽 손목  \n",
    "11 - 오른쪽 팔꿈치  \n",
    "12 - 오른쪽 어깨  \n",
    "13 - 왼쪽 어깨  \n",
    "14 - 왼쪽 팔꿈치  \n",
    "15 - 왼쪽 손목  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pii_human_pose_v1_u12_2.zip 을 풀어보면 mpii_human_pose_v1_u12_1.mat 파일  \n",
    "파이썬에서 읽기 쉽도록 json 파일로 변환  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"joints_vis\": [\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"joints\": [\n",
      "    [\n",
      "      620.0,\n",
      "      394.0\n",
      "    ],\n",
      "    [\n",
      "      616.0,\n",
      "      269.0\n",
      "    ],\n",
      "    [\n",
      "      573.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      188.0\n",
      "    ],\n",
      "    [\n",
      "      661.0,\n",
      "      221.0\n",
      "    ],\n",
      "    [\n",
      "      656.0,\n",
      "      231.0\n",
      "    ],\n",
      "    [\n",
      "      610.0,\n",
      "      187.0\n",
      "    ],\n",
      "    [\n",
      "      647.0,\n",
      "      176.0\n",
      "    ],\n",
      "    [\n",
      "      637.0201,\n",
      "      189.8183\n",
      "    ],\n",
      "    [\n",
      "      695.9799,\n",
      "      108.1817\n",
      "    ],\n",
      "    [\n",
      "      606.0,\n",
      "      217.0\n",
      "    ],\n",
      "    [\n",
      "      553.0,\n",
      "      161.0\n",
      "    ],\n",
      "    [\n",
      "      601.0,\n",
      "      167.0\n",
      "    ],\n",
      "    [\n",
      "      692.0,\n",
      "      185.0\n",
      "    ],\n",
      "    [\n",
      "      693.0,\n",
      "      240.0\n",
      "    ],\n",
      "    [\n",
      "      688.0,\n",
      "      313.0\n",
      "    ]\n",
      "  ],\n",
      "  \"image\": \"015601864.jpg\",\n",
      "  \"scale\": 3.021046,\n",
      "  \"center\": [\n",
      "    594.0,\n",
      "    257.0\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    json_formatted_str = json.dumps(train_annos[0], indent=2)\n",
    "    print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json annotation 을 파싱하는 함수  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse_one_annotation()함수를 테스트  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/mpii/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    test = parse_one_annotation(train_annos[0], IMAGE_PATH)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. TFRecord 파일 만들기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 annotation을 하나의 tf.train.Example로 만들어 주는 함수  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tfexample(anno):\n",
    "    \n",
    "    # byte 인코딩을 위한 함수\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터를 몇 개의 그룹으로 나눌지 결정  \n",
    "  - 얼마나 많은 TFRecord를 만들지 결정할 함수  \n",
    "  - n개로 shard했다고 함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test_chunks = chunkify([0] * 1000, 64)\n",
    "print(test_chunks)\n",
    "print(len(test_chunks))\n",
    "print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chunk안에는 여러 annotation들이 있고, annotation들은 tf.train.Example로 변환된 후에 문자열로 직렬화되어 TFRecord에 들어감.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 3. ray를 이용한 분산 처리.  \n",
    "  - ray.init() 실행\n",
    "  - @ray.remote 를 함수나 클래스에 붙여줌.  \n",
    "  - 결과obj = obj.remote()로 호출하고, ray.get(결과obj)로 결과를 가져옴.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno in chunk:\n",
    "            tf_example = generate_tfexample(anno)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "                TFRECORD_PATH,\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train 데이터는 64개로, val 데이터는 8개의 파일로 TFRecord생성.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 10:55:34,557\tWARNING services.py:1729 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.93gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to parse annotations.\n",
      "First train annotation:  {'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/mpii/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n",
      "First val annotation:  {'filename': '005808361.jpg', 'filepath': '/aiffel/aiffel/mpii/images/005808361.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[804.0, 711.0], [816.0, 510.0], [908.0, 438.0], [1040.0, 454.0], [906.0, 528.0], [883.0, 707.0], [974.0, 446.0], [985.0, 253.0], [982.7591, 235.9694], [962.2409, 80.0306], [869.0, 214.0], [798.0, 340.0], [902.0, 253.0], [1067.0, 253.0], [1167.0, 353.0], [1142.0, 478.0]], 'center': [966.0, 340.0], 'scale': 4.718488}\n",
      "Start to build TF Records.\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0001_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0002_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0003_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0004_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0006_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0005_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0008_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0007_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0009_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0010_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0011_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0012_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0013_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0014_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0015_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0016_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0017_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0018_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0019_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0022_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0020_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0022_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0021_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0023_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0024_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0025_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0026_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0027_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0028_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0029_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0030_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0032_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0031_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0033_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0034_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0035_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0036_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0037_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0038_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0039_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0042_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0040_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0041_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0042_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0045_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0043_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0045_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0044_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0046_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0047_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0048_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0049_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0050_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0051_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0052_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0053_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0054_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0055_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0056_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0058_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0057_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0059_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0061_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0060_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0062_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0063_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/train_0064_of_0064.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0001_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0002_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0005_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0003_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0006_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0004_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0007_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0005_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m start to build tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0008_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=126)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0006_of_0008.tfrecords\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=125)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0007_of_0008.tfrecords\n",
      "Successfully wrote 25204 annotations to TF Records.\n",
      "\u001b[2m\u001b[36m(build_single_tfrecord pid=124)\u001b[0m finished building tf records for /aiffel/aiffel/mpii/tfrecords_mpii/val_0008_of_0008.tfrecords\n"
     ]
    }
   ],
   "source": [
    "num_train_shards = 64\n",
    "num_val_shards = 8\n",
    "\n",
    "ray.init()\n",
    "\n",
    "print('Start to parse annotations.')\n",
    "if not os.path.exists(TFRECORD_PATH):\n",
    "    os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    train_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH)\n",
    "        for anno in train_annos\n",
    "    ]\n",
    "    print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "with open(VALID_JSON) as val_json:\n",
    "    val_annos = json.load(val_json)\n",
    "    val_annotations = [\n",
    "        parse_one_annotation(anno, IMAGE_PATH) \n",
    "        for anno in val_annos\n",
    "    ]\n",
    "    print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "print('Start to build TF Records.')\n",
    "build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "    len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Data로 Label만들기.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFRecord로 저장된 데이터를 모델에 학습에 필요한 데이터로 변경.   \n",
    "TFRecord가 직렬화된 데이터이기 때문에   \n",
    "  - 만들 때 데이터 순서와 읽어올 때 데이터 순서가 같아야함.  \n",
    "  - 데이터의 형식도 동일해야함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfexample(example):\n",
    "    image_feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, image_feature_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image 와 label 을 이용해서 적절한 학습 형태로 변환  \n",
    "적당히 정사각형으로 crop하여 사용  \n",
    "crop box 가 이미지 바깥으로 나가지 않는지 예외 처리  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_roi(image, features, margin=0.2):\n",
    "    img_shape = tf.shape(image)\n",
    "    img_height = img_shape[0]\n",
    "    img_width = img_shape[1]\n",
    "    img_depth = img_shape[2]\n",
    "\n",
    "    keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "    keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "    center_x = features['image/object/center/x']\n",
    "    center_y = features['image/object/center/y']\n",
    "    body_height = features['image/object/scale'] * 200.0\n",
    "\n",
    "    # keypoint 중 유효한값(visible = 1) 만 사용합니다.\n",
    "    masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "    masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "\n",
    "    # min, max 값을 찾습니다.\n",
    "    keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "    keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "    keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "    keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "\n",
    "    # 높이 값을 이용해서 x, y 위치를 재조정 합니다. 박스를 정사각형으로 사용하기 위해 아래와 같이 사용합니다.\n",
    "    xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "\n",
    "    # 이미지 크기를 벗어나는 점을 재조정 해줍니다.\n",
    "    effective_xmin = xmin if xmin > 0 else 0\n",
    "    effective_ymin = ymin if ymin > 0 else 0\n",
    "    effective_xmax = xmax if xmax < img_width else img_width\n",
    "    effective_ymax = ymax if ymax < img_height else img_height\n",
    "    effective_height = effective_ymax - effective_ymin\n",
    "    effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "    image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "    new_shape = tf.shape(image)\n",
    "    new_height = new_shape[0]\n",
    "    new_width = new_shape[1]\n",
    "\n",
    "    effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "    effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "\n",
    "    return image, effective_keypoint_x, effective_keypoint_y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(x, y) 좌표로 되어있는 keypoint 를 heatmap 으로 변경  \n",
    "확률 분포로는 2차원 가우시안 분포를 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_2d_guassian(height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "    heatmap = tf.zeros((height, width))\n",
    "\n",
    "    xmin = x0 - 3 * sigma\n",
    "    ymin = y0 - 3 * sigma\n",
    "    xmax = x0 + 3 * sigma\n",
    "    ymax = y0 + 3 * sigma\n",
    "    \n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x, y = tf.meshgrid(tf.range(0, 6 * sigma + 1, 1), tf.range(0, 6 * sigma + 1, 1), indexing='xy')\n",
    "\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    gaussian_patch = tf.cast(tf.math.exp(\n",
    "        -(tf.math.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    patch_xmin = tf.math.maximum(0, -xmin)\n",
    "    patch_ymin = tf.math.maximum(0, -ymin)\n",
    "    patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "    patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "    heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "    heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "    heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "    heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for j in tf.range(patch_ymin, patch_ymax):\n",
    "        for i in tf.range(patch_xmin, patch_xmax):\n",
    "            indices = indices.write(count, [heatmap_ymin + j, heatmap_xmin + i])\n",
    "            updates = updates.write(count, gaussian_patch[j][i])\n",
    "            count += 1\n",
    "\n",
    "    heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmaps(features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "    v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "    x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "    y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "\n",
    "    num_heatmap = heatmap_shape[2]\n",
    "    heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "    for i in range(num_heatmap):\n",
    "        gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "        heatmap_array = heatmap_array.write(i, gaussian)\n",
    "\n",
    "    heatmaps = heatmap_array.stack()\n",
    "    heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0])  # change to (64, 64, 16)\n",
    "\n",
    "    return heatmaps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "함수들을 객체 형태로 조합  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Hourglass 모델  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 두가지 residual block :  \n",
    " 3x3-3x3 basic block, 1x1-3x3-1x1 bottleneck block  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "intermediate output을 위한 linear layer  \n",
    "모델이 깊어지는 만큼 학습이 어려워 intermediate loss (auxilary loss) 를 추가  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " stacked 되는 hourglass 층 사이사이에 LinearLayer 를 삽입하고 중간 loss 를 계산  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 학습 엔진 만들기  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU가 여러 개이고 데이터를 병렬로 학습시:  \n",
    " - tf.distribute.MirroredStrategy : 여러 GPU가 모델을 학습한 후 각각의 Loss를 계산하면 CPU가 전체 Loss를 종합  \n",
    " - 그런 후 모델의 가중치를 업데이트  \n",
    " - GPU에서 계산한 Loss를 토대로 전체 Loss를 종합해주는 역할은 strategy.reduce 함수가 담당  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0\n",
    "        for output in outputs:\n",
    "            weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "            loss += tf.math.reduce_mean(\n",
    "                tf.math.square(labels - output) * weights) * (\n",
    "                    1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFRecord 파일이 여러개이므로 tf.data.Dataset.list_files 사용  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋과 모델, 훈련용 객체를 조립  \n",
    "with strategy.scope():부분이 반드시 필요함.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "\n",
    "        model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 모델 학습  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.\n",
      "  warnings.warn(\"To make it possible to preserve tf.data options across \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 2.46386862 epoch total loss 2.46386862\n",
      "Trained batch 2 batch loss 2.26817131 epoch total loss 2.36602\n",
      "Trained batch 3 batch loss 2.20947409 epoch total loss 2.31383801\n",
      "Trained batch 4 batch loss 2.28389668 epoch total loss 2.30635262\n",
      "Trained batch 5 batch loss 2.26265836 epoch total loss 2.29761362\n",
      "Trained batch 6 batch loss 2.06922483 epoch total loss 2.2595489\n",
      "Trained batch 7 batch loss 2.096838 epoch total loss 2.23630452\n",
      "Trained batch 8 batch loss 2.20964146 epoch total loss 2.23297167\n",
      "Trained batch 9 batch loss 2.19048071 epoch total loss 2.2282505\n",
      "Trained batch 10 batch loss 2.1592164 epoch total loss 2.22134709\n",
      "Trained batch 11 batch loss 2.12789154 epoch total loss 2.21285105\n",
      "Trained batch 12 batch loss 2.08242965 epoch total loss 2.20198274\n",
      "Trained batch 13 batch loss 1.89405632 epoch total loss 2.17829609\n",
      "Trained batch 14 batch loss 2.0883491 epoch total loss 2.17187119\n",
      "Trained batch 15 batch loss 2.03816867 epoch total loss 2.16295767\n",
      "Trained batch 16 batch loss 1.93036973 epoch total loss 2.14842105\n",
      "Trained batch 17 batch loss 1.98240423 epoch total loss 2.13865519\n",
      "Trained batch 18 batch loss 2.04112649 epoch total loss 2.13323689\n",
      "Trained batch 19 batch loss 1.93639266 epoch total loss 2.12287688\n",
      "Trained batch 20 batch loss 1.7632947 epoch total loss 2.10489774\n",
      "Trained batch 21 batch loss 1.89947474 epoch total loss 2.09511566\n",
      "Trained batch 22 batch loss 1.8330096 epoch total loss 2.08320165\n",
      "Trained batch 23 batch loss 1.84619331 epoch total loss 2.07289696\n",
      "Trained batch 24 batch loss 1.83318281 epoch total loss 2.06290889\n",
      "Trained batch 25 batch loss 1.76440263 epoch total loss 2.05096865\n",
      "Trained batch 26 batch loss 1.82790828 epoch total loss 2.04238939\n",
      "Trained batch 27 batch loss 1.80544376 epoch total loss 2.03361344\n",
      "Trained batch 28 batch loss 1.85925698 epoch total loss 2.02738643\n",
      "Trained batch 29 batch loss 1.88550842 epoch total loss 2.02249432\n",
      "Trained batch 30 batch loss 1.76614797 epoch total loss 2.01394939\n",
      "Trained batch 31 batch loss 1.82352054 epoch total loss 2.00780654\n",
      "Trained batch 32 batch loss 1.71610188 epoch total loss 1.99869072\n",
      "Trained batch 33 batch loss 1.85198855 epoch total loss 1.99424517\n",
      "Trained batch 34 batch loss 1.79964018 epoch total loss 1.98852134\n",
      "Trained batch 35 batch loss 1.67530417 epoch total loss 1.97957218\n",
      "Trained batch 36 batch loss 1.71868968 epoch total loss 1.97232544\n",
      "Trained batch 37 batch loss 1.795398 epoch total loss 1.96754348\n",
      "Trained batch 38 batch loss 1.76344085 epoch total loss 1.96217251\n",
      "Trained batch 39 batch loss 1.79764915 epoch total loss 1.95795381\n",
      "Trained batch 40 batch loss 1.7308619 epoch total loss 1.95227659\n",
      "Trained batch 41 batch loss 1.82894623 epoch total loss 1.94926858\n",
      "Trained batch 42 batch loss 1.70514166 epoch total loss 1.94345605\n",
      "Trained batch 43 batch loss 1.62181199 epoch total loss 1.93597591\n",
      "Trained batch 44 batch loss 1.58288503 epoch total loss 1.9279511\n",
      "Trained batch 45 batch loss 1.65494335 epoch total loss 1.9218843\n",
      "Trained batch 46 batch loss 1.79529679 epoch total loss 1.91913235\n",
      "Trained batch 47 batch loss 1.8304944 epoch total loss 1.91724658\n",
      "Trained batch 48 batch loss 1.69722629 epoch total loss 1.91266286\n",
      "Trained batch 49 batch loss 1.72617245 epoch total loss 1.90885687\n",
      "Trained batch 50 batch loss 1.78062487 epoch total loss 1.90629232\n",
      "Trained batch 51 batch loss 1.72112107 epoch total loss 1.90266144\n",
      "Trained batch 52 batch loss 1.7274065 epoch total loss 1.89929128\n",
      "Trained batch 53 batch loss 1.85924625 epoch total loss 1.89853573\n",
      "Trained batch 54 batch loss 1.73903775 epoch total loss 1.89558196\n",
      "Trained batch 55 batch loss 1.77929473 epoch total loss 1.89346766\n",
      "Trained batch 56 batch loss 1.81215286 epoch total loss 1.8920157\n",
      "Trained batch 57 batch loss 1.54730368 epoch total loss 1.88596809\n",
      "Trained batch 58 batch loss 1.70240974 epoch total loss 1.88280332\n",
      "Trained batch 59 batch loss 1.54909098 epoch total loss 1.87714708\n",
      "Trained batch 60 batch loss 1.52593231 epoch total loss 1.87129354\n",
      "Trained batch 61 batch loss 1.67249954 epoch total loss 1.8680346\n",
      "Trained batch 62 batch loss 1.72472274 epoch total loss 1.86572313\n",
      "Trained batch 63 batch loss 1.76062095 epoch total loss 1.8640548\n",
      "Trained batch 64 batch loss 1.76656103 epoch total loss 1.86253154\n",
      "Trained batch 65 batch loss 1.73968434 epoch total loss 1.8606416\n",
      "Trained batch 66 batch loss 1.77272415 epoch total loss 1.85930955\n",
      "Trained batch 67 batch loss 1.72984552 epoch total loss 1.85737729\n",
      "Trained batch 68 batch loss 1.764992 epoch total loss 1.85601866\n",
      "Trained batch 69 batch loss 1.74682462 epoch total loss 1.85443616\n",
      "Trained batch 70 batch loss 1.64133132 epoch total loss 1.85139179\n",
      "Trained batch 71 batch loss 1.66455305 epoch total loss 1.84876025\n",
      "Trained batch 72 batch loss 1.59456134 epoch total loss 1.84522963\n",
      "Trained batch 73 batch loss 1.65431273 epoch total loss 1.84261441\n",
      "Trained batch 74 batch loss 1.61441123 epoch total loss 1.83953059\n",
      "Trained batch 75 batch loss 1.63731778 epoch total loss 1.83683431\n",
      "Trained batch 76 batch loss 1.63034558 epoch total loss 1.83411729\n",
      "Trained batch 77 batch loss 1.69479895 epoch total loss 1.83230793\n",
      "Trained batch 78 batch loss 1.76786232 epoch total loss 1.8314817\n",
      "Trained batch 79 batch loss 1.66011226 epoch total loss 1.82931244\n",
      "Trained batch 80 batch loss 1.65245545 epoch total loss 1.82710171\n",
      "Trained batch 81 batch loss 1.71148443 epoch total loss 1.82567441\n",
      "Trained batch 82 batch loss 1.7350955 epoch total loss 1.8245697\n",
      "Trained batch 83 batch loss 1.649158 epoch total loss 1.82245624\n",
      "Trained batch 84 batch loss 1.59872174 epoch total loss 1.81979275\n",
      "Trained batch 85 batch loss 1.76861954 epoch total loss 1.81919074\n",
      "Trained batch 86 batch loss 1.65695477 epoch total loss 1.81730425\n",
      "Trained batch 87 batch loss 1.68045187 epoch total loss 1.81573117\n",
      "Trained batch 88 batch loss 1.62605977 epoch total loss 1.81357574\n",
      "Trained batch 89 batch loss 1.68277979 epoch total loss 1.81210613\n",
      "Trained batch 90 batch loss 1.74647403 epoch total loss 1.81137693\n",
      "Trained batch 91 batch loss 1.71653688 epoch total loss 1.8103348\n",
      "Trained batch 92 batch loss 1.70417774 epoch total loss 1.80918086\n",
      "Trained batch 93 batch loss 1.73005188 epoch total loss 1.80833\n",
      "Trained batch 94 batch loss 1.66290629 epoch total loss 1.80678296\n",
      "Trained batch 95 batch loss 1.71829176 epoch total loss 1.80585146\n",
      "Trained batch 96 batch loss 1.69385338 epoch total loss 1.80468476\n",
      "Trained batch 97 batch loss 1.73267961 epoch total loss 1.80394244\n",
      "Trained batch 98 batch loss 1.68861461 epoch total loss 1.80276573\n",
      "Trained batch 99 batch loss 1.63731 epoch total loss 1.80109441\n",
      "Trained batch 100 batch loss 1.71551788 epoch total loss 1.80023861\n",
      "Trained batch 101 batch loss 1.74963498 epoch total loss 1.79973757\n",
      "Trained batch 102 batch loss 1.68112278 epoch total loss 1.79857469\n",
      "Trained batch 103 batch loss 1.79157639 epoch total loss 1.79850686\n",
      "Trained batch 104 batch loss 1.73837423 epoch total loss 1.79792857\n",
      "Trained batch 105 batch loss 1.68047905 epoch total loss 1.79681\n",
      "Trained batch 106 batch loss 1.73437142 epoch total loss 1.79622102\n",
      "Trained batch 107 batch loss 1.73240364 epoch total loss 1.79562461\n",
      "Trained batch 108 batch loss 1.77691102 epoch total loss 1.7954514\n",
      "Trained batch 109 batch loss 1.74953961 epoch total loss 1.79503024\n",
      "Trained batch 110 batch loss 1.74208832 epoch total loss 1.79454899\n",
      "Trained batch 111 batch loss 1.75901759 epoch total loss 1.79422891\n",
      "Trained batch 112 batch loss 1.74529457 epoch total loss 1.79379201\n",
      "Trained batch 113 batch loss 1.71301484 epoch total loss 1.79307723\n",
      "Trained batch 114 batch loss 1.6745044 epoch total loss 1.79203701\n",
      "Trained batch 115 batch loss 1.70104909 epoch total loss 1.79124582\n",
      "Trained batch 116 batch loss 1.68780708 epoch total loss 1.79035413\n",
      "Trained batch 117 batch loss 1.8032769 epoch total loss 1.79046464\n",
      "Trained batch 118 batch loss 1.73878431 epoch total loss 1.79002666\n",
      "Trained batch 119 batch loss 1.7328651 epoch total loss 1.78954625\n",
      "Trained batch 120 batch loss 1.75089169 epoch total loss 1.78922415\n",
      "Trained batch 121 batch loss 1.72025144 epoch total loss 1.78865409\n",
      "Trained batch 122 batch loss 1.6773957 epoch total loss 1.78774214\n",
      "Trained batch 123 batch loss 1.62503731 epoch total loss 1.78641927\n",
      "Trained batch 124 batch loss 1.6968981 epoch total loss 1.78569734\n",
      "Trained batch 125 batch loss 1.76823676 epoch total loss 1.78555763\n",
      "Trained batch 126 batch loss 1.7277987 epoch total loss 1.78509927\n",
      "Trained batch 127 batch loss 1.74216247 epoch total loss 1.78476107\n",
      "Trained batch 128 batch loss 1.70898426 epoch total loss 1.78416908\n",
      "Trained batch 129 batch loss 1.67925477 epoch total loss 1.78335583\n",
      "Trained batch 130 batch loss 1.59492278 epoch total loss 1.78190637\n",
      "Trained batch 131 batch loss 1.46089852 epoch total loss 1.7794559\n",
      "Trained batch 132 batch loss 1.56370282 epoch total loss 1.77782142\n",
      "Trained batch 133 batch loss 1.72696126 epoch total loss 1.777439\n",
      "Trained batch 134 batch loss 1.69362628 epoch total loss 1.77681351\n",
      "Trained batch 135 batch loss 1.62705505 epoch total loss 1.77570415\n",
      "Trained batch 136 batch loss 1.66696155 epoch total loss 1.77490461\n",
      "Trained batch 137 batch loss 1.66464782 epoch total loss 1.77409971\n",
      "Trained batch 138 batch loss 1.69899237 epoch total loss 1.77355552\n",
      "Trained batch 139 batch loss 1.75373375 epoch total loss 1.77341294\n",
      "Trained batch 140 batch loss 1.69202089 epoch total loss 1.77283156\n",
      "Trained batch 141 batch loss 1.69368577 epoch total loss 1.7722702\n",
      "Trained batch 142 batch loss 1.68991184 epoch total loss 1.77169013\n",
      "Trained batch 143 batch loss 1.67896271 epoch total loss 1.77104175\n",
      "Trained batch 144 batch loss 1.55298972 epoch total loss 1.76952755\n",
      "Trained batch 145 batch loss 1.71821761 epoch total loss 1.76917362\n",
      "Trained batch 146 batch loss 1.70462537 epoch total loss 1.76873147\n",
      "Trained batch 147 batch loss 1.69826579 epoch total loss 1.76825225\n",
      "Trained batch 148 batch loss 1.58754396 epoch total loss 1.76703131\n",
      "Trained batch 149 batch loss 1.64440453 epoch total loss 1.76620829\n",
      "Trained batch 150 batch loss 1.52313673 epoch total loss 1.76458776\n",
      "Trained batch 151 batch loss 1.6045475 epoch total loss 1.76352799\n",
      "Trained batch 152 batch loss 1.72029555 epoch total loss 1.76324368\n",
      "Trained batch 153 batch loss 1.57580709 epoch total loss 1.76201856\n",
      "Trained batch 154 batch loss 1.61846197 epoch total loss 1.76108634\n",
      "Trained batch 155 batch loss 1.53441262 epoch total loss 1.759624\n",
      "Trained batch 156 batch loss 1.67204714 epoch total loss 1.75906277\n",
      "Trained batch 157 batch loss 1.40786099 epoch total loss 1.7568258\n",
      "Trained batch 158 batch loss 1.53839362 epoch total loss 1.75544333\n",
      "Trained batch 159 batch loss 1.53313589 epoch total loss 1.75404525\n",
      "Trained batch 160 batch loss 1.48043346 epoch total loss 1.75233519\n",
      "Trained batch 161 batch loss 1.61580563 epoch total loss 1.75148726\n",
      "Trained batch 162 batch loss 1.70552492 epoch total loss 1.75120354\n",
      "Trained batch 163 batch loss 1.69432878 epoch total loss 1.75085473\n",
      "Trained batch 164 batch loss 1.60237312 epoch total loss 1.74994934\n",
      "Trained batch 165 batch loss 1.48785663 epoch total loss 1.74836087\n",
      "Trained batch 166 batch loss 1.56103015 epoch total loss 1.74723244\n",
      "Trained batch 167 batch loss 1.71751273 epoch total loss 1.74705446\n",
      "Trained batch 168 batch loss 1.61917567 epoch total loss 1.74629319\n",
      "Trained batch 169 batch loss 1.63695097 epoch total loss 1.74564624\n",
      "Trained batch 170 batch loss 1.66622782 epoch total loss 1.74517918\n",
      "Trained batch 171 batch loss 1.57956 epoch total loss 1.7442106\n",
      "Trained batch 172 batch loss 1.62460673 epoch total loss 1.74351513\n",
      "Trained batch 173 batch loss 1.66078854 epoch total loss 1.7430371\n",
      "Trained batch 174 batch loss 1.72897029 epoch total loss 1.74295628\n",
      "Trained batch 175 batch loss 1.68726802 epoch total loss 1.74263799\n",
      "Trained batch 176 batch loss 1.59078217 epoch total loss 1.74177516\n",
      "Trained batch 177 batch loss 1.62023234 epoch total loss 1.74108851\n",
      "Trained batch 178 batch loss 1.62285566 epoch total loss 1.74042439\n",
      "Trained batch 179 batch loss 1.51443815 epoch total loss 1.73916185\n",
      "Trained batch 180 batch loss 1.51609874 epoch total loss 1.73792267\n",
      "Trained batch 181 batch loss 1.57499504 epoch total loss 1.7370224\n",
      "Trained batch 182 batch loss 1.58366334 epoch total loss 1.73617971\n",
      "Trained batch 183 batch loss 1.6599009 epoch total loss 1.73576295\n",
      "Trained batch 184 batch loss 1.60235608 epoch total loss 1.73503792\n",
      "Trained batch 185 batch loss 1.67113352 epoch total loss 1.73469257\n",
      "Trained batch 186 batch loss 1.65373933 epoch total loss 1.73425734\n",
      "Trained batch 187 batch loss 1.64712048 epoch total loss 1.73379147\n",
      "Trained batch 188 batch loss 1.67489076 epoch total loss 1.73347819\n",
      "Trained batch 189 batch loss 1.50255191 epoch total loss 1.73225641\n",
      "Trained batch 190 batch loss 1.59801412 epoch total loss 1.73154986\n",
      "Trained batch 191 batch loss 1.55922246 epoch total loss 1.73064768\n",
      "Trained batch 192 batch loss 1.6478107 epoch total loss 1.73021615\n",
      "Trained batch 193 batch loss 1.68196344 epoch total loss 1.72996628\n",
      "Trained batch 194 batch loss 1.73217893 epoch total loss 1.72997761\n",
      "Trained batch 195 batch loss 1.69650459 epoch total loss 1.72980595\n",
      "Trained batch 196 batch loss 1.6968627 epoch total loss 1.72963798\n",
      "Trained batch 197 batch loss 1.63479149 epoch total loss 1.72915649\n",
      "Trained batch 198 batch loss 1.68113923 epoch total loss 1.72891402\n",
      "Trained batch 199 batch loss 1.67992783 epoch total loss 1.72866786\n",
      "Trained batch 200 batch loss 1.68771911 epoch total loss 1.72846317\n",
      "Trained batch 201 batch loss 1.61387289 epoch total loss 1.72789299\n",
      "Trained batch 202 batch loss 1.59060228 epoch total loss 1.72721338\n",
      "Trained batch 203 batch loss 1.68790507 epoch total loss 1.72701967\n",
      "Trained batch 204 batch loss 1.65024662 epoch total loss 1.72664332\n",
      "Trained batch 205 batch loss 1.65636694 epoch total loss 1.72630048\n",
      "Trained batch 206 batch loss 1.71517265 epoch total loss 1.72624648\n",
      "Trained batch 207 batch loss 1.71367669 epoch total loss 1.7261858\n",
      "Trained batch 208 batch loss 1.73938131 epoch total loss 1.72624922\n",
      "Trained batch 209 batch loss 1.72916818 epoch total loss 1.72626317\n",
      "Trained batch 210 batch loss 1.71146345 epoch total loss 1.72619271\n",
      "Trained batch 211 batch loss 1.72716558 epoch total loss 1.72619724\n",
      "Trained batch 212 batch loss 1.6712184 epoch total loss 1.72593784\n",
      "Trained batch 213 batch loss 1.65835667 epoch total loss 1.72562063\n",
      "Trained batch 214 batch loss 1.68376398 epoch total loss 1.72542512\n",
      "Trained batch 215 batch loss 1.64420903 epoch total loss 1.72504723\n",
      "Trained batch 216 batch loss 1.6388334 epoch total loss 1.72464812\n",
      "Trained batch 217 batch loss 1.63087678 epoch total loss 1.72421598\n",
      "Trained batch 218 batch loss 1.62722921 epoch total loss 1.7237711\n",
      "Trained batch 219 batch loss 1.61784434 epoch total loss 1.72328746\n",
      "Trained batch 220 batch loss 1.59763551 epoch total loss 1.72271633\n",
      "Trained batch 221 batch loss 1.55106485 epoch total loss 1.72193956\n",
      "Trained batch 222 batch loss 1.69473529 epoch total loss 1.72181702\n",
      "Trained batch 223 batch loss 1.69432187 epoch total loss 1.72169375\n",
      "Trained batch 224 batch loss 1.8046627 epoch total loss 1.72206414\n",
      "Trained batch 225 batch loss 1.65319729 epoch total loss 1.72175813\n",
      "Trained batch 226 batch loss 1.69007921 epoch total loss 1.72161794\n",
      "Trained batch 227 batch loss 1.62802768 epoch total loss 1.72120571\n",
      "Trained batch 228 batch loss 1.62665403 epoch total loss 1.72079098\n",
      "Trained batch 229 batch loss 1.57327354 epoch total loss 1.72014678\n",
      "Trained batch 230 batch loss 1.53358638 epoch total loss 1.71933568\n",
      "Trained batch 231 batch loss 1.69680285 epoch total loss 1.71923816\n",
      "Trained batch 232 batch loss 1.603127 epoch total loss 1.7187376\n",
      "Trained batch 233 batch loss 1.75920415 epoch total loss 1.71891141\n",
      "Trained batch 234 batch loss 1.66604888 epoch total loss 1.71868539\n",
      "Trained batch 235 batch loss 1.67461395 epoch total loss 1.71849799\n",
      "Trained batch 236 batch loss 1.57983422 epoch total loss 1.71791041\n",
      "Trained batch 237 batch loss 1.60531199 epoch total loss 1.71743524\n",
      "Trained batch 238 batch loss 1.57322621 epoch total loss 1.7168293\n",
      "Trained batch 239 batch loss 1.58728254 epoch total loss 1.71628726\n",
      "Trained batch 240 batch loss 1.51810718 epoch total loss 1.71546149\n",
      "Trained batch 241 batch loss 1.58355927 epoch total loss 1.7149142\n",
      "Trained batch 242 batch loss 1.6213429 epoch total loss 1.71452749\n",
      "Trained batch 243 batch loss 1.75638545 epoch total loss 1.71469975\n",
      "Trained batch 244 batch loss 1.68523669 epoch total loss 1.71457899\n",
      "Trained batch 245 batch loss 1.67624748 epoch total loss 1.71442246\n",
      "Trained batch 246 batch loss 1.61080146 epoch total loss 1.7140013\n",
      "Trained batch 247 batch loss 1.57302082 epoch total loss 1.71343052\n",
      "Trained batch 248 batch loss 1.57682621 epoch total loss 1.71287966\n",
      "Trained batch 249 batch loss 1.60124636 epoch total loss 1.71243143\n",
      "Trained batch 250 batch loss 1.65958846 epoch total loss 1.71222\n",
      "Trained batch 251 batch loss 1.74229515 epoch total loss 1.71233988\n",
      "Trained batch 252 batch loss 1.7360574 epoch total loss 1.71243393\n",
      "Trained batch 253 batch loss 1.69433403 epoch total loss 1.71236241\n",
      "Trained batch 254 batch loss 1.76275539 epoch total loss 1.71256077\n",
      "Trained batch 255 batch loss 1.71578467 epoch total loss 1.71257353\n",
      "Trained batch 256 batch loss 1.7655046 epoch total loss 1.71278024\n",
      "Trained batch 257 batch loss 1.77055502 epoch total loss 1.71300507\n",
      "Trained batch 258 batch loss 1.72886491 epoch total loss 1.71306646\n",
      "Trained batch 259 batch loss 1.71231985 epoch total loss 1.7130636\n",
      "Trained batch 260 batch loss 1.56503093 epoch total loss 1.71249425\n",
      "Trained batch 261 batch loss 1.60251343 epoch total loss 1.71207285\n",
      "Trained batch 262 batch loss 1.53811789 epoch total loss 1.71140885\n",
      "Trained batch 263 batch loss 1.64597404 epoch total loss 1.71116006\n",
      "Trained batch 264 batch loss 1.52393651 epoch total loss 1.71045089\n",
      "Trained batch 265 batch loss 1.6475811 epoch total loss 1.71021354\n",
      "Trained batch 266 batch loss 1.64614308 epoch total loss 1.70997274\n",
      "Trained batch 267 batch loss 1.65988362 epoch total loss 1.7097851\n",
      "Trained batch 268 batch loss 1.66699755 epoch total loss 1.70962548\n",
      "Trained batch 269 batch loss 1.67990959 epoch total loss 1.70951498\n",
      "Trained batch 270 batch loss 1.62971425 epoch total loss 1.70921934\n",
      "Trained batch 271 batch loss 1.68466425 epoch total loss 1.70912874\n",
      "Trained batch 272 batch loss 1.55671644 epoch total loss 1.70856833\n",
      "Trained batch 273 batch loss 1.45268083 epoch total loss 1.70763099\n",
      "Trained batch 274 batch loss 1.41509831 epoch total loss 1.70656335\n",
      "Trained batch 275 batch loss 1.58513284 epoch total loss 1.7061218\n",
      "Trained batch 276 batch loss 1.51614141 epoch total loss 1.70543349\n",
      "Trained batch 277 batch loss 1.64091873 epoch total loss 1.70520067\n",
      "Trained batch 278 batch loss 1.64808106 epoch total loss 1.70499516\n",
      "Trained batch 279 batch loss 1.54171824 epoch total loss 1.70441\n",
      "Trained batch 280 batch loss 1.46745634 epoch total loss 1.70356369\n",
      "Trained batch 281 batch loss 1.61845338 epoch total loss 1.70326078\n",
      "Trained batch 282 batch loss 1.54886353 epoch total loss 1.70271325\n",
      "Trained batch 283 batch loss 1.6746366 epoch total loss 1.70261395\n",
      "Trained batch 284 batch loss 1.58565152 epoch total loss 1.7022022\n",
      "Trained batch 285 batch loss 1.44097567 epoch total loss 1.7012856\n",
      "Trained batch 286 batch loss 1.44091535 epoch total loss 1.7003752\n",
      "Trained batch 287 batch loss 1.49184299 epoch total loss 1.69964862\n",
      "Trained batch 288 batch loss 1.50696874 epoch total loss 1.69897962\n",
      "Trained batch 289 batch loss 1.50703847 epoch total loss 1.6983155\n",
      "Trained batch 290 batch loss 1.52464497 epoch total loss 1.69771671\n",
      "Trained batch 291 batch loss 1.61540365 epoch total loss 1.69743383\n",
      "Trained batch 292 batch loss 1.59859467 epoch total loss 1.69709539\n",
      "Trained batch 293 batch loss 1.62133551 epoch total loss 1.69683683\n",
      "Trained batch 294 batch loss 1.53319216 epoch total loss 1.69628024\n",
      "Trained batch 295 batch loss 1.610533 epoch total loss 1.69598961\n",
      "Trained batch 296 batch loss 1.63199353 epoch total loss 1.69577336\n",
      "Trained batch 297 batch loss 1.28145 epoch total loss 1.69437838\n",
      "Trained batch 298 batch loss 1.22994721 epoch total loss 1.69281983\n",
      "Trained batch 299 batch loss 1.44021964 epoch total loss 1.69197512\n",
      "Trained batch 300 batch loss 1.53028035 epoch total loss 1.69143605\n",
      "Trained batch 301 batch loss 1.74234259 epoch total loss 1.69160521\n",
      "Trained batch 302 batch loss 1.76052046 epoch total loss 1.69183338\n",
      "Trained batch 303 batch loss 1.64199066 epoch total loss 1.69166887\n",
      "Trained batch 304 batch loss 1.53196442 epoch total loss 1.69114363\n",
      "Trained batch 305 batch loss 1.63608456 epoch total loss 1.69096315\n",
      "Trained batch 306 batch loss 1.71237576 epoch total loss 1.69103324\n",
      "Trained batch 307 batch loss 1.63776016 epoch total loss 1.69085968\n",
      "Trained batch 308 batch loss 1.52107549 epoch total loss 1.69030845\n",
      "Trained batch 309 batch loss 1.57129622 epoch total loss 1.68992329\n",
      "Trained batch 310 batch loss 1.65586972 epoch total loss 1.68981338\n",
      "Trained batch 311 batch loss 1.58664322 epoch total loss 1.68948174\n",
      "Trained batch 312 batch loss 1.65947247 epoch total loss 1.68938565\n",
      "Trained batch 313 batch loss 1.63636088 epoch total loss 1.68921626\n",
      "Trained batch 314 batch loss 1.52459049 epoch total loss 1.68869197\n",
      "Trained batch 315 batch loss 1.48077297 epoch total loss 1.68803191\n",
      "Trained batch 316 batch loss 1.65411711 epoch total loss 1.6879245\n",
      "Trained batch 317 batch loss 1.57486057 epoch total loss 1.68756795\n",
      "Trained batch 318 batch loss 1.64716566 epoch total loss 1.68744087\n",
      "Trained batch 319 batch loss 1.55582738 epoch total loss 1.68702841\n",
      "Trained batch 320 batch loss 1.61578846 epoch total loss 1.68680573\n",
      "Trained batch 321 batch loss 1.62922204 epoch total loss 1.68662632\n",
      "Trained batch 322 batch loss 1.57130039 epoch total loss 1.68626809\n",
      "Trained batch 323 batch loss 1.52839732 epoch total loss 1.68577933\n",
      "Trained batch 324 batch loss 1.69841528 epoch total loss 1.68581831\n",
      "Trained batch 325 batch loss 1.62725103 epoch total loss 1.68563819\n",
      "Trained batch 326 batch loss 1.58905411 epoch total loss 1.68534184\n",
      "Trained batch 327 batch loss 1.5048219 epoch total loss 1.68478978\n",
      "Trained batch 328 batch loss 1.55861294 epoch total loss 1.68440509\n",
      "Trained batch 329 batch loss 1.65525138 epoch total loss 1.68431652\n",
      "Trained batch 330 batch loss 1.66724932 epoch total loss 1.68426478\n",
      "Trained batch 331 batch loss 1.70787668 epoch total loss 1.68433619\n",
      "Trained batch 332 batch loss 1.74698019 epoch total loss 1.68452489\n",
      "Trained batch 333 batch loss 1.5178299 epoch total loss 1.68402433\n",
      "Trained batch 334 batch loss 1.48965216 epoch total loss 1.68344223\n",
      "Trained batch 335 batch loss 1.56480026 epoch total loss 1.68308818\n",
      "Trained batch 336 batch loss 1.56519008 epoch total loss 1.68273723\n",
      "Trained batch 337 batch loss 1.5465945 epoch total loss 1.68233323\n",
      "Trained batch 338 batch loss 1.61736369 epoch total loss 1.68214095\n",
      "Trained batch 339 batch loss 1.61595857 epoch total loss 1.6819458\n",
      "Trained batch 340 batch loss 1.61339498 epoch total loss 1.68174422\n",
      "Trained batch 341 batch loss 1.61359489 epoch total loss 1.6815443\n",
      "Trained batch 342 batch loss 1.60116279 epoch total loss 1.68130922\n",
      "Trained batch 343 batch loss 1.58881843 epoch total loss 1.68103957\n",
      "Trained batch 344 batch loss 1.64637828 epoch total loss 1.68093872\n",
      "Trained batch 345 batch loss 1.59151101 epoch total loss 1.68067944\n",
      "Trained batch 346 batch loss 1.61515474 epoch total loss 1.68049014\n",
      "Trained batch 347 batch loss 1.51389897 epoch total loss 1.68001008\n",
      "Trained batch 348 batch loss 1.54481101 epoch total loss 1.67962158\n",
      "Trained batch 349 batch loss 1.56118095 epoch total loss 1.67928207\n",
      "Trained batch 350 batch loss 1.55005264 epoch total loss 1.67891288\n",
      "Trained batch 351 batch loss 1.57962346 epoch total loss 1.67863011\n",
      "Trained batch 352 batch loss 1.52333415 epoch total loss 1.6781888\n",
      "Trained batch 353 batch loss 1.535532 epoch total loss 1.67778468\n",
      "Trained batch 354 batch loss 1.44237339 epoch total loss 1.67711973\n",
      "Trained batch 355 batch loss 1.5510695 epoch total loss 1.67676473\n",
      "Trained batch 356 batch loss 1.5006516 epoch total loss 1.67627\n",
      "Trained batch 357 batch loss 1.63673079 epoch total loss 1.67615926\n",
      "Trained batch 358 batch loss 1.66203141 epoch total loss 1.6761198\n",
      "Trained batch 359 batch loss 1.49164426 epoch total loss 1.67560601\n",
      "Trained batch 360 batch loss 1.53944099 epoch total loss 1.67522764\n",
      "Trained batch 361 batch loss 1.57587123 epoch total loss 1.67495251\n",
      "Trained batch 362 batch loss 1.63868535 epoch total loss 1.67485225\n",
      "Trained batch 363 batch loss 1.63015306 epoch total loss 1.67472899\n",
      "Trained batch 364 batch loss 1.57985592 epoch total loss 1.67446828\n",
      "Trained batch 365 batch loss 1.51287973 epoch total loss 1.67402565\n",
      "Trained batch 366 batch loss 1.55409956 epoch total loss 1.67369783\n",
      "Trained batch 367 batch loss 1.50972462 epoch total loss 1.67325103\n",
      "Trained batch 368 batch loss 1.49569988 epoch total loss 1.67276859\n",
      "Trained batch 369 batch loss 1.55748487 epoch total loss 1.67245626\n",
      "Trained batch 370 batch loss 1.63084161 epoch total loss 1.67234385\n",
      "Trained batch 371 batch loss 1.58673513 epoch total loss 1.67211306\n",
      "Trained batch 372 batch loss 1.63983345 epoch total loss 1.67202628\n",
      "Trained batch 373 batch loss 1.65512323 epoch total loss 1.67198098\n",
      "Trained batch 374 batch loss 1.6167798 epoch total loss 1.6718334\n",
      "Trained batch 375 batch loss 1.61283898 epoch total loss 1.67167616\n",
      "Trained batch 376 batch loss 1.62784505 epoch total loss 1.67155957\n",
      "Trained batch 377 batch loss 1.63070834 epoch total loss 1.67145133\n",
      "Trained batch 378 batch loss 1.63203537 epoch total loss 1.67134702\n",
      "Trained batch 379 batch loss 1.60769486 epoch total loss 1.67117894\n",
      "Trained batch 380 batch loss 1.60200465 epoch total loss 1.6709969\n",
      "Trained batch 381 batch loss 1.60000706 epoch total loss 1.6708107\n",
      "Trained batch 382 batch loss 1.58071136 epoch total loss 1.67057478\n",
      "Trained batch 383 batch loss 1.60307 epoch total loss 1.67039847\n",
      "Trained batch 384 batch loss 1.62135696 epoch total loss 1.6702708\n",
      "Trained batch 385 batch loss 1.5185076 epoch total loss 1.66987658\n",
      "Trained batch 386 batch loss 1.62956572 epoch total loss 1.66977215\n",
      "Trained batch 387 batch loss 1.61443734 epoch total loss 1.66962922\n",
      "Trained batch 388 batch loss 1.61297989 epoch total loss 1.66948318\n",
      "Trained batch 389 batch loss 1.58169353 epoch total loss 1.6692574\n",
      "Trained batch 390 batch loss 1.60478163 epoch total loss 1.66909206\n",
      "Trained batch 391 batch loss 1.61945415 epoch total loss 1.6689651\n",
      "Trained batch 392 batch loss 1.47411 epoch total loss 1.66846812\n",
      "Trained batch 393 batch loss 1.60680282 epoch total loss 1.66831124\n",
      "Trained batch 394 batch loss 1.57427931 epoch total loss 1.66807258\n",
      "Trained batch 395 batch loss 1.59188628 epoch total loss 1.66787958\n",
      "Trained batch 396 batch loss 1.57717085 epoch total loss 1.66765046\n",
      "Trained batch 397 batch loss 1.51996088 epoch total loss 1.66727841\n",
      "Trained batch 398 batch loss 1.51781535 epoch total loss 1.6669029\n",
      "Trained batch 399 batch loss 1.57606244 epoch total loss 1.66667521\n",
      "Trained batch 400 batch loss 1.45256221 epoch total loss 1.66614\n",
      "Trained batch 401 batch loss 1.47374034 epoch total loss 1.66566026\n",
      "Trained batch 402 batch loss 1.4645834 epoch total loss 1.66516006\n",
      "Trained batch 403 batch loss 1.4541713 epoch total loss 1.66463649\n",
      "Trained batch 404 batch loss 1.41139972 epoch total loss 1.66400957\n",
      "Trained batch 405 batch loss 1.5942843 epoch total loss 1.66383755\n",
      "Trained batch 406 batch loss 1.54159391 epoch total loss 1.66353631\n",
      "Trained batch 407 batch loss 1.52648151 epoch total loss 1.66319966\n",
      "Trained batch 408 batch loss 1.5759455 epoch total loss 1.66298568\n",
      "Trained batch 409 batch loss 1.63813841 epoch total loss 1.66292489\n",
      "Trained batch 410 batch loss 1.5267756 epoch total loss 1.66259289\n",
      "Trained batch 411 batch loss 1.56721151 epoch total loss 1.66236079\n",
      "Trained batch 412 batch loss 1.512182 epoch total loss 1.66199636\n",
      "Trained batch 413 batch loss 1.56858909 epoch total loss 1.66177022\n",
      "Trained batch 414 batch loss 1.52364326 epoch total loss 1.66143656\n",
      "Trained batch 415 batch loss 1.56951094 epoch total loss 1.66121507\n",
      "Trained batch 416 batch loss 1.52502608 epoch total loss 1.6608876\n",
      "Trained batch 417 batch loss 1.57576263 epoch total loss 1.66068351\n",
      "Trained batch 418 batch loss 1.57388377 epoch total loss 1.66047585\n",
      "Trained batch 419 batch loss 1.50336385 epoch total loss 1.66010094\n",
      "Trained batch 420 batch loss 1.44310701 epoch total loss 1.65958428\n",
      "Trained batch 421 batch loss 1.28313398 epoch total loss 1.65869009\n",
      "Trained batch 422 batch loss 1.26922965 epoch total loss 1.65776718\n",
      "Trained batch 423 batch loss 1.42080426 epoch total loss 1.65720689\n",
      "Trained batch 424 batch loss 1.65945125 epoch total loss 1.65721214\n",
      "Trained batch 425 batch loss 1.6144557 epoch total loss 1.65711153\n",
      "Trained batch 426 batch loss 1.52388132 epoch total loss 1.65679872\n",
      "Trained batch 427 batch loss 1.55701768 epoch total loss 1.65656507\n",
      "Trained batch 428 batch loss 1.64139318 epoch total loss 1.65652966\n",
      "Trained batch 429 batch loss 1.48897409 epoch total loss 1.65613902\n",
      "Trained batch 430 batch loss 1.42078567 epoch total loss 1.65559173\n",
      "Trained batch 431 batch loss 1.50632405 epoch total loss 1.65524542\n",
      "Trained batch 432 batch loss 1.48309553 epoch total loss 1.65484691\n",
      "Trained batch 433 batch loss 1.47471905 epoch total loss 1.65443099\n",
      "Trained batch 434 batch loss 1.5362227 epoch total loss 1.65415847\n",
      "Trained batch 435 batch loss 1.60284519 epoch total loss 1.65404058\n",
      "Trained batch 436 batch loss 1.626683 epoch total loss 1.65397787\n",
      "Trained batch 437 batch loss 1.64117742 epoch total loss 1.65394855\n",
      "Trained batch 438 batch loss 1.59327054 epoch total loss 1.65381\n",
      "Trained batch 439 batch loss 1.57564449 epoch total loss 1.65363193\n",
      "Trained batch 440 batch loss 1.55944669 epoch total loss 1.65341783\n",
      "Trained batch 441 batch loss 1.56034565 epoch total loss 1.65320683\n",
      "Trained batch 442 batch loss 1.53055978 epoch total loss 1.65292943\n",
      "Trained batch 443 batch loss 1.52498412 epoch total loss 1.65264046\n",
      "Trained batch 444 batch loss 1.52443421 epoch total loss 1.65235174\n",
      "Trained batch 445 batch loss 1.44790888 epoch total loss 1.65189242\n",
      "Trained batch 446 batch loss 1.53962588 epoch total loss 1.65164065\n",
      "Trained batch 447 batch loss 1.57324755 epoch total loss 1.65146518\n",
      "Trained batch 448 batch loss 1.50085187 epoch total loss 1.65112901\n",
      "Trained batch 449 batch loss 1.54099298 epoch total loss 1.65088379\n",
      "Trained batch 450 batch loss 1.50121713 epoch total loss 1.6505512\n",
      "Trained batch 451 batch loss 1.40154576 epoch total loss 1.64999914\n",
      "Trained batch 452 batch loss 1.50031972 epoch total loss 1.64966798\n",
      "Trained batch 453 batch loss 1.5483402 epoch total loss 1.64944422\n",
      "Trained batch 454 batch loss 1.49051869 epoch total loss 1.64909422\n",
      "Trained batch 455 batch loss 1.60900545 epoch total loss 1.64900613\n",
      "Trained batch 456 batch loss 1.5699563 epoch total loss 1.6488328\n",
      "Trained batch 457 batch loss 1.53547788 epoch total loss 1.64858472\n",
      "Trained batch 458 batch loss 1.58652937 epoch total loss 1.64844918\n",
      "Trained batch 459 batch loss 1.53549266 epoch total loss 1.64820325\n",
      "Trained batch 460 batch loss 1.55439854 epoch total loss 1.64799929\n",
      "Trained batch 461 batch loss 1.54564786 epoch total loss 1.6477772\n",
      "Trained batch 462 batch loss 1.54974258 epoch total loss 1.64756501\n",
      "Trained batch 463 batch loss 1.57823515 epoch total loss 1.64741528\n",
      "Trained batch 464 batch loss 1.53978431 epoch total loss 1.64718342\n",
      "Trained batch 465 batch loss 1.56545568 epoch total loss 1.64700758\n",
      "Trained batch 466 batch loss 1.58503616 epoch total loss 1.64687455\n",
      "Trained batch 467 batch loss 1.51386905 epoch total loss 1.64658976\n",
      "Trained batch 468 batch loss 1.50552547 epoch total loss 1.64628839\n",
      "Trained batch 469 batch loss 1.62124443 epoch total loss 1.64623487\n",
      "Trained batch 470 batch loss 1.65053761 epoch total loss 1.64624405\n",
      "Trained batch 471 batch loss 1.60670269 epoch total loss 1.64616\n",
      "Trained batch 472 batch loss 1.69863486 epoch total loss 1.64627111\n",
      "Trained batch 473 batch loss 1.73910475 epoch total loss 1.64646733\n",
      "Trained batch 474 batch loss 1.68165207 epoch total loss 1.6465416\n",
      "Trained batch 475 batch loss 1.68219531 epoch total loss 1.64661658\n",
      "Trained batch 476 batch loss 1.61931252 epoch total loss 1.64655924\n",
      "Trained batch 477 batch loss 1.52002728 epoch total loss 1.646294\n",
      "Trained batch 478 batch loss 1.56609607 epoch total loss 1.64612615\n",
      "Trained batch 479 batch loss 1.6546526 epoch total loss 1.64614403\n",
      "Trained batch 480 batch loss 1.64412498 epoch total loss 1.64613974\n",
      "Trained batch 481 batch loss 1.57377112 epoch total loss 1.64598942\n",
      "Trained batch 482 batch loss 1.60070777 epoch total loss 1.64589548\n",
      "Trained batch 483 batch loss 1.59503233 epoch total loss 1.6457901\n",
      "Trained batch 484 batch loss 1.60806227 epoch total loss 1.64571214\n",
      "Trained batch 485 batch loss 1.62470329 epoch total loss 1.64566875\n",
      "Trained batch 486 batch loss 1.60048556 epoch total loss 1.64557576\n",
      "Trained batch 487 batch loss 1.61063659 epoch total loss 1.645504\n",
      "Trained batch 488 batch loss 1.60550237 epoch total loss 1.6454221\n",
      "Trained batch 489 batch loss 1.58325744 epoch total loss 1.64529502\n",
      "Trained batch 490 batch loss 1.6367178 epoch total loss 1.6452775\n",
      "Trained batch 491 batch loss 1.59487379 epoch total loss 1.64517474\n",
      "Trained batch 492 batch loss 1.60977602 epoch total loss 1.64510286\n",
      "Trained batch 493 batch loss 1.61004639 epoch total loss 1.64503181\n",
      "Trained batch 494 batch loss 1.58335674 epoch total loss 1.644907\n",
      "Trained batch 495 batch loss 1.58819675 epoch total loss 1.64479244\n",
      "Trained batch 496 batch loss 1.52549338 epoch total loss 1.64455187\n",
      "Trained batch 497 batch loss 1.45384514 epoch total loss 1.64416826\n",
      "Trained batch 498 batch loss 1.36823857 epoch total loss 1.64361417\n",
      "Trained batch 499 batch loss 1.39091945 epoch total loss 1.64310777\n",
      "Trained batch 500 batch loss 1.28398156 epoch total loss 1.64238954\n",
      "Trained batch 501 batch loss 1.48442566 epoch total loss 1.64207423\n",
      "Trained batch 502 batch loss 1.58041406 epoch total loss 1.64195144\n",
      "Trained batch 503 batch loss 1.60767102 epoch total loss 1.64188337\n",
      "Trained batch 504 batch loss 1.64468551 epoch total loss 1.64188898\n",
      "Trained batch 505 batch loss 1.58089066 epoch total loss 1.6417681\n",
      "Trained batch 506 batch loss 1.71081066 epoch total loss 1.64190459\n",
      "Trained batch 507 batch loss 1.5941025 epoch total loss 1.6418103\n",
      "Trained batch 508 batch loss 1.59599924 epoch total loss 1.64172018\n",
      "Trained batch 509 batch loss 1.68613398 epoch total loss 1.64180744\n",
      "Trained batch 510 batch loss 1.62448096 epoch total loss 1.64177346\n",
      "Trained batch 511 batch loss 1.6073209 epoch total loss 1.64170599\n",
      "Trained batch 512 batch loss 1.5380218 epoch total loss 1.64150345\n",
      "Trained batch 513 batch loss 1.45654893 epoch total loss 1.64114296\n",
      "Trained batch 514 batch loss 1.45050716 epoch total loss 1.64077199\n",
      "Trained batch 515 batch loss 1.45235503 epoch total loss 1.64040613\n",
      "Trained batch 516 batch loss 1.6449585 epoch total loss 1.64041495\n",
      "Trained batch 517 batch loss 1.52363896 epoch total loss 1.64018905\n",
      "Trained batch 518 batch loss 1.58717251 epoch total loss 1.64008665\n",
      "Trained batch 519 batch loss 1.67221475 epoch total loss 1.64014864\n",
      "Trained batch 520 batch loss 1.53513646 epoch total loss 1.6399467\n",
      "Trained batch 521 batch loss 1.61697912 epoch total loss 1.63990271\n",
      "Trained batch 522 batch loss 1.56278 epoch total loss 1.63975501\n",
      "Trained batch 523 batch loss 1.44913363 epoch total loss 1.63939047\n",
      "Trained batch 524 batch loss 1.25686479 epoch total loss 1.63866043\n",
      "Trained batch 525 batch loss 1.46296036 epoch total loss 1.63832581\n",
      "Trained batch 526 batch loss 1.59323478 epoch total loss 1.6382401\n",
      "Trained batch 527 batch loss 1.58813334 epoch total loss 1.63814497\n",
      "Trained batch 528 batch loss 1.59001946 epoch total loss 1.63805389\n",
      "Trained batch 529 batch loss 1.49861479 epoch total loss 1.63779032\n",
      "Trained batch 530 batch loss 1.55429351 epoch total loss 1.63763273\n",
      "Trained batch 531 batch loss 1.5529809 epoch total loss 1.63747334\n",
      "Trained batch 532 batch loss 1.54657292 epoch total loss 1.63730252\n",
      "Trained batch 533 batch loss 1.36160743 epoch total loss 1.63678527\n",
      "Trained batch 534 batch loss 1.53247786 epoch total loss 1.63658988\n",
      "Trained batch 535 batch loss 1.53594828 epoch total loss 1.63640177\n",
      "Trained batch 536 batch loss 1.46476686 epoch total loss 1.6360817\n",
      "Trained batch 537 batch loss 1.56262386 epoch total loss 1.63594484\n",
      "Trained batch 538 batch loss 1.55045688 epoch total loss 1.63578594\n",
      "Trained batch 539 batch loss 1.54369831 epoch total loss 1.63561511\n",
      "Trained batch 540 batch loss 1.5572964 epoch total loss 1.63547015\n",
      "Trained batch 541 batch loss 1.59396231 epoch total loss 1.63539338\n",
      "Trained batch 542 batch loss 1.54758346 epoch total loss 1.63523138\n",
      "Trained batch 543 batch loss 1.57257366 epoch total loss 1.63511598\n",
      "Trained batch 544 batch loss 1.60825896 epoch total loss 1.63506663\n",
      "Trained batch 545 batch loss 1.58389843 epoch total loss 1.63497281\n",
      "Trained batch 546 batch loss 1.5415833 epoch total loss 1.63480175\n",
      "Trained batch 547 batch loss 1.56040108 epoch total loss 1.63466573\n",
      "Trained batch 548 batch loss 1.52959824 epoch total loss 1.63447404\n",
      "Trained batch 549 batch loss 1.61928499 epoch total loss 1.63444638\n",
      "Trained batch 550 batch loss 1.60304976 epoch total loss 1.63438916\n",
      "Trained batch 551 batch loss 1.54705811 epoch total loss 1.63423073\n",
      "Trained batch 552 batch loss 1.60413754 epoch total loss 1.63417614\n",
      "Trained batch 553 batch loss 1.6551919 epoch total loss 1.63421416\n",
      "Trained batch 554 batch loss 1.54697502 epoch total loss 1.63405681\n",
      "Trained batch 555 batch loss 1.56893849 epoch total loss 1.63393939\n",
      "Trained batch 556 batch loss 1.48312581 epoch total loss 1.63366818\n",
      "Trained batch 557 batch loss 1.54848981 epoch total loss 1.63351524\n",
      "Trained batch 558 batch loss 1.61886835 epoch total loss 1.63348901\n",
      "Trained batch 559 batch loss 1.63916063 epoch total loss 1.63349915\n",
      "Trained batch 560 batch loss 1.53876948 epoch total loss 1.63333\n",
      "Trained batch 561 batch loss 1.5627296 epoch total loss 1.63320422\n",
      "Trained batch 562 batch loss 1.57684469 epoch total loss 1.63310385\n",
      "Trained batch 563 batch loss 1.58969891 epoch total loss 1.63302684\n",
      "Trained batch 564 batch loss 1.65775681 epoch total loss 1.63307071\n",
      "Trained batch 565 batch loss 1.56255031 epoch total loss 1.6329459\n",
      "Trained batch 566 batch loss 1.54510093 epoch total loss 1.63279068\n",
      "Trained batch 567 batch loss 1.57479787 epoch total loss 1.6326884\n",
      "Trained batch 568 batch loss 1.57952225 epoch total loss 1.63259482\n",
      "Trained batch 569 batch loss 1.6482836 epoch total loss 1.63262236\n",
      "Trained batch 570 batch loss 1.58653688 epoch total loss 1.63254154\n",
      "Trained batch 571 batch loss 1.54092717 epoch total loss 1.63238108\n",
      "Trained batch 572 batch loss 1.47836924 epoch total loss 1.63211191\n",
      "Trained batch 573 batch loss 1.58307981 epoch total loss 1.63202631\n",
      "Trained batch 574 batch loss 1.57641518 epoch total loss 1.6319294\n",
      "Trained batch 575 batch loss 1.5365262 epoch total loss 1.63176346\n",
      "Trained batch 576 batch loss 1.45111394 epoch total loss 1.63144982\n",
      "Trained batch 577 batch loss 1.49236608 epoch total loss 1.63120878\n",
      "Trained batch 578 batch loss 1.52706254 epoch total loss 1.63102853\n",
      "Trained batch 579 batch loss 1.55480611 epoch total loss 1.63089693\n",
      "Trained batch 580 batch loss 1.51648951 epoch total loss 1.63069963\n",
      "Trained batch 581 batch loss 1.52916121 epoch total loss 1.63052487\n",
      "Trained batch 582 batch loss 1.53765416 epoch total loss 1.63036537\n",
      "Trained batch 583 batch loss 1.50301254 epoch total loss 1.63014686\n",
      "Trained batch 584 batch loss 1.52334476 epoch total loss 1.62996387\n",
      "Trained batch 585 batch loss 1.52163053 epoch total loss 1.62977874\n",
      "Trained batch 586 batch loss 1.4647342 epoch total loss 1.62949705\n",
      "Trained batch 587 batch loss 1.61890399 epoch total loss 1.62947893\n",
      "Trained batch 588 batch loss 1.60271299 epoch total loss 1.62943351\n",
      "Trained batch 589 batch loss 1.49779046 epoch total loss 1.62921\n",
      "Trained batch 590 batch loss 1.66162169 epoch total loss 1.62926495\n",
      "Trained batch 591 batch loss 1.72047186 epoch total loss 1.62941921\n",
      "Trained batch 592 batch loss 1.56744695 epoch total loss 1.62931454\n",
      "Trained batch 593 batch loss 1.46652913 epoch total loss 1.62904\n",
      "Trained batch 594 batch loss 1.52032542 epoch total loss 1.62885702\n",
      "Trained batch 595 batch loss 1.30713463 epoch total loss 1.62831628\n",
      "Trained batch 596 batch loss 1.41984272 epoch total loss 1.62796652\n",
      "Trained batch 597 batch loss 1.41744041 epoch total loss 1.6276139\n",
      "Trained batch 598 batch loss 1.39463031 epoch total loss 1.62722433\n",
      "Trained batch 599 batch loss 1.22582138 epoch total loss 1.62655425\n",
      "Trained batch 600 batch loss 1.31972909 epoch total loss 1.62604284\n",
      "Trained batch 601 batch loss 1.34377265 epoch total loss 1.62557304\n",
      "Trained batch 602 batch loss 1.48436522 epoch total loss 1.62533855\n",
      "Trained batch 603 batch loss 1.49197042 epoch total loss 1.6251173\n",
      "Trained batch 604 batch loss 1.59797573 epoch total loss 1.62507236\n",
      "Trained batch 605 batch loss 1.56902015 epoch total loss 1.62497973\n",
      "Trained batch 606 batch loss 1.6620332 epoch total loss 1.62504089\n",
      "Trained batch 607 batch loss 1.637115 epoch total loss 1.62506068\n",
      "Trained batch 608 batch loss 1.50680578 epoch total loss 1.62486625\n",
      "Trained batch 609 batch loss 1.61222172 epoch total loss 1.6248455\n",
      "Trained batch 610 batch loss 1.51850033 epoch total loss 1.62467122\n",
      "Trained batch 611 batch loss 1.58928263 epoch total loss 1.62461329\n",
      "Trained batch 612 batch loss 1.46640992 epoch total loss 1.62435484\n",
      "Trained batch 613 batch loss 1.50722015 epoch total loss 1.62416375\n",
      "Trained batch 614 batch loss 1.49480295 epoch total loss 1.6239531\n",
      "Trained batch 615 batch loss 1.56921113 epoch total loss 1.62386405\n",
      "Trained batch 616 batch loss 1.49994779 epoch total loss 1.62366283\n",
      "Trained batch 617 batch loss 1.48130476 epoch total loss 1.62343216\n",
      "Trained batch 618 batch loss 1.53759694 epoch total loss 1.62329328\n",
      "Trained batch 619 batch loss 1.47190011 epoch total loss 1.62304878\n",
      "Trained batch 620 batch loss 1.47033679 epoch total loss 1.6228025\n",
      "Trained batch 621 batch loss 1.48730874 epoch total loss 1.62258422\n",
      "Trained batch 622 batch loss 1.47457552 epoch total loss 1.62234628\n",
      "Trained batch 623 batch loss 1.50255883 epoch total loss 1.622154\n",
      "Trained batch 624 batch loss 1.64713871 epoch total loss 1.62219405\n",
      "Trained batch 625 batch loss 1.67547846 epoch total loss 1.62227929\n",
      "Trained batch 626 batch loss 1.68103147 epoch total loss 1.6223731\n",
      "Trained batch 627 batch loss 1.58723664 epoch total loss 1.62231708\n",
      "Trained batch 628 batch loss 1.4703393 epoch total loss 1.62207508\n",
      "Trained batch 629 batch loss 1.36261964 epoch total loss 1.62166262\n",
      "Trained batch 630 batch loss 1.28124452 epoch total loss 1.62112224\n",
      "Trained batch 631 batch loss 1.30381632 epoch total loss 1.62061942\n",
      "Trained batch 632 batch loss 1.4311974 epoch total loss 1.6203196\n",
      "Trained batch 633 batch loss 1.5764904 epoch total loss 1.62025046\n",
      "Trained batch 634 batch loss 1.68257248 epoch total loss 1.62034881\n",
      "Trained batch 635 batch loss 1.73667836 epoch total loss 1.62053204\n",
      "Trained batch 636 batch loss 1.44179392 epoch total loss 1.62025094\n",
      "Trained batch 637 batch loss 1.41673815 epoch total loss 1.61993146\n",
      "Trained batch 638 batch loss 1.63719785 epoch total loss 1.61995852\n",
      "Trained batch 639 batch loss 1.62498558 epoch total loss 1.61996651\n",
      "Trained batch 640 batch loss 1.58959973 epoch total loss 1.61991906\n",
      "Trained batch 641 batch loss 1.57104659 epoch total loss 1.61984277\n",
      "Trained batch 642 batch loss 1.60802 epoch total loss 1.61982441\n",
      "Trained batch 643 batch loss 1.58105969 epoch total loss 1.61976409\n",
      "Trained batch 644 batch loss 1.52249169 epoch total loss 1.61961293\n",
      "Trained batch 645 batch loss 1.56477451 epoch total loss 1.61952806\n",
      "Trained batch 646 batch loss 1.44490397 epoch total loss 1.61925781\n",
      "Trained batch 647 batch loss 1.539289 epoch total loss 1.61913419\n",
      "Trained batch 648 batch loss 1.5426321 epoch total loss 1.61901605\n",
      "Trained batch 649 batch loss 1.57249606 epoch total loss 1.61894441\n",
      "Trained batch 650 batch loss 1.32045567 epoch total loss 1.61848521\n",
      "Trained batch 651 batch loss 1.46580124 epoch total loss 1.61825073\n",
      "Trained batch 652 batch loss 1.46425259 epoch total loss 1.61801445\n",
      "Trained batch 653 batch loss 1.53262067 epoch total loss 1.61788368\n",
      "Trained batch 654 batch loss 1.51628447 epoch total loss 1.61772823\n",
      "Trained batch 655 batch loss 1.47930348 epoch total loss 1.61751676\n",
      "Trained batch 656 batch loss 1.49566865 epoch total loss 1.61733115\n",
      "Trained batch 657 batch loss 1.60310853 epoch total loss 1.61730957\n",
      "Trained batch 658 batch loss 1.61171579 epoch total loss 1.61730099\n",
      "Trained batch 659 batch loss 1.54783249 epoch total loss 1.61719561\n",
      "Trained batch 660 batch loss 1.53849864 epoch total loss 1.6170764\n",
      "Trained batch 661 batch loss 1.55346668 epoch total loss 1.61698008\n",
      "Trained batch 662 batch loss 1.44473505 epoch total loss 1.61671984\n",
      "Trained batch 663 batch loss 1.39464223 epoch total loss 1.61638498\n",
      "Trained batch 664 batch loss 1.31753922 epoch total loss 1.61593485\n",
      "Trained batch 665 batch loss 1.37116122 epoch total loss 1.61556685\n",
      "Trained batch 666 batch loss 1.49563169 epoch total loss 1.61538672\n",
      "Trained batch 667 batch loss 1.5281812 epoch total loss 1.61525595\n",
      "Trained batch 668 batch loss 1.49104428 epoch total loss 1.6150701\n",
      "Trained batch 669 batch loss 1.45434332 epoch total loss 1.6148299\n",
      "Trained batch 670 batch loss 1.47812581 epoch total loss 1.61462581\n",
      "Trained batch 671 batch loss 1.47094965 epoch total loss 1.61441171\n",
      "Trained batch 672 batch loss 1.46218252 epoch total loss 1.61418509\n",
      "Trained batch 673 batch loss 1.59377825 epoch total loss 1.61415482\n",
      "Trained batch 674 batch loss 1.50167465 epoch total loss 1.61398792\n",
      "Trained batch 675 batch loss 1.54708028 epoch total loss 1.61388886\n",
      "Trained batch 676 batch loss 1.550493 epoch total loss 1.61379516\n",
      "Trained batch 677 batch loss 1.62646103 epoch total loss 1.61381388\n",
      "Trained batch 678 batch loss 1.58469558 epoch total loss 1.61377096\n",
      "Trained batch 679 batch loss 1.54736304 epoch total loss 1.61367321\n",
      "Trained batch 680 batch loss 1.59505177 epoch total loss 1.61364579\n",
      "Trained batch 681 batch loss 1.42092824 epoch total loss 1.61336279\n",
      "Trained batch 682 batch loss 1.41048717 epoch total loss 1.61306536\n",
      "Trained batch 683 batch loss 1.34574258 epoch total loss 1.61267388\n",
      "Trained batch 684 batch loss 1.41384757 epoch total loss 1.61238325\n",
      "Trained batch 685 batch loss 1.3342917 epoch total loss 1.61197734\n",
      "Trained batch 686 batch loss 1.30428934 epoch total loss 1.61152887\n",
      "Trained batch 687 batch loss 1.28698289 epoch total loss 1.61105645\n",
      "Trained batch 688 batch loss 1.19743693 epoch total loss 1.61045516\n",
      "Trained batch 689 batch loss 1.49134135 epoch total loss 1.6102823\n",
      "Trained batch 690 batch loss 1.48914957 epoch total loss 1.61010671\n",
      "Trained batch 691 batch loss 1.57873011 epoch total loss 1.61006129\n",
      "Trained batch 692 batch loss 1.55457878 epoch total loss 1.60998106\n",
      "Trained batch 693 batch loss 1.49292421 epoch total loss 1.60981214\n",
      "Trained batch 694 batch loss 1.5641644 epoch total loss 1.60974646\n",
      "Trained batch 695 batch loss 1.45838857 epoch total loss 1.60952866\n",
      "Trained batch 696 batch loss 1.43776715 epoch total loss 1.6092819\n",
      "Trained batch 697 batch loss 1.46530521 epoch total loss 1.60907531\n",
      "Trained batch 698 batch loss 1.35231972 epoch total loss 1.60870743\n",
      "Trained batch 699 batch loss 1.3807137 epoch total loss 1.60838127\n",
      "Trained batch 700 batch loss 1.5817821 epoch total loss 1.60834336\n",
      "Trained batch 701 batch loss 1.62653875 epoch total loss 1.60836935\n",
      "Trained batch 702 batch loss 1.65136576 epoch total loss 1.60843062\n",
      "Trained batch 703 batch loss 1.54726589 epoch total loss 1.6083436\n",
      "Trained batch 704 batch loss 1.5453831 epoch total loss 1.60825419\n",
      "Trained batch 705 batch loss 1.49738765 epoch total loss 1.60809696\n",
      "Trained batch 706 batch loss 1.47872615 epoch total loss 1.60791373\n",
      "Trained batch 707 batch loss 1.51812935 epoch total loss 1.60778689\n",
      "Trained batch 708 batch loss 1.56690228 epoch total loss 1.60772908\n",
      "Trained batch 709 batch loss 1.53151798 epoch total loss 1.60762155\n",
      "Trained batch 710 batch loss 1.54107571 epoch total loss 1.60752773\n",
      "Trained batch 711 batch loss 1.55378103 epoch total loss 1.60745227\n",
      "Trained batch 712 batch loss 1.5763762 epoch total loss 1.60740864\n",
      "Trained batch 713 batch loss 1.53510869 epoch total loss 1.60730731\n",
      "Trained batch 714 batch loss 1.46639812 epoch total loss 1.60711\n",
      "Trained batch 715 batch loss 1.49214077 epoch total loss 1.60694933\n",
      "Trained batch 716 batch loss 1.54016209 epoch total loss 1.60685599\n",
      "Trained batch 717 batch loss 1.53477 epoch total loss 1.6067555\n",
      "Trained batch 718 batch loss 1.49162769 epoch total loss 1.60659504\n",
      "Trained batch 719 batch loss 1.51253271 epoch total loss 1.60646439\n",
      "Trained batch 720 batch loss 1.5524019 epoch total loss 1.60638916\n",
      "Trained batch 721 batch loss 1.57036209 epoch total loss 1.60633922\n",
      "Trained batch 722 batch loss 1.55051327 epoch total loss 1.60626185\n",
      "Trained batch 723 batch loss 1.53047872 epoch total loss 1.60615706\n",
      "Trained batch 724 batch loss 1.3828851 epoch total loss 1.60584879\n",
      "Trained batch 725 batch loss 1.44805777 epoch total loss 1.60563111\n",
      "Trained batch 726 batch loss 1.47350073 epoch total loss 1.60544908\n",
      "Trained batch 727 batch loss 1.46919 epoch total loss 1.60526168\n",
      "Trained batch 728 batch loss 1.55756581 epoch total loss 1.60519624\n",
      "Trained batch 729 batch loss 1.5920589 epoch total loss 1.60517824\n",
      "Trained batch 730 batch loss 1.68315768 epoch total loss 1.60528493\n",
      "Trained batch 731 batch loss 1.64978814 epoch total loss 1.60534585\n",
      "Trained batch 732 batch loss 1.69127393 epoch total loss 1.60546327\n",
      "Trained batch 733 batch loss 1.45592117 epoch total loss 1.6052593\n",
      "Trained batch 734 batch loss 1.37671399 epoch total loss 1.60494792\n",
      "Trained batch 735 batch loss 1.38319707 epoch total loss 1.60464609\n",
      "Trained batch 736 batch loss 1.25246418 epoch total loss 1.60416758\n",
      "Trained batch 737 batch loss 1.35549486 epoch total loss 1.60383022\n",
      "Trained batch 738 batch loss 1.37622356 epoch total loss 1.6035217\n",
      "Trained batch 739 batch loss 1.37131262 epoch total loss 1.60320759\n",
      "Trained batch 740 batch loss 1.57875264 epoch total loss 1.60317445\n",
      "Trained batch 741 batch loss 1.56231785 epoch total loss 1.60311937\n",
      "Trained batch 742 batch loss 1.55438876 epoch total loss 1.60305381\n",
      "Trained batch 743 batch loss 1.63020396 epoch total loss 1.60309041\n",
      "Trained batch 744 batch loss 1.61830664 epoch total loss 1.60311091\n",
      "Trained batch 745 batch loss 1.43095863 epoch total loss 1.60287976\n",
      "Trained batch 746 batch loss 1.49094486 epoch total loss 1.60272968\n",
      "Trained batch 747 batch loss 1.4091692 epoch total loss 1.60247064\n",
      "Trained batch 748 batch loss 1.48622322 epoch total loss 1.60231519\n",
      "Trained batch 749 batch loss 1.54757643 epoch total loss 1.60224211\n",
      "Trained batch 750 batch loss 1.558 epoch total loss 1.6021831\n",
      "Trained batch 751 batch loss 1.61895609 epoch total loss 1.6022054\n",
      "Trained batch 752 batch loss 1.62333488 epoch total loss 1.60223341\n",
      "Trained batch 753 batch loss 1.64448309 epoch total loss 1.60228956\n",
      "Trained batch 754 batch loss 1.6650598 epoch total loss 1.60237277\n",
      "Trained batch 755 batch loss 1.56860042 epoch total loss 1.60232806\n",
      "Trained batch 756 batch loss 1.56532717 epoch total loss 1.60227907\n",
      "Trained batch 757 batch loss 1.54205394 epoch total loss 1.60219967\n",
      "Trained batch 758 batch loss 1.5709976 epoch total loss 1.60215855\n",
      "Trained batch 759 batch loss 1.5146929 epoch total loss 1.60204327\n",
      "Trained batch 760 batch loss 1.52211618 epoch total loss 1.60193801\n",
      "Trained batch 761 batch loss 1.53771627 epoch total loss 1.60185361\n",
      "Trained batch 762 batch loss 1.56640065 epoch total loss 1.60180712\n",
      "Trained batch 763 batch loss 1.55280328 epoch total loss 1.60174298\n",
      "Trained batch 764 batch loss 1.55173528 epoch total loss 1.60167754\n",
      "Trained batch 765 batch loss 1.54249859 epoch total loss 1.60160017\n",
      "Trained batch 766 batch loss 1.51525712 epoch total loss 1.6014874\n",
      "Trained batch 767 batch loss 1.5009073 epoch total loss 1.60135627\n",
      "Trained batch 768 batch loss 1.514961 epoch total loss 1.60124385\n",
      "Trained batch 769 batch loss 1.54135823 epoch total loss 1.60116601\n",
      "Trained batch 770 batch loss 1.46886694 epoch total loss 1.60099411\n",
      "Trained batch 771 batch loss 1.47885156 epoch total loss 1.6008358\n",
      "Trained batch 772 batch loss 1.44248652 epoch total loss 1.60063064\n",
      "Trained batch 773 batch loss 1.55422282 epoch total loss 1.60057068\n",
      "Trained batch 774 batch loss 1.54898417 epoch total loss 1.60050392\n",
      "Trained batch 775 batch loss 1.54333925 epoch total loss 1.60043013\n",
      "Trained batch 776 batch loss 1.54765546 epoch total loss 1.60036206\n",
      "Trained batch 777 batch loss 1.59806728 epoch total loss 1.60035908\n",
      "Trained batch 778 batch loss 1.59034765 epoch total loss 1.60034621\n",
      "Trained batch 779 batch loss 1.59449458 epoch total loss 1.6003387\n",
      "Trained batch 780 batch loss 1.48451853 epoch total loss 1.60019016\n",
      "Trained batch 781 batch loss 1.41447806 epoch total loss 1.59995234\n",
      "Trained batch 782 batch loss 1.50429738 epoch total loss 1.59982991\n",
      "Trained batch 783 batch loss 1.46885419 epoch total loss 1.59966266\n",
      "Trained batch 784 batch loss 1.45404625 epoch total loss 1.59947705\n",
      "Trained batch 785 batch loss 1.53306854 epoch total loss 1.59939241\n",
      "Trained batch 786 batch loss 1.62512112 epoch total loss 1.5994252\n",
      "Trained batch 787 batch loss 1.58520627 epoch total loss 1.59940708\n",
      "Trained batch 788 batch loss 1.53887331 epoch total loss 1.59933019\n",
      "Trained batch 789 batch loss 1.49648488 epoch total loss 1.59919989\n",
      "Trained batch 790 batch loss 1.49508595 epoch total loss 1.59906805\n",
      "Trained batch 791 batch loss 1.62025595 epoch total loss 1.59909487\n",
      "Trained batch 792 batch loss 1.56406248 epoch total loss 1.59905064\n",
      "Trained batch 793 batch loss 1.44430947 epoch total loss 1.59885561\n",
      "Trained batch 794 batch loss 1.49586391 epoch total loss 1.5987258\n",
      "Trained batch 795 batch loss 1.4683311 epoch total loss 1.59856188\n",
      "Trained batch 796 batch loss 1.44588423 epoch total loss 1.59837008\n",
      "Trained batch 797 batch loss 1.46689057 epoch total loss 1.59820521\n",
      "Trained batch 798 batch loss 1.59943581 epoch total loss 1.59820676\n",
      "Trained batch 799 batch loss 1.46499419 epoch total loss 1.59804\n",
      "Trained batch 800 batch loss 1.5319556 epoch total loss 1.59795749\n",
      "Trained batch 801 batch loss 1.40118337 epoch total loss 1.59771168\n",
      "Trained batch 802 batch loss 1.43400323 epoch total loss 1.5975076\n",
      "Trained batch 803 batch loss 1.5132 epoch total loss 1.59740257\n",
      "Trained batch 804 batch loss 1.54334497 epoch total loss 1.59733534\n",
      "Trained batch 805 batch loss 1.67337632 epoch total loss 1.59742975\n",
      "Trained batch 806 batch loss 1.6040616 epoch total loss 1.59743786\n",
      "Trained batch 807 batch loss 1.68620443 epoch total loss 1.59754777\n",
      "Trained batch 808 batch loss 1.57985091 epoch total loss 1.59752584\n",
      "Trained batch 809 batch loss 1.55532491 epoch total loss 1.59747362\n",
      "Trained batch 810 batch loss 1.43420196 epoch total loss 1.59727216\n",
      "Trained batch 811 batch loss 1.50640655 epoch total loss 1.59716\n",
      "Trained batch 812 batch loss 1.55086374 epoch total loss 1.597103\n",
      "Trained batch 813 batch loss 1.59124041 epoch total loss 1.59709573\n",
      "Trained batch 814 batch loss 1.46454167 epoch total loss 1.59693301\n",
      "Trained batch 815 batch loss 1.46559882 epoch total loss 1.59677184\n",
      "Trained batch 816 batch loss 1.48653018 epoch total loss 1.59663677\n",
      "Trained batch 817 batch loss 1.46516871 epoch total loss 1.59647584\n",
      "Trained batch 818 batch loss 1.5667789 epoch total loss 1.5964396\n",
      "Trained batch 819 batch loss 1.69849968 epoch total loss 1.59656417\n",
      "Trained batch 820 batch loss 1.63815141 epoch total loss 1.59661496\n",
      "Trained batch 821 batch loss 1.60378492 epoch total loss 1.59662366\n",
      "Trained batch 822 batch loss 1.54804182 epoch total loss 1.59656465\n",
      "Trained batch 823 batch loss 1.64025068 epoch total loss 1.5966177\n",
      "Trained batch 824 batch loss 1.68262446 epoch total loss 1.59672201\n",
      "Trained batch 825 batch loss 1.52331865 epoch total loss 1.59663308\n",
      "Trained batch 826 batch loss 1.53171349 epoch total loss 1.59655452\n",
      "Trained batch 827 batch loss 1.55706644 epoch total loss 1.59650671\n",
      "Trained batch 828 batch loss 1.40842414 epoch total loss 1.59627962\n",
      "Trained batch 829 batch loss 1.34569085 epoch total loss 1.59597731\n",
      "Trained batch 830 batch loss 1.42730522 epoch total loss 1.59577405\n",
      "Trained batch 831 batch loss 1.47046661 epoch total loss 1.59562325\n",
      "Trained batch 832 batch loss 1.51421094 epoch total loss 1.59552526\n",
      "Trained batch 833 batch loss 1.49451137 epoch total loss 1.59540403\n",
      "Trained batch 834 batch loss 1.55620766 epoch total loss 1.59535694\n",
      "Trained batch 835 batch loss 1.53736365 epoch total loss 1.59528744\n",
      "Trained batch 836 batch loss 1.49363506 epoch total loss 1.59516597\n",
      "Trained batch 837 batch loss 1.49506116 epoch total loss 1.5950464\n",
      "Trained batch 838 batch loss 1.46330631 epoch total loss 1.59488916\n",
      "Trained batch 839 batch loss 1.39705634 epoch total loss 1.59465337\n",
      "Trained batch 840 batch loss 1.4199121 epoch total loss 1.59444535\n",
      "Trained batch 841 batch loss 1.54527354 epoch total loss 1.59438694\n",
      "Trained batch 842 batch loss 1.53129363 epoch total loss 1.59431195\n",
      "Trained batch 843 batch loss 1.48466897 epoch total loss 1.59418178\n",
      "Trained batch 844 batch loss 1.44604242 epoch total loss 1.5940063\n",
      "Trained batch 845 batch loss 1.45873833 epoch total loss 1.5938462\n",
      "Trained batch 846 batch loss 1.52387595 epoch total loss 1.59376359\n",
      "Trained batch 847 batch loss 1.56546843 epoch total loss 1.59373009\n",
      "Trained batch 848 batch loss 1.40741086 epoch total loss 1.59351051\n",
      "Trained batch 849 batch loss 1.44980657 epoch total loss 1.59334123\n",
      "Trained batch 850 batch loss 1.40881944 epoch total loss 1.59312415\n",
      "Trained batch 851 batch loss 1.42074192 epoch total loss 1.59292161\n",
      "Trained batch 852 batch loss 1.45976782 epoch total loss 1.59276521\n",
      "Trained batch 853 batch loss 1.45085835 epoch total loss 1.5925988\n",
      "Trained batch 854 batch loss 1.4995749 epoch total loss 1.59249\n",
      "Trained batch 855 batch loss 1.4722842 epoch total loss 1.59234941\n",
      "Trained batch 856 batch loss 1.45308673 epoch total loss 1.59218681\n",
      "Trained batch 857 batch loss 1.48641539 epoch total loss 1.59206343\n",
      "Trained batch 858 batch loss 1.53304613 epoch total loss 1.59199464\n",
      "Trained batch 859 batch loss 1.41892076 epoch total loss 1.59179318\n",
      "Trained batch 860 batch loss 1.35739326 epoch total loss 1.59152067\n",
      "Trained batch 861 batch loss 1.41428328 epoch total loss 1.59131479\n",
      "Trained batch 862 batch loss 1.54159653 epoch total loss 1.59125721\n",
      "Trained batch 863 batch loss 1.53899097 epoch total loss 1.59119654\n",
      "Trained batch 864 batch loss 1.59779954 epoch total loss 1.59120417\n",
      "Trained batch 865 batch loss 1.51550245 epoch total loss 1.59111667\n",
      "Trained batch 866 batch loss 1.45742178 epoch total loss 1.59096229\n",
      "Trained batch 867 batch loss 1.39500475 epoch total loss 1.59073627\n",
      "Trained batch 868 batch loss 1.4502306 epoch total loss 1.59057438\n",
      "Trained batch 869 batch loss 1.58826232 epoch total loss 1.59057164\n",
      "Trained batch 870 batch loss 1.60722947 epoch total loss 1.59059072\n",
      "Trained batch 871 batch loss 1.46652269 epoch total loss 1.59044838\n",
      "Trained batch 872 batch loss 1.52194953 epoch total loss 1.59036982\n",
      "Trained batch 873 batch loss 1.51861167 epoch total loss 1.59028757\n",
      "Trained batch 874 batch loss 1.4084183 epoch total loss 1.59007955\n",
      "Trained batch 875 batch loss 1.51059031 epoch total loss 1.58998871\n",
      "Trained batch 876 batch loss 1.49242628 epoch total loss 1.58987737\n",
      "Trained batch 877 batch loss 1.53555179 epoch total loss 1.58981538\n",
      "Trained batch 878 batch loss 1.45946836 epoch total loss 1.58966684\n",
      "Trained batch 879 batch loss 1.44874573 epoch total loss 1.58950651\n",
      "Trained batch 880 batch loss 1.508425 epoch total loss 1.58941448\n",
      "Trained batch 881 batch loss 1.46432209 epoch total loss 1.5892725\n",
      "Trained batch 882 batch loss 1.50258946 epoch total loss 1.58917415\n",
      "Trained batch 883 batch loss 1.53099132 epoch total loss 1.58910823\n",
      "Trained batch 884 batch loss 1.47997212 epoch total loss 1.58898485\n",
      "Trained batch 885 batch loss 1.4573369 epoch total loss 1.58883619\n",
      "Trained batch 886 batch loss 1.43610954 epoch total loss 1.58866382\n",
      "Trained batch 887 batch loss 1.41670799 epoch total loss 1.58847\n",
      "Trained batch 888 batch loss 1.46740937 epoch total loss 1.58833373\n",
      "Trained batch 889 batch loss 1.49399638 epoch total loss 1.58822763\n",
      "Trained batch 890 batch loss 1.47532415 epoch total loss 1.58810079\n",
      "Trained batch 891 batch loss 1.53129053 epoch total loss 1.58803689\n",
      "Trained batch 892 batch loss 1.45477819 epoch total loss 1.58788764\n",
      "Trained batch 893 batch loss 1.41056597 epoch total loss 1.58768904\n",
      "Trained batch 894 batch loss 1.47423565 epoch total loss 1.58756208\n",
      "Trained batch 895 batch loss 1.48371863 epoch total loss 1.58744609\n",
      "Trained batch 896 batch loss 1.46604538 epoch total loss 1.58731067\n",
      "Trained batch 897 batch loss 1.47638094 epoch total loss 1.58718705\n",
      "Trained batch 898 batch loss 1.50877726 epoch total loss 1.58709979\n",
      "Trained batch 899 batch loss 1.37213778 epoch total loss 1.58686066\n",
      "Trained batch 900 batch loss 1.24358559 epoch total loss 1.58647919\n",
      "Trained batch 901 batch loss 1.23900533 epoch total loss 1.58609354\n",
      "Trained batch 902 batch loss 1.533638 epoch total loss 1.58603549\n",
      "Trained batch 903 batch loss 1.45835197 epoch total loss 1.58589411\n",
      "Trained batch 904 batch loss 1.44488549 epoch total loss 1.58573818\n",
      "Trained batch 905 batch loss 1.48595405 epoch total loss 1.58562791\n",
      "Trained batch 906 batch loss 1.45688915 epoch total loss 1.58548582\n",
      "Trained batch 907 batch loss 1.47184217 epoch total loss 1.58536053\n",
      "Trained batch 908 batch loss 1.52065599 epoch total loss 1.58528924\n",
      "Trained batch 909 batch loss 1.62201571 epoch total loss 1.58532965\n",
      "Trained batch 910 batch loss 1.72006583 epoch total loss 1.58547783\n",
      "Trained batch 911 batch loss 1.49951208 epoch total loss 1.58538342\n",
      "Trained batch 912 batch loss 1.5957725 epoch total loss 1.58539486\n",
      "Trained batch 913 batch loss 1.39168739 epoch total loss 1.58518279\n",
      "Trained batch 914 batch loss 1.48796427 epoch total loss 1.58507633\n",
      "Trained batch 915 batch loss 1.5371201 epoch total loss 1.58502388\n",
      "Trained batch 916 batch loss 1.34939754 epoch total loss 1.58476663\n",
      "Trained batch 917 batch loss 1.39091229 epoch total loss 1.58455515\n",
      "Trained batch 918 batch loss 1.50563192 epoch total loss 1.5844692\n",
      "Trained batch 919 batch loss 1.58245516 epoch total loss 1.58446693\n",
      "Trained batch 920 batch loss 1.52362275 epoch total loss 1.58440089\n",
      "Trained batch 921 batch loss 1.46109962 epoch total loss 1.5842669\n",
      "Trained batch 922 batch loss 1.43838453 epoch total loss 1.58410871\n",
      "Trained batch 923 batch loss 1.3876816 epoch total loss 1.58389592\n",
      "Trained batch 924 batch loss 1.40232801 epoch total loss 1.58369946\n",
      "Trained batch 925 batch loss 1.37717104 epoch total loss 1.58347619\n",
      "Trained batch 926 batch loss 1.38811564 epoch total loss 1.58326519\n",
      "Trained batch 927 batch loss 1.42191935 epoch total loss 1.58309102\n",
      "Trained batch 928 batch loss 1.43941426 epoch total loss 1.58293629\n",
      "Trained batch 929 batch loss 1.45512271 epoch total loss 1.5827986\n",
      "Trained batch 930 batch loss 1.56886101 epoch total loss 1.58278358\n",
      "Trained batch 931 batch loss 1.51005328 epoch total loss 1.5827055\n",
      "Trained batch 932 batch loss 1.50125337 epoch total loss 1.582618\n",
      "Trained batch 933 batch loss 1.40703058 epoch total loss 1.58242977\n",
      "Trained batch 934 batch loss 1.4500308 epoch total loss 1.58228803\n",
      "Trained batch 935 batch loss 1.43876278 epoch total loss 1.58213449\n",
      "Trained batch 936 batch loss 1.42256677 epoch total loss 1.58196414\n",
      "Trained batch 937 batch loss 1.47007096 epoch total loss 1.58184469\n",
      "Trained batch 938 batch loss 1.55106688 epoch total loss 1.58181179\n",
      "Trained batch 939 batch loss 1.56083441 epoch total loss 1.58178949\n",
      "Trained batch 940 batch loss 1.45895 epoch total loss 1.58165884\n",
      "Trained batch 941 batch loss 1.29374838 epoch total loss 1.58135283\n",
      "Trained batch 942 batch loss 1.43913817 epoch total loss 1.58120179\n",
      "Trained batch 943 batch loss 1.41318607 epoch total loss 1.58102357\n",
      "Trained batch 944 batch loss 1.44922113 epoch total loss 1.58088398\n",
      "Trained batch 945 batch loss 1.59039795 epoch total loss 1.58089411\n",
      "Trained batch 946 batch loss 1.47481179 epoch total loss 1.58078206\n",
      "Trained batch 947 batch loss 1.52287221 epoch total loss 1.58072078\n",
      "Trained batch 948 batch loss 1.49428427 epoch total loss 1.58062959\n",
      "Trained batch 949 batch loss 1.54483259 epoch total loss 1.58059192\n",
      "Trained batch 950 batch loss 1.43592048 epoch total loss 1.58043957\n",
      "Trained batch 951 batch loss 1.47482932 epoch total loss 1.58032858\n",
      "Trained batch 952 batch loss 1.40271211 epoch total loss 1.58014202\n",
      "Trained batch 953 batch loss 1.46649742 epoch total loss 1.58002281\n",
      "Trained batch 954 batch loss 1.7266463 epoch total loss 1.58017647\n",
      "Trained batch 955 batch loss 1.60175228 epoch total loss 1.58019912\n",
      "Trained batch 956 batch loss 1.57606411 epoch total loss 1.58019483\n",
      "Trained batch 957 batch loss 1.58902633 epoch total loss 1.58020401\n",
      "Trained batch 958 batch loss 1.55792677 epoch total loss 1.58018088\n",
      "Trained batch 959 batch loss 1.54917932 epoch total loss 1.58014846\n",
      "Trained batch 960 batch loss 1.48438168 epoch total loss 1.5800488\n",
      "Trained batch 961 batch loss 1.49541247 epoch total loss 1.57996058\n",
      "Trained batch 962 batch loss 1.45870686 epoch total loss 1.57983458\n",
      "Trained batch 963 batch loss 1.52168536 epoch total loss 1.57977426\n",
      "Trained batch 964 batch loss 1.395661 epoch total loss 1.57958329\n",
      "Trained batch 965 batch loss 1.47521353 epoch total loss 1.57947516\n",
      "Trained batch 966 batch loss 1.48523116 epoch total loss 1.57937753\n",
      "Trained batch 967 batch loss 1.61205435 epoch total loss 1.57941139\n",
      "Trained batch 968 batch loss 1.57750154 epoch total loss 1.57940936\n",
      "Trained batch 969 batch loss 1.57243097 epoch total loss 1.57940209\n",
      "Trained batch 970 batch loss 1.49267483 epoch total loss 1.57931268\n",
      "Trained batch 971 batch loss 1.46811807 epoch total loss 1.57919824\n",
      "Trained batch 972 batch loss 1.51197577 epoch total loss 1.5791291\n",
      "Trained batch 973 batch loss 1.4081347 epoch total loss 1.57895327\n",
      "Trained batch 974 batch loss 1.48739195 epoch total loss 1.57885933\n",
      "Trained batch 975 batch loss 1.4115839 epoch total loss 1.57868779\n",
      "Trained batch 976 batch loss 1.33679879 epoch total loss 1.57844\n",
      "Trained batch 977 batch loss 1.32496977 epoch total loss 1.57818043\n",
      "Trained batch 978 batch loss 1.29499066 epoch total loss 1.57789099\n",
      "Trained batch 979 batch loss 1.35061944 epoch total loss 1.57765877\n",
      "Trained batch 980 batch loss 1.38440716 epoch total loss 1.5774616\n",
      "Trained batch 981 batch loss 1.50283432 epoch total loss 1.57738554\n",
      "Trained batch 982 batch loss 1.45228052 epoch total loss 1.57725811\n",
      "Trained batch 983 batch loss 1.4600575 epoch total loss 1.5771389\n",
      "Trained batch 984 batch loss 1.42735243 epoch total loss 1.57698667\n",
      "Trained batch 985 batch loss 1.47212493 epoch total loss 1.57688022\n",
      "Trained batch 986 batch loss 1.48723555 epoch total loss 1.57678926\n",
      "Trained batch 987 batch loss 1.46207523 epoch total loss 1.57667303\n",
      "Trained batch 988 batch loss 1.35928059 epoch total loss 1.57645297\n",
      "Trained batch 989 batch loss 1.41421556 epoch total loss 1.57628894\n",
      "Trained batch 990 batch loss 1.37578797 epoch total loss 1.57608628\n",
      "Trained batch 991 batch loss 1.46686041 epoch total loss 1.57597613\n",
      "Trained batch 992 batch loss 1.55551934 epoch total loss 1.57595551\n",
      "Trained batch 993 batch loss 1.61506987 epoch total loss 1.57599497\n",
      "Trained batch 994 batch loss 1.62340009 epoch total loss 1.57604265\n",
      "Trained batch 995 batch loss 1.42305589 epoch total loss 1.57588899\n",
      "Trained batch 996 batch loss 1.45723259 epoch total loss 1.5757699\n",
      "Trained batch 997 batch loss 1.31026375 epoch total loss 1.57550359\n",
      "Trained batch 998 batch loss 1.43476129 epoch total loss 1.57536268\n",
      "Trained batch 999 batch loss 1.52199507 epoch total loss 1.57530916\n",
      "Trained batch 1000 batch loss 1.40824127 epoch total loss 1.57514215\n",
      "Trained batch 1001 batch loss 1.56618237 epoch total loss 1.57513309\n",
      "Trained batch 1002 batch loss 1.44041073 epoch total loss 1.57499874\n",
      "Trained batch 1003 batch loss 1.4426831 epoch total loss 1.57486665\n",
      "Trained batch 1004 batch loss 1.41249728 epoch total loss 1.574705\n",
      "Trained batch 1005 batch loss 1.43196893 epoch total loss 1.57456303\n",
      "Trained batch 1006 batch loss 1.47768974 epoch total loss 1.57446671\n",
      "Trained batch 1007 batch loss 1.48030734 epoch total loss 1.57437325\n",
      "Trained batch 1008 batch loss 1.48541141 epoch total loss 1.57428491\n",
      "Trained batch 1009 batch loss 1.6053232 epoch total loss 1.57431567\n",
      "Trained batch 1010 batch loss 1.56823468 epoch total loss 1.57430959\n",
      "Trained batch 1011 batch loss 1.50066257 epoch total loss 1.57423675\n",
      "Trained batch 1012 batch loss 1.48707104 epoch total loss 1.57415056\n",
      "Trained batch 1013 batch loss 1.49729574 epoch total loss 1.57407475\n",
      "Trained batch 1014 batch loss 1.56783748 epoch total loss 1.57406867\n",
      "Trained batch 1015 batch loss 1.51191413 epoch total loss 1.57400739\n",
      "Trained batch 1016 batch loss 1.46477866 epoch total loss 1.57389987\n",
      "Trained batch 1017 batch loss 1.3998946 epoch total loss 1.5737288\n",
      "Trained batch 1018 batch loss 1.3742907 epoch total loss 1.57353282\n",
      "Trained batch 1019 batch loss 1.46504569 epoch total loss 1.57342649\n",
      "Trained batch 1020 batch loss 1.55525208 epoch total loss 1.5734086\n",
      "Trained batch 1021 batch loss 1.42179525 epoch total loss 1.57326007\n",
      "Trained batch 1022 batch loss 1.40631032 epoch total loss 1.57309675\n",
      "Trained batch 1023 batch loss 1.46062756 epoch total loss 1.57298672\n",
      "Trained batch 1024 batch loss 1.48229361 epoch total loss 1.57289815\n",
      "Trained batch 1025 batch loss 1.45875978 epoch total loss 1.57278681\n",
      "Trained batch 1026 batch loss 1.43325 epoch total loss 1.57265079\n",
      "Trained batch 1027 batch loss 1.4665612 epoch total loss 1.57254744\n",
      "Trained batch 1028 batch loss 1.57502329 epoch total loss 1.57254994\n",
      "Trained batch 1029 batch loss 1.5487076 epoch total loss 1.57252669\n",
      "Trained batch 1030 batch loss 1.55312943 epoch total loss 1.57250786\n",
      "Trained batch 1031 batch loss 1.56749213 epoch total loss 1.57250297\n",
      "Trained batch 1032 batch loss 1.50217116 epoch total loss 1.5724349\n",
      "Trained batch 1033 batch loss 1.38221657 epoch total loss 1.57225072\n",
      "Trained batch 1034 batch loss 1.3985033 epoch total loss 1.57208276\n",
      "Trained batch 1035 batch loss 1.47341502 epoch total loss 1.57198739\n",
      "Trained batch 1036 batch loss 1.46735096 epoch total loss 1.57188642\n",
      "Trained batch 1037 batch loss 1.39641094 epoch total loss 1.57171714\n",
      "Trained batch 1038 batch loss 1.48775029 epoch total loss 1.57163632\n",
      "Trained batch 1039 batch loss 1.45377159 epoch total loss 1.57152283\n",
      "Trained batch 1040 batch loss 1.47990561 epoch total loss 1.57143474\n",
      "Trained batch 1041 batch loss 1.44197917 epoch total loss 1.5713104\n",
      "Trained batch 1042 batch loss 1.43608248 epoch total loss 1.57118058\n",
      "Trained batch 1043 batch loss 1.57855403 epoch total loss 1.57118773\n",
      "Trained batch 1044 batch loss 1.50717759 epoch total loss 1.57112646\n",
      "Trained batch 1045 batch loss 1.72085202 epoch total loss 1.57126963\n",
      "Trained batch 1046 batch loss 1.66556525 epoch total loss 1.57135975\n",
      "Trained batch 1047 batch loss 1.60457265 epoch total loss 1.57139158\n",
      "Trained batch 1048 batch loss 1.57683289 epoch total loss 1.57139671\n",
      "Trained batch 1049 batch loss 1.47826052 epoch total loss 1.5713079\n",
      "Trained batch 1050 batch loss 1.39912617 epoch total loss 1.57114398\n",
      "Trained batch 1051 batch loss 1.38416564 epoch total loss 1.57096601\n",
      "Trained batch 1052 batch loss 1.52335441 epoch total loss 1.57092071\n",
      "Trained batch 1053 batch loss 1.57875729 epoch total loss 1.57092822\n",
      "Trained batch 1054 batch loss 1.46041512 epoch total loss 1.57082331\n",
      "Trained batch 1055 batch loss 1.45888174 epoch total loss 1.57071722\n",
      "Trained batch 1056 batch loss 1.36408341 epoch total loss 1.57052159\n",
      "Trained batch 1057 batch loss 1.43089747 epoch total loss 1.57038951\n",
      "Trained batch 1058 batch loss 1.38627124 epoch total loss 1.57021546\n",
      "Trained batch 1059 batch loss 1.38258088 epoch total loss 1.57003832\n",
      "Trained batch 1060 batch loss 1.4809835 epoch total loss 1.56995428\n",
      "Trained batch 1061 batch loss 1.39642966 epoch total loss 1.56979072\n",
      "Trained batch 1062 batch loss 1.4481796 epoch total loss 1.56967616\n",
      "Trained batch 1063 batch loss 1.48212636 epoch total loss 1.56959391\n",
      "Trained batch 1064 batch loss 1.50948775 epoch total loss 1.5695374\n",
      "Trained batch 1065 batch loss 1.44886744 epoch total loss 1.56942403\n",
      "Trained batch 1066 batch loss 1.51058483 epoch total loss 1.56936896\n",
      "Trained batch 1067 batch loss 1.49502027 epoch total loss 1.56929922\n",
      "Trained batch 1068 batch loss 1.55492616 epoch total loss 1.56928575\n",
      "Trained batch 1069 batch loss 1.51637125 epoch total loss 1.56923628\n",
      "Trained batch 1070 batch loss 1.51760387 epoch total loss 1.569188\n",
      "Trained batch 1071 batch loss 1.43961525 epoch total loss 1.569067\n",
      "Trained batch 1072 batch loss 1.39670277 epoch total loss 1.56890619\n",
      "Trained batch 1073 batch loss 1.48581982 epoch total loss 1.56882882\n",
      "Trained batch 1074 batch loss 1.49878573 epoch total loss 1.56876349\n",
      "Trained batch 1075 batch loss 1.49625063 epoch total loss 1.56869602\n",
      "Trained batch 1076 batch loss 1.47213721 epoch total loss 1.56860638\n",
      "Trained batch 1077 batch loss 1.53924108 epoch total loss 1.56857908\n",
      "Trained batch 1078 batch loss 1.51309967 epoch total loss 1.56852758\n",
      "Trained batch 1079 batch loss 1.48819947 epoch total loss 1.56845307\n",
      "Trained batch 1080 batch loss 1.3095578 epoch total loss 1.56821334\n",
      "Trained batch 1081 batch loss 1.47985744 epoch total loss 1.56813157\n",
      "Trained batch 1082 batch loss 1.48911178 epoch total loss 1.56805861\n",
      "Trained batch 1083 batch loss 1.51737785 epoch total loss 1.56801176\n",
      "Trained batch 1084 batch loss 1.52746987 epoch total loss 1.56797433\n",
      "Trained batch 1085 batch loss 1.70188963 epoch total loss 1.56809783\n",
      "Trained batch 1086 batch loss 1.68154407 epoch total loss 1.56820226\n",
      "Trained batch 1087 batch loss 1.49653 epoch total loss 1.56813633\n",
      "Trained batch 1088 batch loss 1.42387319 epoch total loss 1.56800365\n",
      "Trained batch 1089 batch loss 1.38601208 epoch total loss 1.56783652\n",
      "Trained batch 1090 batch loss 1.41106057 epoch total loss 1.56769264\n",
      "Trained batch 1091 batch loss 1.41862488 epoch total loss 1.56755602\n",
      "Trained batch 1092 batch loss 1.49698544 epoch total loss 1.56749141\n",
      "Trained batch 1093 batch loss 1.45429778 epoch total loss 1.56738782\n",
      "Trained batch 1094 batch loss 1.49957681 epoch total loss 1.56732595\n",
      "Trained batch 1095 batch loss 1.49559927 epoch total loss 1.56726038\n",
      "Trained batch 1096 batch loss 1.5932225 epoch total loss 1.56728411\n",
      "Trained batch 1097 batch loss 1.53066063 epoch total loss 1.56725073\n",
      "Trained batch 1098 batch loss 1.45861816 epoch total loss 1.56715178\n",
      "Trained batch 1099 batch loss 1.43635774 epoch total loss 1.56703281\n",
      "Trained batch 1100 batch loss 1.48682523 epoch total loss 1.56695986\n",
      "Trained batch 1101 batch loss 1.45389426 epoch total loss 1.56685722\n",
      "Trained batch 1102 batch loss 1.41461813 epoch total loss 1.56671906\n",
      "Trained batch 1103 batch loss 1.45518637 epoch total loss 1.56661797\n",
      "Trained batch 1104 batch loss 1.3990438 epoch total loss 1.56646621\n",
      "Trained batch 1105 batch loss 1.33193231 epoch total loss 1.5662539\n",
      "Trained batch 1106 batch loss 1.46952724 epoch total loss 1.5661664\n",
      "Trained batch 1107 batch loss 1.5322988 epoch total loss 1.56613588\n",
      "Trained batch 1108 batch loss 1.38518286 epoch total loss 1.56597245\n",
      "Trained batch 1109 batch loss 1.52141404 epoch total loss 1.56593227\n",
      "Trained batch 1110 batch loss 1.3564955 epoch total loss 1.56574357\n",
      "Trained batch 1111 batch loss 1.32413816 epoch total loss 1.56552601\n",
      "Trained batch 1112 batch loss 1.5317626 epoch total loss 1.56549561\n",
      "Trained batch 1113 batch loss 1.29563928 epoch total loss 1.56525326\n",
      "Trained batch 1114 batch loss 1.26911044 epoch total loss 1.56498742\n",
      "Trained batch 1115 batch loss 1.27295947 epoch total loss 1.56472552\n",
      "Trained batch 1116 batch loss 1.21819687 epoch total loss 1.56441498\n",
      "Trained batch 1117 batch loss 1.38924873 epoch total loss 1.56425822\n",
      "Trained batch 1118 batch loss 1.26504815 epoch total loss 1.56399047\n",
      "Trained batch 1119 batch loss 1.31288815 epoch total loss 1.56376612\n",
      "Trained batch 1120 batch loss 1.39474201 epoch total loss 1.5636152\n",
      "Trained batch 1121 batch loss 1.35816491 epoch total loss 1.56343186\n",
      "Trained batch 1122 batch loss 1.40834749 epoch total loss 1.5632937\n",
      "Trained batch 1123 batch loss 1.37281752 epoch total loss 1.56312406\n",
      "Trained batch 1124 batch loss 1.38332081 epoch total loss 1.56296408\n",
      "Trained batch 1125 batch loss 1.46881723 epoch total loss 1.5628804\n",
      "Trained batch 1126 batch loss 1.47055852 epoch total loss 1.5627985\n",
      "Trained batch 1127 batch loss 1.51317835 epoch total loss 1.56275439\n",
      "Trained batch 1128 batch loss 1.35302508 epoch total loss 1.56256855\n",
      "Trained batch 1129 batch loss 1.28060365 epoch total loss 1.5623188\n",
      "Trained batch 1130 batch loss 1.36377966 epoch total loss 1.56214309\n",
      "Trained batch 1131 batch loss 1.47063243 epoch total loss 1.56206214\n",
      "Trained batch 1132 batch loss 1.45648372 epoch total loss 1.56196892\n",
      "Trained batch 1133 batch loss 1.45354176 epoch total loss 1.5618732\n",
      "Trained batch 1134 batch loss 1.55562329 epoch total loss 1.56186771\n",
      "Trained batch 1135 batch loss 1.51195645 epoch total loss 1.56182373\n",
      "Trained batch 1136 batch loss 1.54040861 epoch total loss 1.56180489\n",
      "Trained batch 1137 batch loss 1.55550528 epoch total loss 1.56179941\n",
      "Trained batch 1138 batch loss 1.54839885 epoch total loss 1.56178749\n",
      "Trained batch 1139 batch loss 1.44266152 epoch total loss 1.56168294\n",
      "Trained batch 1140 batch loss 1.43414688 epoch total loss 1.56157112\n",
      "Trained batch 1141 batch loss 1.4646 epoch total loss 1.56148612\n",
      "Trained batch 1142 batch loss 1.52580905 epoch total loss 1.56145477\n",
      "Trained batch 1143 batch loss 1.44451892 epoch total loss 1.56135249\n",
      "Trained batch 1144 batch loss 1.39689016 epoch total loss 1.56120861\n",
      "Trained batch 1145 batch loss 1.41159952 epoch total loss 1.56107807\n",
      "Trained batch 1146 batch loss 1.4024992 epoch total loss 1.56093955\n",
      "Trained batch 1147 batch loss 1.36566448 epoch total loss 1.56076944\n",
      "Trained batch 1148 batch loss 1.45568919 epoch total loss 1.56067789\n",
      "Trained batch 1149 batch loss 1.37247932 epoch total loss 1.56051409\n",
      "Trained batch 1150 batch loss 1.39438486 epoch total loss 1.56036961\n",
      "Trained batch 1151 batch loss 1.31983984 epoch total loss 1.56016064\n",
      "Trained batch 1152 batch loss 1.44235623 epoch total loss 1.56005836\n",
      "Trained batch 1153 batch loss 1.50333571 epoch total loss 1.56000912\n",
      "Trained batch 1154 batch loss 1.50175858 epoch total loss 1.55995858\n",
      "Trained batch 1155 batch loss 1.51008916 epoch total loss 1.55991554\n",
      "Trained batch 1156 batch loss 1.34685612 epoch total loss 1.55973113\n",
      "Trained batch 1157 batch loss 1.40394139 epoch total loss 1.55959642\n",
      "Trained batch 1158 batch loss 1.37760329 epoch total loss 1.5594393\n",
      "Trained batch 1159 batch loss 1.49063 epoch total loss 1.55937994\n",
      "Trained batch 1160 batch loss 1.42762828 epoch total loss 1.55926633\n",
      "Trained batch 1161 batch loss 1.38417602 epoch total loss 1.55911541\n",
      "Trained batch 1162 batch loss 1.36672306 epoch total loss 1.55894983\n",
      "Trained batch 1163 batch loss 1.35250723 epoch total loss 1.55877244\n",
      "Trained batch 1164 batch loss 1.50018704 epoch total loss 1.55872214\n",
      "Trained batch 1165 batch loss 1.5850873 epoch total loss 1.55874479\n",
      "Trained batch 1166 batch loss 1.48080313 epoch total loss 1.55867791\n",
      "Trained batch 1167 batch loss 1.44401133 epoch total loss 1.55857968\n",
      "Trained batch 1168 batch loss 1.35960066 epoch total loss 1.55840933\n",
      "Trained batch 1169 batch loss 1.32232296 epoch total loss 1.55820727\n",
      "Trained batch 1170 batch loss 1.36877048 epoch total loss 1.55804539\n",
      "Trained batch 1171 batch loss 1.46888614 epoch total loss 1.55796921\n",
      "Trained batch 1172 batch loss 1.5325824 epoch total loss 1.55794752\n",
      "Trained batch 1173 batch loss 1.48302794 epoch total loss 1.55788374\n",
      "Trained batch 1174 batch loss 1.46110415 epoch total loss 1.55780125\n",
      "Trained batch 1175 batch loss 1.54765773 epoch total loss 1.55779254\n",
      "Trained batch 1176 batch loss 1.49562371 epoch total loss 1.55773962\n",
      "Trained batch 1177 batch loss 1.53170943 epoch total loss 1.55771756\n",
      "Trained batch 1178 batch loss 1.4695493 epoch total loss 1.55764282\n",
      "Trained batch 1179 batch loss 1.50688291 epoch total loss 1.55759966\n",
      "Trained batch 1180 batch loss 1.46954703 epoch total loss 1.55752516\n",
      "Trained batch 1181 batch loss 1.5391382 epoch total loss 1.55750954\n",
      "Trained batch 1182 batch loss 1.39352143 epoch total loss 1.5573709\n",
      "Trained batch 1183 batch loss 1.47554648 epoch total loss 1.55730176\n",
      "Trained batch 1184 batch loss 1.45671558 epoch total loss 1.55721676\n",
      "Trained batch 1185 batch loss 1.43635178 epoch total loss 1.55711484\n",
      "Trained batch 1186 batch loss 1.39096868 epoch total loss 1.55697477\n",
      "Trained batch 1187 batch loss 1.33258319 epoch total loss 1.5567857\n",
      "Trained batch 1188 batch loss 1.36849666 epoch total loss 1.55662727\n",
      "Trained batch 1189 batch loss 1.39988732 epoch total loss 1.55649543\n",
      "Trained batch 1190 batch loss 1.35185504 epoch total loss 1.55632341\n",
      "Trained batch 1191 batch loss 1.34909058 epoch total loss 1.55614948\n",
      "Trained batch 1192 batch loss 1.3608098 epoch total loss 1.55598557\n",
      "Trained batch 1193 batch loss 1.18782687 epoch total loss 1.55567706\n",
      "Trained batch 1194 batch loss 1.41216803 epoch total loss 1.55555677\n",
      "Trained batch 1195 batch loss 1.56422138 epoch total loss 1.55556405\n",
      "Trained batch 1196 batch loss 1.62641168 epoch total loss 1.55562329\n",
      "Trained batch 1197 batch loss 1.56348753 epoch total loss 1.55562985\n",
      "Trained batch 1198 batch loss 1.57354689 epoch total loss 1.55564475\n",
      "Trained batch 1199 batch loss 1.55551231 epoch total loss 1.55564475\n",
      "Trained batch 1200 batch loss 1.4571228 epoch total loss 1.55556262\n",
      "Trained batch 1201 batch loss 1.37091303 epoch total loss 1.55540895\n",
      "Trained batch 1202 batch loss 1.38451719 epoch total loss 1.55526674\n",
      "Trained batch 1203 batch loss 1.47178638 epoch total loss 1.55519736\n",
      "Trained batch 1204 batch loss 1.46935713 epoch total loss 1.55512607\n",
      "Trained batch 1205 batch loss 1.4664408 epoch total loss 1.55505252\n",
      "Trained batch 1206 batch loss 1.53119266 epoch total loss 1.55503273\n",
      "Trained batch 1207 batch loss 1.56320095 epoch total loss 1.55503953\n",
      "Trained batch 1208 batch loss 1.49246454 epoch total loss 1.55498767\n",
      "Trained batch 1209 batch loss 1.54130638 epoch total loss 1.55497634\n",
      "Trained batch 1210 batch loss 1.57101059 epoch total loss 1.5549897\n",
      "Trained batch 1211 batch loss 1.56975317 epoch total loss 1.55500185\n",
      "Trained batch 1212 batch loss 1.49067926 epoch total loss 1.55494881\n",
      "Trained batch 1213 batch loss 1.59010196 epoch total loss 1.55497777\n",
      "Trained batch 1214 batch loss 1.48187494 epoch total loss 1.55491757\n",
      "Trained batch 1215 batch loss 1.47375298 epoch total loss 1.55485082\n",
      "Trained batch 1216 batch loss 1.43442059 epoch total loss 1.55475175\n",
      "Trained batch 1217 batch loss 1.40192795 epoch total loss 1.55462623\n",
      "Trained batch 1218 batch loss 1.40164256 epoch total loss 1.55450058\n",
      "Trained batch 1219 batch loss 1.48530316 epoch total loss 1.55444384\n",
      "Trained batch 1220 batch loss 1.50064111 epoch total loss 1.55439973\n",
      "Trained batch 1221 batch loss 1.47357142 epoch total loss 1.55433345\n",
      "Trained batch 1222 batch loss 1.41856885 epoch total loss 1.55422235\n",
      "Trained batch 1223 batch loss 1.46929967 epoch total loss 1.55415297\n",
      "Trained batch 1224 batch loss 1.56744897 epoch total loss 1.55416393\n",
      "Trained batch 1225 batch loss 1.51846957 epoch total loss 1.55413473\n",
      "Trained batch 1226 batch loss 1.54623914 epoch total loss 1.55412829\n",
      "Trained batch 1227 batch loss 1.43811297 epoch total loss 1.55403376\n",
      "Trained batch 1228 batch loss 1.54146945 epoch total loss 1.55402362\n",
      "Trained batch 1229 batch loss 1.53401661 epoch total loss 1.55400729\n",
      "Trained batch 1230 batch loss 1.50153327 epoch total loss 1.55396473\n",
      "Trained batch 1231 batch loss 1.46911407 epoch total loss 1.55389583\n",
      "Trained batch 1232 batch loss 1.51763165 epoch total loss 1.55386627\n",
      "Trained batch 1233 batch loss 1.59076226 epoch total loss 1.55389631\n",
      "Trained batch 1234 batch loss 1.55283296 epoch total loss 1.55389547\n",
      "Trained batch 1235 batch loss 1.50143027 epoch total loss 1.55385292\n",
      "Trained batch 1236 batch loss 1.47152174 epoch total loss 1.5537864\n",
      "Trained batch 1237 batch loss 1.49430561 epoch total loss 1.55373824\n",
      "Trained batch 1238 batch loss 1.47567642 epoch total loss 1.55367529\n",
      "Trained batch 1239 batch loss 1.45188105 epoch total loss 1.55359316\n",
      "Trained batch 1240 batch loss 1.35159707 epoch total loss 1.5534302\n",
      "Trained batch 1241 batch loss 1.38241458 epoch total loss 1.55329239\n",
      "Trained batch 1242 batch loss 1.44261074 epoch total loss 1.55320334\n",
      "Trained batch 1243 batch loss 1.36813855 epoch total loss 1.55305445\n",
      "Trained batch 1244 batch loss 1.42634511 epoch total loss 1.55295265\n",
      "Trained batch 1245 batch loss 1.5116365 epoch total loss 1.55291939\n",
      "Trained batch 1246 batch loss 1.31561041 epoch total loss 1.55272889\n",
      "Trained batch 1247 batch loss 1.44072354 epoch total loss 1.55263901\n",
      "Trained batch 1248 batch loss 1.53632414 epoch total loss 1.55262601\n",
      "Trained batch 1249 batch loss 1.48150778 epoch total loss 1.55256915\n",
      "Trained batch 1250 batch loss 1.62777221 epoch total loss 1.55262935\n",
      "Trained batch 1251 batch loss 1.57293987 epoch total loss 1.55264556\n",
      "Trained batch 1252 batch loss 1.62040889 epoch total loss 1.55269969\n",
      "Trained batch 1253 batch loss 1.37128758 epoch total loss 1.55255497\n",
      "Trained batch 1254 batch loss 1.37858737 epoch total loss 1.55241621\n",
      "Trained batch 1255 batch loss 1.54947352 epoch total loss 1.55241382\n",
      "Trained batch 1256 batch loss 1.47523522 epoch total loss 1.55235231\n",
      "Trained batch 1257 batch loss 1.55664587 epoch total loss 1.55235577\n",
      "Trained batch 1258 batch loss 1.5093956 epoch total loss 1.55232155\n",
      "Trained batch 1259 batch loss 1.51400971 epoch total loss 1.55229115\n",
      "Trained batch 1260 batch loss 1.35185361 epoch total loss 1.55213201\n",
      "Trained batch 1261 batch loss 1.32513893 epoch total loss 1.55195212\n",
      "Trained batch 1262 batch loss 1.26863432 epoch total loss 1.55172765\n",
      "Trained batch 1263 batch loss 1.30224156 epoch total loss 1.55153012\n",
      "Trained batch 1264 batch loss 1.49347138 epoch total loss 1.55148423\n",
      "Trained batch 1265 batch loss 1.43457866 epoch total loss 1.55139184\n",
      "Trained batch 1266 batch loss 1.53706205 epoch total loss 1.55138052\n",
      "Trained batch 1267 batch loss 1.58201182 epoch total loss 1.55140471\n",
      "Trained batch 1268 batch loss 1.52677858 epoch total loss 1.55138528\n",
      "Trained batch 1269 batch loss 1.46250284 epoch total loss 1.55131519\n",
      "Trained batch 1270 batch loss 1.5540427 epoch total loss 1.55131745\n",
      "Trained batch 1271 batch loss 1.50392497 epoch total loss 1.55128014\n",
      "Trained batch 1272 batch loss 1.59995294 epoch total loss 1.55131841\n",
      "Trained batch 1273 batch loss 1.5296216 epoch total loss 1.55130136\n",
      "Trained batch 1274 batch loss 1.5610286 epoch total loss 1.55130899\n",
      "Trained batch 1275 batch loss 1.59292793 epoch total loss 1.55134165\n",
      "Trained batch 1276 batch loss 1.45865023 epoch total loss 1.55126894\n",
      "Trained batch 1277 batch loss 1.50928104 epoch total loss 1.55123603\n",
      "Trained batch 1278 batch loss 1.39118743 epoch total loss 1.55111086\n",
      "Trained batch 1279 batch loss 1.30862677 epoch total loss 1.55092132\n",
      "Trained batch 1280 batch loss 1.3738457 epoch total loss 1.55078292\n",
      "Trained batch 1281 batch loss 1.43246448 epoch total loss 1.55069065\n",
      "Trained batch 1282 batch loss 1.42323422 epoch total loss 1.55059123\n",
      "Trained batch 1283 batch loss 1.35115659 epoch total loss 1.55043578\n",
      "Trained batch 1284 batch loss 1.24130523 epoch total loss 1.5501951\n",
      "Trained batch 1285 batch loss 1.38865113 epoch total loss 1.55006933\n",
      "Trained batch 1286 batch loss 1.35760808 epoch total loss 1.54991972\n",
      "Trained batch 1287 batch loss 1.41533089 epoch total loss 1.54981518\n",
      "Trained batch 1288 batch loss 1.36968434 epoch total loss 1.54967523\n",
      "Trained batch 1289 batch loss 1.44702172 epoch total loss 1.54959559\n",
      "Trained batch 1290 batch loss 1.39018917 epoch total loss 1.54947197\n",
      "Trained batch 1291 batch loss 1.47580051 epoch total loss 1.54941487\n",
      "Trained batch 1292 batch loss 1.49176085 epoch total loss 1.54937041\n",
      "Trained batch 1293 batch loss 1.52033257 epoch total loss 1.549348\n",
      "Trained batch 1294 batch loss 1.39061892 epoch total loss 1.54922533\n",
      "Trained batch 1295 batch loss 1.48092413 epoch total loss 1.54917252\n",
      "Trained batch 1296 batch loss 1.36914051 epoch total loss 1.54903364\n",
      "Trained batch 1297 batch loss 1.35503531 epoch total loss 1.54888403\n",
      "Trained batch 1298 batch loss 1.37882161 epoch total loss 1.54875302\n",
      "Trained batch 1299 batch loss 1.37233 epoch total loss 1.54861712\n",
      "Trained batch 1300 batch loss 1.36248302 epoch total loss 1.54847395\n",
      "Trained batch 1301 batch loss 1.37598991 epoch total loss 1.54834139\n",
      "Trained batch 1302 batch loss 1.33901799 epoch total loss 1.54818058\n",
      "Trained batch 1303 batch loss 1.43671179 epoch total loss 1.54809499\n",
      "Trained batch 1304 batch loss 1.4095782 epoch total loss 1.54798877\n",
      "Trained batch 1305 batch loss 1.28184211 epoch total loss 1.54778492\n",
      "Trained batch 1306 batch loss 1.30072093 epoch total loss 1.54759574\n",
      "Trained batch 1307 batch loss 1.36372435 epoch total loss 1.54745507\n",
      "Trained batch 1308 batch loss 1.40458822 epoch total loss 1.54734588\n",
      "Trained batch 1309 batch loss 1.36258519 epoch total loss 1.54720461\n",
      "Trained batch 1310 batch loss 1.30735826 epoch total loss 1.54702163\n",
      "Trained batch 1311 batch loss 1.42724288 epoch total loss 1.54693019\n",
      "Trained batch 1312 batch loss 1.24014843 epoch total loss 1.54669631\n",
      "Trained batch 1313 batch loss 1.24616599 epoch total loss 1.54646754\n",
      "Trained batch 1314 batch loss 1.22036159 epoch total loss 1.54621935\n",
      "Trained batch 1315 batch loss 1.36786306 epoch total loss 1.54608369\n",
      "Trained batch 1316 batch loss 1.39268064 epoch total loss 1.54596722\n",
      "Trained batch 1317 batch loss 1.4243927 epoch total loss 1.54587495\n",
      "Trained batch 1318 batch loss 1.38311481 epoch total loss 1.54575133\n",
      "Trained batch 1319 batch loss 1.46279609 epoch total loss 1.54568839\n",
      "Trained batch 1320 batch loss 1.48001087 epoch total loss 1.54563868\n",
      "Trained batch 1321 batch loss 1.58378041 epoch total loss 1.54566753\n",
      "Trained batch 1322 batch loss 1.47053993 epoch total loss 1.54561067\n",
      "Trained batch 1323 batch loss 1.43395734 epoch total loss 1.54552627\n",
      "Trained batch 1324 batch loss 1.49582279 epoch total loss 1.54548883\n",
      "Trained batch 1325 batch loss 1.38540983 epoch total loss 1.54536796\n",
      "Trained batch 1326 batch loss 1.40098691 epoch total loss 1.545259\n",
      "Trained batch 1327 batch loss 1.47264171 epoch total loss 1.54520428\n",
      "Trained batch 1328 batch loss 1.33644259 epoch total loss 1.54504704\n",
      "Trained batch 1329 batch loss 1.45729709 epoch total loss 1.544981\n",
      "Trained batch 1330 batch loss 1.4549216 epoch total loss 1.54491329\n",
      "Trained batch 1331 batch loss 1.44996488 epoch total loss 1.54484189\n",
      "Trained batch 1332 batch loss 1.41880298 epoch total loss 1.54474723\n",
      "Trained batch 1333 batch loss 1.40718126 epoch total loss 1.544644\n",
      "Trained batch 1334 batch loss 1.53565395 epoch total loss 1.54463732\n",
      "Trained batch 1335 batch loss 1.48340988 epoch total loss 1.54459143\n",
      "Trained batch 1336 batch loss 1.49135053 epoch total loss 1.54455161\n",
      "Trained batch 1337 batch loss 1.56963599 epoch total loss 1.54457033\n",
      "Trained batch 1338 batch loss 1.40417051 epoch total loss 1.5444653\n",
      "Trained batch 1339 batch loss 1.44140708 epoch total loss 1.54438841\n",
      "Trained batch 1340 batch loss 1.41922379 epoch total loss 1.54429495\n",
      "Trained batch 1341 batch loss 1.36364567 epoch total loss 1.54416013\n",
      "Trained batch 1342 batch loss 1.42308378 epoch total loss 1.54406989\n",
      "Trained batch 1343 batch loss 1.40075803 epoch total loss 1.54396331\n",
      "Trained batch 1344 batch loss 1.32075191 epoch total loss 1.54379725\n",
      "Trained batch 1345 batch loss 1.50939596 epoch total loss 1.54377162\n",
      "Trained batch 1346 batch loss 1.39037514 epoch total loss 1.54365766\n",
      "Trained batch 1347 batch loss 1.55458808 epoch total loss 1.54366589\n",
      "Trained batch 1348 batch loss 1.5137949 epoch total loss 1.54364371\n",
      "Trained batch 1349 batch loss 1.45491993 epoch total loss 1.54357791\n",
      "Trained batch 1350 batch loss 1.52034736 epoch total loss 1.54356062\n",
      "Trained batch 1351 batch loss 1.53544009 epoch total loss 1.54355466\n",
      "Trained batch 1352 batch loss 1.49172544 epoch total loss 1.54351628\n",
      "Trained batch 1353 batch loss 1.3389889 epoch total loss 1.543365\n",
      "Trained batch 1354 batch loss 1.54371953 epoch total loss 1.54336524\n",
      "Trained batch 1355 batch loss 1.53923607 epoch total loss 1.54336226\n",
      "Trained batch 1356 batch loss 1.48506522 epoch total loss 1.54331934\n",
      "Trained batch 1357 batch loss 1.48117459 epoch total loss 1.54327357\n",
      "Trained batch 1358 batch loss 1.49569297 epoch total loss 1.5432384\n",
      "Trained batch 1359 batch loss 1.48709607 epoch total loss 1.54319704\n",
      "Trained batch 1360 batch loss 1.46228552 epoch total loss 1.54313767\n",
      "Trained batch 1361 batch loss 1.44048858 epoch total loss 1.54306221\n",
      "Trained batch 1362 batch loss 1.56291413 epoch total loss 1.54307687\n",
      "Trained batch 1363 batch loss 1.51816356 epoch total loss 1.54305851\n",
      "Trained batch 1364 batch loss 1.44842 epoch total loss 1.54298913\n",
      "Trained batch 1365 batch loss 1.29725158 epoch total loss 1.54280925\n",
      "Trained batch 1366 batch loss 1.24696159 epoch total loss 1.54259276\n",
      "Trained batch 1367 batch loss 1.46651328 epoch total loss 1.54253709\n",
      "Trained batch 1368 batch loss 1.46724832 epoch total loss 1.54248202\n",
      "Trained batch 1369 batch loss 1.44637585 epoch total loss 1.5424118\n",
      "Trained batch 1370 batch loss 1.45644665 epoch total loss 1.5423491\n",
      "Trained batch 1371 batch loss 1.37867904 epoch total loss 1.54222977\n",
      "Trained batch 1372 batch loss 1.24422789 epoch total loss 1.54201245\n",
      "Trained batch 1373 batch loss 1.31366289 epoch total loss 1.54184616\n",
      "Trained batch 1374 batch loss 1.38948166 epoch total loss 1.54173529\n",
      "Trained batch 1375 batch loss 1.58349943 epoch total loss 1.54176557\n",
      "Trained batch 1376 batch loss 1.5419004 epoch total loss 1.54176581\n",
      "Trained batch 1377 batch loss 1.51198757 epoch total loss 1.54174411\n",
      "Trained batch 1378 batch loss 1.55204725 epoch total loss 1.54175162\n",
      "Trained batch 1379 batch loss 1.48502398 epoch total loss 1.5417105\n",
      "Trained batch 1380 batch loss 1.51665425 epoch total loss 1.54169238\n",
      "Trained batch 1381 batch loss 1.45305359 epoch total loss 1.54162824\n",
      "Trained batch 1382 batch loss 1.47746551 epoch total loss 1.54158187\n",
      "Trained batch 1383 batch loss 1.45734346 epoch total loss 1.54152083\n",
      "Trained batch 1384 batch loss 1.5001756 epoch total loss 1.54149103\n",
      "Trained batch 1385 batch loss 1.51992226 epoch total loss 1.54147553\n",
      "Trained batch 1386 batch loss 1.49210453 epoch total loss 1.54144\n",
      "Trained batch 1387 batch loss 1.4669435 epoch total loss 1.54138637\n",
      "Trained batch 1388 batch loss 1.39131021 epoch total loss 1.54127824\n",
      "Epoch 1 train loss 1.5412782430648804\n",
      "Validated batch 1 batch loss 1.33134508\n",
      "Validated batch 2 batch loss 1.46425903\n",
      "Validated batch 3 batch loss 1.45099926\n",
      "Validated batch 4 batch loss 1.3894881\n",
      "Validated batch 5 batch loss 1.47585273\n",
      "Validated batch 6 batch loss 1.4913888\n",
      "Validated batch 7 batch loss 1.31185722\n",
      "Validated batch 8 batch loss 1.46971095\n",
      "Validated batch 9 batch loss 1.36777949\n",
      "Validated batch 10 batch loss 1.45849729\n",
      "Validated batch 11 batch loss 1.40737283\n",
      "Validated batch 12 batch loss 1.29044509\n",
      "Validated batch 13 batch loss 1.33072639\n",
      "Validated batch 14 batch loss 1.43744755\n",
      "Validated batch 15 batch loss 1.41191113\n",
      "Validated batch 16 batch loss 1.40029562\n",
      "Validated batch 17 batch loss 1.3757596\n",
      "Validated batch 18 batch loss 1.41532493\n",
      "Validated batch 19 batch loss 1.4385165\n",
      "Validated batch 20 batch loss 1.49845266\n",
      "Validated batch 21 batch loss 1.44962621\n",
      "Validated batch 22 batch loss 1.43940616\n",
      "Validated batch 23 batch loss 1.31526506\n",
      "Validated batch 24 batch loss 1.37060785\n",
      "Validated batch 25 batch loss 1.43062007\n",
      "Validated batch 26 batch loss 1.35642982\n",
      "Validated batch 27 batch loss 1.34612656\n",
      "Validated batch 28 batch loss 1.33242726\n",
      "Validated batch 29 batch loss 1.45685053\n",
      "Validated batch 30 batch loss 1.4195292\n",
      "Validated batch 31 batch loss 1.33893979\n",
      "Validated batch 32 batch loss 1.40086031\n",
      "Validated batch 33 batch loss 1.41796505\n",
      "Validated batch 34 batch loss 1.36334085\n",
      "Validated batch 35 batch loss 1.37779438\n",
      "Validated batch 36 batch loss 1.46144462\n",
      "Validated batch 37 batch loss 1.39985549\n",
      "Validated batch 38 batch loss 1.46541667\n",
      "Validated batch 39 batch loss 1.49612725\n",
      "Validated batch 40 batch loss 1.41776562\n",
      "Validated batch 41 batch loss 1.46738243\n",
      "Validated batch 42 batch loss 1.2890842\n",
      "Validated batch 43 batch loss 1.35889506\n",
      "Validated batch 44 batch loss 1.33852828\n",
      "Validated batch 45 batch loss 1.4373467\n",
      "Validated batch 46 batch loss 1.52334762\n",
      "Validated batch 47 batch loss 1.47828293\n",
      "Validated batch 48 batch loss 1.40244186\n",
      "Validated batch 49 batch loss 1.3561\n",
      "Validated batch 50 batch loss 1.34148157\n",
      "Validated batch 51 batch loss 1.39963913\n",
      "Validated batch 52 batch loss 1.5275836\n",
      "Validated batch 53 batch loss 1.34447956\n",
      "Validated batch 54 batch loss 1.46570468\n",
      "Validated batch 55 batch loss 1.44075108\n",
      "Validated batch 56 batch loss 1.41650605\n",
      "Validated batch 57 batch loss 1.40746045\n",
      "Validated batch 58 batch loss 1.30931425\n",
      "Validated batch 59 batch loss 1.56806016\n",
      "Validated batch 60 batch loss 1.35313785\n",
      "Validated batch 61 batch loss 1.44478619\n",
      "Validated batch 62 batch loss 1.37567782\n",
      "Validated batch 63 batch loss 1.45427251\n",
      "Validated batch 64 batch loss 1.28895044\n",
      "Validated batch 65 batch loss 1.38859189\n",
      "Validated batch 66 batch loss 1.38802612\n",
      "Validated batch 67 batch loss 1.35972953\n",
      "Validated batch 68 batch loss 1.41993809\n",
      "Validated batch 69 batch loss 1.41892123\n",
      "Validated batch 70 batch loss 1.40215182\n",
      "Validated batch 71 batch loss 1.33326161\n",
      "Validated batch 72 batch loss 1.39539552\n",
      "Validated batch 73 batch loss 1.31901073\n",
      "Validated batch 74 batch loss 1.40675783\n",
      "Validated batch 75 batch loss 1.49205422\n",
      "Validated batch 76 batch loss 1.44104409\n",
      "Validated batch 77 batch loss 1.50904799\n",
      "Validated batch 78 batch loss 1.46914458\n",
      "Validated batch 79 batch loss 1.45498645\n",
      "Validated batch 80 batch loss 1.42549634\n",
      "Validated batch 81 batch loss 1.51096082\n",
      "Validated batch 82 batch loss 1.44049752\n",
      "Validated batch 83 batch loss 1.50537944\n",
      "Validated batch 84 batch loss 1.50723338\n",
      "Validated batch 85 batch loss 1.46001232\n",
      "Validated batch 86 batch loss 1.46535909\n",
      "Validated batch 87 batch loss 1.30401313\n",
      "Validated batch 88 batch loss 1.40039611\n",
      "Validated batch 89 batch loss 1.42375851\n",
      "Validated batch 90 batch loss 1.45280218\n",
      "Validated batch 91 batch loss 1.41071784\n",
      "Validated batch 92 batch loss 1.38678586\n",
      "Validated batch 93 batch loss 1.45326257\n",
      "Validated batch 94 batch loss 1.49826229\n",
      "Validated batch 95 batch loss 1.35223293\n",
      "Validated batch 96 batch loss 1.34677303\n",
      "Validated batch 97 batch loss 1.45564544\n",
      "Validated batch 98 batch loss 1.38467336\n",
      "Validated batch 99 batch loss 1.3556025\n",
      "Validated batch 100 batch loss 1.42374492\n",
      "Validated batch 101 batch loss 1.33836961\n",
      "Validated batch 102 batch loss 1.52224159\n",
      "Validated batch 103 batch loss 1.35169971\n",
      "Validated batch 104 batch loss 1.32657886\n",
      "Validated batch 105 batch loss 1.36837041\n",
      "Validated batch 106 batch loss 1.54439974\n",
      "Validated batch 107 batch loss 1.445503\n",
      "Validated batch 108 batch loss 1.50670123\n",
      "Validated batch 109 batch loss 1.35820484\n",
      "Validated batch 110 batch loss 1.50027442\n",
      "Validated batch 111 batch loss 1.41780734\n",
      "Validated batch 112 batch loss 1.48482668\n",
      "Validated batch 113 batch loss 1.48989606\n",
      "Validated batch 114 batch loss 1.2126044\n",
      "Validated batch 115 batch loss 1.46024442\n",
      "Validated batch 116 batch loss 1.52021992\n",
      "Validated batch 117 batch loss 1.41790295\n",
      "Validated batch 118 batch loss 1.40412474\n",
      "Validated batch 119 batch loss 1.40759635\n",
      "Validated batch 120 batch loss 1.35456467\n",
      "Validated batch 121 batch loss 1.42574334\n",
      "Validated batch 122 batch loss 1.41749966\n",
      "Validated batch 123 batch loss 1.35511243\n",
      "Validated batch 124 batch loss 1.36636198\n",
      "Validated batch 125 batch loss 1.375579\n",
      "Validated batch 126 batch loss 1.42892635\n",
      "Validated batch 127 batch loss 1.42147923\n",
      "Validated batch 128 batch loss 1.40942729\n",
      "Validated batch 129 batch loss 1.33970928\n",
      "Validated batch 130 batch loss 1.37592506\n",
      "Validated batch 131 batch loss 1.4522171\n",
      "Validated batch 132 batch loss 1.43619597\n",
      "Validated batch 133 batch loss 1.42209339\n",
      "Validated batch 134 batch loss 1.52755535\n",
      "Validated batch 135 batch loss 1.6517601\n",
      "Validated batch 136 batch loss 1.54322553\n",
      "Validated batch 137 batch loss 1.40045309\n",
      "Validated batch 138 batch loss 1.32603097\n",
      "Validated batch 139 batch loss 1.32034063\n",
      "Validated batch 140 batch loss 1.46899772\n",
      "Validated batch 141 batch loss 1.34444678\n",
      "Validated batch 142 batch loss 1.36481583\n",
      "Validated batch 143 batch loss 1.42926121\n",
      "Validated batch 144 batch loss 1.40933943\n",
      "Validated batch 145 batch loss 1.46909535\n",
      "Validated batch 146 batch loss 1.49636483\n",
      "Validated batch 147 batch loss 1.46827161\n",
      "Validated batch 148 batch loss 1.4383384\n",
      "Validated batch 149 batch loss 1.47790468\n",
      "Validated batch 150 batch loss 1.48396242\n",
      "Validated batch 151 batch loss 1.35006535\n",
      "Validated batch 152 batch loss 1.4677031\n",
      "Validated batch 153 batch loss 1.48442674\n",
      "Validated batch 154 batch loss 1.42714858\n",
      "Validated batch 155 batch loss 1.50863039\n",
      "Validated batch 156 batch loss 1.35561919\n",
      "Validated batch 157 batch loss 1.32853341\n",
      "Validated batch 158 batch loss 1.40638244\n",
      "Validated batch 159 batch loss 1.33552897\n",
      "Validated batch 160 batch loss 1.52227306\n",
      "Validated batch 161 batch loss 1.35106456\n",
      "Validated batch 162 batch loss 1.42355835\n",
      "Validated batch 163 batch loss 1.3528688\n",
      "Validated batch 164 batch loss 1.39861882\n",
      "Validated batch 165 batch loss 1.35813987\n",
      "Validated batch 166 batch loss 1.35635924\n",
      "Validated batch 167 batch loss 1.41328716\n",
      "Validated batch 168 batch loss 1.36339235\n",
      "Validated batch 169 batch loss 1.44006515\n",
      "Validated batch 170 batch loss 1.46958971\n",
      "Validated batch 171 batch loss 1.34071875\n",
      "Validated batch 172 batch loss 1.51487792\n",
      "Validated batch 173 batch loss 1.47070765\n",
      "Validated batch 174 batch loss 1.32176709\n",
      "Validated batch 175 batch loss 1.40910125\n",
      "Validated batch 176 batch loss 1.45602608\n",
      "Validated batch 177 batch loss 1.40310216\n",
      "Validated batch 178 batch loss 1.52265346\n",
      "Validated batch 179 batch loss 1.40061104\n",
      "Validated batch 180 batch loss 1.46429074\n",
      "Validated batch 181 batch loss 1.36842036\n",
      "Validated batch 182 batch loss 1.41420293\n",
      "Validated batch 183 batch loss 1.39382303\n",
      "Validated batch 184 batch loss 1.34327924\n",
      "Validated batch 185 batch loss 1.49661267\n",
      "Epoch 1 val loss 1.415874719619751\n",
      "Model /aiffel/aiffel/mpii/models1/model-epoch-1-loss-1.4159.h5 saved.\n",
      "Start epoch 2 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.23220956 epoch total loss 1.23220956\n",
      "Trained batch 2 batch loss 1.4253161 epoch total loss 1.32876277\n",
      "Trained batch 3 batch loss 1.54359055 epoch total loss 1.40037203\n",
      "Trained batch 4 batch loss 1.4919908 epoch total loss 1.42327666\n",
      "Trained batch 5 batch loss 1.56662059 epoch total loss 1.45194554\n",
      "Trained batch 6 batch loss 1.51797748 epoch total loss 1.46295083\n",
      "Trained batch 7 batch loss 1.4443084 epoch total loss 1.46028769\n",
      "Trained batch 8 batch loss 1.30311549 epoch total loss 1.44064116\n",
      "Trained batch 9 batch loss 1.29745865 epoch total loss 1.42473197\n",
      "Trained batch 10 batch loss 1.3903594 epoch total loss 1.42129481\n",
      "Trained batch 11 batch loss 1.41285682 epoch total loss 1.4205277\n",
      "Trained batch 12 batch loss 1.40369964 epoch total loss 1.41912544\n",
      "Trained batch 13 batch loss 1.4804194 epoch total loss 1.42384028\n",
      "Trained batch 14 batch loss 1.51200819 epoch total loss 1.43013799\n",
      "Trained batch 15 batch loss 1.41582727 epoch total loss 1.42918396\n",
      "Trained batch 16 batch loss 1.48652208 epoch total loss 1.43276763\n",
      "Trained batch 17 batch loss 1.52813029 epoch total loss 1.43837714\n",
      "Trained batch 18 batch loss 1.54028988 epoch total loss 1.44403899\n",
      "Trained batch 19 batch loss 1.42940545 epoch total loss 1.44326878\n",
      "Trained batch 20 batch loss 1.53188968 epoch total loss 1.44769979\n",
      "Trained batch 21 batch loss 1.48755765 epoch total loss 1.44959784\n",
      "Trained batch 22 batch loss 1.40519857 epoch total loss 1.44757974\n",
      "Trained batch 23 batch loss 1.48327506 epoch total loss 1.44913173\n",
      "Trained batch 24 batch loss 1.37033761 epoch total loss 1.44584858\n",
      "Trained batch 25 batch loss 1.47699785 epoch total loss 1.44709456\n",
      "Trained batch 26 batch loss 1.56527519 epoch total loss 1.45163989\n",
      "Trained batch 27 batch loss 1.59670234 epoch total loss 1.45701265\n",
      "Trained batch 28 batch loss 1.60775268 epoch total loss 1.46239626\n",
      "Trained batch 29 batch loss 1.56459534 epoch total loss 1.46592033\n",
      "Trained batch 30 batch loss 1.36684382 epoch total loss 1.46261775\n",
      "Trained batch 31 batch loss 1.3508122 epoch total loss 1.45901108\n",
      "Trained batch 32 batch loss 1.3790946 epoch total loss 1.45651364\n",
      "Trained batch 33 batch loss 1.34430718 epoch total loss 1.45311344\n",
      "Trained batch 34 batch loss 1.37387609 epoch total loss 1.4507829\n",
      "Trained batch 35 batch loss 1.38157821 epoch total loss 1.44880557\n",
      "Trained batch 36 batch loss 1.41931248 epoch total loss 1.44798625\n",
      "Trained batch 37 batch loss 1.37817478 epoch total loss 1.44609952\n",
      "Trained batch 38 batch loss 1.35016561 epoch total loss 1.44357491\n",
      "Trained batch 39 batch loss 1.36218083 epoch total loss 1.44148791\n",
      "Trained batch 40 batch loss 1.43799424 epoch total loss 1.44140065\n",
      "Trained batch 41 batch loss 1.38904178 epoch total loss 1.44012356\n",
      "Trained batch 42 batch loss 1.3738426 epoch total loss 1.43854547\n",
      "Trained batch 43 batch loss 1.33308792 epoch total loss 1.43609297\n",
      "Trained batch 44 batch loss 1.3271606 epoch total loss 1.43361723\n",
      "Trained batch 45 batch loss 1.32149982 epoch total loss 1.43112576\n",
      "Trained batch 46 batch loss 1.44106579 epoch total loss 1.43134177\n",
      "Trained batch 47 batch loss 1.48117685 epoch total loss 1.43240213\n",
      "Trained batch 48 batch loss 1.53922796 epoch total loss 1.43462765\n",
      "Trained batch 49 batch loss 1.6774224 epoch total loss 1.43958271\n",
      "Trained batch 50 batch loss 1.50357723 epoch total loss 1.44086254\n",
      "Trained batch 51 batch loss 1.4087925 epoch total loss 1.44023371\n",
      "Trained batch 52 batch loss 1.39001501 epoch total loss 1.43926799\n",
      "Trained batch 53 batch loss 1.36025882 epoch total loss 1.43777728\n",
      "Trained batch 54 batch loss 1.4450345 epoch total loss 1.43791175\n",
      "Trained batch 55 batch loss 1.48737383 epoch total loss 1.43881106\n",
      "Trained batch 56 batch loss 1.54504085 epoch total loss 1.44070804\n",
      "Trained batch 57 batch loss 1.50223196 epoch total loss 1.44178748\n",
      "Trained batch 58 batch loss 1.58155417 epoch total loss 1.44419718\n",
      "Trained batch 59 batch loss 1.57150531 epoch total loss 1.44635487\n",
      "Trained batch 60 batch loss 1.59803522 epoch total loss 1.44888294\n",
      "Trained batch 61 batch loss 1.54718518 epoch total loss 1.45049453\n",
      "Trained batch 62 batch loss 1.4529829 epoch total loss 1.45053458\n",
      "Trained batch 63 batch loss 1.55848074 epoch total loss 1.45224798\n",
      "Trained batch 64 batch loss 1.49388921 epoch total loss 1.45289862\n",
      "Trained batch 65 batch loss 1.53062391 epoch total loss 1.45409441\n",
      "Trained batch 66 batch loss 1.35392022 epoch total loss 1.45257664\n",
      "Trained batch 67 batch loss 1.50181389 epoch total loss 1.45331156\n",
      "Trained batch 68 batch loss 1.48571265 epoch total loss 1.45378792\n",
      "Trained batch 69 batch loss 1.43064916 epoch total loss 1.45345259\n",
      "Trained batch 70 batch loss 1.34289432 epoch total loss 1.45187318\n",
      "Trained batch 71 batch loss 1.21434188 epoch total loss 1.44852769\n",
      "Trained batch 72 batch loss 1.34459662 epoch total loss 1.44708419\n",
      "Trained batch 73 batch loss 1.44911242 epoch total loss 1.44711196\n",
      "Trained batch 74 batch loss 1.50027514 epoch total loss 1.44783044\n",
      "Trained batch 75 batch loss 1.52093172 epoch total loss 1.44880509\n",
      "Trained batch 76 batch loss 1.46487606 epoch total loss 1.44901657\n",
      "Trained batch 77 batch loss 1.51357436 epoch total loss 1.44985497\n",
      "Trained batch 78 batch loss 1.50172412 epoch total loss 1.45051992\n",
      "Trained batch 79 batch loss 1.47056043 epoch total loss 1.4507736\n",
      "Trained batch 80 batch loss 1.44766366 epoch total loss 1.45073473\n",
      "Trained batch 81 batch loss 1.48216629 epoch total loss 1.45112276\n",
      "Trained batch 82 batch loss 1.44490814 epoch total loss 1.45104694\n",
      "Trained batch 83 batch loss 1.49910975 epoch total loss 1.45162594\n",
      "Trained batch 84 batch loss 1.49822116 epoch total loss 1.45218062\n",
      "Trained batch 85 batch loss 1.45175982 epoch total loss 1.45217574\n",
      "Trained batch 86 batch loss 1.43211222 epoch total loss 1.45194244\n",
      "Trained batch 87 batch loss 1.48348594 epoch total loss 1.45230496\n",
      "Trained batch 88 batch loss 1.37017441 epoch total loss 1.45137167\n",
      "Trained batch 89 batch loss 1.42921805 epoch total loss 1.45112264\n",
      "Trained batch 90 batch loss 1.40703797 epoch total loss 1.45063293\n",
      "Trained batch 91 batch loss 1.30977178 epoch total loss 1.449085\n",
      "Trained batch 92 batch loss 1.3319149 epoch total loss 1.44781125\n",
      "Trained batch 93 batch loss 1.34793687 epoch total loss 1.44673729\n",
      "Trained batch 94 batch loss 1.39760661 epoch total loss 1.44621468\n",
      "Trained batch 95 batch loss 1.47493243 epoch total loss 1.44651699\n",
      "Trained batch 96 batch loss 1.3431294 epoch total loss 1.44543993\n",
      "Trained batch 97 batch loss 1.44981742 epoch total loss 1.44548512\n",
      "Trained batch 98 batch loss 1.43274498 epoch total loss 1.44535506\n",
      "Trained batch 99 batch loss 1.34275234 epoch total loss 1.44431865\n",
      "Trained batch 100 batch loss 1.37353718 epoch total loss 1.44361079\n",
      "Trained batch 101 batch loss 1.41148388 epoch total loss 1.44329274\n",
      "Trained batch 102 batch loss 1.25854993 epoch total loss 1.44148147\n",
      "Trained batch 103 batch loss 1.39558053 epoch total loss 1.44103587\n",
      "Trained batch 104 batch loss 1.45965803 epoch total loss 1.44121492\n",
      "Trained batch 105 batch loss 1.45061541 epoch total loss 1.44130456\n",
      "Trained batch 106 batch loss 1.3884567 epoch total loss 1.44080603\n",
      "Trained batch 107 batch loss 1.40855789 epoch total loss 1.44050455\n",
      "Trained batch 108 batch loss 1.34594631 epoch total loss 1.43962908\n",
      "Trained batch 109 batch loss 1.40380228 epoch total loss 1.43930042\n",
      "Trained batch 110 batch loss 1.34854567 epoch total loss 1.43847537\n",
      "Trained batch 111 batch loss 1.36648345 epoch total loss 1.43782675\n",
      "Trained batch 112 batch loss 1.297562 epoch total loss 1.43657434\n",
      "Trained batch 113 batch loss 1.24978709 epoch total loss 1.43492138\n",
      "Trained batch 114 batch loss 1.28496563 epoch total loss 1.43360603\n",
      "Trained batch 115 batch loss 1.30315518 epoch total loss 1.43247175\n",
      "Trained batch 116 batch loss 1.49298418 epoch total loss 1.43299341\n",
      "Trained batch 117 batch loss 1.38330925 epoch total loss 1.43256879\n",
      "Trained batch 118 batch loss 1.40119255 epoch total loss 1.43230295\n",
      "Trained batch 119 batch loss 1.37752795 epoch total loss 1.43184268\n",
      "Trained batch 120 batch loss 1.3944366 epoch total loss 1.43153107\n",
      "Trained batch 121 batch loss 1.47422314 epoch total loss 1.43188393\n",
      "Trained batch 122 batch loss 1.48947823 epoch total loss 1.43235588\n",
      "Trained batch 123 batch loss 1.33910871 epoch total loss 1.43159783\n",
      "Trained batch 124 batch loss 1.3779695 epoch total loss 1.43116534\n",
      "Trained batch 125 batch loss 1.35778213 epoch total loss 1.43057835\n",
      "Trained batch 126 batch loss 1.20962691 epoch total loss 1.42882478\n",
      "Trained batch 127 batch loss 1.40171862 epoch total loss 1.42861128\n",
      "Trained batch 128 batch loss 1.34712052 epoch total loss 1.4279747\n",
      "Trained batch 129 batch loss 1.39208961 epoch total loss 1.42769647\n",
      "Trained batch 130 batch loss 1.34801483 epoch total loss 1.42708361\n",
      "Trained batch 131 batch loss 1.41049147 epoch total loss 1.42695701\n",
      "Trained batch 132 batch loss 1.45536566 epoch total loss 1.42717218\n",
      "Trained batch 133 batch loss 1.35888052 epoch total loss 1.42665875\n",
      "Trained batch 134 batch loss 1.34603584 epoch total loss 1.42605722\n",
      "Trained batch 135 batch loss 1.32618308 epoch total loss 1.42531741\n",
      "Trained batch 136 batch loss 1.31091893 epoch total loss 1.42447615\n",
      "Trained batch 137 batch loss 1.34926343 epoch total loss 1.42392719\n",
      "Trained batch 138 batch loss 1.49377441 epoch total loss 1.42443323\n",
      "Trained batch 139 batch loss 1.58827138 epoch total loss 1.42561197\n",
      "Trained batch 140 batch loss 1.62278032 epoch total loss 1.42702043\n",
      "Trained batch 141 batch loss 1.56512809 epoch total loss 1.42799985\n",
      "Trained batch 142 batch loss 1.49417233 epoch total loss 1.42846584\n",
      "Trained batch 143 batch loss 1.45202076 epoch total loss 1.42863059\n",
      "Trained batch 144 batch loss 1.38636971 epoch total loss 1.4283371\n",
      "Trained batch 145 batch loss 1.33701789 epoch total loss 1.42770731\n",
      "Trained batch 146 batch loss 1.39422822 epoch total loss 1.42747796\n",
      "Trained batch 147 batch loss 1.47795403 epoch total loss 1.4278214\n",
      "Trained batch 148 batch loss 1.44763947 epoch total loss 1.42795527\n",
      "Trained batch 149 batch loss 1.44313526 epoch total loss 1.42805707\n",
      "Trained batch 150 batch loss 1.41861153 epoch total loss 1.42799413\n",
      "Trained batch 151 batch loss 1.39896679 epoch total loss 1.42780185\n",
      "Trained batch 152 batch loss 1.32535052 epoch total loss 1.42712784\n",
      "Trained batch 153 batch loss 1.36330318 epoch total loss 1.42671061\n",
      "Trained batch 154 batch loss 1.24458194 epoch total loss 1.42552805\n",
      "Trained batch 155 batch loss 1.43205333 epoch total loss 1.42557013\n",
      "Trained batch 156 batch loss 1.42932177 epoch total loss 1.42559409\n",
      "Trained batch 157 batch loss 1.46078455 epoch total loss 1.42581832\n",
      "Trained batch 158 batch loss 1.3919667 epoch total loss 1.42560399\n",
      "Trained batch 159 batch loss 1.31024754 epoch total loss 1.42487848\n",
      "Trained batch 160 batch loss 1.32059681 epoch total loss 1.42422676\n",
      "Trained batch 161 batch loss 1.39829719 epoch total loss 1.42406571\n",
      "Trained batch 162 batch loss 1.42405152 epoch total loss 1.42406571\n",
      "Trained batch 163 batch loss 1.29543757 epoch total loss 1.42327654\n",
      "Trained batch 164 batch loss 1.33615518 epoch total loss 1.42274535\n",
      "Trained batch 165 batch loss 1.29981494 epoch total loss 1.42200029\n",
      "Trained batch 166 batch loss 1.45084345 epoch total loss 1.42217398\n",
      "Trained batch 167 batch loss 1.4639473 epoch total loss 1.42242408\n",
      "Trained batch 168 batch loss 1.42990017 epoch total loss 1.42246866\n",
      "Trained batch 169 batch loss 1.3656981 epoch total loss 1.42213273\n",
      "Trained batch 170 batch loss 1.25118887 epoch total loss 1.42112708\n",
      "Trained batch 171 batch loss 1.26846957 epoch total loss 1.42023432\n",
      "Trained batch 172 batch loss 1.26539612 epoch total loss 1.41933417\n",
      "Trained batch 173 batch loss 1.28632593 epoch total loss 1.41856539\n",
      "Trained batch 174 batch loss 1.28929925 epoch total loss 1.41782248\n",
      "Trained batch 175 batch loss 1.49267626 epoch total loss 1.4182502\n",
      "Trained batch 176 batch loss 1.4623518 epoch total loss 1.41850078\n",
      "Trained batch 177 batch loss 1.40421391 epoch total loss 1.41842008\n",
      "Trained batch 178 batch loss 1.4678545 epoch total loss 1.41869783\n",
      "Trained batch 179 batch loss 1.36858857 epoch total loss 1.41841793\n",
      "Trained batch 180 batch loss 1.4874506 epoch total loss 1.41880143\n",
      "Trained batch 181 batch loss 1.40201449 epoch total loss 1.4187088\n",
      "Trained batch 182 batch loss 1.45568275 epoch total loss 1.41891193\n",
      "Trained batch 183 batch loss 1.49396622 epoch total loss 1.41932201\n",
      "Trained batch 184 batch loss 1.35219049 epoch total loss 1.41895723\n",
      "Trained batch 185 batch loss 1.41982543 epoch total loss 1.418962\n",
      "Trained batch 186 batch loss 1.45379877 epoch total loss 1.41914928\n",
      "Trained batch 187 batch loss 1.33262491 epoch total loss 1.41868651\n",
      "Trained batch 188 batch loss 1.49970222 epoch total loss 1.41911733\n",
      "Trained batch 189 batch loss 1.37924838 epoch total loss 1.41890645\n",
      "Trained batch 190 batch loss 1.39511251 epoch total loss 1.41878116\n",
      "Trained batch 191 batch loss 1.43952584 epoch total loss 1.41888976\n",
      "Trained batch 192 batch loss 1.39992309 epoch total loss 1.41879094\n",
      "Trained batch 193 batch loss 1.51626027 epoch total loss 1.41929603\n",
      "Trained batch 194 batch loss 1.49192238 epoch total loss 1.41967034\n",
      "Trained batch 195 batch loss 1.41430914 epoch total loss 1.41964281\n",
      "Trained batch 196 batch loss 1.36350274 epoch total loss 1.41935635\n",
      "Trained batch 197 batch loss 1.34197938 epoch total loss 1.41896355\n",
      "Trained batch 198 batch loss 1.3167603 epoch total loss 1.41844749\n",
      "Trained batch 199 batch loss 1.38171828 epoch total loss 1.41826284\n",
      "Trained batch 200 batch loss 1.45575106 epoch total loss 1.41845036\n",
      "Trained batch 201 batch loss 1.44283617 epoch total loss 1.41857171\n",
      "Trained batch 202 batch loss 1.46461332 epoch total loss 1.41879952\n",
      "Trained batch 203 batch loss 1.41845834 epoch total loss 1.41879785\n",
      "Trained batch 204 batch loss 1.43507326 epoch total loss 1.4188776\n",
      "Trained batch 205 batch loss 1.4797498 epoch total loss 1.41917443\n",
      "Trained batch 206 batch loss 1.47827101 epoch total loss 1.41946125\n",
      "Trained batch 207 batch loss 1.42640376 epoch total loss 1.41949475\n",
      "Trained batch 208 batch loss 1.4197948 epoch total loss 1.4194963\n",
      "Trained batch 209 batch loss 1.33691406 epoch total loss 1.41910112\n",
      "Trained batch 210 batch loss 1.32684422 epoch total loss 1.41866183\n",
      "Trained batch 211 batch loss 1.27132082 epoch total loss 1.4179635\n",
      "Trained batch 212 batch loss 1.47319734 epoch total loss 1.4182241\n",
      "Trained batch 213 batch loss 1.45144808 epoch total loss 1.41838014\n",
      "Trained batch 214 batch loss 1.38617039 epoch total loss 1.41822958\n",
      "Trained batch 215 batch loss 1.32420325 epoch total loss 1.4177922\n",
      "Trained batch 216 batch loss 1.39346743 epoch total loss 1.41767955\n",
      "Trained batch 217 batch loss 1.36553645 epoch total loss 1.41743922\n",
      "Trained batch 218 batch loss 1.44372356 epoch total loss 1.41755986\n",
      "Trained batch 219 batch loss 1.41985452 epoch total loss 1.41757035\n",
      "Trained batch 220 batch loss 1.46300483 epoch total loss 1.41777694\n",
      "Trained batch 221 batch loss 1.37614393 epoch total loss 1.41758847\n",
      "Trained batch 222 batch loss 1.46880436 epoch total loss 1.41781914\n",
      "Trained batch 223 batch loss 1.47768617 epoch total loss 1.41808772\n",
      "Trained batch 224 batch loss 1.37060535 epoch total loss 1.41787565\n",
      "Trained batch 225 batch loss 1.5203774 epoch total loss 1.41833127\n",
      "Trained batch 226 batch loss 1.52735984 epoch total loss 1.41881382\n",
      "Trained batch 227 batch loss 1.57359242 epoch total loss 1.41949558\n",
      "Trained batch 228 batch loss 1.39722705 epoch total loss 1.41939783\n",
      "Trained batch 229 batch loss 1.3038733 epoch total loss 1.41889334\n",
      "Trained batch 230 batch loss 1.40628147 epoch total loss 1.4188385\n",
      "Trained batch 231 batch loss 1.35584879 epoch total loss 1.41856575\n",
      "Trained batch 232 batch loss 1.36880803 epoch total loss 1.41835129\n",
      "Trained batch 233 batch loss 1.45078361 epoch total loss 1.41849041\n",
      "Trained batch 234 batch loss 1.3938427 epoch total loss 1.41838503\n",
      "Trained batch 235 batch loss 1.24166203 epoch total loss 1.41763306\n",
      "Trained batch 236 batch loss 1.40152121 epoch total loss 1.41756475\n",
      "Trained batch 237 batch loss 1.35095906 epoch total loss 1.41728377\n",
      "Trained batch 238 batch loss 1.32234478 epoch total loss 1.4168849\n",
      "Trained batch 239 batch loss 1.37841058 epoch total loss 1.41672397\n",
      "Trained batch 240 batch loss 1.33593035 epoch total loss 1.41638732\n",
      "Trained batch 241 batch loss 1.36983883 epoch total loss 1.4161942\n",
      "Trained batch 242 batch loss 1.33465791 epoch total loss 1.4158572\n",
      "Trained batch 243 batch loss 1.2789098 epoch total loss 1.41529357\n",
      "Trained batch 244 batch loss 1.38519061 epoch total loss 1.41517031\n",
      "Trained batch 245 batch loss 1.3954736 epoch total loss 1.41508985\n",
      "Trained batch 246 batch loss 1.22135925 epoch total loss 1.41430247\n",
      "Trained batch 247 batch loss 1.38381612 epoch total loss 1.41417897\n",
      "Trained batch 248 batch loss 1.3161726 epoch total loss 1.41378379\n",
      "Trained batch 249 batch loss 1.24904943 epoch total loss 1.41312218\n",
      "Trained batch 250 batch loss 1.26727974 epoch total loss 1.41253877\n",
      "Trained batch 251 batch loss 1.20914578 epoch total loss 1.4117285\n",
      "Trained batch 252 batch loss 1.24420393 epoch total loss 1.41106367\n",
      "Trained batch 253 batch loss 1.36458325 epoch total loss 1.41088\n",
      "Trained batch 254 batch loss 1.37680173 epoch total loss 1.41074586\n",
      "Trained batch 255 batch loss 1.37929201 epoch total loss 1.41062248\n",
      "Trained batch 256 batch loss 1.39664841 epoch total loss 1.41056788\n",
      "Trained batch 257 batch loss 1.36573863 epoch total loss 1.41039348\n",
      "Trained batch 258 batch loss 1.48951483 epoch total loss 1.41070008\n",
      "Trained batch 259 batch loss 1.46543777 epoch total loss 1.41091144\n",
      "Trained batch 260 batch loss 1.41029978 epoch total loss 1.41090906\n",
      "Trained batch 261 batch loss 1.48853827 epoch total loss 1.41120648\n",
      "Trained batch 262 batch loss 1.36701584 epoch total loss 1.4110378\n",
      "Trained batch 263 batch loss 1.37310696 epoch total loss 1.41089356\n",
      "Trained batch 264 batch loss 1.48434854 epoch total loss 1.41117179\n",
      "Trained batch 265 batch loss 1.36331952 epoch total loss 1.41099119\n",
      "Trained batch 266 batch loss 1.40035677 epoch total loss 1.41095126\n",
      "Trained batch 267 batch loss 1.36044323 epoch total loss 1.41076207\n",
      "Trained batch 268 batch loss 1.34487641 epoch total loss 1.41051614\n",
      "Trained batch 269 batch loss 1.44739926 epoch total loss 1.41065323\n",
      "Trained batch 270 batch loss 1.57163596 epoch total loss 1.4112494\n",
      "Trained batch 271 batch loss 1.51836491 epoch total loss 1.4116447\n",
      "Trained batch 272 batch loss 1.46368551 epoch total loss 1.41183603\n",
      "Trained batch 273 batch loss 1.42882276 epoch total loss 1.41189837\n",
      "Trained batch 274 batch loss 1.29362071 epoch total loss 1.4114666\n",
      "Trained batch 275 batch loss 1.40586221 epoch total loss 1.41144621\n",
      "Trained batch 276 batch loss 1.39167523 epoch total loss 1.41137457\n",
      "Trained batch 277 batch loss 1.33032298 epoch total loss 1.41108191\n",
      "Trained batch 278 batch loss 1.41836798 epoch total loss 1.41110814\n",
      "Trained batch 279 batch loss 1.33360815 epoch total loss 1.41083038\n",
      "Trained batch 280 batch loss 1.41605353 epoch total loss 1.41084898\n",
      "Trained batch 281 batch loss 1.4298985 epoch total loss 1.41091681\n",
      "Trained batch 282 batch loss 1.31111443 epoch total loss 1.41056299\n",
      "Trained batch 283 batch loss 1.33834898 epoch total loss 1.41030777\n",
      "Trained batch 284 batch loss 1.29977179 epoch total loss 1.40991855\n",
      "Trained batch 285 batch loss 1.24797285 epoch total loss 1.4093504\n",
      "Trained batch 286 batch loss 1.20961237 epoch total loss 1.40865207\n",
      "Trained batch 287 batch loss 1.30032742 epoch total loss 1.40827453\n",
      "Trained batch 288 batch loss 1.27482224 epoch total loss 1.40781116\n",
      "Trained batch 289 batch loss 1.40854287 epoch total loss 1.40781367\n",
      "Trained batch 290 batch loss 1.40449858 epoch total loss 1.40780234\n",
      "Trained batch 291 batch loss 1.36446834 epoch total loss 1.40765333\n",
      "Trained batch 292 batch loss 1.41933966 epoch total loss 1.40769339\n",
      "Trained batch 293 batch loss 1.29435956 epoch total loss 1.40730667\n",
      "Trained batch 294 batch loss 1.3061738 epoch total loss 1.40696275\n",
      "Trained batch 295 batch loss 1.38738894 epoch total loss 1.40689635\n",
      "Trained batch 296 batch loss 1.44551659 epoch total loss 1.40702689\n",
      "Trained batch 297 batch loss 1.13379216 epoch total loss 1.40610683\n",
      "Trained batch 298 batch loss 1.09073579 epoch total loss 1.40504861\n",
      "Trained batch 299 batch loss 1.19472492 epoch total loss 1.40434515\n",
      "Trained batch 300 batch loss 1.40093517 epoch total loss 1.40433383\n",
      "Trained batch 301 batch loss 1.56591 epoch total loss 1.40487063\n",
      "Trained batch 302 batch loss 1.55147362 epoch total loss 1.40535605\n",
      "Trained batch 303 batch loss 1.48522413 epoch total loss 1.40561974\n",
      "Trained batch 304 batch loss 1.51893187 epoch total loss 1.40599239\n",
      "Trained batch 305 batch loss 1.39886355 epoch total loss 1.40596902\n",
      "Trained batch 306 batch loss 1.34407246 epoch total loss 1.40576684\n",
      "Trained batch 307 batch loss 1.34286571 epoch total loss 1.40556192\n",
      "Trained batch 308 batch loss 1.34823394 epoch total loss 1.40537584\n",
      "Trained batch 309 batch loss 1.3719697 epoch total loss 1.40526772\n",
      "Trained batch 310 batch loss 1.28529978 epoch total loss 1.40488076\n",
      "Trained batch 311 batch loss 1.38821507 epoch total loss 1.40482712\n",
      "Trained batch 312 batch loss 1.29298067 epoch total loss 1.40446866\n",
      "Trained batch 313 batch loss 1.36968493 epoch total loss 1.40435755\n",
      "Trained batch 314 batch loss 1.29085839 epoch total loss 1.40399611\n",
      "Trained batch 315 batch loss 1.33484352 epoch total loss 1.40377653\n",
      "Trained batch 316 batch loss 1.25631607 epoch total loss 1.40331\n",
      "Trained batch 317 batch loss 1.44939554 epoch total loss 1.40345526\n",
      "Trained batch 318 batch loss 1.50977707 epoch total loss 1.40378964\n",
      "Trained batch 319 batch loss 1.4907217 epoch total loss 1.40406215\n",
      "Trained batch 320 batch loss 1.45651269 epoch total loss 1.40422606\n",
      "Trained batch 321 batch loss 1.52071619 epoch total loss 1.40458894\n",
      "Trained batch 322 batch loss 1.6321454 epoch total loss 1.40529561\n",
      "Trained batch 323 batch loss 1.50403261 epoch total loss 1.40560126\n",
      "Trained batch 324 batch loss 1.46776962 epoch total loss 1.40579319\n",
      "Trained batch 325 batch loss 1.35486317 epoch total loss 1.40563643\n",
      "Trained batch 326 batch loss 1.44412708 epoch total loss 1.40575457\n",
      "Trained batch 327 batch loss 1.49321246 epoch total loss 1.40602195\n",
      "Trained batch 328 batch loss 1.30582178 epoch total loss 1.40571654\n",
      "Trained batch 329 batch loss 1.226789 epoch total loss 1.40517259\n",
      "Trained batch 330 batch loss 1.3605566 epoch total loss 1.4050374\n",
      "Trained batch 331 batch loss 1.48407602 epoch total loss 1.40527618\n",
      "Trained batch 332 batch loss 1.4191221 epoch total loss 1.4053179\n",
      "Trained batch 333 batch loss 1.42691052 epoch total loss 1.40538275\n",
      "Trained batch 334 batch loss 1.43025517 epoch total loss 1.40545726\n",
      "Trained batch 335 batch loss 1.42474127 epoch total loss 1.40551484\n",
      "Trained batch 336 batch loss 1.4102236 epoch total loss 1.40552878\n",
      "Trained batch 337 batch loss 1.35963261 epoch total loss 1.40539265\n",
      "Trained batch 338 batch loss 1.34908891 epoch total loss 1.40522599\n",
      "Trained batch 339 batch loss 1.4497875 epoch total loss 1.40535748\n",
      "Trained batch 340 batch loss 1.39889896 epoch total loss 1.40533853\n",
      "Trained batch 341 batch loss 1.31993341 epoch total loss 1.40508807\n",
      "Trained batch 342 batch loss 1.35440755 epoch total loss 1.40493989\n",
      "Trained batch 343 batch loss 1.41248655 epoch total loss 1.40496182\n",
      "Trained batch 344 batch loss 1.38904166 epoch total loss 1.40491557\n",
      "Trained batch 345 batch loss 1.39365172 epoch total loss 1.40488291\n",
      "Trained batch 346 batch loss 1.45248616 epoch total loss 1.40502048\n",
      "Trained batch 347 batch loss 1.44318545 epoch total loss 1.40513039\n",
      "Trained batch 348 batch loss 1.49852169 epoch total loss 1.40539885\n",
      "Trained batch 349 batch loss 1.35574627 epoch total loss 1.40525651\n",
      "Trained batch 350 batch loss 1.27177238 epoch total loss 1.40487516\n",
      "Trained batch 351 batch loss 1.23900151 epoch total loss 1.40440261\n",
      "Trained batch 352 batch loss 1.34077656 epoch total loss 1.40422189\n",
      "Trained batch 353 batch loss 1.32543588 epoch total loss 1.40399873\n",
      "Trained batch 354 batch loss 1.28582811 epoch total loss 1.40366483\n",
      "Trained batch 355 batch loss 1.29265177 epoch total loss 1.40335226\n",
      "Trained batch 356 batch loss 1.39829707 epoch total loss 1.40333796\n",
      "Trained batch 357 batch loss 1.41304028 epoch total loss 1.40336514\n",
      "Trained batch 358 batch loss 1.39113808 epoch total loss 1.40333104\n",
      "Trained batch 359 batch loss 1.41691494 epoch total loss 1.40336883\n",
      "Trained batch 360 batch loss 1.43605578 epoch total loss 1.40345967\n",
      "Trained batch 361 batch loss 1.24112272 epoch total loss 1.40301\n",
      "Trained batch 362 batch loss 1.28144181 epoch total loss 1.40267408\n",
      "Trained batch 363 batch loss 1.34053314 epoch total loss 1.40250301\n",
      "Trained batch 364 batch loss 1.38677299 epoch total loss 1.40245974\n",
      "Trained batch 365 batch loss 1.57085562 epoch total loss 1.4029212\n",
      "Trained batch 366 batch loss 1.43672657 epoch total loss 1.40301347\n",
      "Trained batch 367 batch loss 1.42257071 epoch total loss 1.40306664\n",
      "Trained batch 368 batch loss 1.24978566 epoch total loss 1.40265012\n",
      "Trained batch 369 batch loss 1.41707039 epoch total loss 1.4026891\n",
      "Trained batch 370 batch loss 1.35172129 epoch total loss 1.40255141\n",
      "Trained batch 371 batch loss 1.40898299 epoch total loss 1.40256882\n",
      "Trained batch 372 batch loss 1.47353542 epoch total loss 1.40275955\n",
      "Trained batch 373 batch loss 1.38220632 epoch total loss 1.40270436\n",
      "Trained batch 374 batch loss 1.32883203 epoch total loss 1.40250695\n",
      "Trained batch 375 batch loss 1.34430718 epoch total loss 1.40235174\n",
      "Trained batch 376 batch loss 1.39845777 epoch total loss 1.40234137\n",
      "Trained batch 377 batch loss 1.37235212 epoch total loss 1.40226185\n",
      "Trained batch 378 batch loss 1.2271136 epoch total loss 1.40179849\n",
      "Trained batch 379 batch loss 1.2915411 epoch total loss 1.40150762\n",
      "Trained batch 380 batch loss 1.28064954 epoch total loss 1.40118957\n",
      "Trained batch 381 batch loss 1.38316798 epoch total loss 1.40114224\n",
      "Trained batch 382 batch loss 1.31117725 epoch total loss 1.40090668\n",
      "Trained batch 383 batch loss 1.36394513 epoch total loss 1.40081024\n",
      "Trained batch 384 batch loss 1.28414333 epoch total loss 1.40050638\n",
      "Trained batch 385 batch loss 1.37061203 epoch total loss 1.40042865\n",
      "Trained batch 386 batch loss 1.52189124 epoch total loss 1.40074337\n",
      "Trained batch 387 batch loss 1.39974606 epoch total loss 1.40074074\n",
      "Trained batch 388 batch loss 1.48509884 epoch total loss 1.40095818\n",
      "Trained batch 389 batch loss 1.5586952 epoch total loss 1.40136373\n",
      "Trained batch 390 batch loss 1.42327094 epoch total loss 1.40141988\n",
      "Trained batch 391 batch loss 1.30371797 epoch total loss 1.40117\n",
      "Trained batch 392 batch loss 1.45594549 epoch total loss 1.40130973\n",
      "Trained batch 393 batch loss 1.39259422 epoch total loss 1.40128756\n",
      "Trained batch 394 batch loss 1.32637322 epoch total loss 1.4010973\n",
      "Trained batch 395 batch loss 1.37735927 epoch total loss 1.40103734\n",
      "Trained batch 396 batch loss 1.44292927 epoch total loss 1.40114307\n",
      "Trained batch 397 batch loss 1.36214685 epoch total loss 1.40104485\n",
      "Trained batch 398 batch loss 1.38741755 epoch total loss 1.40101051\n",
      "Trained batch 399 batch loss 1.3347404 epoch total loss 1.40084434\n",
      "Trained batch 400 batch loss 1.41986537 epoch total loss 1.4008919\n",
      "Trained batch 401 batch loss 1.38209367 epoch total loss 1.40084493\n",
      "Trained batch 402 batch loss 1.46542645 epoch total loss 1.40100563\n",
      "Trained batch 403 batch loss 1.33281589 epoch total loss 1.40083647\n",
      "Trained batch 404 batch loss 1.42234516 epoch total loss 1.40088975\n",
      "Trained batch 405 batch loss 1.4323802 epoch total loss 1.40096748\n",
      "Trained batch 406 batch loss 1.39843404 epoch total loss 1.40096128\n",
      "Trained batch 407 batch loss 1.27917814 epoch total loss 1.40066206\n",
      "Trained batch 408 batch loss 1.30916619 epoch total loss 1.40043771\n",
      "Trained batch 409 batch loss 1.4393177 epoch total loss 1.40053284\n",
      "Trained batch 410 batch loss 1.39224029 epoch total loss 1.40051258\n",
      "Trained batch 411 batch loss 1.49063468 epoch total loss 1.40073192\n",
      "Trained batch 412 batch loss 1.39122725 epoch total loss 1.40070879\n",
      "Trained batch 413 batch loss 1.46924424 epoch total loss 1.40087473\n",
      "Trained batch 414 batch loss 1.42879629 epoch total loss 1.40094221\n",
      "Trained batch 415 batch loss 1.3063457 epoch total loss 1.40071416\n",
      "Trained batch 416 batch loss 1.29257035 epoch total loss 1.40045416\n",
      "Trained batch 417 batch loss 1.29026 epoch total loss 1.40019\n",
      "Trained batch 418 batch loss 1.33276415 epoch total loss 1.40002871\n",
      "Trained batch 419 batch loss 1.33494234 epoch total loss 1.39987338\n",
      "Trained batch 420 batch loss 1.35232413 epoch total loss 1.39976013\n",
      "Trained batch 421 batch loss 1.45856297 epoch total loss 1.39989972\n",
      "Trained batch 422 batch loss 1.24052811 epoch total loss 1.39952207\n",
      "Trained batch 423 batch loss 1.46209598 epoch total loss 1.39967\n",
      "Trained batch 424 batch loss 1.4304111 epoch total loss 1.3997426\n",
      "Trained batch 425 batch loss 1.5016489 epoch total loss 1.39998233\n",
      "Trained batch 426 batch loss 1.60054636 epoch total loss 1.40045309\n",
      "Trained batch 427 batch loss 1.50349283 epoch total loss 1.40069437\n",
      "Trained batch 428 batch loss 1.50416267 epoch total loss 1.40093613\n",
      "Trained batch 429 batch loss 1.33226013 epoch total loss 1.40077603\n",
      "Trained batch 430 batch loss 1.3371588 epoch total loss 1.40062809\n",
      "Trained batch 431 batch loss 1.34087372 epoch total loss 1.40048945\n",
      "Trained batch 432 batch loss 1.65785384 epoch total loss 1.40108514\n",
      "Trained batch 433 batch loss 1.5105263 epoch total loss 1.40133786\n",
      "Trained batch 434 batch loss 1.54185033 epoch total loss 1.40166163\n",
      "Trained batch 435 batch loss 1.50674033 epoch total loss 1.40190315\n",
      "Trained batch 436 batch loss 1.41002905 epoch total loss 1.40192187\n",
      "Trained batch 437 batch loss 1.48656702 epoch total loss 1.40211558\n",
      "Trained batch 438 batch loss 1.4328475 epoch total loss 1.40218568\n",
      "Trained batch 439 batch loss 1.41930723 epoch total loss 1.40222478\n",
      "Trained batch 440 batch loss 1.47410023 epoch total loss 1.4023881\n",
      "Trained batch 441 batch loss 1.41123915 epoch total loss 1.40240824\n",
      "Trained batch 442 batch loss 1.48876 epoch total loss 1.40260363\n",
      "Trained batch 443 batch loss 1.3581785 epoch total loss 1.40250325\n",
      "Trained batch 444 batch loss 1.41281521 epoch total loss 1.40252662\n",
      "Trained batch 445 batch loss 1.38352883 epoch total loss 1.40248394\n",
      "Trained batch 446 batch loss 1.49512446 epoch total loss 1.4026916\n",
      "Trained batch 447 batch loss 1.34311271 epoch total loss 1.40255845\n",
      "Trained batch 448 batch loss 1.33696818 epoch total loss 1.40241206\n",
      "Trained batch 449 batch loss 1.35131526 epoch total loss 1.40229821\n",
      "Trained batch 450 batch loss 1.20680559 epoch total loss 1.40186369\n",
      "Trained batch 451 batch loss 1.32305753 epoch total loss 1.40168905\n",
      "Trained batch 452 batch loss 1.32104659 epoch total loss 1.4015106\n",
      "Trained batch 453 batch loss 1.31619215 epoch total loss 1.40132213\n",
      "Trained batch 454 batch loss 1.17863977 epoch total loss 1.4008317\n",
      "Trained batch 455 batch loss 1.37334561 epoch total loss 1.40077138\n",
      "Trained batch 456 batch loss 1.24342418 epoch total loss 1.40042627\n",
      "Trained batch 457 batch loss 1.51673126 epoch total loss 1.40068066\n",
      "Trained batch 458 batch loss 1.18411279 epoch total loss 1.40020788\n",
      "Trained batch 459 batch loss 1.14666915 epoch total loss 1.39965558\n",
      "Trained batch 460 batch loss 1.14683294 epoch total loss 1.39910603\n",
      "Trained batch 461 batch loss 1.2251066 epoch total loss 1.39872849\n",
      "Trained batch 462 batch loss 1.39119387 epoch total loss 1.39871216\n",
      "Trained batch 463 batch loss 1.5587821 epoch total loss 1.39905787\n",
      "Trained batch 464 batch loss 1.51222372 epoch total loss 1.39930177\n",
      "Trained batch 465 batch loss 1.34377575 epoch total loss 1.39918232\n",
      "Trained batch 466 batch loss 1.33778906 epoch total loss 1.39905047\n",
      "Trained batch 467 batch loss 1.40494514 epoch total loss 1.39906311\n",
      "Trained batch 468 batch loss 1.40039492 epoch total loss 1.39906597\n",
      "Trained batch 469 batch loss 1.47431469 epoch total loss 1.39922643\n",
      "Trained batch 470 batch loss 1.47854352 epoch total loss 1.39939511\n",
      "Trained batch 471 batch loss 1.41149175 epoch total loss 1.39942086\n",
      "Trained batch 472 batch loss 1.56759453 epoch total loss 1.39977705\n",
      "Trained batch 473 batch loss 1.44085753 epoch total loss 1.39986384\n",
      "Trained batch 474 batch loss 1.43270516 epoch total loss 1.3999331\n",
      "Trained batch 475 batch loss 1.35598886 epoch total loss 1.39984071\n",
      "Trained batch 476 batch loss 1.32605708 epoch total loss 1.39968562\n",
      "Trained batch 477 batch loss 1.30258775 epoch total loss 1.39948213\n",
      "Trained batch 478 batch loss 1.3091855 epoch total loss 1.3992933\n",
      "Trained batch 479 batch loss 1.38944471 epoch total loss 1.3992728\n",
      "Trained batch 480 batch loss 1.28932786 epoch total loss 1.39904368\n",
      "Trained batch 481 batch loss 1.35258019 epoch total loss 1.39894712\n",
      "Trained batch 482 batch loss 1.4241364 epoch total loss 1.39899933\n",
      "Trained batch 483 batch loss 1.42223287 epoch total loss 1.39904749\n",
      "Trained batch 484 batch loss 1.4845798 epoch total loss 1.39922416\n",
      "Trained batch 485 batch loss 1.67097974 epoch total loss 1.39978445\n",
      "Trained batch 486 batch loss 1.521209 epoch total loss 1.40003419\n",
      "Trained batch 487 batch loss 1.40353942 epoch total loss 1.40004146\n",
      "Trained batch 488 batch loss 1.50706923 epoch total loss 1.40026081\n",
      "Trained batch 489 batch loss 1.50561976 epoch total loss 1.40047622\n",
      "Trained batch 490 batch loss 1.40464127 epoch total loss 1.4004848\n",
      "Trained batch 491 batch loss 1.35625482 epoch total loss 1.40039468\n",
      "Trained batch 492 batch loss 1.36764932 epoch total loss 1.40032828\n",
      "Trained batch 493 batch loss 1.44808161 epoch total loss 1.40042508\n",
      "Trained batch 494 batch loss 1.46358585 epoch total loss 1.40055287\n",
      "Trained batch 495 batch loss 1.38589132 epoch total loss 1.40052319\n",
      "Trained batch 496 batch loss 1.3608501 epoch total loss 1.4004432\n",
      "Trained batch 497 batch loss 1.36908925 epoch total loss 1.40038\n",
      "Trained batch 498 batch loss 1.30096185 epoch total loss 1.40018046\n",
      "Trained batch 499 batch loss 1.28755665 epoch total loss 1.39995468\n",
      "Trained batch 500 batch loss 1.22846889 epoch total loss 1.39961171\n",
      "Trained batch 501 batch loss 1.34953427 epoch total loss 1.39951181\n",
      "Trained batch 502 batch loss 1.24860227 epoch total loss 1.39921117\n",
      "Trained batch 503 batch loss 1.36664629 epoch total loss 1.39914644\n",
      "Trained batch 504 batch loss 1.35888779 epoch total loss 1.39906645\n",
      "Trained batch 505 batch loss 1.46089101 epoch total loss 1.39918888\n",
      "Trained batch 506 batch loss 1.37591851 epoch total loss 1.39914286\n",
      "Trained batch 507 batch loss 1.38158751 epoch total loss 1.39910829\n",
      "Trained batch 508 batch loss 1.5016588 epoch total loss 1.39931011\n",
      "Trained batch 509 batch loss 1.39575815 epoch total loss 1.3993032\n",
      "Trained batch 510 batch loss 1.42055058 epoch total loss 1.3993448\n",
      "Trained batch 511 batch loss 1.31059182 epoch total loss 1.39917111\n",
      "Trained batch 512 batch loss 1.27990067 epoch total loss 1.39893818\n",
      "Trained batch 513 batch loss 1.31145799 epoch total loss 1.39876771\n",
      "Trained batch 514 batch loss 1.33541059 epoch total loss 1.39864433\n",
      "Trained batch 515 batch loss 1.35091221 epoch total loss 1.39855158\n",
      "Trained batch 516 batch loss 1.51047373 epoch total loss 1.39876854\n",
      "Trained batch 517 batch loss 1.36717057 epoch total loss 1.39870751\n",
      "Trained batch 518 batch loss 1.38094389 epoch total loss 1.39867318\n",
      "Trained batch 519 batch loss 1.34540486 epoch total loss 1.39857054\n",
      "Trained batch 520 batch loss 1.35995877 epoch total loss 1.39849627\n",
      "Trained batch 521 batch loss 1.42204618 epoch total loss 1.39854157\n",
      "Trained batch 522 batch loss 1.30367231 epoch total loss 1.39835978\n",
      "Trained batch 523 batch loss 1.47897828 epoch total loss 1.39851391\n",
      "Trained batch 524 batch loss 1.418751 epoch total loss 1.39855254\n",
      "Trained batch 525 batch loss 1.40129519 epoch total loss 1.39855778\n",
      "Trained batch 526 batch loss 1.2905606 epoch total loss 1.3983525\n",
      "Trained batch 527 batch loss 1.3621664 epoch total loss 1.39828396\n",
      "Trained batch 528 batch loss 1.33858216 epoch total loss 1.39817083\n",
      "Trained batch 529 batch loss 1.37267768 epoch total loss 1.39812267\n",
      "Trained batch 530 batch loss 1.34528482 epoch total loss 1.39802289\n",
      "Trained batch 531 batch loss 1.39045238 epoch total loss 1.3980087\n",
      "Trained batch 532 batch loss 1.31483984 epoch total loss 1.3978523\n",
      "Trained batch 533 batch loss 1.29543352 epoch total loss 1.39766\n",
      "Trained batch 534 batch loss 1.31704044 epoch total loss 1.3975091\n",
      "Trained batch 535 batch loss 1.39249659 epoch total loss 1.39749968\n",
      "Trained batch 536 batch loss 1.42158759 epoch total loss 1.39754462\n",
      "Trained batch 537 batch loss 1.34347701 epoch total loss 1.39744401\n",
      "Trained batch 538 batch loss 1.38544357 epoch total loss 1.39742172\n",
      "Trained batch 539 batch loss 1.32665277 epoch total loss 1.39729035\n",
      "Trained batch 540 batch loss 1.27474463 epoch total loss 1.39706337\n",
      "Trained batch 541 batch loss 1.42129791 epoch total loss 1.39710832\n",
      "Trained batch 542 batch loss 1.41640747 epoch total loss 1.39714384\n",
      "Trained batch 543 batch loss 1.28418434 epoch total loss 1.39693582\n",
      "Trained batch 544 batch loss 1.36793649 epoch total loss 1.39688241\n",
      "Trained batch 545 batch loss 1.3933351 epoch total loss 1.39687586\n",
      "Trained batch 546 batch loss 1.40708268 epoch total loss 1.39689457\n",
      "Trained batch 547 batch loss 1.31587398 epoch total loss 1.39674652\n",
      "Trained batch 548 batch loss 1.33207715 epoch total loss 1.3966285\n",
      "Trained batch 549 batch loss 1.22917271 epoch total loss 1.39632356\n",
      "Trained batch 550 batch loss 1.243752 epoch total loss 1.39604616\n",
      "Trained batch 551 batch loss 1.28919983 epoch total loss 1.39585221\n",
      "Trained batch 552 batch loss 1.39443731 epoch total loss 1.39584959\n",
      "Trained batch 553 batch loss 1.42742586 epoch total loss 1.39590669\n",
      "Trained batch 554 batch loss 1.27132559 epoch total loss 1.39568174\n",
      "Trained batch 555 batch loss 1.31978655 epoch total loss 1.39554501\n",
      "Trained batch 556 batch loss 1.29909158 epoch total loss 1.39537144\n",
      "Trained batch 557 batch loss 1.36886263 epoch total loss 1.39532387\n",
      "Trained batch 558 batch loss 1.45446825 epoch total loss 1.39542985\n",
      "Trained batch 559 batch loss 1.37000847 epoch total loss 1.39538431\n",
      "Trained batch 560 batch loss 1.42647243 epoch total loss 1.39543974\n",
      "Trained batch 561 batch loss 1.2471838 epoch total loss 1.39517558\n",
      "Trained batch 562 batch loss 1.15189731 epoch total loss 1.39474273\n",
      "Trained batch 563 batch loss 1.18515432 epoch total loss 1.39437044\n",
      "Trained batch 564 batch loss 1.24395752 epoch total loss 1.39410377\n",
      "Trained batch 565 batch loss 1.30141854 epoch total loss 1.39393973\n",
      "Trained batch 566 batch loss 1.39986014 epoch total loss 1.3939501\n",
      "Trained batch 567 batch loss 1.4471432 epoch total loss 1.39404392\n",
      "Trained batch 568 batch loss 1.39671636 epoch total loss 1.39404869\n",
      "Trained batch 569 batch loss 1.31247663 epoch total loss 1.3939054\n",
      "Trained batch 570 batch loss 1.2917676 epoch total loss 1.39372611\n",
      "Trained batch 571 batch loss 1.24613166 epoch total loss 1.39346766\n",
      "Trained batch 572 batch loss 1.37920713 epoch total loss 1.39344275\n",
      "Trained batch 573 batch loss 1.41973925 epoch total loss 1.39348865\n",
      "Trained batch 574 batch loss 1.30779231 epoch total loss 1.3933394\n",
      "Trained batch 575 batch loss 1.37331545 epoch total loss 1.39330447\n",
      "Trained batch 576 batch loss 1.3180002 epoch total loss 1.39317369\n",
      "Trained batch 577 batch loss 1.27458525 epoch total loss 1.3929683\n",
      "Trained batch 578 batch loss 1.36012018 epoch total loss 1.39291143\n",
      "Trained batch 579 batch loss 1.34920669 epoch total loss 1.39283586\n",
      "Trained batch 580 batch loss 1.33658314 epoch total loss 1.39273894\n",
      "Trained batch 581 batch loss 1.31572032 epoch total loss 1.39260638\n",
      "Trained batch 582 batch loss 1.36245608 epoch total loss 1.39255452\n",
      "Trained batch 583 batch loss 1.28749084 epoch total loss 1.39237428\n",
      "Trained batch 584 batch loss 1.34745169 epoch total loss 1.39229739\n",
      "Trained batch 585 batch loss 1.44306815 epoch total loss 1.39238417\n",
      "Trained batch 586 batch loss 1.34095109 epoch total loss 1.39229643\n",
      "Trained batch 587 batch loss 1.33643126 epoch total loss 1.39220119\n",
      "Trained batch 588 batch loss 1.36215281 epoch total loss 1.39215016\n",
      "Trained batch 589 batch loss 1.26811326 epoch total loss 1.39193964\n",
      "Trained batch 590 batch loss 1.33481741 epoch total loss 1.39184284\n",
      "Trained batch 591 batch loss 1.33672011 epoch total loss 1.3917495\n",
      "Trained batch 592 batch loss 1.2524507 epoch total loss 1.39151418\n",
      "Trained batch 593 batch loss 1.26951015 epoch total loss 1.39130855\n",
      "Trained batch 594 batch loss 1.36870217 epoch total loss 1.39127052\n",
      "Trained batch 595 batch loss 1.33014476 epoch total loss 1.39116776\n",
      "Trained batch 596 batch loss 1.30690932 epoch total loss 1.39102638\n",
      "Trained batch 597 batch loss 1.36567497 epoch total loss 1.39098382\n",
      "Trained batch 598 batch loss 1.30691826 epoch total loss 1.39084327\n",
      "Trained batch 599 batch loss 1.37123716 epoch total loss 1.39081061\n",
      "Trained batch 600 batch loss 1.33950377 epoch total loss 1.39072502\n",
      "Trained batch 601 batch loss 1.34715271 epoch total loss 1.39065254\n",
      "Trained batch 602 batch loss 1.41098213 epoch total loss 1.39068639\n",
      "Trained batch 603 batch loss 1.38656449 epoch total loss 1.39067948\n",
      "Trained batch 604 batch loss 1.20530748 epoch total loss 1.39037251\n",
      "Trained batch 605 batch loss 1.26670694 epoch total loss 1.39016819\n",
      "Trained batch 606 batch loss 1.38537693 epoch total loss 1.39016032\n",
      "Trained batch 607 batch loss 1.26860476 epoch total loss 1.38996\n",
      "Trained batch 608 batch loss 1.28485751 epoch total loss 1.3897872\n",
      "Trained batch 609 batch loss 1.51237607 epoch total loss 1.38998854\n",
      "Trained batch 610 batch loss 1.43883133 epoch total loss 1.39006853\n",
      "Trained batch 611 batch loss 1.48954833 epoch total loss 1.39023137\n",
      "Trained batch 612 batch loss 1.42706954 epoch total loss 1.39029157\n",
      "Trained batch 613 batch loss 1.45577598 epoch total loss 1.39039838\n",
      "Trained batch 614 batch loss 1.38036859 epoch total loss 1.39038205\n",
      "Trained batch 615 batch loss 1.32454073 epoch total loss 1.390275\n",
      "Trained batch 616 batch loss 1.40394151 epoch total loss 1.39029717\n",
      "Trained batch 617 batch loss 1.47216856 epoch total loss 1.39042985\n",
      "Trained batch 618 batch loss 1.49473524 epoch total loss 1.39059865\n",
      "Trained batch 619 batch loss 1.41856325 epoch total loss 1.39064384\n",
      "Trained batch 620 batch loss 1.37546372 epoch total loss 1.3906194\n",
      "Trained batch 621 batch loss 1.46713603 epoch total loss 1.39074266\n",
      "Trained batch 622 batch loss 1.35003948 epoch total loss 1.39067721\n",
      "Trained batch 623 batch loss 1.37156749 epoch total loss 1.39064658\n",
      "Trained batch 624 batch loss 1.41140938 epoch total loss 1.39067984\n",
      "Trained batch 625 batch loss 1.45977163 epoch total loss 1.39079046\n",
      "Trained batch 626 batch loss 1.45926249 epoch total loss 1.3908999\n",
      "Trained batch 627 batch loss 1.31034708 epoch total loss 1.39077139\n",
      "Trained batch 628 batch loss 1.23716331 epoch total loss 1.39052689\n",
      "Trained batch 629 batch loss 1.19918799 epoch total loss 1.39022255\n",
      "Trained batch 630 batch loss 1.20756078 epoch total loss 1.38993263\n",
      "Trained batch 631 batch loss 1.24729431 epoch total loss 1.38970661\n",
      "Trained batch 632 batch loss 1.27822065 epoch total loss 1.38953018\n",
      "Trained batch 633 batch loss 1.40733945 epoch total loss 1.38955843\n",
      "Trained batch 634 batch loss 1.39454532 epoch total loss 1.38956618\n",
      "Trained batch 635 batch loss 1.44197559 epoch total loss 1.38964868\n",
      "Trained batch 636 batch loss 1.46358919 epoch total loss 1.3897649\n",
      "Trained batch 637 batch loss 1.43333519 epoch total loss 1.38983333\n",
      "Trained batch 638 batch loss 1.45697379 epoch total loss 1.38993859\n",
      "Trained batch 639 batch loss 1.51365018 epoch total loss 1.39013219\n",
      "Trained batch 640 batch loss 1.3597753 epoch total loss 1.39008486\n",
      "Trained batch 641 batch loss 1.35550857 epoch total loss 1.39003098\n",
      "Trained batch 642 batch loss 1.39682865 epoch total loss 1.39004159\n",
      "Trained batch 643 batch loss 1.41985273 epoch total loss 1.39008796\n",
      "Trained batch 644 batch loss 1.34935045 epoch total loss 1.39002466\n",
      "Trained batch 645 batch loss 1.30549562 epoch total loss 1.38989365\n",
      "Trained batch 646 batch loss 1.33541012 epoch total loss 1.38980925\n",
      "Trained batch 647 batch loss 1.31077552 epoch total loss 1.38968706\n",
      "Trained batch 648 batch loss 1.24112964 epoch total loss 1.38945794\n",
      "Trained batch 649 batch loss 1.41281295 epoch total loss 1.38949394\n",
      "Trained batch 650 batch loss 1.28634906 epoch total loss 1.38933527\n",
      "Trained batch 651 batch loss 1.43588 epoch total loss 1.38940668\n",
      "Trained batch 652 batch loss 1.30680943 epoch total loss 1.38928008\n",
      "Trained batch 653 batch loss 1.36128616 epoch total loss 1.38923717\n",
      "Trained batch 654 batch loss 1.3456862 epoch total loss 1.38917065\n",
      "Trained batch 655 batch loss 1.30111754 epoch total loss 1.38903618\n",
      "Trained batch 656 batch loss 1.44359493 epoch total loss 1.38911939\n",
      "Trained batch 657 batch loss 1.4555099 epoch total loss 1.38922048\n",
      "Trained batch 658 batch loss 1.53756464 epoch total loss 1.3894459\n",
      "Trained batch 659 batch loss 1.29713464 epoch total loss 1.38930571\n",
      "Trained batch 660 batch loss 1.29071522 epoch total loss 1.38915634\n",
      "Trained batch 661 batch loss 1.30492961 epoch total loss 1.38902891\n",
      "Trained batch 662 batch loss 1.36708069 epoch total loss 1.38899577\n",
      "Trained batch 663 batch loss 1.38767469 epoch total loss 1.38899386\n",
      "Trained batch 664 batch loss 1.30720925 epoch total loss 1.3888706\n",
      "Trained batch 665 batch loss 1.37673223 epoch total loss 1.38885236\n",
      "Trained batch 666 batch loss 1.39686227 epoch total loss 1.38886428\n",
      "Trained batch 667 batch loss 1.39127517 epoch total loss 1.38886797\n",
      "Trained batch 668 batch loss 1.37760305 epoch total loss 1.38885117\n",
      "Trained batch 669 batch loss 1.47337365 epoch total loss 1.38897753\n",
      "Trained batch 670 batch loss 1.44305849 epoch total loss 1.38905823\n",
      "Trained batch 671 batch loss 1.30979109 epoch total loss 1.3889401\n",
      "Trained batch 672 batch loss 1.34848523 epoch total loss 1.38888\n",
      "Trained batch 673 batch loss 1.32353079 epoch total loss 1.38878286\n",
      "Trained batch 674 batch loss 1.34361935 epoch total loss 1.38871586\n",
      "Trained batch 675 batch loss 1.42162323 epoch total loss 1.38876462\n",
      "Trained batch 676 batch loss 1.32917523 epoch total loss 1.38867652\n",
      "Trained batch 677 batch loss 1.35927129 epoch total loss 1.38863301\n",
      "Trained batch 678 batch loss 1.32808948 epoch total loss 1.38854373\n",
      "Trained batch 679 batch loss 1.39453149 epoch total loss 1.38855255\n",
      "Trained batch 680 batch loss 1.37067604 epoch total loss 1.3885262\n",
      "Trained batch 681 batch loss 1.33641601 epoch total loss 1.38844967\n",
      "Trained batch 682 batch loss 1.42615521 epoch total loss 1.38850498\n",
      "Trained batch 683 batch loss 1.34627724 epoch total loss 1.38844311\n",
      "Trained batch 684 batch loss 1.31663942 epoch total loss 1.38833809\n",
      "Trained batch 685 batch loss 1.32629275 epoch total loss 1.38824761\n",
      "Trained batch 686 batch loss 1.42098427 epoch total loss 1.38829529\n",
      "Trained batch 687 batch loss 1.34247756 epoch total loss 1.38822854\n",
      "Trained batch 688 batch loss 1.42246652 epoch total loss 1.38827837\n",
      "Trained batch 689 batch loss 1.45633745 epoch total loss 1.38837719\n",
      "Trained batch 690 batch loss 1.35224605 epoch total loss 1.38832474\n",
      "Trained batch 691 batch loss 1.37783718 epoch total loss 1.3883096\n",
      "Trained batch 692 batch loss 1.35551775 epoch total loss 1.38826215\n",
      "Trained batch 693 batch loss 1.35772777 epoch total loss 1.38821816\n",
      "Trained batch 694 batch loss 1.426368 epoch total loss 1.38827312\n",
      "Trained batch 695 batch loss 1.27957869 epoch total loss 1.38811672\n",
      "Trained batch 696 batch loss 1.28087318 epoch total loss 1.3879627\n",
      "Trained batch 697 batch loss 1.24928749 epoch total loss 1.38776374\n",
      "Trained batch 698 batch loss 1.40359187 epoch total loss 1.38778639\n",
      "Trained batch 699 batch loss 1.35236573 epoch total loss 1.38773561\n",
      "Trained batch 700 batch loss 1.42155516 epoch total loss 1.387784\n",
      "Trained batch 701 batch loss 1.28865075 epoch total loss 1.3876425\n",
      "Trained batch 702 batch loss 1.28041649 epoch total loss 1.3874898\n",
      "Trained batch 703 batch loss 1.26240468 epoch total loss 1.38731182\n",
      "Trained batch 704 batch loss 1.2779175 epoch total loss 1.38715637\n",
      "Trained batch 705 batch loss 1.27249587 epoch total loss 1.38699377\n",
      "Trained batch 706 batch loss 1.44685888 epoch total loss 1.38707852\n",
      "Trained batch 707 batch loss 1.35124421 epoch total loss 1.38702786\n",
      "Trained batch 708 batch loss 1.42122912 epoch total loss 1.38707614\n",
      "Trained batch 709 batch loss 1.38530827 epoch total loss 1.38707364\n",
      "Trained batch 710 batch loss 1.4051187 epoch total loss 1.38709903\n",
      "Trained batch 711 batch loss 1.27439058 epoch total loss 1.3869406\n",
      "Trained batch 712 batch loss 1.31297898 epoch total loss 1.38683665\n",
      "Trained batch 713 batch loss 1.32067823 epoch total loss 1.3867439\n",
      "Trained batch 714 batch loss 1.33567643 epoch total loss 1.38667238\n",
      "Trained batch 715 batch loss 1.39226007 epoch total loss 1.38668025\n",
      "Trained batch 716 batch loss 1.45051849 epoch total loss 1.38676941\n",
      "Trained batch 717 batch loss 1.29235506 epoch total loss 1.38663769\n",
      "Trained batch 718 batch loss 1.32544482 epoch total loss 1.38655245\n",
      "Trained batch 719 batch loss 1.46683908 epoch total loss 1.38666415\n",
      "Trained batch 720 batch loss 1.36367285 epoch total loss 1.3866322\n",
      "Trained batch 721 batch loss 1.39871669 epoch total loss 1.38664901\n",
      "Trained batch 722 batch loss 1.27331126 epoch total loss 1.38649201\n",
      "Trained batch 723 batch loss 1.38205481 epoch total loss 1.38648593\n",
      "Trained batch 724 batch loss 1.25665271 epoch total loss 1.38630664\n",
      "Trained batch 725 batch loss 1.27003145 epoch total loss 1.38614619\n",
      "Trained batch 726 batch loss 1.23946393 epoch total loss 1.38594413\n",
      "Trained batch 727 batch loss 1.28127575 epoch total loss 1.38580012\n",
      "Trained batch 728 batch loss 1.22590101 epoch total loss 1.38558042\n",
      "Trained batch 729 batch loss 1.27859282 epoch total loss 1.38543367\n",
      "Trained batch 730 batch loss 1.26340961 epoch total loss 1.38526654\n",
      "Trained batch 731 batch loss 1.37406588 epoch total loss 1.38525128\n",
      "Trained batch 732 batch loss 1.27299905 epoch total loss 1.38509786\n",
      "Trained batch 733 batch loss 1.36807156 epoch total loss 1.38507462\n",
      "Trained batch 734 batch loss 1.28005862 epoch total loss 1.38493156\n",
      "Trained batch 735 batch loss 1.42690527 epoch total loss 1.38498855\n",
      "Trained batch 736 batch loss 1.41428149 epoch total loss 1.38502848\n",
      "Trained batch 737 batch loss 1.3339299 epoch total loss 1.3849591\n",
      "Trained batch 738 batch loss 1.36511028 epoch total loss 1.38493216\n",
      "Trained batch 739 batch loss 1.3523761 epoch total loss 1.38488805\n",
      "Trained batch 740 batch loss 1.46538448 epoch total loss 1.38499689\n",
      "Trained batch 741 batch loss 1.37103844 epoch total loss 1.38497818\n",
      "Trained batch 742 batch loss 1.62021041 epoch total loss 1.38529515\n",
      "Trained batch 743 batch loss 1.56657231 epoch total loss 1.38553917\n",
      "Trained batch 744 batch loss 1.4111737 epoch total loss 1.38557351\n",
      "Trained batch 745 batch loss 1.33968174 epoch total loss 1.38551199\n",
      "Trained batch 746 batch loss 1.24439085 epoch total loss 1.38532281\n",
      "Trained batch 747 batch loss 1.07378232 epoch total loss 1.3849057\n",
      "Trained batch 748 batch loss 1.29468703 epoch total loss 1.38478506\n",
      "Trained batch 749 batch loss 1.33292246 epoch total loss 1.3847158\n",
      "Trained batch 750 batch loss 1.10555959 epoch total loss 1.38434362\n",
      "Trained batch 751 batch loss 1.10232973 epoch total loss 1.383968\n",
      "Trained batch 752 batch loss 1.06101167 epoch total loss 1.3835386\n",
      "Trained batch 753 batch loss 1.24997318 epoch total loss 1.38336122\n",
      "Trained batch 754 batch loss 1.24450731 epoch total loss 1.38317704\n",
      "Trained batch 755 batch loss 1.37319398 epoch total loss 1.38316381\n",
      "Trained batch 756 batch loss 1.37735498 epoch total loss 1.38315606\n",
      "Trained batch 757 batch loss 1.43921041 epoch total loss 1.38323021\n",
      "Trained batch 758 batch loss 1.49417555 epoch total loss 1.38337648\n",
      "Trained batch 759 batch loss 1.3193742 epoch total loss 1.38329208\n",
      "Trained batch 760 batch loss 1.36836541 epoch total loss 1.38327253\n",
      "Trained batch 761 batch loss 1.38523018 epoch total loss 1.38327515\n",
      "Trained batch 762 batch loss 1.51125395 epoch total loss 1.383443\n",
      "Trained batch 763 batch loss 1.63534856 epoch total loss 1.38377321\n",
      "Trained batch 764 batch loss 1.55890954 epoch total loss 1.38400257\n",
      "Trained batch 765 batch loss 1.48320544 epoch total loss 1.38413215\n",
      "Trained batch 766 batch loss 1.44976425 epoch total loss 1.38421774\n",
      "Trained batch 767 batch loss 1.43235731 epoch total loss 1.38428056\n",
      "Trained batch 768 batch loss 1.25290811 epoch total loss 1.3841095\n",
      "Trained batch 769 batch loss 1.29369843 epoch total loss 1.38399196\n",
      "Trained batch 770 batch loss 1.39568734 epoch total loss 1.3840071\n",
      "Trained batch 771 batch loss 1.44501102 epoch total loss 1.38408625\n",
      "Trained batch 772 batch loss 1.43667567 epoch total loss 1.38415432\n",
      "Trained batch 773 batch loss 1.34869039 epoch total loss 1.38410842\n",
      "Trained batch 774 batch loss 1.25746369 epoch total loss 1.38394475\n",
      "Trained batch 775 batch loss 1.27204418 epoch total loss 1.38380039\n",
      "Trained batch 776 batch loss 1.28581023 epoch total loss 1.38367403\n",
      "Trained batch 777 batch loss 1.25747859 epoch total loss 1.38351166\n",
      "Trained batch 778 batch loss 1.34208262 epoch total loss 1.38345826\n",
      "Trained batch 779 batch loss 1.25624585 epoch total loss 1.38329494\n",
      "Trained batch 780 batch loss 1.3529011 epoch total loss 1.38325608\n",
      "Trained batch 781 batch loss 1.27167797 epoch total loss 1.38311327\n",
      "Trained batch 782 batch loss 1.32025123 epoch total loss 1.3830328\n",
      "Trained batch 783 batch loss 1.33425748 epoch total loss 1.38297045\n",
      "Trained batch 784 batch loss 1.33141255 epoch total loss 1.38290465\n",
      "Trained batch 785 batch loss 1.53957677 epoch total loss 1.38310421\n",
      "Trained batch 786 batch loss 1.51260769 epoch total loss 1.38326895\n",
      "Trained batch 787 batch loss 1.42176 epoch total loss 1.38331783\n",
      "Trained batch 788 batch loss 1.38067353 epoch total loss 1.38331437\n",
      "Trained batch 789 batch loss 1.34871638 epoch total loss 1.38327062\n",
      "Trained batch 790 batch loss 1.33347273 epoch total loss 1.38320756\n",
      "Trained batch 791 batch loss 1.36520541 epoch total loss 1.38318491\n",
      "Trained batch 792 batch loss 1.44269454 epoch total loss 1.38326013\n",
      "Trained batch 793 batch loss 1.48146546 epoch total loss 1.38338387\n",
      "Trained batch 794 batch loss 1.6154933 epoch total loss 1.38367617\n",
      "Trained batch 795 batch loss 1.46019101 epoch total loss 1.38377249\n",
      "Trained batch 796 batch loss 1.48312008 epoch total loss 1.3838973\n",
      "Trained batch 797 batch loss 1.53669786 epoch total loss 1.38408911\n",
      "Trained batch 798 batch loss 1.47461307 epoch total loss 1.3842026\n",
      "Trained batch 799 batch loss 1.48707867 epoch total loss 1.38433123\n",
      "Trained batch 800 batch loss 1.5347631 epoch total loss 1.38451934\n",
      "Trained batch 801 batch loss 1.3912425 epoch total loss 1.38452768\n",
      "Trained batch 802 batch loss 1.27834845 epoch total loss 1.38439536\n",
      "Trained batch 803 batch loss 1.1687324 epoch total loss 1.38412666\n",
      "Trained batch 804 batch loss 1.07737398 epoch total loss 1.38374519\n",
      "Trained batch 805 batch loss 1.2237711 epoch total loss 1.38354647\n",
      "Trained batch 806 batch loss 1.41345966 epoch total loss 1.38358355\n",
      "Trained batch 807 batch loss 1.56336713 epoch total loss 1.38380635\n",
      "Trained batch 808 batch loss 1.59541512 epoch total loss 1.38406825\n",
      "Trained batch 809 batch loss 1.42158687 epoch total loss 1.38411474\n",
      "Trained batch 810 batch loss 1.26264811 epoch total loss 1.38396478\n",
      "Trained batch 811 batch loss 1.31099379 epoch total loss 1.38387489\n",
      "Trained batch 812 batch loss 1.46905875 epoch total loss 1.3839798\n",
      "Trained batch 813 batch loss 1.41110325 epoch total loss 1.38401318\n",
      "Trained batch 814 batch loss 1.39755785 epoch total loss 1.38402987\n",
      "Trained batch 815 batch loss 1.39637899 epoch total loss 1.384045\n",
      "Trained batch 816 batch loss 1.51772499 epoch total loss 1.3842088\n",
      "Trained batch 817 batch loss 1.37336731 epoch total loss 1.38419557\n",
      "Trained batch 818 batch loss 1.38365293 epoch total loss 1.38419497\n",
      "Trained batch 819 batch loss 1.38100195 epoch total loss 1.38419104\n",
      "Trained batch 820 batch loss 1.25977135 epoch total loss 1.38403928\n",
      "Trained batch 821 batch loss 1.44397807 epoch total loss 1.38411236\n",
      "Trained batch 822 batch loss 1.30484891 epoch total loss 1.3840158\n",
      "Trained batch 823 batch loss 1.25501537 epoch total loss 1.38385904\n",
      "Trained batch 824 batch loss 1.18517125 epoch total loss 1.383618\n",
      "Trained batch 825 batch loss 1.14346874 epoch total loss 1.38332677\n",
      "Trained batch 826 batch loss 1.21604371 epoch total loss 1.38312435\n",
      "Trained batch 827 batch loss 1.31233168 epoch total loss 1.38303876\n",
      "Trained batch 828 batch loss 1.49056602 epoch total loss 1.3831687\n",
      "Trained batch 829 batch loss 1.44304442 epoch total loss 1.38324082\n",
      "Trained batch 830 batch loss 1.42002809 epoch total loss 1.38328516\n",
      "Trained batch 831 batch loss 1.5014925 epoch total loss 1.38342738\n",
      "Trained batch 832 batch loss 1.46148574 epoch total loss 1.3835212\n",
      "Trained batch 833 batch loss 1.34099936 epoch total loss 1.38347\n",
      "Trained batch 834 batch loss 1.46171045 epoch total loss 1.38356376\n",
      "Trained batch 835 batch loss 1.43669403 epoch total loss 1.38362741\n",
      "Trained batch 836 batch loss 1.3669281 epoch total loss 1.38360739\n",
      "Trained batch 837 batch loss 1.30234468 epoch total loss 1.38351035\n",
      "Trained batch 838 batch loss 1.26772046 epoch total loss 1.38337219\n",
      "Trained batch 839 batch loss 1.26595438 epoch total loss 1.38323224\n",
      "Trained batch 840 batch loss 1.20601726 epoch total loss 1.38302135\n",
      "Trained batch 841 batch loss 1.38731551 epoch total loss 1.38302648\n",
      "Trained batch 842 batch loss 1.41026032 epoch total loss 1.38305879\n",
      "Trained batch 843 batch loss 1.36907744 epoch total loss 1.38304222\n",
      "Trained batch 844 batch loss 1.56122911 epoch total loss 1.38325334\n",
      "Trained batch 845 batch loss 1.38830602 epoch total loss 1.3832593\n",
      "Trained batch 846 batch loss 1.39233756 epoch total loss 1.38327\n",
      "Trained batch 847 batch loss 1.44682431 epoch total loss 1.38334501\n",
      "Trained batch 848 batch loss 1.26619697 epoch total loss 1.38320696\n",
      "Trained batch 849 batch loss 1.28228164 epoch total loss 1.38308799\n",
      "Trained batch 850 batch loss 1.4353255 epoch total loss 1.38314939\n",
      "Trained batch 851 batch loss 1.20047283 epoch total loss 1.38293469\n",
      "Trained batch 852 batch loss 1.30202234 epoch total loss 1.38283968\n",
      "Trained batch 853 batch loss 1.48839772 epoch total loss 1.38296342\n",
      "Trained batch 854 batch loss 1.35096157 epoch total loss 1.38292599\n",
      "Trained batch 855 batch loss 1.32465231 epoch total loss 1.38285792\n",
      "Trained batch 856 batch loss 1.22121227 epoch total loss 1.38266909\n",
      "Trained batch 857 batch loss 1.21455443 epoch total loss 1.38247287\n",
      "Trained batch 858 batch loss 1.29237211 epoch total loss 1.38236785\n",
      "Trained batch 859 batch loss 1.23395526 epoch total loss 1.38219523\n",
      "Trained batch 860 batch loss 1.20696831 epoch total loss 1.38199139\n",
      "Trained batch 861 batch loss 1.11408782 epoch total loss 1.38168025\n",
      "Trained batch 862 batch loss 1.27348161 epoch total loss 1.38155472\n",
      "Trained batch 863 batch loss 1.32559896 epoch total loss 1.38148975\n",
      "Trained batch 864 batch loss 1.35304701 epoch total loss 1.38145685\n",
      "Trained batch 865 batch loss 1.388309 epoch total loss 1.38146484\n",
      "Trained batch 866 batch loss 1.3758136 epoch total loss 1.38145828\n",
      "Trained batch 867 batch loss 1.39047933 epoch total loss 1.38146877\n",
      "Trained batch 868 batch loss 1.3839103 epoch total loss 1.38147151\n",
      "Trained batch 869 batch loss 1.33625078 epoch total loss 1.38141954\n",
      "Trained batch 870 batch loss 1.30760336 epoch total loss 1.38133478\n",
      "Trained batch 871 batch loss 1.4521246 epoch total loss 1.38141608\n",
      "Trained batch 872 batch loss 1.4509238 epoch total loss 1.38149571\n",
      "Trained batch 873 batch loss 1.31505418 epoch total loss 1.38141966\n",
      "Trained batch 874 batch loss 1.27725184 epoch total loss 1.38130045\n",
      "Trained batch 875 batch loss 1.36027455 epoch total loss 1.38127637\n",
      "Trained batch 876 batch loss 1.27421403 epoch total loss 1.38115406\n",
      "Trained batch 877 batch loss 1.27434659 epoch total loss 1.38103223\n",
      "Trained batch 878 batch loss 1.38620365 epoch total loss 1.38103819\n",
      "Trained batch 879 batch loss 1.38148212 epoch total loss 1.38103867\n",
      "Trained batch 880 batch loss 1.49494112 epoch total loss 1.38116813\n",
      "Trained batch 881 batch loss 1.45648563 epoch total loss 1.38125372\n",
      "Trained batch 882 batch loss 1.42260051 epoch total loss 1.38130057\n",
      "Trained batch 883 batch loss 1.32919836 epoch total loss 1.38124168\n",
      "Trained batch 884 batch loss 1.43504167 epoch total loss 1.38130248\n",
      "Trained batch 885 batch loss 1.32553315 epoch total loss 1.38123953\n",
      "Trained batch 886 batch loss 1.34914625 epoch total loss 1.38120329\n",
      "Trained batch 887 batch loss 1.39947712 epoch total loss 1.38122392\n",
      "Trained batch 888 batch loss 1.27186322 epoch total loss 1.38110077\n",
      "Trained batch 889 batch loss 1.44567561 epoch total loss 1.38117337\n",
      "Trained batch 890 batch loss 1.45911062 epoch total loss 1.38126099\n",
      "Trained batch 891 batch loss 1.43985534 epoch total loss 1.38132668\n",
      "Trained batch 892 batch loss 1.45219922 epoch total loss 1.38140607\n",
      "Trained batch 893 batch loss 1.31276321 epoch total loss 1.38132918\n",
      "Trained batch 894 batch loss 1.42201471 epoch total loss 1.38137472\n",
      "Trained batch 895 batch loss 1.28940845 epoch total loss 1.38127196\n",
      "Trained batch 896 batch loss 1.34804821 epoch total loss 1.38123488\n",
      "Trained batch 897 batch loss 1.29784513 epoch total loss 1.3811419\n",
      "Trained batch 898 batch loss 1.26369357 epoch total loss 1.38101113\n",
      "Trained batch 899 batch loss 1.45163417 epoch total loss 1.38108969\n",
      "Trained batch 900 batch loss 1.27533937 epoch total loss 1.38097227\n",
      "Trained batch 901 batch loss 1.34163761 epoch total loss 1.38092864\n",
      "Trained batch 902 batch loss 1.40359282 epoch total loss 1.38095367\n",
      "Trained batch 903 batch loss 1.34269834 epoch total loss 1.38091123\n",
      "Trained batch 904 batch loss 1.29921746 epoch total loss 1.38082087\n",
      "Trained batch 905 batch loss 1.29674041 epoch total loss 1.38072801\n",
      "Trained batch 906 batch loss 1.23458934 epoch total loss 1.38056672\n",
      "Trained batch 907 batch loss 1.27513397 epoch total loss 1.38045049\n",
      "Trained batch 908 batch loss 1.27449989 epoch total loss 1.3803339\n",
      "Trained batch 909 batch loss 1.27692819 epoch total loss 1.38022017\n",
      "Trained batch 910 batch loss 1.35523248 epoch total loss 1.38019264\n",
      "Trained batch 911 batch loss 1.36509526 epoch total loss 1.38017619\n",
      "Trained batch 912 batch loss 1.32974124 epoch total loss 1.38012075\n",
      "Trained batch 913 batch loss 1.51095891 epoch total loss 1.38026416\n",
      "Trained batch 914 batch loss 1.43560314 epoch total loss 1.3803246\n",
      "Trained batch 915 batch loss 1.28094912 epoch total loss 1.38021612\n",
      "Trained batch 916 batch loss 1.14035606 epoch total loss 1.37995422\n",
      "Trained batch 917 batch loss 1.18896067 epoch total loss 1.37974596\n",
      "Trained batch 918 batch loss 1.32085395 epoch total loss 1.37968171\n",
      "Trained batch 919 batch loss 1.32451367 epoch total loss 1.37962162\n",
      "Trained batch 920 batch loss 1.5053575 epoch total loss 1.37975836\n",
      "Trained batch 921 batch loss 1.30063415 epoch total loss 1.37967253\n",
      "Trained batch 922 batch loss 1.40805376 epoch total loss 1.37970328\n",
      "Trained batch 923 batch loss 1.23416114 epoch total loss 1.37954557\n",
      "Trained batch 924 batch loss 1.35506237 epoch total loss 1.3795191\n",
      "Trained batch 925 batch loss 1.3147707 epoch total loss 1.37944913\n",
      "Trained batch 926 batch loss 1.39747834 epoch total loss 1.37946856\n",
      "Trained batch 927 batch loss 1.48058724 epoch total loss 1.37957776\n",
      "Trained batch 928 batch loss 1.50337684 epoch total loss 1.37971115\n",
      "Trained batch 929 batch loss 1.3164686 epoch total loss 1.37964308\n",
      "Trained batch 930 batch loss 1.32941961 epoch total loss 1.3795892\n",
      "Trained batch 931 batch loss 1.21719337 epoch total loss 1.37941468\n",
      "Trained batch 932 batch loss 1.46662354 epoch total loss 1.37950838\n",
      "Trained batch 933 batch loss 1.32904387 epoch total loss 1.37945437\n",
      "Trained batch 934 batch loss 1.42739701 epoch total loss 1.37950563\n",
      "Trained batch 935 batch loss 1.35990524 epoch total loss 1.37948465\n",
      "Trained batch 936 batch loss 1.31872094 epoch total loss 1.37941968\n",
      "Trained batch 937 batch loss 1.34240031 epoch total loss 1.37938023\n",
      "Trained batch 938 batch loss 1.24080801 epoch total loss 1.37923253\n",
      "Trained batch 939 batch loss 1.39085937 epoch total loss 1.37924492\n",
      "Trained batch 940 batch loss 1.37597406 epoch total loss 1.37924147\n",
      "Trained batch 941 batch loss 1.31121016 epoch total loss 1.37916911\n",
      "Trained batch 942 batch loss 1.3789072 epoch total loss 1.37916875\n",
      "Trained batch 943 batch loss 1.4095279 epoch total loss 1.37920105\n",
      "Trained batch 944 batch loss 1.44883871 epoch total loss 1.37927485\n",
      "Trained batch 945 batch loss 1.40034044 epoch total loss 1.37929714\n",
      "Trained batch 946 batch loss 1.45709717 epoch total loss 1.37937939\n",
      "Trained batch 947 batch loss 1.44488955 epoch total loss 1.37944865\n",
      "Trained batch 948 batch loss 1.33176017 epoch total loss 1.37939835\n",
      "Trained batch 949 batch loss 1.2934891 epoch total loss 1.37930787\n",
      "Trained batch 950 batch loss 1.29992807 epoch total loss 1.3792243\n",
      "Trained batch 951 batch loss 1.22396684 epoch total loss 1.3790611\n",
      "Trained batch 952 batch loss 1.2134974 epoch total loss 1.37888718\n",
      "Trained batch 953 batch loss 1.2724 epoch total loss 1.37877548\n",
      "Trained batch 954 batch loss 1.30465424 epoch total loss 1.37869775\n",
      "Trained batch 955 batch loss 1.37896442 epoch total loss 1.37869799\n",
      "Trained batch 956 batch loss 1.3482095 epoch total loss 1.37866616\n",
      "Trained batch 957 batch loss 1.28180742 epoch total loss 1.37856507\n",
      "Trained batch 958 batch loss 1.24312162 epoch total loss 1.37842369\n",
      "Trained batch 959 batch loss 1.23749328 epoch total loss 1.37827682\n",
      "Trained batch 960 batch loss 1.28996301 epoch total loss 1.3781848\n",
      "Trained batch 961 batch loss 1.24259627 epoch total loss 1.37804365\n",
      "Trained batch 962 batch loss 1.17604625 epoch total loss 1.3778336\n",
      "Trained batch 963 batch loss 1.26030266 epoch total loss 1.37771153\n",
      "Trained batch 964 batch loss 1.29685056 epoch total loss 1.37762773\n",
      "Trained batch 965 batch loss 1.27904773 epoch total loss 1.37752557\n",
      "Trained batch 966 batch loss 1.18198812 epoch total loss 1.37732315\n",
      "Trained batch 967 batch loss 1.27680969 epoch total loss 1.3772192\n",
      "Trained batch 968 batch loss 1.40860367 epoch total loss 1.37725163\n",
      "Trained batch 969 batch loss 1.29811597 epoch total loss 1.37717\n",
      "Trained batch 970 batch loss 1.55178571 epoch total loss 1.37735\n",
      "Trained batch 971 batch loss 1.4324435 epoch total loss 1.37740672\n",
      "Trained batch 972 batch loss 1.29199731 epoch total loss 1.37731886\n",
      "Trained batch 973 batch loss 1.36528635 epoch total loss 1.37730646\n",
      "Trained batch 974 batch loss 1.34293234 epoch total loss 1.37727106\n",
      "Trained batch 975 batch loss 1.379094 epoch total loss 1.37727296\n",
      "Trained batch 976 batch loss 1.25762224 epoch total loss 1.37715042\n",
      "Trained batch 977 batch loss 1.22988069 epoch total loss 1.37699962\n",
      "Trained batch 978 batch loss 1.4670341 epoch total loss 1.37709165\n",
      "Trained batch 979 batch loss 1.39265168 epoch total loss 1.37710762\n",
      "Trained batch 980 batch loss 1.50834143 epoch total loss 1.37724149\n",
      "Trained batch 981 batch loss 1.41038871 epoch total loss 1.37727523\n",
      "Trained batch 982 batch loss 1.39030266 epoch total loss 1.37728846\n",
      "Trained batch 983 batch loss 1.36198008 epoch total loss 1.37727284\n",
      "Trained batch 984 batch loss 1.32182336 epoch total loss 1.37721646\n",
      "Trained batch 985 batch loss 1.35505104 epoch total loss 1.37719405\n",
      "Trained batch 986 batch loss 1.26248145 epoch total loss 1.3770777\n",
      "Trained batch 987 batch loss 1.33899426 epoch total loss 1.37703907\n",
      "Trained batch 988 batch loss 1.37164235 epoch total loss 1.37703359\n",
      "Trained batch 989 batch loss 1.36045742 epoch total loss 1.37701678\n",
      "Trained batch 990 batch loss 1.35585594 epoch total loss 1.37699544\n",
      "Trained batch 991 batch loss 1.20533264 epoch total loss 1.37682223\n",
      "Trained batch 992 batch loss 1.19375825 epoch total loss 1.37663758\n",
      "Trained batch 993 batch loss 1.17440248 epoch total loss 1.37643397\n",
      "Trained batch 994 batch loss 1.29143238 epoch total loss 1.37634838\n",
      "Trained batch 995 batch loss 1.37943244 epoch total loss 1.37635148\n",
      "Trained batch 996 batch loss 1.59591222 epoch total loss 1.37657201\n",
      "Trained batch 997 batch loss 1.49554384 epoch total loss 1.37669122\n",
      "Trained batch 998 batch loss 1.36912251 epoch total loss 1.37668371\n",
      "Trained batch 999 batch loss 1.25422454 epoch total loss 1.37656116\n",
      "Trained batch 1000 batch loss 1.26235247 epoch total loss 1.37644684\n",
      "Trained batch 1001 batch loss 1.2597568 epoch total loss 1.37633038\n",
      "Trained batch 1002 batch loss 1.36611879 epoch total loss 1.37632012\n",
      "Trained batch 1003 batch loss 1.32074785 epoch total loss 1.37626481\n",
      "Trained batch 1004 batch loss 1.43208468 epoch total loss 1.37632036\n",
      "Trained batch 1005 batch loss 1.42910981 epoch total loss 1.37637293\n",
      "Trained batch 1006 batch loss 1.34662831 epoch total loss 1.37634337\n",
      "Trained batch 1007 batch loss 1.3267343 epoch total loss 1.37629414\n",
      "Trained batch 1008 batch loss 1.43304169 epoch total loss 1.3763504\n",
      "Trained batch 1009 batch loss 1.40528822 epoch total loss 1.37637901\n",
      "Trained batch 1010 batch loss 1.37479913 epoch total loss 1.37637746\n",
      "Trained batch 1011 batch loss 1.39048886 epoch total loss 1.37639141\n",
      "Trained batch 1012 batch loss 1.45698714 epoch total loss 1.37647116\n",
      "Trained batch 1013 batch loss 1.37587428 epoch total loss 1.37647057\n",
      "Trained batch 1014 batch loss 1.32460749 epoch total loss 1.37641931\n",
      "Trained batch 1015 batch loss 1.37072921 epoch total loss 1.3764137\n",
      "Trained batch 1016 batch loss 1.51354635 epoch total loss 1.37654865\n",
      "Trained batch 1017 batch loss 1.47196472 epoch total loss 1.37664247\n",
      "Trained batch 1018 batch loss 1.32126939 epoch total loss 1.37658811\n",
      "Trained batch 1019 batch loss 1.404217 epoch total loss 1.37661517\n",
      "Trained batch 1020 batch loss 1.43871868 epoch total loss 1.37667608\n",
      "Trained batch 1021 batch loss 1.39457309 epoch total loss 1.37669361\n",
      "Trained batch 1022 batch loss 1.40073168 epoch total loss 1.37671709\n",
      "Trained batch 1023 batch loss 1.35789573 epoch total loss 1.37669873\n",
      "Trained batch 1024 batch loss 1.48739123 epoch total loss 1.37680686\n",
      "Trained batch 1025 batch loss 1.42991018 epoch total loss 1.37685871\n",
      "Trained batch 1026 batch loss 1.30595422 epoch total loss 1.37678957\n",
      "Trained batch 1027 batch loss 1.32764351 epoch total loss 1.37674165\n",
      "Trained batch 1028 batch loss 1.2404325 epoch total loss 1.37660909\n",
      "Trained batch 1029 batch loss 1.25153494 epoch total loss 1.37648761\n",
      "Trained batch 1030 batch loss 1.15017843 epoch total loss 1.37626791\n",
      "Trained batch 1031 batch loss 1.21368122 epoch total loss 1.37611008\n",
      "Trained batch 1032 batch loss 1.19268346 epoch total loss 1.37593234\n",
      "Trained batch 1033 batch loss 1.06495929 epoch total loss 1.37563121\n",
      "Trained batch 1034 batch loss 1.10805726 epoch total loss 1.37537241\n",
      "Trained batch 1035 batch loss 0.985940695 epoch total loss 1.37499619\n",
      "Trained batch 1036 batch loss 1.23159289 epoch total loss 1.37485778\n",
      "Trained batch 1037 batch loss 1.34341526 epoch total loss 1.37482738\n",
      "Trained batch 1038 batch loss 1.35690355 epoch total loss 1.37481022\n",
      "Trained batch 1039 batch loss 1.34709632 epoch total loss 1.37478352\n",
      "Trained batch 1040 batch loss 1.30389035 epoch total loss 1.37471521\n",
      "Trained batch 1041 batch loss 1.48024249 epoch total loss 1.37481666\n",
      "Trained batch 1042 batch loss 1.30940652 epoch total loss 1.37475383\n",
      "Trained batch 1043 batch loss 1.46587157 epoch total loss 1.37484121\n",
      "Trained batch 1044 batch loss 1.18740654 epoch total loss 1.37466156\n",
      "Trained batch 1045 batch loss 1.35422373 epoch total loss 1.37464213\n",
      "Trained batch 1046 batch loss 1.27332783 epoch total loss 1.37454522\n",
      "Trained batch 1047 batch loss 1.26801908 epoch total loss 1.37444353\n",
      "Trained batch 1048 batch loss 1.21812463 epoch total loss 1.3742944\n",
      "Trained batch 1049 batch loss 1.22843289 epoch total loss 1.37415528\n",
      "Trained batch 1050 batch loss 1.27776885 epoch total loss 1.37406337\n",
      "Trained batch 1051 batch loss 1.23377573 epoch total loss 1.37393\n",
      "Trained batch 1052 batch loss 1.23284078 epoch total loss 1.37379575\n",
      "Trained batch 1053 batch loss 1.24244261 epoch total loss 1.37367105\n",
      "Trained batch 1054 batch loss 1.2736361 epoch total loss 1.37357616\n",
      "Trained batch 1055 batch loss 1.43654871 epoch total loss 1.37363577\n",
      "Trained batch 1056 batch loss 1.28252542 epoch total loss 1.37354946\n",
      "Trained batch 1057 batch loss 1.33846855 epoch total loss 1.37351632\n",
      "Trained batch 1058 batch loss 1.41749334 epoch total loss 1.37355793\n",
      "Trained batch 1059 batch loss 1.27763975 epoch total loss 1.37346721\n",
      "Trained batch 1060 batch loss 1.24382591 epoch total loss 1.3733449\n",
      "Trained batch 1061 batch loss 1.34781742 epoch total loss 1.37332082\n",
      "Trained batch 1062 batch loss 1.53140402 epoch total loss 1.37346959\n",
      "Trained batch 1063 batch loss 1.36594057 epoch total loss 1.37346256\n",
      "Trained batch 1064 batch loss 1.3247937 epoch total loss 1.3734169\n",
      "Trained batch 1065 batch loss 1.48903227 epoch total loss 1.37352538\n",
      "Trained batch 1066 batch loss 1.54641426 epoch total loss 1.37368762\n",
      "Trained batch 1067 batch loss 1.46762967 epoch total loss 1.3737756\n",
      "Trained batch 1068 batch loss 1.45225 epoch total loss 1.37384915\n",
      "Trained batch 1069 batch loss 1.36673915 epoch total loss 1.37384248\n",
      "Trained batch 1070 batch loss 1.37067175 epoch total loss 1.3738395\n",
      "Trained batch 1071 batch loss 1.20810592 epoch total loss 1.37368476\n",
      "Trained batch 1072 batch loss 1.36678255 epoch total loss 1.37367845\n",
      "Trained batch 1073 batch loss 1.35930061 epoch total loss 1.37366498\n",
      "Trained batch 1074 batch loss 1.26330757 epoch total loss 1.37356222\n",
      "Trained batch 1075 batch loss 1.26531661 epoch total loss 1.37346148\n",
      "Trained batch 1076 batch loss 1.20437276 epoch total loss 1.37330425\n",
      "Trained batch 1077 batch loss 1.22255683 epoch total loss 1.3731643\n",
      "Trained batch 1078 batch loss 1.25263858 epoch total loss 1.37305248\n",
      "Trained batch 1079 batch loss 1.53738844 epoch total loss 1.37320483\n",
      "Trained batch 1080 batch loss 1.64235616 epoch total loss 1.37345397\n",
      "Trained batch 1081 batch loss 1.52206552 epoch total loss 1.37359154\n",
      "Trained batch 1082 batch loss 1.47910571 epoch total loss 1.37368906\n",
      "Trained batch 1083 batch loss 1.47165394 epoch total loss 1.37377954\n",
      "Trained batch 1084 batch loss 1.49207771 epoch total loss 1.37388861\n",
      "Trained batch 1085 batch loss 1.42518187 epoch total loss 1.37393594\n",
      "Trained batch 1086 batch loss 1.33974075 epoch total loss 1.37390435\n",
      "Trained batch 1087 batch loss 1.36574256 epoch total loss 1.37389684\n",
      "Trained batch 1088 batch loss 1.34821725 epoch total loss 1.37387335\n",
      "Trained batch 1089 batch loss 1.43677855 epoch total loss 1.37393105\n",
      "Trained batch 1090 batch loss 1.43851507 epoch total loss 1.3739903\n",
      "Trained batch 1091 batch loss 1.24021769 epoch total loss 1.37386763\n",
      "Trained batch 1092 batch loss 1.43542612 epoch total loss 1.37392402\n",
      "Trained batch 1093 batch loss 1.38922596 epoch total loss 1.37393808\n",
      "Trained batch 1094 batch loss 1.39359593 epoch total loss 1.37395608\n",
      "Trained batch 1095 batch loss 1.42136097 epoch total loss 1.37399936\n",
      "Trained batch 1096 batch loss 1.40281689 epoch total loss 1.3740257\n",
      "Trained batch 1097 batch loss 1.44345629 epoch total loss 1.374089\n",
      "Trained batch 1098 batch loss 1.46534324 epoch total loss 1.37417209\n",
      "Trained batch 1099 batch loss 1.28962779 epoch total loss 1.3740952\n",
      "Trained batch 1100 batch loss 1.36011648 epoch total loss 1.37408245\n",
      "Trained batch 1101 batch loss 1.34921217 epoch total loss 1.37405992\n",
      "Trained batch 1102 batch loss 1.39722705 epoch total loss 1.3740809\n",
      "Trained batch 1103 batch loss 1.36795354 epoch total loss 1.37407529\n",
      "Trained batch 1104 batch loss 1.32700491 epoch total loss 1.37403274\n",
      "Trained batch 1105 batch loss 1.24823785 epoch total loss 1.37391889\n",
      "Trained batch 1106 batch loss 1.16793394 epoch total loss 1.37373269\n",
      "Trained batch 1107 batch loss 1.24437666 epoch total loss 1.37361586\n",
      "Trained batch 1108 batch loss 1.20435476 epoch total loss 1.37346315\n",
      "Trained batch 1109 batch loss 1.34677637 epoch total loss 1.37343907\n",
      "Trained batch 1110 batch loss 1.22039 epoch total loss 1.37330115\n",
      "Trained batch 1111 batch loss 1.22434783 epoch total loss 1.37316704\n",
      "Trained batch 1112 batch loss 1.27904534 epoch total loss 1.3730824\n",
      "Trained batch 1113 batch loss 1.48558497 epoch total loss 1.37318349\n",
      "Trained batch 1114 batch loss 1.42328978 epoch total loss 1.37322855\n",
      "Trained batch 1115 batch loss 1.36291409 epoch total loss 1.37321925\n",
      "Trained batch 1116 batch loss 1.38078582 epoch total loss 1.37322605\n",
      "Trained batch 1117 batch loss 1.33710277 epoch total loss 1.37319374\n",
      "Trained batch 1118 batch loss 1.22365451 epoch total loss 1.37306\n",
      "Trained batch 1119 batch loss 1.26638675 epoch total loss 1.37296462\n",
      "Trained batch 1120 batch loss 1.23196888 epoch total loss 1.37283874\n",
      "Trained batch 1121 batch loss 1.36828375 epoch total loss 1.37283468\n",
      "Trained batch 1122 batch loss 1.40646529 epoch total loss 1.3728646\n",
      "Trained batch 1123 batch loss 1.30829287 epoch total loss 1.37280715\n",
      "Trained batch 1124 batch loss 1.33735681 epoch total loss 1.37277567\n",
      "Trained batch 1125 batch loss 1.25248122 epoch total loss 1.37266874\n",
      "Trained batch 1126 batch loss 1.34997463 epoch total loss 1.3726486\n",
      "Trained batch 1127 batch loss 1.18835676 epoch total loss 1.37248504\n",
      "Trained batch 1128 batch loss 1.23880935 epoch total loss 1.37236655\n",
      "Trained batch 1129 batch loss 1.28279388 epoch total loss 1.37228715\n",
      "Trained batch 1130 batch loss 1.29462504 epoch total loss 1.37221849\n",
      "Trained batch 1131 batch loss 1.43761277 epoch total loss 1.37227631\n",
      "Trained batch 1132 batch loss 1.23897052 epoch total loss 1.37215865\n",
      "Trained batch 1133 batch loss 1.2316817 epoch total loss 1.37203467\n",
      "Trained batch 1134 batch loss 1.29154313 epoch total loss 1.37196362\n",
      "Trained batch 1135 batch loss 1.39555216 epoch total loss 1.37198436\n",
      "Trained batch 1136 batch loss 1.41783261 epoch total loss 1.37202477\n",
      "Trained batch 1137 batch loss 1.23582363 epoch total loss 1.37190497\n",
      "Trained batch 1138 batch loss 1.1398989 epoch total loss 1.37170112\n",
      "Trained batch 1139 batch loss 1.14124584 epoch total loss 1.3714987\n",
      "Trained batch 1140 batch loss 1.31719363 epoch total loss 1.37145102\n",
      "Trained batch 1141 batch loss 1.28411365 epoch total loss 1.37137449\n",
      "Trained batch 1142 batch loss 1.16751993 epoch total loss 1.37119591\n",
      "Trained batch 1143 batch loss 1.285671 epoch total loss 1.37112105\n",
      "Trained batch 1144 batch loss 1.37492466 epoch total loss 1.37112439\n",
      "Trained batch 1145 batch loss 1.40874577 epoch total loss 1.37115717\n",
      "Trained batch 1146 batch loss 1.37674522 epoch total loss 1.37116206\n",
      "Trained batch 1147 batch loss 1.33992946 epoch total loss 1.37113488\n",
      "Trained batch 1148 batch loss 1.5572449 epoch total loss 1.371297\n",
      "Trained batch 1149 batch loss 1.53522849 epoch total loss 1.3714397\n",
      "Trained batch 1150 batch loss 1.39323497 epoch total loss 1.37145853\n",
      "Trained batch 1151 batch loss 1.3683219 epoch total loss 1.37145579\n",
      "Trained batch 1152 batch loss 1.37081409 epoch total loss 1.37145531\n",
      "Trained batch 1153 batch loss 1.38762057 epoch total loss 1.37146926\n",
      "Trained batch 1154 batch loss 1.32232606 epoch total loss 1.37142658\n",
      "Trained batch 1155 batch loss 1.38806391 epoch total loss 1.37144101\n",
      "Trained batch 1156 batch loss 1.38459778 epoch total loss 1.37145245\n",
      "Trained batch 1157 batch loss 1.36671567 epoch total loss 1.3714484\n",
      "Trained batch 1158 batch loss 1.36839855 epoch total loss 1.37144578\n",
      "Trained batch 1159 batch loss 1.33223009 epoch total loss 1.37141192\n",
      "Trained batch 1160 batch loss 1.24179947 epoch total loss 1.37130022\n",
      "Trained batch 1161 batch loss 1.35267127 epoch total loss 1.37128413\n",
      "Trained batch 1162 batch loss 1.39791083 epoch total loss 1.37130713\n",
      "Trained batch 1163 batch loss 1.32836604 epoch total loss 1.37127018\n",
      "Trained batch 1164 batch loss 1.37297106 epoch total loss 1.37127161\n",
      "Trained batch 1165 batch loss 1.25558 epoch total loss 1.37117231\n",
      "Trained batch 1166 batch loss 1.16878605 epoch total loss 1.37099874\n",
      "Trained batch 1167 batch loss 1.25372052 epoch total loss 1.37089825\n",
      "Trained batch 1168 batch loss 1.29691648 epoch total loss 1.37083483\n",
      "Trained batch 1169 batch loss 1.25220752 epoch total loss 1.37073338\n",
      "Trained batch 1170 batch loss 1.39735162 epoch total loss 1.37075615\n",
      "Trained batch 1171 batch loss 1.4399364 epoch total loss 1.37081516\n",
      "Trained batch 1172 batch loss 1.33051753 epoch total loss 1.37078083\n",
      "Trained batch 1173 batch loss 1.30693507 epoch total loss 1.37072635\n",
      "Trained batch 1174 batch loss 1.306126 epoch total loss 1.37067139\n",
      "Trained batch 1175 batch loss 1.12356734 epoch total loss 1.37046111\n",
      "Trained batch 1176 batch loss 1.09656167 epoch total loss 1.37022817\n",
      "Trained batch 1177 batch loss 1.27515388 epoch total loss 1.37014735\n",
      "Trained batch 1178 batch loss 1.58438516 epoch total loss 1.37032926\n",
      "Trained batch 1179 batch loss 1.38481224 epoch total loss 1.37034142\n",
      "Trained batch 1180 batch loss 1.25225711 epoch total loss 1.37024128\n",
      "Trained batch 1181 batch loss 1.35840106 epoch total loss 1.37023127\n",
      "Trained batch 1182 batch loss 1.27351034 epoch total loss 1.37014949\n",
      "Trained batch 1183 batch loss 1.3287847 epoch total loss 1.37011445\n",
      "Trained batch 1184 batch loss 1.27091253 epoch total loss 1.37003064\n",
      "Trained batch 1185 batch loss 1.25189734 epoch total loss 1.3699311\n",
      "Trained batch 1186 batch loss 1.25838768 epoch total loss 1.36983705\n",
      "Trained batch 1187 batch loss 1.36222017 epoch total loss 1.36983061\n",
      "Trained batch 1188 batch loss 1.35637891 epoch total loss 1.36981916\n",
      "Trained batch 1189 batch loss 1.33781445 epoch total loss 1.36979222\n",
      "Trained batch 1190 batch loss 1.22376585 epoch total loss 1.36966956\n",
      "Trained batch 1191 batch loss 1.24628472 epoch total loss 1.36956596\n",
      "Trained batch 1192 batch loss 1.35239363 epoch total loss 1.36955154\n",
      "Trained batch 1193 batch loss 1.44772124 epoch total loss 1.3696171\n",
      "Trained batch 1194 batch loss 1.47174966 epoch total loss 1.3697027\n",
      "Trained batch 1195 batch loss 1.50195801 epoch total loss 1.36981344\n",
      "Trained batch 1196 batch loss 1.28905857 epoch total loss 1.36974585\n",
      "Trained batch 1197 batch loss 1.26571405 epoch total loss 1.36965895\n",
      "Trained batch 1198 batch loss 1.24539447 epoch total loss 1.36955523\n",
      "Trained batch 1199 batch loss 1.28941751 epoch total loss 1.36948836\n",
      "Trained batch 1200 batch loss 1.34425116 epoch total loss 1.36946738\n",
      "Trained batch 1201 batch loss 1.28678286 epoch total loss 1.36939847\n",
      "Trained batch 1202 batch loss 1.34636188 epoch total loss 1.36937928\n",
      "Trained batch 1203 batch loss 1.48428619 epoch total loss 1.36947477\n",
      "Trained batch 1204 batch loss 1.44953442 epoch total loss 1.36954129\n",
      "Trained batch 1205 batch loss 1.37431979 epoch total loss 1.36954522\n",
      "Trained batch 1206 batch loss 1.37336445 epoch total loss 1.36954844\n",
      "Trained batch 1207 batch loss 1.34765577 epoch total loss 1.36953032\n",
      "Trained batch 1208 batch loss 1.34114373 epoch total loss 1.36950684\n",
      "Trained batch 1209 batch loss 1.33114278 epoch total loss 1.36947513\n",
      "Trained batch 1210 batch loss 1.30848837 epoch total loss 1.3694247\n",
      "Trained batch 1211 batch loss 1.25364375 epoch total loss 1.36932909\n",
      "Trained batch 1212 batch loss 1.30154693 epoch total loss 1.36927319\n",
      "Trained batch 1213 batch loss 1.24906826 epoch total loss 1.369174\n",
      "Trained batch 1214 batch loss 1.22592902 epoch total loss 1.36905611\n",
      "Trained batch 1215 batch loss 1.23450458 epoch total loss 1.36894536\n",
      "Trained batch 1216 batch loss 1.22602689 epoch total loss 1.36882782\n",
      "Trained batch 1217 batch loss 1.37765527 epoch total loss 1.36883509\n",
      "Trained batch 1218 batch loss 1.28258121 epoch total loss 1.36876428\n",
      "Trained batch 1219 batch loss 1.32368183 epoch total loss 1.36872733\n",
      "Trained batch 1220 batch loss 1.25680637 epoch total loss 1.36863565\n",
      "Trained batch 1221 batch loss 1.23870397 epoch total loss 1.3685292\n",
      "Trained batch 1222 batch loss 1.32612753 epoch total loss 1.36849451\n",
      "Trained batch 1223 batch loss 1.34866726 epoch total loss 1.3684783\n",
      "Trained batch 1224 batch loss 1.39052951 epoch total loss 1.3684963\n",
      "Trained batch 1225 batch loss 1.39440846 epoch total loss 1.3685174\n",
      "Trained batch 1226 batch loss 1.26386428 epoch total loss 1.36843204\n",
      "Trained batch 1227 batch loss 1.25773942 epoch total loss 1.3683418\n",
      "Trained batch 1228 batch loss 1.29392076 epoch total loss 1.36828125\n",
      "Trained batch 1229 batch loss 1.37103522 epoch total loss 1.36828351\n",
      "Trained batch 1230 batch loss 1.37646568 epoch total loss 1.36829019\n",
      "Trained batch 1231 batch loss 1.41412735 epoch total loss 1.3683275\n",
      "Trained batch 1232 batch loss 1.49262702 epoch total loss 1.36842847\n",
      "Trained batch 1233 batch loss 1.45323837 epoch total loss 1.36849725\n",
      "Trained batch 1234 batch loss 1.40141559 epoch total loss 1.36852384\n",
      "Trained batch 1235 batch loss 1.31608772 epoch total loss 1.3684814\n",
      "Trained batch 1236 batch loss 1.3255614 epoch total loss 1.36844659\n",
      "Trained batch 1237 batch loss 1.45218635 epoch total loss 1.3685143\n",
      "Trained batch 1238 batch loss 1.37710023 epoch total loss 1.36852121\n",
      "Trained batch 1239 batch loss 1.32626283 epoch total loss 1.36848712\n",
      "Trained batch 1240 batch loss 1.06212354 epoch total loss 1.36824012\n",
      "Trained batch 1241 batch loss 1.33510864 epoch total loss 1.3682133\n",
      "Trained batch 1242 batch loss 1.3309592 epoch total loss 1.36818337\n",
      "Trained batch 1243 batch loss 1.18089199 epoch total loss 1.36803269\n",
      "Trained batch 1244 batch loss 1.20376408 epoch total loss 1.36790061\n",
      "Trained batch 1245 batch loss 1.19875479 epoch total loss 1.36776471\n",
      "Trained batch 1246 batch loss 1.22687149 epoch total loss 1.3676517\n",
      "Trained batch 1247 batch loss 1.1997745 epoch total loss 1.36751711\n",
      "Trained batch 1248 batch loss 1.18584597 epoch total loss 1.36737144\n",
      "Trained batch 1249 batch loss 1.16419852 epoch total loss 1.36720884\n",
      "Trained batch 1250 batch loss 1.22570062 epoch total loss 1.36709559\n",
      "Trained batch 1251 batch loss 1.29229856 epoch total loss 1.36703587\n",
      "Trained batch 1252 batch loss 1.24646974 epoch total loss 1.36693954\n",
      "Trained batch 1253 batch loss 1.27194262 epoch total loss 1.36686373\n",
      "Trained batch 1254 batch loss 1.18608773 epoch total loss 1.3667196\n",
      "Trained batch 1255 batch loss 1.37214088 epoch total loss 1.3667239\n",
      "Trained batch 1256 batch loss 1.36045349 epoch total loss 1.36671901\n",
      "Trained batch 1257 batch loss 1.34775853 epoch total loss 1.36670387\n",
      "Trained batch 1258 batch loss 1.56980991 epoch total loss 1.3668654\n",
      "Trained batch 1259 batch loss 1.51876795 epoch total loss 1.36698604\n",
      "Trained batch 1260 batch loss 1.34723103 epoch total loss 1.36697042\n",
      "Trained batch 1261 batch loss 1.38518131 epoch total loss 1.36698484\n",
      "Trained batch 1262 batch loss 1.5059166 epoch total loss 1.36709487\n",
      "Trained batch 1263 batch loss 1.39453566 epoch total loss 1.36711657\n",
      "Trained batch 1264 batch loss 1.43871474 epoch total loss 1.36717319\n",
      "Trained batch 1265 batch loss 1.28376746 epoch total loss 1.36710727\n",
      "Trained batch 1266 batch loss 1.30661952 epoch total loss 1.36705959\n",
      "Trained batch 1267 batch loss 1.25330174 epoch total loss 1.3669697\n",
      "Trained batch 1268 batch loss 1.36724854 epoch total loss 1.36697\n",
      "Trained batch 1269 batch loss 1.32703948 epoch total loss 1.36693847\n",
      "Trained batch 1270 batch loss 1.36968935 epoch total loss 1.36694062\n",
      "Trained batch 1271 batch loss 1.40234971 epoch total loss 1.36696839\n",
      "Trained batch 1272 batch loss 1.3486973 epoch total loss 1.36695409\n",
      "Trained batch 1273 batch loss 1.49552989 epoch total loss 1.36705506\n",
      "Trained batch 1274 batch loss 1.24289 epoch total loss 1.36695766\n",
      "Trained batch 1275 batch loss 1.31543207 epoch total loss 1.36691725\n",
      "Trained batch 1276 batch loss 1.19963384 epoch total loss 1.36678612\n",
      "Trained batch 1277 batch loss 1.36635923 epoch total loss 1.36678576\n",
      "Trained batch 1278 batch loss 1.28347492 epoch total loss 1.36672056\n",
      "Trained batch 1279 batch loss 1.32163954 epoch total loss 1.36668527\n",
      "Trained batch 1280 batch loss 1.35604978 epoch total loss 1.36667705\n",
      "Trained batch 1281 batch loss 1.38250208 epoch total loss 1.36668932\n",
      "Trained batch 1282 batch loss 1.31816018 epoch total loss 1.36665142\n",
      "Trained batch 1283 batch loss 1.34019923 epoch total loss 1.36663079\n",
      "Trained batch 1284 batch loss 1.43408811 epoch total loss 1.36668336\n",
      "Trained batch 1285 batch loss 1.39428568 epoch total loss 1.36670482\n",
      "Trained batch 1286 batch loss 1.36483037 epoch total loss 1.36670339\n",
      "Trained batch 1287 batch loss 1.35013008 epoch total loss 1.36669052\n",
      "Trained batch 1288 batch loss 1.37699628 epoch total loss 1.3666985\n",
      "Trained batch 1289 batch loss 1.31374383 epoch total loss 1.36665738\n",
      "Trained batch 1290 batch loss 1.25377822 epoch total loss 1.36656988\n",
      "Trained batch 1291 batch loss 1.34502542 epoch total loss 1.36655319\n",
      "Trained batch 1292 batch loss 1.29921234 epoch total loss 1.36650097\n",
      "Trained batch 1293 batch loss 1.28062105 epoch total loss 1.36643457\n",
      "Trained batch 1294 batch loss 1.32443917 epoch total loss 1.36640215\n",
      "Trained batch 1295 batch loss 1.18348408 epoch total loss 1.36626089\n",
      "Trained batch 1296 batch loss 1.23384356 epoch total loss 1.36615872\n",
      "Trained batch 1297 batch loss 1.28727937 epoch total loss 1.36609793\n",
      "Trained batch 1298 batch loss 1.41659021 epoch total loss 1.36613679\n",
      "Trained batch 1299 batch loss 1.32863379 epoch total loss 1.36610794\n",
      "Trained batch 1300 batch loss 1.32776761 epoch total loss 1.3660785\n",
      "Trained batch 1301 batch loss 1.28645658 epoch total loss 1.36601722\n",
      "Trained batch 1302 batch loss 1.18081033 epoch total loss 1.36587501\n",
      "Trained batch 1303 batch loss 1.20297825 epoch total loss 1.36575\n",
      "Trained batch 1304 batch loss 1.26351964 epoch total loss 1.36567163\n",
      "Trained batch 1305 batch loss 1.22551429 epoch total loss 1.36556423\n",
      "Trained batch 1306 batch loss 1.26916349 epoch total loss 1.36549044\n",
      "Trained batch 1307 batch loss 1.29321635 epoch total loss 1.36543512\n",
      "Trained batch 1308 batch loss 1.28347015 epoch total loss 1.36537242\n",
      "Trained batch 1309 batch loss 1.2993083 epoch total loss 1.36532199\n",
      "Trained batch 1310 batch loss 1.37487435 epoch total loss 1.36532927\n",
      "Trained batch 1311 batch loss 1.27036 epoch total loss 1.36525679\n",
      "Trained batch 1312 batch loss 1.36256802 epoch total loss 1.36525476\n",
      "Trained batch 1313 batch loss 1.10449672 epoch total loss 1.36505616\n",
      "Trained batch 1314 batch loss 1.16603947 epoch total loss 1.36490464\n",
      "Trained batch 1315 batch loss 1.29829633 epoch total loss 1.3648541\n",
      "Trained batch 1316 batch loss 1.28010154 epoch total loss 1.36478972\n",
      "Trained batch 1317 batch loss 1.43785846 epoch total loss 1.36484516\n",
      "Trained batch 1318 batch loss 1.45748901 epoch total loss 1.36491549\n",
      "Trained batch 1319 batch loss 1.57929075 epoch total loss 1.36507809\n",
      "Trained batch 1320 batch loss 1.44434416 epoch total loss 1.36513805\n",
      "Trained batch 1321 batch loss 1.31449866 epoch total loss 1.36509979\n",
      "Trained batch 1322 batch loss 1.19450092 epoch total loss 1.36497068\n",
      "Trained batch 1323 batch loss 1.24302852 epoch total loss 1.36487854\n",
      "Trained batch 1324 batch loss 1.25067663 epoch total loss 1.36479223\n",
      "Trained batch 1325 batch loss 1.35611045 epoch total loss 1.36478567\n",
      "Trained batch 1326 batch loss 1.25814116 epoch total loss 1.36470532\n",
      "Trained batch 1327 batch loss 1.31519485 epoch total loss 1.36466801\n",
      "Trained batch 1328 batch loss 1.19837403 epoch total loss 1.36454272\n",
      "Trained batch 1329 batch loss 1.39189482 epoch total loss 1.36456335\n",
      "Trained batch 1330 batch loss 1.30198276 epoch total loss 1.36451626\n",
      "Trained batch 1331 batch loss 1.19085813 epoch total loss 1.36438584\n",
      "Trained batch 1332 batch loss 1.11137342 epoch total loss 1.36419582\n",
      "Trained batch 1333 batch loss 1.02839875 epoch total loss 1.36394393\n",
      "Trained batch 1334 batch loss 1.15298784 epoch total loss 1.36378586\n",
      "Trained batch 1335 batch loss 1.35622287 epoch total loss 1.36378014\n",
      "Trained batch 1336 batch loss 1.52560592 epoch total loss 1.36390126\n",
      "Trained batch 1337 batch loss 1.36296344 epoch total loss 1.36390054\n",
      "Trained batch 1338 batch loss 1.29444432 epoch total loss 1.36384869\n",
      "Trained batch 1339 batch loss 1.34795821 epoch total loss 1.36383677\n",
      "Trained batch 1340 batch loss 1.18644333 epoch total loss 1.36370432\n",
      "Trained batch 1341 batch loss 1.25627184 epoch total loss 1.36362422\n",
      "Trained batch 1342 batch loss 1.35589671 epoch total loss 1.36361849\n",
      "Trained batch 1343 batch loss 1.36041391 epoch total loss 1.36361611\n",
      "Trained batch 1344 batch loss 1.26268291 epoch total loss 1.36354101\n",
      "Trained batch 1345 batch loss 1.33396077 epoch total loss 1.36351907\n",
      "Trained batch 1346 batch loss 1.27103305 epoch total loss 1.36345029\n",
      "Trained batch 1347 batch loss 1.39587104 epoch total loss 1.36347437\n",
      "Trained batch 1348 batch loss 1.32017899 epoch total loss 1.3634423\n",
      "Trained batch 1349 batch loss 1.22499156 epoch total loss 1.36333966\n",
      "Trained batch 1350 batch loss 1.40132713 epoch total loss 1.3633678\n",
      "Trained batch 1351 batch loss 1.27873302 epoch total loss 1.36330509\n",
      "Trained batch 1352 batch loss 1.25630808 epoch total loss 1.36322594\n",
      "Trained batch 1353 batch loss 1.24838591 epoch total loss 1.36314118\n",
      "Trained batch 1354 batch loss 1.35912585 epoch total loss 1.3631382\n",
      "Trained batch 1355 batch loss 1.39545774 epoch total loss 1.36316204\n",
      "Trained batch 1356 batch loss 1.39754 epoch total loss 1.36318743\n",
      "Trained batch 1357 batch loss 1.44633913 epoch total loss 1.36324871\n",
      "Trained batch 1358 batch loss 1.35560989 epoch total loss 1.3632431\n",
      "Trained batch 1359 batch loss 1.42528784 epoch total loss 1.36328876\n",
      "Trained batch 1360 batch loss 1.38501227 epoch total loss 1.36330473\n",
      "Trained batch 1361 batch loss 1.26517844 epoch total loss 1.36323249\n",
      "Trained batch 1362 batch loss 1.28846145 epoch total loss 1.36317766\n",
      "Trained batch 1363 batch loss 1.35316467 epoch total loss 1.36317027\n",
      "Trained batch 1364 batch loss 1.30781567 epoch total loss 1.36312973\n",
      "Trained batch 1365 batch loss 1.18936181 epoch total loss 1.36300242\n",
      "Trained batch 1366 batch loss 1.33001041 epoch total loss 1.36297822\n",
      "Trained batch 1367 batch loss 1.20770776 epoch total loss 1.36286473\n",
      "Trained batch 1368 batch loss 1.36470509 epoch total loss 1.36286604\n",
      "Trained batch 1369 batch loss 1.29751158 epoch total loss 1.36281824\n",
      "Trained batch 1370 batch loss 1.34008 epoch total loss 1.36280167\n",
      "Trained batch 1371 batch loss 1.42375696 epoch total loss 1.36284614\n",
      "Trained batch 1372 batch loss 1.32649112 epoch total loss 1.36281967\n",
      "Trained batch 1373 batch loss 1.22888064 epoch total loss 1.36272216\n",
      "Trained batch 1374 batch loss 1.32448876 epoch total loss 1.36269426\n",
      "Trained batch 1375 batch loss 1.20632744 epoch total loss 1.36258054\n",
      "Trained batch 1376 batch loss 1.27384901 epoch total loss 1.36251605\n",
      "Trained batch 1377 batch loss 1.21064758 epoch total loss 1.36240578\n",
      "Trained batch 1378 batch loss 1.26916099 epoch total loss 1.36233807\n",
      "Trained batch 1379 batch loss 1.39905071 epoch total loss 1.36236465\n",
      "Trained batch 1380 batch loss 1.46734619 epoch total loss 1.36244071\n",
      "Trained batch 1381 batch loss 1.54290199 epoch total loss 1.36257136\n",
      "Trained batch 1382 batch loss 1.47897136 epoch total loss 1.36265564\n",
      "Trained batch 1383 batch loss 1.38327527 epoch total loss 1.36267054\n",
      "Trained batch 1384 batch loss 1.34191024 epoch total loss 1.36265552\n",
      "Trained batch 1385 batch loss 1.15536714 epoch total loss 1.36250591\n",
      "Trained batch 1386 batch loss 1.08095264 epoch total loss 1.36230278\n",
      "Trained batch 1387 batch loss 1.07669306 epoch total loss 1.36209679\n",
      "Trained batch 1388 batch loss 1.09180582 epoch total loss 1.36190212\n",
      "Epoch 2 train loss 1.361902117729187\n",
      "Validated batch 1 batch loss 1.30556726\n",
      "Validated batch 2 batch loss 1.16968954\n",
      "Validated batch 3 batch loss 1.33080137\n",
      "Validated batch 4 batch loss 1.23156273\n",
      "Validated batch 5 batch loss 1.28812015\n",
      "Validated batch 6 batch loss 1.33881152\n",
      "Validated batch 7 batch loss 1.29197061\n",
      "Validated batch 8 batch loss 1.43259788\n",
      "Validated batch 9 batch loss 1.3993516\n",
      "Validated batch 10 batch loss 1.30021966\n",
      "Validated batch 11 batch loss 1.30665135\n",
      "Validated batch 12 batch loss 1.37788975\n",
      "Validated batch 13 batch loss 1.39657676\n",
      "Validated batch 14 batch loss 1.38689518\n",
      "Validated batch 15 batch loss 1.35531545\n",
      "Validated batch 16 batch loss 1.41303515\n",
      "Validated batch 17 batch loss 1.3781693\n",
      "Validated batch 18 batch loss 1.21386552\n",
      "Validated batch 19 batch loss 1.32169545\n",
      "Validated batch 20 batch loss 1.37855637\n",
      "Validated batch 21 batch loss 1.31154203\n",
      "Validated batch 22 batch loss 1.34612608\n",
      "Validated batch 23 batch loss 1.28334904\n",
      "Validated batch 24 batch loss 1.37225688\n",
      "Validated batch 25 batch loss 1.30483484\n",
      "Validated batch 26 batch loss 1.28025985\n",
      "Validated batch 27 batch loss 1.25033557\n",
      "Validated batch 28 batch loss 1.34237194\n",
      "Validated batch 29 batch loss 1.42568302\n",
      "Validated batch 30 batch loss 1.21690559\n",
      "Validated batch 31 batch loss 1.32089043\n",
      "Validated batch 32 batch loss 1.32348609\n",
      "Validated batch 33 batch loss 1.31525195\n",
      "Validated batch 34 batch loss 1.33332372\n",
      "Validated batch 35 batch loss 1.19985747\n",
      "Validated batch 36 batch loss 1.46493232\n",
      "Validated batch 37 batch loss 1.23069334\n",
      "Validated batch 38 batch loss 1.34570718\n",
      "Validated batch 39 batch loss 1.31065893\n",
      "Validated batch 40 batch loss 1.38358366\n",
      "Validated batch 41 batch loss 1.16670942\n",
      "Validated batch 42 batch loss 1.29949129\n",
      "Validated batch 43 batch loss 1.26463854\n",
      "Validated batch 44 batch loss 1.33595181\n",
      "Validated batch 45 batch loss 1.30427527\n",
      "Validated batch 46 batch loss 1.30101573\n",
      "Validated batch 47 batch loss 1.2267909\n",
      "Validated batch 48 batch loss 1.34000015\n",
      "Validated batch 49 batch loss 1.34696352\n",
      "Validated batch 50 batch loss 1.24176013\n",
      "Validated batch 51 batch loss 1.37639213\n",
      "Validated batch 52 batch loss 1.44576621\n",
      "Validated batch 53 batch loss 1.15137506\n",
      "Validated batch 54 batch loss 1.33918142\n",
      "Validated batch 55 batch loss 1.31278992\n",
      "Validated batch 56 batch loss 1.36247182\n",
      "Validated batch 57 batch loss 1.35267186\n",
      "Validated batch 58 batch loss 1.193241\n",
      "Validated batch 59 batch loss 1.16435075\n",
      "Validated batch 60 batch loss 1.29998422\n",
      "Validated batch 61 batch loss 1.27888227\n",
      "Validated batch 62 batch loss 1.24697351\n",
      "Validated batch 63 batch loss 1.34387887\n",
      "Validated batch 64 batch loss 1.2638098\n",
      "Validated batch 65 batch loss 1.30809093\n",
      "Validated batch 66 batch loss 1.35295534\n",
      "Validated batch 67 batch loss 1.32452321\n",
      "Validated batch 68 batch loss 1.3201642\n",
      "Validated batch 69 batch loss 1.20408964\n",
      "Validated batch 70 batch loss 1.2591182\n",
      "Validated batch 71 batch loss 1.18802416\n",
      "Validated batch 72 batch loss 1.28706193\n",
      "Validated batch 73 batch loss 1.24534762\n",
      "Validated batch 74 batch loss 1.2677505\n",
      "Validated batch 75 batch loss 1.32303965\n",
      "Validated batch 76 batch loss 1.34091926\n",
      "Validated batch 77 batch loss 1.28087199\n",
      "Validated batch 78 batch loss 1.32903361\n",
      "Validated batch 79 batch loss 1.2983042\n",
      "Validated batch 80 batch loss 1.35660577\n",
      "Validated batch 81 batch loss 1.33386993\n",
      "Validated batch 82 batch loss 1.25985265\n",
      "Validated batch 83 batch loss 1.26874936\n",
      "Validated batch 84 batch loss 1.32967758\n",
      "Validated batch 85 batch loss 1.27338195\n",
      "Validated batch 86 batch loss 1.45424342\n",
      "Validated batch 87 batch loss 1.31691742\n",
      "Validated batch 88 batch loss 1.23508012\n",
      "Validated batch 89 batch loss 1.35978878\n",
      "Validated batch 90 batch loss 1.3111881\n",
      "Validated batch 91 batch loss 1.25046051\n",
      "Validated batch 92 batch loss 1.31082046\n",
      "Validated batch 93 batch loss 1.2509408\n",
      "Validated batch 94 batch loss 1.31648374\n",
      "Validated batch 95 batch loss 1.2730329\n",
      "Validated batch 96 batch loss 1.14590383\n",
      "Validated batch 97 batch loss 1.21677172\n",
      "Validated batch 98 batch loss 1.40449536\n",
      "Validated batch 99 batch loss 1.21924281\n",
      "Validated batch 100 batch loss 1.21948552\n",
      "Validated batch 101 batch loss 1.25884259\n",
      "Validated batch 102 batch loss 1.29391122\n",
      "Validated batch 103 batch loss 1.22743702\n",
      "Validated batch 104 batch loss 1.28322697\n",
      "Validated batch 105 batch loss 1.2754972\n",
      "Validated batch 106 batch loss 1.22906232\n",
      "Validated batch 107 batch loss 1.35327959\n",
      "Validated batch 108 batch loss 1.42099023\n",
      "Validated batch 109 batch loss 1.20028257\n",
      "Validated batch 110 batch loss 1.38958013\n",
      "Validated batch 111 batch loss 1.16666901\n",
      "Validated batch 112 batch loss 1.24583411\n",
      "Validated batch 113 batch loss 1.27783382\n",
      "Validated batch 114 batch loss 1.28277922\n",
      "Validated batch 115 batch loss 1.45126605\n",
      "Validated batch 116 batch loss 1.30793357\n",
      "Validated batch 117 batch loss 1.37119091\n",
      "Validated batch 118 batch loss 1.21140373\n",
      "Validated batch 119 batch loss 1.27890778\n",
      "Validated batch 120 batch loss 1.30124295\n",
      "Validated batch 121 batch loss 1.344208\n",
      "Validated batch 122 batch loss 1.38537514\n",
      "Validated batch 123 batch loss 1.40059698\n",
      "Validated batch 124 batch loss 1.36496389\n",
      "Validated batch 125 batch loss 1.28381777\n",
      "Validated batch 126 batch loss 1.37066352\n",
      "Validated batch 127 batch loss 1.35210478\n",
      "Validated batch 128 batch loss 1.29461336\n",
      "Validated batch 129 batch loss 1.41331577\n",
      "Validated batch 130 batch loss 1.36523259\n",
      "Validated batch 131 batch loss 1.33407021\n",
      "Validated batch 132 batch loss 1.39602649\n",
      "Validated batch 133 batch loss 1.21043396\n",
      "Validated batch 134 batch loss 1.27089262\n",
      "Validated batch 135 batch loss 1.25682521\n",
      "Validated batch 136 batch loss 1.18789315\n",
      "Validated batch 137 batch loss 1.4464829\n",
      "Validated batch 138 batch loss 1.2736429\n",
      "Validated batch 139 batch loss 1.43677628\n",
      "Validated batch 140 batch loss 1.28142858\n",
      "Validated batch 141 batch loss 1.30841517\n",
      "Validated batch 142 batch loss 1.26505828\n",
      "Validated batch 143 batch loss 1.21198225\n",
      "Validated batch 144 batch loss 1.34621763\n",
      "Validated batch 145 batch loss 1.31630373\n",
      "Validated batch 146 batch loss 1.25461388\n",
      "Validated batch 147 batch loss 1.25159824\n",
      "Validated batch 148 batch loss 1.31918287\n",
      "Validated batch 149 batch loss 1.31159663\n",
      "Validated batch 150 batch loss 1.35676718\n",
      "Validated batch 151 batch loss 1.34450674\n",
      "Validated batch 152 batch loss 1.21684098\n",
      "Validated batch 153 batch loss 1.26918054\n",
      "Validated batch 154 batch loss 1.30868375\n",
      "Validated batch 155 batch loss 1.28585649\n",
      "Validated batch 156 batch loss 1.36113572\n",
      "Validated batch 157 batch loss 1.37820339\n",
      "Validated batch 158 batch loss 1.48340058\n",
      "Validated batch 159 batch loss 1.46130419\n",
      "Validated batch 160 batch loss 1.31377387\n",
      "Validated batch 161 batch loss 1.20012498\n",
      "Validated batch 162 batch loss 1.25579214\n",
      "Validated batch 163 batch loss 1.34824646\n",
      "Validated batch 164 batch loss 1.24724936\n",
      "Validated batch 165 batch loss 1.27096474\n",
      "Validated batch 166 batch loss 1.33794427\n",
      "Validated batch 167 batch loss 1.26946068\n",
      "Validated batch 168 batch loss 1.29985428\n",
      "Validated batch 169 batch loss 1.2498256\n",
      "Validated batch 170 batch loss 1.2134403\n",
      "Validated batch 171 batch loss 1.44053936\n",
      "Validated batch 172 batch loss 1.24332738\n",
      "Validated batch 173 batch loss 1.15499461\n",
      "Validated batch 174 batch loss 1.23899186\n",
      "Validated batch 175 batch loss 1.39257812\n",
      "Validated batch 176 batch loss 1.39489365\n",
      "Validated batch 177 batch loss 1.4230665\n",
      "Validated batch 178 batch loss 1.26990509\n",
      "Validated batch 179 batch loss 1.44345784\n",
      "Validated batch 180 batch loss 1.29272723\n",
      "Validated batch 181 batch loss 1.35822976\n",
      "Validated batch 182 batch loss 1.36656809\n",
      "Validated batch 183 batch loss 1.10662484\n",
      "Validated batch 184 batch loss 1.24115479\n",
      "Validated batch 185 batch loss 1.44164205\n",
      "Epoch 2 val loss 1.3066908121109009\n",
      "Model /aiffel/aiffel/mpii/models1/model-epoch-2-loss-1.3067.h5 saved.\n",
      "Start epoch 3 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.27556968 epoch total loss 1.27556968\n",
      "Trained batch 2 batch loss 1.39226747 epoch total loss 1.33391857\n",
      "Trained batch 3 batch loss 1.34963131 epoch total loss 1.33915615\n",
      "Trained batch 4 batch loss 1.36327994 epoch total loss 1.34518707\n",
      "Trained batch 5 batch loss 1.53719354 epoch total loss 1.38358843\n",
      "Trained batch 6 batch loss 1.46024728 epoch total loss 1.39636481\n",
      "Trained batch 7 batch loss 1.39664245 epoch total loss 1.3964045\n",
      "Trained batch 8 batch loss 1.25551629 epoch total loss 1.37879348\n",
      "Trained batch 9 batch loss 1.3113004 epoch total loss 1.37129426\n",
      "Trained batch 10 batch loss 1.30816 epoch total loss 1.36498082\n",
      "Trained batch 11 batch loss 1.28274608 epoch total loss 1.35750496\n",
      "Trained batch 12 batch loss 1.36500716 epoch total loss 1.3581301\n",
      "Trained batch 13 batch loss 1.39372277 epoch total loss 1.36086798\n",
      "Trained batch 14 batch loss 1.40472043 epoch total loss 1.36400032\n",
      "Trained batch 15 batch loss 1.48696423 epoch total loss 1.37219799\n",
      "Trained batch 16 batch loss 1.48416686 epoch total loss 1.37919605\n",
      "Trained batch 17 batch loss 1.50916457 epoch total loss 1.3868413\n",
      "Trained batch 18 batch loss 1.41807151 epoch total loss 1.38857627\n",
      "Trained batch 19 batch loss 1.42599809 epoch total loss 1.39054585\n",
      "Trained batch 20 batch loss 1.40324235 epoch total loss 1.39118075\n",
      "Trained batch 21 batch loss 1.41796982 epoch total loss 1.39245641\n",
      "Trained batch 22 batch loss 1.32381535 epoch total loss 1.38933635\n",
      "Trained batch 23 batch loss 1.23385453 epoch total loss 1.38257623\n",
      "Trained batch 24 batch loss 1.28224468 epoch total loss 1.37839568\n",
      "Trained batch 25 batch loss 1.3932718 epoch total loss 1.37899077\n",
      "Trained batch 26 batch loss 1.31669629 epoch total loss 1.37659478\n",
      "Trained batch 27 batch loss 1.36633062 epoch total loss 1.37621462\n",
      "Trained batch 28 batch loss 1.2877841 epoch total loss 1.37305641\n",
      "Trained batch 29 batch loss 1.3360486 epoch total loss 1.37178028\n",
      "Trained batch 30 batch loss 1.24970043 epoch total loss 1.36771083\n",
      "Trained batch 31 batch loss 1.34883308 epoch total loss 1.36710191\n",
      "Trained batch 32 batch loss 1.30162311 epoch total loss 1.36505568\n",
      "Trained batch 33 batch loss 1.2177701 epoch total loss 1.36059248\n",
      "Trained batch 34 batch loss 1.21809685 epoch total loss 1.35640144\n",
      "Trained batch 35 batch loss 1.28470695 epoch total loss 1.35435295\n",
      "Trained batch 36 batch loss 1.28040028 epoch total loss 1.35229874\n",
      "Trained batch 37 batch loss 1.4110955 epoch total loss 1.3538878\n",
      "Trained batch 38 batch loss 1.26869321 epoch total loss 1.35164583\n",
      "Trained batch 39 batch loss 1.25730205 epoch total loss 1.34922671\n",
      "Trained batch 40 batch loss 1.15082204 epoch total loss 1.34426665\n",
      "Trained batch 41 batch loss 1.11950779 epoch total loss 1.33878469\n",
      "Trained batch 42 batch loss 1.16715693 epoch total loss 1.33469832\n",
      "Trained batch 43 batch loss 1.19135165 epoch total loss 1.33136463\n",
      "Trained batch 44 batch loss 1.26082885 epoch total loss 1.32976162\n",
      "Trained batch 45 batch loss 1.36591733 epoch total loss 1.33056509\n",
      "Trained batch 46 batch loss 1.13304019 epoch total loss 1.32627106\n",
      "Trained batch 47 batch loss 1.18103051 epoch total loss 1.32318079\n",
      "Trained batch 48 batch loss 1.25031686 epoch total loss 1.32166278\n",
      "Trained batch 49 batch loss 1.26307046 epoch total loss 1.32046711\n",
      "Trained batch 50 batch loss 1.25600517 epoch total loss 1.31917787\n",
      "Trained batch 51 batch loss 1.19359112 epoch total loss 1.31671536\n",
      "Trained batch 52 batch loss 1.41648912 epoch total loss 1.31863403\n",
      "Trained batch 53 batch loss 1.32322478 epoch total loss 1.3187207\n",
      "Trained batch 54 batch loss 1.33650625 epoch total loss 1.31905007\n",
      "Trained batch 55 batch loss 1.33326411 epoch total loss 1.31930864\n",
      "Trained batch 56 batch loss 1.3597604 epoch total loss 1.32003105\n",
      "Trained batch 57 batch loss 1.49498987 epoch total loss 1.32310045\n",
      "Trained batch 58 batch loss 1.580369 epoch total loss 1.32753611\n",
      "Trained batch 59 batch loss 1.51401377 epoch total loss 1.3306967\n",
      "Trained batch 60 batch loss 1.23861551 epoch total loss 1.32916212\n",
      "Trained batch 61 batch loss 1.2665019 epoch total loss 1.32813489\n",
      "Trained batch 62 batch loss 1.36975121 epoch total loss 1.32880616\n",
      "Trained batch 63 batch loss 1.43183529 epoch total loss 1.33044159\n",
      "Trained batch 64 batch loss 1.35151589 epoch total loss 1.33077085\n",
      "Trained batch 65 batch loss 1.505481 epoch total loss 1.33345866\n",
      "Trained batch 66 batch loss 1.37889469 epoch total loss 1.33414698\n",
      "Trained batch 67 batch loss 1.41182649 epoch total loss 1.33530641\n",
      "Trained batch 68 batch loss 1.30813241 epoch total loss 1.33490682\n",
      "Trained batch 69 batch loss 1.45387197 epoch total loss 1.33663106\n",
      "Trained batch 70 batch loss 1.47521091 epoch total loss 1.33861077\n",
      "Trained batch 71 batch loss 1.36418796 epoch total loss 1.33897102\n",
      "Trained batch 72 batch loss 1.35214853 epoch total loss 1.33915401\n",
      "Trained batch 73 batch loss 1.25684118 epoch total loss 1.33802652\n",
      "Trained batch 74 batch loss 1.24436092 epoch total loss 1.33676076\n",
      "Trained batch 75 batch loss 1.09766793 epoch total loss 1.33357286\n",
      "Trained batch 76 batch loss 1.21561527 epoch total loss 1.33202076\n",
      "Trained batch 77 batch loss 1.19973469 epoch total loss 1.33030283\n",
      "Trained batch 78 batch loss 1.08303297 epoch total loss 1.3271327\n",
      "Trained batch 79 batch loss 1.0922246 epoch total loss 1.32415915\n",
      "Trained batch 80 batch loss 1.00119185 epoch total loss 1.320122\n",
      "Trained batch 81 batch loss 1.04003763 epoch total loss 1.31666422\n",
      "Trained batch 82 batch loss 1.16350377 epoch total loss 1.31479645\n",
      "Trained batch 83 batch loss 1.27688754 epoch total loss 1.31433964\n",
      "Trained batch 84 batch loss 1.25159788 epoch total loss 1.31359267\n",
      "Trained batch 85 batch loss 1.29171288 epoch total loss 1.3133353\n",
      "Trained batch 86 batch loss 1.26809144 epoch total loss 1.31280911\n",
      "Trained batch 87 batch loss 1.32774651 epoch total loss 1.31298077\n",
      "Trained batch 88 batch loss 1.39763618 epoch total loss 1.31394279\n",
      "Trained batch 89 batch loss 1.33707762 epoch total loss 1.31420279\n",
      "Trained batch 90 batch loss 1.28256798 epoch total loss 1.31385124\n",
      "Trained batch 91 batch loss 1.33811092 epoch total loss 1.31411791\n",
      "Trained batch 92 batch loss 1.34053671 epoch total loss 1.31440508\n",
      "Trained batch 93 batch loss 1.27029848 epoch total loss 1.31393075\n",
      "Trained batch 94 batch loss 1.27986526 epoch total loss 1.31356847\n",
      "Trained batch 95 batch loss 1.20055461 epoch total loss 1.31237876\n",
      "Trained batch 96 batch loss 1.23843431 epoch total loss 1.31160855\n",
      "Trained batch 97 batch loss 1.22036839 epoch total loss 1.31066787\n",
      "Trained batch 98 batch loss 1.27620029 epoch total loss 1.31031632\n",
      "Trained batch 99 batch loss 1.22060132 epoch total loss 1.30941\n",
      "Trained batch 100 batch loss 1.40147758 epoch total loss 1.31033063\n",
      "Trained batch 101 batch loss 1.44446659 epoch total loss 1.31165886\n",
      "Trained batch 102 batch loss 1.4563961 epoch total loss 1.31307769\n",
      "Trained batch 103 batch loss 1.41277802 epoch total loss 1.31404579\n",
      "Trained batch 104 batch loss 1.25348639 epoch total loss 1.31346333\n",
      "Trained batch 105 batch loss 1.18209827 epoch total loss 1.31221223\n",
      "Trained batch 106 batch loss 1.07265306 epoch total loss 1.30995226\n",
      "Trained batch 107 batch loss 1.05650938 epoch total loss 1.30758357\n",
      "Trained batch 108 batch loss 1.04083991 epoch total loss 1.30511367\n",
      "Trained batch 109 batch loss 1.33528137 epoch total loss 1.30539036\n",
      "Trained batch 110 batch loss 1.36363435 epoch total loss 1.30591989\n",
      "Trained batch 111 batch loss 1.24720562 epoch total loss 1.30539095\n",
      "Trained batch 112 batch loss 1.08573055 epoch total loss 1.3034296\n",
      "Trained batch 113 batch loss 1.22610712 epoch total loss 1.30274534\n",
      "Trained batch 114 batch loss 1.41682649 epoch total loss 1.30374599\n",
      "Trained batch 115 batch loss 1.40685058 epoch total loss 1.30464256\n",
      "Trained batch 116 batch loss 1.34412503 epoch total loss 1.3049829\n",
      "Trained batch 117 batch loss 1.35551989 epoch total loss 1.3054148\n",
      "Trained batch 118 batch loss 1.32623637 epoch total loss 1.30559123\n",
      "Trained batch 119 batch loss 1.26278043 epoch total loss 1.30523157\n",
      "Trained batch 120 batch loss 1.31869972 epoch total loss 1.30534375\n",
      "Trained batch 121 batch loss 1.33135116 epoch total loss 1.30555868\n",
      "Trained batch 122 batch loss 1.23657811 epoch total loss 1.30499315\n",
      "Trained batch 123 batch loss 1.33035719 epoch total loss 1.30519938\n",
      "Trained batch 124 batch loss 1.31360638 epoch total loss 1.30526721\n",
      "Trained batch 125 batch loss 1.29891014 epoch total loss 1.30521631\n",
      "Trained batch 126 batch loss 1.24934387 epoch total loss 1.30477285\n",
      "Trained batch 127 batch loss 1.30420732 epoch total loss 1.30476844\n",
      "Trained batch 128 batch loss 1.37857032 epoch total loss 1.30534506\n",
      "Trained batch 129 batch loss 1.29964721 epoch total loss 1.30530095\n",
      "Trained batch 130 batch loss 1.32121539 epoch total loss 1.30542338\n",
      "Trained batch 131 batch loss 1.34334123 epoch total loss 1.3057127\n",
      "Trained batch 132 batch loss 1.34416127 epoch total loss 1.30600405\n",
      "Trained batch 133 batch loss 1.30518365 epoch total loss 1.30599797\n",
      "Trained batch 134 batch loss 1.39517832 epoch total loss 1.30666339\n",
      "Trained batch 135 batch loss 1.43802321 epoch total loss 1.30763638\n",
      "Trained batch 136 batch loss 1.56538892 epoch total loss 1.30953157\n",
      "Trained batch 137 batch loss 1.4841994 epoch total loss 1.31080651\n",
      "Trained batch 138 batch loss 1.29061031 epoch total loss 1.31066012\n",
      "Trained batch 139 batch loss 1.18661571 epoch total loss 1.30976772\n",
      "Trained batch 140 batch loss 1.3853054 epoch total loss 1.31030715\n",
      "Trained batch 141 batch loss 1.26401043 epoch total loss 1.30997884\n",
      "Trained batch 142 batch loss 1.17034125 epoch total loss 1.30899537\n",
      "Trained batch 143 batch loss 1.15918076 epoch total loss 1.30794775\n",
      "Trained batch 144 batch loss 1.25986373 epoch total loss 1.30761385\n",
      "Trained batch 145 batch loss 1.1798532 epoch total loss 1.30673265\n",
      "Trained batch 146 batch loss 1.15883756 epoch total loss 1.30571973\n",
      "Trained batch 147 batch loss 1.15890229 epoch total loss 1.304721\n",
      "Trained batch 148 batch loss 1.24647629 epoch total loss 1.30432749\n",
      "Trained batch 149 batch loss 1.31336844 epoch total loss 1.30438817\n",
      "Trained batch 150 batch loss 1.16893733 epoch total loss 1.30348516\n",
      "Trained batch 151 batch loss 1.24976897 epoch total loss 1.30312943\n",
      "Trained batch 152 batch loss 1.16050243 epoch total loss 1.30219114\n",
      "Trained batch 153 batch loss 1.2336396 epoch total loss 1.30174303\n",
      "Trained batch 154 batch loss 1.30311739 epoch total loss 1.30175197\n",
      "Trained batch 155 batch loss 1.26277304 epoch total loss 1.30150044\n",
      "Trained batch 156 batch loss 1.26847339 epoch total loss 1.30128884\n",
      "Trained batch 157 batch loss 1.33782482 epoch total loss 1.30152154\n",
      "Trained batch 158 batch loss 1.32501209 epoch total loss 1.30167019\n",
      "Trained batch 159 batch loss 1.17893028 epoch total loss 1.30089819\n",
      "Trained batch 160 batch loss 1.23231602 epoch total loss 1.30046964\n",
      "Trained batch 161 batch loss 1.23821473 epoch total loss 1.30008292\n",
      "Trained batch 162 batch loss 1.21320248 epoch total loss 1.2995466\n",
      "Trained batch 163 batch loss 1.11524725 epoch total loss 1.2984159\n",
      "Trained batch 164 batch loss 1.17738712 epoch total loss 1.29767799\n",
      "Trained batch 165 batch loss 1.17255318 epoch total loss 1.29691958\n",
      "Trained batch 166 batch loss 1.28206158 epoch total loss 1.29683\n",
      "Trained batch 167 batch loss 1.3329103 epoch total loss 1.29704618\n",
      "Trained batch 168 batch loss 1.2682246 epoch total loss 1.29687452\n",
      "Trained batch 169 batch loss 1.3671174 epoch total loss 1.29729021\n",
      "Trained batch 170 batch loss 1.30360985 epoch total loss 1.29732728\n",
      "Trained batch 171 batch loss 1.41409385 epoch total loss 1.29801011\n",
      "Trained batch 172 batch loss 1.38424468 epoch total loss 1.29851151\n",
      "Trained batch 173 batch loss 1.25566745 epoch total loss 1.29826379\n",
      "Trained batch 174 batch loss 1.29656339 epoch total loss 1.29825413\n",
      "Trained batch 175 batch loss 1.37202096 epoch total loss 1.29867566\n",
      "Trained batch 176 batch loss 1.33571863 epoch total loss 1.29888618\n",
      "Trained batch 177 batch loss 1.30621552 epoch total loss 1.29892755\n",
      "Trained batch 178 batch loss 1.211411 epoch total loss 1.29843581\n",
      "Trained batch 179 batch loss 1.33127511 epoch total loss 1.29861927\n",
      "Trained batch 180 batch loss 1.23890924 epoch total loss 1.29828751\n",
      "Trained batch 181 batch loss 1.31901431 epoch total loss 1.29840207\n",
      "Trained batch 182 batch loss 1.33511877 epoch total loss 1.29860377\n",
      "Trained batch 183 batch loss 1.28132176 epoch total loss 1.29850936\n",
      "Trained batch 184 batch loss 1.42331028 epoch total loss 1.29918766\n",
      "Trained batch 185 batch loss 1.32976103 epoch total loss 1.29935288\n",
      "Trained batch 186 batch loss 1.423962 epoch total loss 1.30002284\n",
      "Trained batch 187 batch loss 1.37018585 epoch total loss 1.30039811\n",
      "Trained batch 188 batch loss 1.42123246 epoch total loss 1.30104077\n",
      "Trained batch 189 batch loss 1.1521647 epoch total loss 1.30025303\n",
      "Trained batch 190 batch loss 1.26878989 epoch total loss 1.30008745\n",
      "Trained batch 191 batch loss 1.30147433 epoch total loss 1.30009472\n",
      "Trained batch 192 batch loss 1.15479326 epoch total loss 1.29933798\n",
      "Trained batch 193 batch loss 1.08861792 epoch total loss 1.29824615\n",
      "Trained batch 194 batch loss 1.30224347 epoch total loss 1.29826677\n",
      "Trained batch 195 batch loss 1.22302449 epoch total loss 1.29788089\n",
      "Trained batch 196 batch loss 1.26850975 epoch total loss 1.29773104\n",
      "Trained batch 197 batch loss 1.21393597 epoch total loss 1.2973057\n",
      "Trained batch 198 batch loss 1.25152957 epoch total loss 1.29707456\n",
      "Trained batch 199 batch loss 1.27246749 epoch total loss 1.29695094\n",
      "Trained batch 200 batch loss 1.30887437 epoch total loss 1.29701054\n",
      "Trained batch 201 batch loss 1.37772334 epoch total loss 1.29741204\n",
      "Trained batch 202 batch loss 1.22195971 epoch total loss 1.29703844\n",
      "Trained batch 203 batch loss 1.31253433 epoch total loss 1.29711473\n",
      "Trained batch 204 batch loss 1.12948835 epoch total loss 1.29629302\n",
      "Trained batch 205 batch loss 1.1851474 epoch total loss 1.29575086\n",
      "Trained batch 206 batch loss 1.24085617 epoch total loss 1.29548442\n",
      "Trained batch 207 batch loss 1.24210835 epoch total loss 1.29522645\n",
      "Trained batch 208 batch loss 1.38991439 epoch total loss 1.29568172\n",
      "Trained batch 209 batch loss 1.29825401 epoch total loss 1.29569399\n",
      "Trained batch 210 batch loss 1.28009915 epoch total loss 1.29561973\n",
      "Trained batch 211 batch loss 1.2145834 epoch total loss 1.29523563\n",
      "Trained batch 212 batch loss 1.28814816 epoch total loss 1.29520214\n",
      "Trained batch 213 batch loss 1.31683207 epoch total loss 1.2953037\n",
      "Trained batch 214 batch loss 1.26877069 epoch total loss 1.29517972\n",
      "Trained batch 215 batch loss 1.34409118 epoch total loss 1.29540718\n",
      "Trained batch 216 batch loss 1.41306686 epoch total loss 1.29595184\n",
      "Trained batch 217 batch loss 1.22961831 epoch total loss 1.29564619\n",
      "Trained batch 218 batch loss 1.19101584 epoch total loss 1.29516613\n",
      "Trained batch 219 batch loss 1.2438643 epoch total loss 1.29493189\n",
      "Trained batch 220 batch loss 1.27572465 epoch total loss 1.29484463\n",
      "Trained batch 221 batch loss 1.24883628 epoch total loss 1.29463649\n",
      "Trained batch 222 batch loss 1.32153738 epoch total loss 1.2947576\n",
      "Trained batch 223 batch loss 1.26130617 epoch total loss 1.29460752\n",
      "Trained batch 224 batch loss 1.28021216 epoch total loss 1.29454327\n",
      "Trained batch 225 batch loss 1.33937955 epoch total loss 1.29474258\n",
      "Trained batch 226 batch loss 1.38063562 epoch total loss 1.29512262\n",
      "Trained batch 227 batch loss 1.31423867 epoch total loss 1.2952069\n",
      "Trained batch 228 batch loss 1.42846429 epoch total loss 1.29579139\n",
      "Trained batch 229 batch loss 1.2362802 epoch total loss 1.29553139\n",
      "Trained batch 230 batch loss 1.27391481 epoch total loss 1.29543746\n",
      "Trained batch 231 batch loss 1.28450418 epoch total loss 1.29539025\n",
      "Trained batch 232 batch loss 1.37730706 epoch total loss 1.29574335\n",
      "Trained batch 233 batch loss 1.23229063 epoch total loss 1.29547107\n",
      "Trained batch 234 batch loss 1.38340425 epoch total loss 1.29584682\n",
      "Trained batch 235 batch loss 1.36297166 epoch total loss 1.29613245\n",
      "Trained batch 236 batch loss 1.33182549 epoch total loss 1.2962836\n",
      "Trained batch 237 batch loss 1.19946527 epoch total loss 1.29587507\n",
      "Trained batch 238 batch loss 1.33667636 epoch total loss 1.2960465\n",
      "Trained batch 239 batch loss 1.42942572 epoch total loss 1.29660451\n",
      "Trained batch 240 batch loss 1.41646743 epoch total loss 1.297104\n",
      "Trained batch 241 batch loss 1.41421 epoch total loss 1.2975899\n",
      "Trained batch 242 batch loss 1.16724253 epoch total loss 1.29705131\n",
      "Trained batch 243 batch loss 1.31279325 epoch total loss 1.29711616\n",
      "Trained batch 244 batch loss 1.26976597 epoch total loss 1.2970041\n",
      "Trained batch 245 batch loss 1.33009052 epoch total loss 1.29713905\n",
      "Trained batch 246 batch loss 1.15835333 epoch total loss 1.29657495\n",
      "Trained batch 247 batch loss 1.10290575 epoch total loss 1.29579079\n",
      "Trained batch 248 batch loss 1.13280284 epoch total loss 1.29513371\n",
      "Trained batch 249 batch loss 1.11985052 epoch total loss 1.29442966\n",
      "Trained batch 250 batch loss 1.15128756 epoch total loss 1.2938571\n",
      "Trained batch 251 batch loss 1.14093566 epoch total loss 1.29324782\n",
      "Trained batch 252 batch loss 1.21481907 epoch total loss 1.29293656\n",
      "Trained batch 253 batch loss 1.29050648 epoch total loss 1.29292691\n",
      "Trained batch 254 batch loss 1.27899325 epoch total loss 1.29287207\n",
      "Trained batch 255 batch loss 1.26083386 epoch total loss 1.29274642\n",
      "Trained batch 256 batch loss 1.19821393 epoch total loss 1.29237711\n",
      "Trained batch 257 batch loss 1.30799389 epoch total loss 1.29243779\n",
      "Trained batch 258 batch loss 1.37718368 epoch total loss 1.29276633\n",
      "Trained batch 259 batch loss 1.30685794 epoch total loss 1.29282081\n",
      "Trained batch 260 batch loss 1.29940271 epoch total loss 1.29284608\n",
      "Trained batch 261 batch loss 1.36965621 epoch total loss 1.29314041\n",
      "Trained batch 262 batch loss 1.28468895 epoch total loss 1.29310822\n",
      "Trained batch 263 batch loss 1.14821267 epoch total loss 1.29255724\n",
      "Trained batch 264 batch loss 1.27622879 epoch total loss 1.29249537\n",
      "Trained batch 265 batch loss 1.22560894 epoch total loss 1.292243\n",
      "Trained batch 266 batch loss 1.21421087 epoch total loss 1.29194963\n",
      "Trained batch 267 batch loss 1.37169933 epoch total loss 1.29224837\n",
      "Trained batch 268 batch loss 1.3672601 epoch total loss 1.29252815\n",
      "Trained batch 269 batch loss 1.38882279 epoch total loss 1.29288614\n",
      "Trained batch 270 batch loss 1.15957522 epoch total loss 1.29239237\n",
      "Trained batch 271 batch loss 1.14545953 epoch total loss 1.29185021\n",
      "Trained batch 272 batch loss 1.16503572 epoch total loss 1.29138398\n",
      "Trained batch 273 batch loss 1.14419067 epoch total loss 1.2908448\n",
      "Trained batch 274 batch loss 1.2002027 epoch total loss 1.29051399\n",
      "Trained batch 275 batch loss 1.15999639 epoch total loss 1.29003942\n",
      "Trained batch 276 batch loss 1.12714887 epoch total loss 1.28944921\n",
      "Trained batch 277 batch loss 1.23282599 epoch total loss 1.28924477\n",
      "Trained batch 278 batch loss 1.26873875 epoch total loss 1.28917098\n",
      "Trained batch 279 batch loss 1.28229976 epoch total loss 1.2891463\n",
      "Trained batch 280 batch loss 1.32656932 epoch total loss 1.28927994\n",
      "Trained batch 281 batch loss 1.28344679 epoch total loss 1.2892592\n",
      "Trained batch 282 batch loss 1.42794156 epoch total loss 1.28975093\n",
      "Trained batch 283 batch loss 1.30356443 epoch total loss 1.28979981\n",
      "Trained batch 284 batch loss 1.29985 epoch total loss 1.2898351\n",
      "Trained batch 285 batch loss 1.31874061 epoch total loss 1.28993642\n",
      "Trained batch 286 batch loss 1.33353281 epoch total loss 1.29008889\n",
      "Trained batch 287 batch loss 1.4719007 epoch total loss 1.29072237\n",
      "Trained batch 288 batch loss 1.23805857 epoch total loss 1.2905395\n",
      "Trained batch 289 batch loss 1.28610337 epoch total loss 1.29052413\n",
      "Trained batch 290 batch loss 1.49436247 epoch total loss 1.29122698\n",
      "Trained batch 291 batch loss 1.42010713 epoch total loss 1.29167\n",
      "Trained batch 292 batch loss 1.44049215 epoch total loss 1.29217958\n",
      "Trained batch 293 batch loss 1.20172775 epoch total loss 1.29187083\n",
      "Trained batch 294 batch loss 1.33066225 epoch total loss 1.2920028\n",
      "Trained batch 295 batch loss 1.21609151 epoch total loss 1.29174542\n",
      "Trained batch 296 batch loss 1.28177 epoch total loss 1.29171181\n",
      "Trained batch 297 batch loss 1.40191245 epoch total loss 1.29208279\n",
      "Trained batch 298 batch loss 1.33446443 epoch total loss 1.29222512\n",
      "Trained batch 299 batch loss 1.18822062 epoch total loss 1.29187727\n",
      "Trained batch 300 batch loss 1.29800296 epoch total loss 1.29189765\n",
      "Trained batch 301 batch loss 1.29193962 epoch total loss 1.29189777\n",
      "Trained batch 302 batch loss 1.23202872 epoch total loss 1.29169953\n",
      "Trained batch 303 batch loss 1.32413757 epoch total loss 1.29180658\n",
      "Trained batch 304 batch loss 1.35211313 epoch total loss 1.29200494\n",
      "Trained batch 305 batch loss 1.40940893 epoch total loss 1.29238987\n",
      "Trained batch 306 batch loss 1.34784043 epoch total loss 1.29257107\n",
      "Trained batch 307 batch loss 1.36478305 epoch total loss 1.29280627\n",
      "Trained batch 308 batch loss 1.29254961 epoch total loss 1.29280543\n",
      "Trained batch 309 batch loss 1.27414262 epoch total loss 1.29274499\n",
      "Trained batch 310 batch loss 1.29782677 epoch total loss 1.29276145\n",
      "Trained batch 311 batch loss 1.27453041 epoch total loss 1.29270279\n",
      "Trained batch 312 batch loss 1.20687008 epoch total loss 1.29242778\n",
      "Trained batch 313 batch loss 1.38925397 epoch total loss 1.29273713\n",
      "Trained batch 314 batch loss 1.37422526 epoch total loss 1.29299664\n",
      "Trained batch 315 batch loss 1.21013319 epoch total loss 1.29273367\n",
      "Trained batch 316 batch loss 1.35090315 epoch total loss 1.29291761\n",
      "Trained batch 317 batch loss 1.17614245 epoch total loss 1.29254925\n",
      "Trained batch 318 batch loss 1.19487083 epoch total loss 1.29224217\n",
      "Trained batch 319 batch loss 1.37441921 epoch total loss 1.29249978\n",
      "Trained batch 320 batch loss 1.28532481 epoch total loss 1.29247737\n",
      "Trained batch 321 batch loss 1.17687225 epoch total loss 1.29211736\n",
      "Trained batch 322 batch loss 1.18349433 epoch total loss 1.29178\n",
      "Trained batch 323 batch loss 1.22956944 epoch total loss 1.29158747\n",
      "Trained batch 324 batch loss 1.20708752 epoch total loss 1.29132664\n",
      "Trained batch 325 batch loss 1.27730489 epoch total loss 1.29128349\n",
      "Trained batch 326 batch loss 1.06746185 epoch total loss 1.29059696\n",
      "Trained batch 327 batch loss 1.10866928 epoch total loss 1.29004061\n",
      "Trained batch 328 batch loss 1.25222254 epoch total loss 1.28992534\n",
      "Trained batch 329 batch loss 1.16610587 epoch total loss 1.28954899\n",
      "Trained batch 330 batch loss 1.21748841 epoch total loss 1.28933072\n",
      "Trained batch 331 batch loss 1.19649816 epoch total loss 1.28905022\n",
      "Trained batch 332 batch loss 1.18211603 epoch total loss 1.28872824\n",
      "Trained batch 333 batch loss 1.18721449 epoch total loss 1.28842342\n",
      "Trained batch 334 batch loss 1.25983357 epoch total loss 1.28833771\n",
      "Trained batch 335 batch loss 1.34025753 epoch total loss 1.2884928\n",
      "Trained batch 336 batch loss 1.19233739 epoch total loss 1.2882067\n",
      "Trained batch 337 batch loss 1.17099917 epoch total loss 1.28785884\n",
      "Trained batch 338 batch loss 1.22577381 epoch total loss 1.28767514\n",
      "Trained batch 339 batch loss 1.14476418 epoch total loss 1.28725362\n",
      "Trained batch 340 batch loss 1.29770947 epoch total loss 1.28728426\n",
      "Trained batch 341 batch loss 1.30721498 epoch total loss 1.28734279\n",
      "Trained batch 342 batch loss 1.40551174 epoch total loss 1.28768837\n",
      "Trained batch 343 batch loss 1.49959731 epoch total loss 1.28830612\n",
      "Trained batch 344 batch loss 1.33641088 epoch total loss 1.28844607\n",
      "Trained batch 345 batch loss 1.25179827 epoch total loss 1.28833985\n",
      "Trained batch 346 batch loss 1.24874496 epoch total loss 1.28822541\n",
      "Trained batch 347 batch loss 1.30486846 epoch total loss 1.28827333\n",
      "Trained batch 348 batch loss 1.34496033 epoch total loss 1.28843629\n",
      "Trained batch 349 batch loss 1.34653723 epoch total loss 1.28860271\n",
      "Trained batch 350 batch loss 1.33384848 epoch total loss 1.28873205\n",
      "Trained batch 351 batch loss 1.18484688 epoch total loss 1.28843606\n",
      "Trained batch 352 batch loss 1.18929374 epoch total loss 1.28815448\n",
      "Trained batch 353 batch loss 1.27387333 epoch total loss 1.28811395\n",
      "Trained batch 354 batch loss 1.28787315 epoch total loss 1.28811324\n",
      "Trained batch 355 batch loss 1.36336362 epoch total loss 1.28832531\n",
      "Trained batch 356 batch loss 1.28546333 epoch total loss 1.2883172\n",
      "Trained batch 357 batch loss 1.33721077 epoch total loss 1.28845417\n",
      "Trained batch 358 batch loss 1.25755894 epoch total loss 1.28836787\n",
      "Trained batch 359 batch loss 1.19977641 epoch total loss 1.2881211\n",
      "Trained batch 360 batch loss 1.27765906 epoch total loss 1.28809202\n",
      "Trained batch 361 batch loss 1.25619781 epoch total loss 1.28800368\n",
      "Trained batch 362 batch loss 1.20950007 epoch total loss 1.28778684\n",
      "Trained batch 363 batch loss 1.26614237 epoch total loss 1.28772724\n",
      "Trained batch 364 batch loss 1.28641963 epoch total loss 1.28772354\n",
      "Trained batch 365 batch loss 1.32449174 epoch total loss 1.28782427\n",
      "Trained batch 366 batch loss 1.24847591 epoch total loss 1.28771687\n",
      "Trained batch 367 batch loss 1.31527472 epoch total loss 1.28779185\n",
      "Trained batch 368 batch loss 1.153175 epoch total loss 1.28742611\n",
      "Trained batch 369 batch loss 1.19861376 epoch total loss 1.28718543\n",
      "Trained batch 370 batch loss 1.08326578 epoch total loss 1.28663421\n",
      "Trained batch 371 batch loss 1.21568847 epoch total loss 1.286443\n",
      "Trained batch 372 batch loss 1.21064436 epoch total loss 1.28623927\n",
      "Trained batch 373 batch loss 1.32019365 epoch total loss 1.28633022\n",
      "Trained batch 374 batch loss 1.26067054 epoch total loss 1.28626168\n",
      "Trained batch 375 batch loss 1.39297581 epoch total loss 1.28654623\n",
      "Trained batch 376 batch loss 1.31813872 epoch total loss 1.28663027\n",
      "Trained batch 377 batch loss 1.45498252 epoch total loss 1.28707683\n",
      "Trained batch 378 batch loss 1.22627652 epoch total loss 1.28691602\n",
      "Trained batch 379 batch loss 1.37979913 epoch total loss 1.28716111\n",
      "Trained batch 380 batch loss 1.3575865 epoch total loss 1.28734636\n",
      "Trained batch 381 batch loss 1.23352182 epoch total loss 1.2872051\n",
      "Trained batch 382 batch loss 1.32990754 epoch total loss 1.2873168\n",
      "Trained batch 383 batch loss 1.42998433 epoch total loss 1.28768933\n",
      "Trained batch 384 batch loss 1.41086185 epoch total loss 1.28801012\n",
      "Trained batch 385 batch loss 1.23276079 epoch total loss 1.28786659\n",
      "Trained batch 386 batch loss 1.32523048 epoch total loss 1.28796339\n",
      "Trained batch 387 batch loss 1.42247534 epoch total loss 1.288311\n",
      "Trained batch 388 batch loss 1.41276658 epoch total loss 1.2886318\n",
      "Trained batch 389 batch loss 1.36885762 epoch total loss 1.28883803\n",
      "Trained batch 390 batch loss 1.1725328 epoch total loss 1.28853989\n",
      "Trained batch 391 batch loss 1.32603776 epoch total loss 1.28863585\n",
      "Trained batch 392 batch loss 1.38081753 epoch total loss 1.28887093\n",
      "Trained batch 393 batch loss 1.2858789 epoch total loss 1.28886342\n",
      "Trained batch 394 batch loss 1.4112823 epoch total loss 1.28917408\n",
      "Trained batch 395 batch loss 1.26970112 epoch total loss 1.28912485\n",
      "Trained batch 396 batch loss 1.08205271 epoch total loss 1.28860199\n",
      "Trained batch 397 batch loss 1.13752651 epoch total loss 1.28822136\n",
      "Trained batch 398 batch loss 1.28008533 epoch total loss 1.28820097\n",
      "Trained batch 399 batch loss 1.3447001 epoch total loss 1.2883426\n",
      "Trained batch 400 batch loss 1.40521479 epoch total loss 1.28863478\n",
      "Trained batch 401 batch loss 1.39827967 epoch total loss 1.28890812\n",
      "Trained batch 402 batch loss 1.42257237 epoch total loss 1.2892406\n",
      "Trained batch 403 batch loss 1.36883521 epoch total loss 1.28943813\n",
      "Trained batch 404 batch loss 1.35166824 epoch total loss 1.28959215\n",
      "Trained batch 405 batch loss 1.41395974 epoch total loss 1.28989923\n",
      "Trained batch 406 batch loss 1.27392089 epoch total loss 1.28985989\n",
      "Trained batch 407 batch loss 1.32316756 epoch total loss 1.28994179\n",
      "Trained batch 408 batch loss 1.3648324 epoch total loss 1.29012525\n",
      "Trained batch 409 batch loss 1.48096859 epoch total loss 1.29059184\n",
      "Trained batch 410 batch loss 1.35319972 epoch total loss 1.29074454\n",
      "Trained batch 411 batch loss 1.32790363 epoch total loss 1.2908349\n",
      "Trained batch 412 batch loss 1.31245708 epoch total loss 1.29088736\n",
      "Trained batch 413 batch loss 1.30152619 epoch total loss 1.29091311\n",
      "Trained batch 414 batch loss 1.32948387 epoch total loss 1.29100621\n",
      "Trained batch 415 batch loss 1.2636174 epoch total loss 1.29094017\n",
      "Trained batch 416 batch loss 1.26805735 epoch total loss 1.29088521\n",
      "Trained batch 417 batch loss 1.13250148 epoch total loss 1.29050541\n",
      "Trained batch 418 batch loss 1.4562676 epoch total loss 1.2909019\n",
      "Trained batch 419 batch loss 1.46636832 epoch total loss 1.29132068\n",
      "Trained batch 420 batch loss 1.12230563 epoch total loss 1.29091823\n",
      "Trained batch 421 batch loss 1.30954134 epoch total loss 1.29096258\n",
      "Trained batch 422 batch loss 1.2460357 epoch total loss 1.29085612\n",
      "Trained batch 423 batch loss 1.26215577 epoch total loss 1.29078817\n",
      "Trained batch 424 batch loss 1.29498649 epoch total loss 1.29079807\n",
      "Trained batch 425 batch loss 1.27865624 epoch total loss 1.29076958\n",
      "Trained batch 426 batch loss 1.25665617 epoch total loss 1.29068959\n",
      "Trained batch 427 batch loss 1.3073535 epoch total loss 1.29072857\n",
      "Trained batch 428 batch loss 1.34112906 epoch total loss 1.29084635\n",
      "Trained batch 429 batch loss 1.29605496 epoch total loss 1.29085851\n",
      "Trained batch 430 batch loss 1.33834207 epoch total loss 1.29096889\n",
      "Trained batch 431 batch loss 1.3694303 epoch total loss 1.29115105\n",
      "Trained batch 432 batch loss 1.38005364 epoch total loss 1.2913568\n",
      "Trained batch 433 batch loss 1.2967726 epoch total loss 1.29136932\n",
      "Trained batch 434 batch loss 1.11031771 epoch total loss 1.29095209\n",
      "Trained batch 435 batch loss 1.06883955 epoch total loss 1.29044151\n",
      "Trained batch 436 batch loss 1.26671267 epoch total loss 1.29038703\n",
      "Trained batch 437 batch loss 1.35492325 epoch total loss 1.29053473\n",
      "Trained batch 438 batch loss 1.29987395 epoch total loss 1.29055607\n",
      "Trained batch 439 batch loss 1.40136838 epoch total loss 1.29080844\n",
      "Trained batch 440 batch loss 1.34959173 epoch total loss 1.29094207\n",
      "Trained batch 441 batch loss 1.34357464 epoch total loss 1.2910614\n",
      "Trained batch 442 batch loss 1.38730478 epoch total loss 1.2912792\n",
      "Trained batch 443 batch loss 1.33765864 epoch total loss 1.29138386\n",
      "Trained batch 444 batch loss 1.41616595 epoch total loss 1.29166484\n",
      "Trained batch 445 batch loss 1.38805532 epoch total loss 1.29188144\n",
      "Trained batch 446 batch loss 1.25020206 epoch total loss 1.29178798\n",
      "Trained batch 447 batch loss 1.22033334 epoch total loss 1.29162812\n",
      "Trained batch 448 batch loss 1.18738341 epoch total loss 1.29139543\n",
      "Trained batch 449 batch loss 1.08798838 epoch total loss 1.29094255\n",
      "Trained batch 450 batch loss 1.26248336 epoch total loss 1.29087937\n",
      "Trained batch 451 batch loss 1.35524869 epoch total loss 1.29102194\n",
      "Trained batch 452 batch loss 1.3029964 epoch total loss 1.29104841\n",
      "Trained batch 453 batch loss 1.28518963 epoch total loss 1.29103553\n",
      "Trained batch 454 batch loss 1.48328614 epoch total loss 1.29145896\n",
      "Trained batch 455 batch loss 1.32638931 epoch total loss 1.29153585\n",
      "Trained batch 456 batch loss 1.24107301 epoch total loss 1.29142523\n",
      "Trained batch 457 batch loss 1.36005878 epoch total loss 1.29157531\n",
      "Trained batch 458 batch loss 1.2650497 epoch total loss 1.2915175\n",
      "Trained batch 459 batch loss 1.26998663 epoch total loss 1.29147053\n",
      "Trained batch 460 batch loss 1.1019547 epoch total loss 1.29105854\n",
      "Trained batch 461 batch loss 1.20889544 epoch total loss 1.29088032\n",
      "Trained batch 462 batch loss 1.1788398 epoch total loss 1.29063773\n",
      "Trained batch 463 batch loss 1.14259315 epoch total loss 1.29031801\n",
      "Trained batch 464 batch loss 1.16613 epoch total loss 1.29005039\n",
      "Trained batch 465 batch loss 1.18933058 epoch total loss 1.28983378\n",
      "Trained batch 466 batch loss 1.19681835 epoch total loss 1.28963423\n",
      "Trained batch 467 batch loss 1.13591957 epoch total loss 1.28930509\n",
      "Trained batch 468 batch loss 1.21406257 epoch total loss 1.28914428\n",
      "Trained batch 469 batch loss 1.51203847 epoch total loss 1.28961945\n",
      "Trained batch 470 batch loss 1.2390008 epoch total loss 1.2895118\n",
      "Trained batch 471 batch loss 1.33015752 epoch total loss 1.28959811\n",
      "Trained batch 472 batch loss 1.17021668 epoch total loss 1.28934515\n",
      "Trained batch 473 batch loss 1.2328434 epoch total loss 1.2892257\n",
      "Trained batch 474 batch loss 1.28959119 epoch total loss 1.28922653\n",
      "Trained batch 475 batch loss 1.23324931 epoch total loss 1.28910875\n",
      "Trained batch 476 batch loss 1.44988716 epoch total loss 1.28944659\n",
      "Trained batch 477 batch loss 1.33114314 epoch total loss 1.28953385\n",
      "Trained batch 478 batch loss 1.23611534 epoch total loss 1.28942215\n",
      "Trained batch 479 batch loss 1.25291395 epoch total loss 1.28934598\n",
      "Trained batch 480 batch loss 1.50488615 epoch total loss 1.28979504\n",
      "Trained batch 481 batch loss 1.27125025 epoch total loss 1.28975642\n",
      "Trained batch 482 batch loss 1.14679527 epoch total loss 1.28945982\n",
      "Trained batch 483 batch loss 1.14174986 epoch total loss 1.28915393\n",
      "Trained batch 484 batch loss 1.13821876 epoch total loss 1.2888422\n",
      "Trained batch 485 batch loss 1.34189725 epoch total loss 1.28895164\n",
      "Trained batch 486 batch loss 1.39290965 epoch total loss 1.2891655\n",
      "Trained batch 487 batch loss 1.25090146 epoch total loss 1.28908694\n",
      "Trained batch 488 batch loss 1.29460061 epoch total loss 1.28909826\n",
      "Trained batch 489 batch loss 1.23158228 epoch total loss 1.2889806\n",
      "Trained batch 490 batch loss 1.2808826 epoch total loss 1.28896415\n",
      "Trained batch 491 batch loss 1.27711606 epoch total loss 1.28894\n",
      "Trained batch 492 batch loss 1.33708453 epoch total loss 1.28903782\n",
      "Trained batch 493 batch loss 1.41819322 epoch total loss 1.28929985\n",
      "Trained batch 494 batch loss 1.33515954 epoch total loss 1.28939259\n",
      "Trained batch 495 batch loss 1.27068985 epoch total loss 1.2893548\n",
      "Trained batch 496 batch loss 1.26984739 epoch total loss 1.28931546\n",
      "Trained batch 497 batch loss 1.16638541 epoch total loss 1.2890681\n",
      "Trained batch 498 batch loss 1.27057445 epoch total loss 1.28903103\n",
      "Trained batch 499 batch loss 1.28660643 epoch total loss 1.28902614\n",
      "Trained batch 500 batch loss 1.4220438 epoch total loss 1.28929222\n",
      "Trained batch 501 batch loss 1.2757864 epoch total loss 1.28926528\n",
      "Trained batch 502 batch loss 1.36718798 epoch total loss 1.28942049\n",
      "Trained batch 503 batch loss 1.29241335 epoch total loss 1.28942645\n",
      "Trained batch 504 batch loss 1.32444596 epoch total loss 1.28949594\n",
      "Trained batch 505 batch loss 1.3019948 epoch total loss 1.28952074\n",
      "Trained batch 506 batch loss 1.3476547 epoch total loss 1.28963554\n",
      "Trained batch 507 batch loss 1.29107451 epoch total loss 1.2896384\n",
      "Trained batch 508 batch loss 1.21296942 epoch total loss 1.28948748\n",
      "Trained batch 509 batch loss 1.25756907 epoch total loss 1.28942478\n",
      "Trained batch 510 batch loss 1.33376813 epoch total loss 1.28951168\n",
      "Trained batch 511 batch loss 1.36904395 epoch total loss 1.28966725\n",
      "Trained batch 512 batch loss 1.39057779 epoch total loss 1.2898643\n",
      "Trained batch 513 batch loss 1.18413329 epoch total loss 1.28965819\n",
      "Trained batch 514 batch loss 1.2666769 epoch total loss 1.28961349\n",
      "Trained batch 515 batch loss 1.30110824 epoch total loss 1.28963578\n",
      "Trained batch 516 batch loss 1.12476444 epoch total loss 1.28931618\n",
      "Trained batch 517 batch loss 1.33308899 epoch total loss 1.28940082\n",
      "Trained batch 518 batch loss 1.2560904 epoch total loss 1.28933656\n",
      "Trained batch 519 batch loss 1.41214919 epoch total loss 1.28957319\n",
      "Trained batch 520 batch loss 1.31169868 epoch total loss 1.28961575\n",
      "Trained batch 521 batch loss 1.26589906 epoch total loss 1.28957021\n",
      "Trained batch 522 batch loss 1.26644123 epoch total loss 1.28952587\n",
      "Trained batch 523 batch loss 1.23311281 epoch total loss 1.28941798\n",
      "Trained batch 524 batch loss 1.22506297 epoch total loss 1.28929508\n",
      "Trained batch 525 batch loss 1.28687692 epoch total loss 1.28929043\n",
      "Trained batch 526 batch loss 1.20756316 epoch total loss 1.2891351\n",
      "Trained batch 527 batch loss 1.22493863 epoch total loss 1.28901327\n",
      "Trained batch 528 batch loss 1.21087825 epoch total loss 1.28886533\n",
      "Trained batch 529 batch loss 1.22470224 epoch total loss 1.28874409\n",
      "Trained batch 530 batch loss 1.22801054 epoch total loss 1.28862953\n",
      "Trained batch 531 batch loss 1.27621698 epoch total loss 1.28860617\n",
      "Trained batch 532 batch loss 1.25942707 epoch total loss 1.28855133\n",
      "Trained batch 533 batch loss 1.23540449 epoch total loss 1.28845155\n",
      "Trained batch 534 batch loss 1.25419176 epoch total loss 1.28838742\n",
      "Trained batch 535 batch loss 1.32342339 epoch total loss 1.28845298\n",
      "Trained batch 536 batch loss 1.30041599 epoch total loss 1.28847528\n",
      "Trained batch 537 batch loss 1.35234523 epoch total loss 1.28859425\n",
      "Trained batch 538 batch loss 1.25279129 epoch total loss 1.28852773\n",
      "Trained batch 539 batch loss 1.15617263 epoch total loss 1.28828216\n",
      "Trained batch 540 batch loss 1.17640722 epoch total loss 1.28807497\n",
      "Trained batch 541 batch loss 1.21401739 epoch total loss 1.287938\n",
      "Trained batch 542 batch loss 1.1635133 epoch total loss 1.28770852\n",
      "Trained batch 543 batch loss 1.29093957 epoch total loss 1.28771448\n",
      "Trained batch 544 batch loss 1.21916533 epoch total loss 1.28758848\n",
      "Trained batch 545 batch loss 1.18276787 epoch total loss 1.28739607\n",
      "Trained batch 546 batch loss 1.20995128 epoch total loss 1.28725421\n",
      "Trained batch 547 batch loss 1.30413818 epoch total loss 1.28728509\n",
      "Trained batch 548 batch loss 1.50138807 epoch total loss 1.28767586\n",
      "Trained batch 549 batch loss 1.58200908 epoch total loss 1.28821206\n",
      "Trained batch 550 batch loss 1.45841312 epoch total loss 1.28852153\n",
      "Trained batch 551 batch loss 1.29409075 epoch total loss 1.28853154\n",
      "Trained batch 552 batch loss 1.41317129 epoch total loss 1.28875732\n",
      "Trained batch 553 batch loss 1.36421871 epoch total loss 1.2888937\n",
      "Trained batch 554 batch loss 1.37316322 epoch total loss 1.28904581\n",
      "Trained batch 555 batch loss 1.28013682 epoch total loss 1.28902984\n",
      "Trained batch 556 batch loss 1.38763 epoch total loss 1.28920722\n",
      "Trained batch 557 batch loss 1.22878695 epoch total loss 1.28909862\n",
      "Trained batch 558 batch loss 1.24215746 epoch total loss 1.28901458\n",
      "Trained batch 559 batch loss 1.32107031 epoch total loss 1.28907192\n",
      "Trained batch 560 batch loss 1.39160478 epoch total loss 1.28925502\n",
      "Trained batch 561 batch loss 1.24905491 epoch total loss 1.28918338\n",
      "Trained batch 562 batch loss 1.3155477 epoch total loss 1.28923035\n",
      "Trained batch 563 batch loss 1.21681571 epoch total loss 1.2891016\n",
      "Trained batch 564 batch loss 1.19316769 epoch total loss 1.28893161\n",
      "Trained batch 565 batch loss 1.18597066 epoch total loss 1.28874934\n",
      "Trained batch 566 batch loss 1.22382891 epoch total loss 1.28863466\n",
      "Trained batch 567 batch loss 1.19722641 epoch total loss 1.28847337\n",
      "Trained batch 568 batch loss 1.17853522 epoch total loss 1.28827977\n",
      "Trained batch 569 batch loss 1.23647761 epoch total loss 1.2881887\n",
      "Trained batch 570 batch loss 1.31388438 epoch total loss 1.28823376\n",
      "Trained batch 571 batch loss 1.35152078 epoch total loss 1.28834462\n",
      "Trained batch 572 batch loss 1.38588202 epoch total loss 1.28851509\n",
      "Trained batch 573 batch loss 1.33059788 epoch total loss 1.28858864\n",
      "Trained batch 574 batch loss 1.26786053 epoch total loss 1.28855252\n",
      "Trained batch 575 batch loss 1.26315308 epoch total loss 1.28850842\n",
      "Trained batch 576 batch loss 1.11957812 epoch total loss 1.28821516\n",
      "Trained batch 577 batch loss 1.20076907 epoch total loss 1.28806353\n",
      "Trained batch 578 batch loss 1.25132406 epoch total loss 1.288\n",
      "Trained batch 579 batch loss 1.34296417 epoch total loss 1.28809488\n",
      "Trained batch 580 batch loss 1.34099936 epoch total loss 1.28818607\n",
      "Trained batch 581 batch loss 1.32542896 epoch total loss 1.28825021\n",
      "Trained batch 582 batch loss 1.25043333 epoch total loss 1.28818524\n",
      "Trained batch 583 batch loss 1.18882084 epoch total loss 1.28801489\n",
      "Trained batch 584 batch loss 1.29087365 epoch total loss 1.28801978\n",
      "Trained batch 585 batch loss 1.12719965 epoch total loss 1.28774488\n",
      "Trained batch 586 batch loss 1.22616935 epoch total loss 1.28763986\n",
      "Trained batch 587 batch loss 1.26540411 epoch total loss 1.28760195\n",
      "Trained batch 588 batch loss 1.34255886 epoch total loss 1.28769529\n",
      "Trained batch 589 batch loss 1.33815289 epoch total loss 1.287781\n",
      "Trained batch 590 batch loss 1.44976592 epoch total loss 1.28805554\n",
      "Trained batch 591 batch loss 1.27839136 epoch total loss 1.28803921\n",
      "Trained batch 592 batch loss 1.21904492 epoch total loss 1.28792262\n",
      "Trained batch 593 batch loss 1.25969398 epoch total loss 1.28787506\n",
      "Trained batch 594 batch loss 1.20270121 epoch total loss 1.28773165\n",
      "Trained batch 595 batch loss 1.21542811 epoch total loss 1.28761017\n",
      "Trained batch 596 batch loss 1.27931917 epoch total loss 1.28759623\n",
      "Trained batch 597 batch loss 1.40246081 epoch total loss 1.28778863\n",
      "Trained batch 598 batch loss 1.40921235 epoch total loss 1.28799176\n",
      "Trained batch 599 batch loss 1.29289222 epoch total loss 1.288\n",
      "Trained batch 600 batch loss 1.31915152 epoch total loss 1.28805184\n",
      "Trained batch 601 batch loss 1.33542466 epoch total loss 1.28813076\n",
      "Trained batch 602 batch loss 1.35276568 epoch total loss 1.28823817\n",
      "Trained batch 603 batch loss 1.20449352 epoch total loss 1.28809917\n",
      "Trained batch 604 batch loss 1.28852749 epoch total loss 1.28809988\n",
      "Trained batch 605 batch loss 1.19831729 epoch total loss 1.28795147\n",
      "Trained batch 606 batch loss 1.20491815 epoch total loss 1.28781438\n",
      "Trained batch 607 batch loss 1.28249788 epoch total loss 1.28780556\n",
      "Trained batch 608 batch loss 1.32298398 epoch total loss 1.28786349\n",
      "Trained batch 609 batch loss 1.30690861 epoch total loss 1.28789473\n",
      "Trained batch 610 batch loss 1.14043677 epoch total loss 1.28765297\n",
      "Trained batch 611 batch loss 1.16353941 epoch total loss 1.28744984\n",
      "Trained batch 612 batch loss 1.08753228 epoch total loss 1.28712308\n",
      "Trained batch 613 batch loss 1.12496138 epoch total loss 1.28685856\n",
      "Trained batch 614 batch loss 1.27624559 epoch total loss 1.28684127\n",
      "Trained batch 615 batch loss 1.22897089 epoch total loss 1.2867471\n",
      "Trained batch 616 batch loss 1.17395389 epoch total loss 1.28656399\n",
      "Trained batch 617 batch loss 1.30065417 epoch total loss 1.28658688\n",
      "Trained batch 618 batch loss 1.3309319 epoch total loss 1.28665864\n",
      "Trained batch 619 batch loss 1.34554589 epoch total loss 1.28675377\n",
      "Trained batch 620 batch loss 1.40115 epoch total loss 1.28693819\n",
      "Trained batch 621 batch loss 1.18945456 epoch total loss 1.28678119\n",
      "Trained batch 622 batch loss 1.15489006 epoch total loss 1.28656924\n",
      "Trained batch 623 batch loss 1.27063 epoch total loss 1.28654361\n",
      "Trained batch 624 batch loss 1.32076144 epoch total loss 1.28659844\n",
      "Trained batch 625 batch loss 1.33860803 epoch total loss 1.28668165\n",
      "Trained batch 626 batch loss 1.3262372 epoch total loss 1.28674483\n",
      "Trained batch 627 batch loss 1.28902912 epoch total loss 1.28674841\n",
      "Trained batch 628 batch loss 1.22866416 epoch total loss 1.2866559\n",
      "Trained batch 629 batch loss 1.16641736 epoch total loss 1.28646481\n",
      "Trained batch 630 batch loss 1.23749828 epoch total loss 1.28638709\n",
      "Trained batch 631 batch loss 1.2620995 epoch total loss 1.28634846\n",
      "Trained batch 632 batch loss 1.19453645 epoch total loss 1.28620327\n",
      "Trained batch 633 batch loss 1.19610655 epoch total loss 1.28606093\n",
      "Trained batch 634 batch loss 1.20110083 epoch total loss 1.28592694\n",
      "Trained batch 635 batch loss 1.15053248 epoch total loss 1.28571367\n",
      "Trained batch 636 batch loss 1.16238523 epoch total loss 1.28551972\n",
      "Trained batch 637 batch loss 1.13772237 epoch total loss 1.28528774\n",
      "Trained batch 638 batch loss 1.12665546 epoch total loss 1.28503907\n",
      "Trained batch 639 batch loss 1.15041661 epoch total loss 1.28482831\n",
      "Trained batch 640 batch loss 1.22681069 epoch total loss 1.28473771\n",
      "Trained batch 641 batch loss 1.10673761 epoch total loss 1.28446007\n",
      "Trained batch 642 batch loss 1.24654901 epoch total loss 1.28440094\n",
      "Trained batch 643 batch loss 1.53726661 epoch total loss 1.28479421\n",
      "Trained batch 644 batch loss 1.34117401 epoch total loss 1.28488183\n",
      "Trained batch 645 batch loss 1.39448702 epoch total loss 1.2850517\n",
      "Trained batch 646 batch loss 1.38460493 epoch total loss 1.28520572\n",
      "Trained batch 647 batch loss 1.48666763 epoch total loss 1.28551722\n",
      "Trained batch 648 batch loss 1.23713183 epoch total loss 1.28544247\n",
      "Trained batch 649 batch loss 1.33259344 epoch total loss 1.28551507\n",
      "Trained batch 650 batch loss 1.1605829 epoch total loss 1.2853229\n",
      "Trained batch 651 batch loss 1.30415154 epoch total loss 1.28535187\n",
      "Trained batch 652 batch loss 1.25258684 epoch total loss 1.28530157\n",
      "Trained batch 653 batch loss 1.3900702 epoch total loss 1.28546202\n",
      "Trained batch 654 batch loss 1.26907086 epoch total loss 1.28543687\n",
      "Trained batch 655 batch loss 1.24547029 epoch total loss 1.28537583\n",
      "Trained batch 656 batch loss 1.32520461 epoch total loss 1.28543663\n",
      "Trained batch 657 batch loss 1.24209273 epoch total loss 1.28537059\n",
      "Trained batch 658 batch loss 1.19285226 epoch total loss 1.28523\n",
      "Trained batch 659 batch loss 1.2320888 epoch total loss 1.28514946\n",
      "Trained batch 660 batch loss 1.33113551 epoch total loss 1.28521907\n",
      "Trained batch 661 batch loss 1.27153099 epoch total loss 1.28519833\n",
      "Trained batch 662 batch loss 1.28441191 epoch total loss 1.28519714\n",
      "Trained batch 663 batch loss 1.24031389 epoch total loss 1.28512943\n",
      "Trained batch 664 batch loss 1.21248055 epoch total loss 1.28502\n",
      "Trained batch 665 batch loss 1.23578727 epoch total loss 1.28494596\n",
      "Trained batch 666 batch loss 1.27940845 epoch total loss 1.28493762\n",
      "Trained batch 667 batch loss 1.19066846 epoch total loss 1.28479636\n",
      "Trained batch 668 batch loss 1.19536877 epoch total loss 1.28466249\n",
      "Trained batch 669 batch loss 1.32490051 epoch total loss 1.28472257\n",
      "Trained batch 670 batch loss 1.15347147 epoch total loss 1.28452671\n",
      "Trained batch 671 batch loss 1.32225442 epoch total loss 1.28458297\n",
      "Trained batch 672 batch loss 1.30357242 epoch total loss 1.28461123\n",
      "Trained batch 673 batch loss 1.28234851 epoch total loss 1.28460789\n",
      "Trained batch 674 batch loss 1.29591441 epoch total loss 1.28462458\n",
      "Trained batch 675 batch loss 1.29380274 epoch total loss 1.28463817\n",
      "Trained batch 676 batch loss 1.27034378 epoch total loss 1.28461707\n",
      "Trained batch 677 batch loss 1.22220469 epoch total loss 1.28452492\n",
      "Trained batch 678 batch loss 1.16902733 epoch total loss 1.28435457\n",
      "Trained batch 679 batch loss 1.30521679 epoch total loss 1.28438532\n",
      "Trained batch 680 batch loss 1.3214767 epoch total loss 1.2844398\n",
      "Trained batch 681 batch loss 1.28476691 epoch total loss 1.28444028\n",
      "Trained batch 682 batch loss 1.19384766 epoch total loss 1.28430748\n",
      "Trained batch 683 batch loss 1.04793298 epoch total loss 1.28396142\n",
      "Trained batch 684 batch loss 1.31345654 epoch total loss 1.28400457\n",
      "Trained batch 685 batch loss 1.1707561 epoch total loss 1.28383923\n",
      "Trained batch 686 batch loss 1.16821885 epoch total loss 1.28367066\n",
      "Trained batch 687 batch loss 1.18601179 epoch total loss 1.28352857\n",
      "Trained batch 688 batch loss 1.2663691 epoch total loss 1.28350365\n",
      "Trained batch 689 batch loss 1.29960668 epoch total loss 1.28352702\n",
      "Trained batch 690 batch loss 1.38824773 epoch total loss 1.28367877\n",
      "Trained batch 691 batch loss 1.19483674 epoch total loss 1.28355014\n",
      "Trained batch 692 batch loss 1.49207699 epoch total loss 1.2838515\n",
      "Trained batch 693 batch loss 1.36700368 epoch total loss 1.28397143\n",
      "Trained batch 694 batch loss 1.47391927 epoch total loss 1.28424525\n",
      "Trained batch 695 batch loss 1.30621064 epoch total loss 1.28427684\n",
      "Trained batch 696 batch loss 1.34764957 epoch total loss 1.28436792\n",
      "Trained batch 697 batch loss 1.3077805 epoch total loss 1.28440154\n",
      "Trained batch 698 batch loss 1.35241485 epoch total loss 1.28449893\n",
      "Trained batch 699 batch loss 1.30290747 epoch total loss 1.28452528\n",
      "Trained batch 700 batch loss 1.35802841 epoch total loss 1.2846303\n",
      "Trained batch 701 batch loss 1.27823615 epoch total loss 1.28462124\n",
      "Trained batch 702 batch loss 1.40334022 epoch total loss 1.28479028\n",
      "Trained batch 703 batch loss 1.35422707 epoch total loss 1.2848891\n",
      "Trained batch 704 batch loss 1.37736797 epoch total loss 1.28502047\n",
      "Trained batch 705 batch loss 1.35363507 epoch total loss 1.28511786\n",
      "Trained batch 706 batch loss 1.35565376 epoch total loss 1.28521776\n",
      "Trained batch 707 batch loss 1.31538033 epoch total loss 1.28526032\n",
      "Trained batch 708 batch loss 1.27569747 epoch total loss 1.28524685\n",
      "Trained batch 709 batch loss 1.31452 epoch total loss 1.2852881\n",
      "Trained batch 710 batch loss 1.21481621 epoch total loss 1.28518891\n",
      "Trained batch 711 batch loss 1.37160909 epoch total loss 1.28531039\n",
      "Trained batch 712 batch loss 1.35443354 epoch total loss 1.28540754\n",
      "Trained batch 713 batch loss 1.31534147 epoch total loss 1.2854495\n",
      "Trained batch 714 batch loss 1.15293229 epoch total loss 1.28526402\n",
      "Trained batch 715 batch loss 1.20002174 epoch total loss 1.28514469\n",
      "Trained batch 716 batch loss 1.17805016 epoch total loss 1.28499508\n",
      "Trained batch 717 batch loss 1.23651671 epoch total loss 1.28492749\n",
      "Trained batch 718 batch loss 1.21159887 epoch total loss 1.28482544\n",
      "Trained batch 719 batch loss 1.25904238 epoch total loss 1.28478956\n",
      "Trained batch 720 batch loss 1.15470421 epoch total loss 1.28460884\n",
      "Trained batch 721 batch loss 1.13599467 epoch total loss 1.28440273\n",
      "Trained batch 722 batch loss 1.25008178 epoch total loss 1.28435516\n",
      "Trained batch 723 batch loss 1.2299459 epoch total loss 1.28428\n",
      "Trained batch 724 batch loss 1.14789975 epoch total loss 1.28409147\n",
      "Trained batch 725 batch loss 0.952585101 epoch total loss 1.28363419\n",
      "Trained batch 726 batch loss 1.01445615 epoch total loss 1.28326344\n",
      "Trained batch 727 batch loss 1.25629377 epoch total loss 1.28322637\n",
      "Trained batch 728 batch loss 1.28000987 epoch total loss 1.28322196\n",
      "Trained batch 729 batch loss 1.36982298 epoch total loss 1.28334081\n",
      "Trained batch 730 batch loss 1.2456069 epoch total loss 1.28328907\n",
      "Trained batch 731 batch loss 1.2787739 epoch total loss 1.28328288\n",
      "Trained batch 732 batch loss 1.2070384 epoch total loss 1.28317869\n",
      "Trained batch 733 batch loss 1.17264378 epoch total loss 1.28302789\n",
      "Trained batch 734 batch loss 1.18427634 epoch total loss 1.28289342\n",
      "Trained batch 735 batch loss 1.1999408 epoch total loss 1.28278053\n",
      "Trained batch 736 batch loss 1.30203128 epoch total loss 1.28280663\n",
      "Trained batch 737 batch loss 1.23155165 epoch total loss 1.28273714\n",
      "Trained batch 738 batch loss 1.08195472 epoch total loss 1.2824651\n",
      "Trained batch 739 batch loss 1.21074092 epoch total loss 1.28236806\n",
      "Trained batch 740 batch loss 1.35875964 epoch total loss 1.2824713\n",
      "Trained batch 741 batch loss 1.37738323 epoch total loss 1.28259933\n",
      "Trained batch 742 batch loss 1.37244678 epoch total loss 1.28272045\n",
      "Trained batch 743 batch loss 1.33030963 epoch total loss 1.28278446\n",
      "Trained batch 744 batch loss 1.34823442 epoch total loss 1.28287244\n",
      "Trained batch 745 batch loss 1.20596504 epoch total loss 1.2827692\n",
      "Trained batch 746 batch loss 1.15035832 epoch total loss 1.2825917\n",
      "Trained batch 747 batch loss 1.19372976 epoch total loss 1.28247273\n",
      "Trained batch 748 batch loss 1.31144416 epoch total loss 1.28251147\n",
      "Trained batch 749 batch loss 1.20865226 epoch total loss 1.28241289\n",
      "Trained batch 750 batch loss 1.29226303 epoch total loss 1.282426\n",
      "Trained batch 751 batch loss 1.3908751 epoch total loss 1.28257048\n",
      "Trained batch 752 batch loss 1.31382596 epoch total loss 1.28261197\n",
      "Trained batch 753 batch loss 1.43868685 epoch total loss 1.28281927\n",
      "Trained batch 754 batch loss 1.40153074 epoch total loss 1.28297675\n",
      "Trained batch 755 batch loss 1.39473867 epoch total loss 1.28312469\n",
      "Trained batch 756 batch loss 1.38572955 epoch total loss 1.28326046\n",
      "Trained batch 757 batch loss 1.43654561 epoch total loss 1.28346288\n",
      "Trained batch 758 batch loss 1.36269116 epoch total loss 1.28356743\n",
      "Trained batch 759 batch loss 1.258322 epoch total loss 1.28353417\n",
      "Trained batch 760 batch loss 1.34207332 epoch total loss 1.28361118\n",
      "Trained batch 761 batch loss 1.30417824 epoch total loss 1.28363824\n",
      "Trained batch 762 batch loss 1.1804353 epoch total loss 1.28350282\n",
      "Trained batch 763 batch loss 1.18190074 epoch total loss 1.28336954\n",
      "Trained batch 764 batch loss 1.1187762 epoch total loss 1.28315413\n",
      "Trained batch 765 batch loss 1.21950483 epoch total loss 1.28307092\n",
      "Trained batch 766 batch loss 1.17031705 epoch total loss 1.2829237\n",
      "Trained batch 767 batch loss 1.18370414 epoch total loss 1.28279436\n",
      "Trained batch 768 batch loss 1.22661257 epoch total loss 1.28272116\n",
      "Trained batch 769 batch loss 1.29945242 epoch total loss 1.28274298\n",
      "Trained batch 770 batch loss 1.1760869 epoch total loss 1.28260446\n",
      "Trained batch 771 batch loss 1.13169158 epoch total loss 1.28240871\n",
      "Trained batch 772 batch loss 1.19274592 epoch total loss 1.2822926\n",
      "Trained batch 773 batch loss 1.29220855 epoch total loss 1.28230548\n",
      "Trained batch 774 batch loss 1.3094418 epoch total loss 1.28234053\n",
      "Trained batch 775 batch loss 1.50901806 epoch total loss 1.28263307\n",
      "Trained batch 776 batch loss 1.32899094 epoch total loss 1.28269279\n",
      "Trained batch 777 batch loss 1.29335058 epoch total loss 1.28270638\n",
      "Trained batch 778 batch loss 1.2437017 epoch total loss 1.28265631\n",
      "Trained batch 779 batch loss 1.3158952 epoch total loss 1.28269899\n",
      "Trained batch 780 batch loss 1.22396779 epoch total loss 1.28262365\n",
      "Trained batch 781 batch loss 1.10267735 epoch total loss 1.28239322\n",
      "Trained batch 782 batch loss 1.39132643 epoch total loss 1.28253257\n",
      "Trained batch 783 batch loss 1.37124801 epoch total loss 1.28264582\n",
      "Trained batch 784 batch loss 1.3505255 epoch total loss 1.28273249\n",
      "Trained batch 785 batch loss 1.51481903 epoch total loss 1.28302813\n",
      "Trained batch 786 batch loss 1.36836684 epoch total loss 1.28313661\n",
      "Trained batch 787 batch loss 1.26692152 epoch total loss 1.28311598\n",
      "Trained batch 788 batch loss 1.31024182 epoch total loss 1.28315043\n",
      "Trained batch 789 batch loss 1.35877252 epoch total loss 1.28324628\n",
      "Trained batch 790 batch loss 1.31070805 epoch total loss 1.28328109\n",
      "Trained batch 791 batch loss 1.23701811 epoch total loss 1.28322256\n",
      "Trained batch 792 batch loss 1.22298646 epoch total loss 1.2831465\n",
      "Trained batch 793 batch loss 1.36282754 epoch total loss 1.28324699\n",
      "Trained batch 794 batch loss 1.29041433 epoch total loss 1.28325605\n",
      "Trained batch 795 batch loss 1.16773212 epoch total loss 1.28311074\n",
      "Trained batch 796 batch loss 1.17530632 epoch total loss 1.2829752\n",
      "Trained batch 797 batch loss 1.08340597 epoch total loss 1.28272486\n",
      "Trained batch 798 batch loss 1.12408018 epoch total loss 1.28252614\n",
      "Trained batch 799 batch loss 1.3931309 epoch total loss 1.28266454\n",
      "Trained batch 800 batch loss 1.34148419 epoch total loss 1.28273809\n",
      "Trained batch 801 batch loss 1.48075604 epoch total loss 1.28298521\n",
      "Trained batch 802 batch loss 1.30146837 epoch total loss 1.28300834\n",
      "Trained batch 803 batch loss 1.40114534 epoch total loss 1.28315544\n",
      "Trained batch 804 batch loss 1.33086109 epoch total loss 1.28321469\n",
      "Trained batch 805 batch loss 1.50065017 epoch total loss 1.2834847\n",
      "Trained batch 806 batch loss 1.3930037 epoch total loss 1.28362048\n",
      "Trained batch 807 batch loss 1.41872025 epoch total loss 1.28378797\n",
      "Trained batch 808 batch loss 1.27052665 epoch total loss 1.28377151\n",
      "Trained batch 809 batch loss 1.33475804 epoch total loss 1.28383446\n",
      "Trained batch 810 batch loss 1.23230362 epoch total loss 1.2837708\n",
      "Trained batch 811 batch loss 1.22536182 epoch total loss 1.2836988\n",
      "Trained batch 812 batch loss 1.37075186 epoch total loss 1.28380597\n",
      "Trained batch 813 batch loss 1.31328321 epoch total loss 1.28384221\n",
      "Trained batch 814 batch loss 1.18103814 epoch total loss 1.28371584\n",
      "Trained batch 815 batch loss 1.13862348 epoch total loss 1.28353786\n",
      "Trained batch 816 batch loss 1.11999309 epoch total loss 1.28333747\n",
      "Trained batch 817 batch loss 1.09417379 epoch total loss 1.28310585\n",
      "Trained batch 818 batch loss 1.29872763 epoch total loss 1.28312492\n",
      "Trained batch 819 batch loss 1.55391848 epoch total loss 1.28345561\n",
      "Trained batch 820 batch loss 1.54493344 epoch total loss 1.2837745\n",
      "Trained batch 821 batch loss 1.48719382 epoch total loss 1.28402221\n",
      "Trained batch 822 batch loss 1.37028408 epoch total loss 1.28412712\n",
      "Trained batch 823 batch loss 1.4974947 epoch total loss 1.28438628\n",
      "Trained batch 824 batch loss 1.38163137 epoch total loss 1.28450429\n",
      "Trained batch 825 batch loss 1.30823874 epoch total loss 1.28453302\n",
      "Trained batch 826 batch loss 1.31255472 epoch total loss 1.28456688\n",
      "Trained batch 827 batch loss 1.26283181 epoch total loss 1.28454053\n",
      "Trained batch 828 batch loss 1.20957148 epoch total loss 1.28445\n",
      "Trained batch 829 batch loss 1.49342251 epoch total loss 1.28470218\n",
      "Trained batch 830 batch loss 1.40008247 epoch total loss 1.28484106\n",
      "Trained batch 831 batch loss 1.40160298 epoch total loss 1.28498161\n",
      "Trained batch 832 batch loss 1.32398641 epoch total loss 1.28502846\n",
      "Trained batch 833 batch loss 1.28338075 epoch total loss 1.28502643\n",
      "Trained batch 834 batch loss 1.25781453 epoch total loss 1.28499377\n",
      "Trained batch 835 batch loss 1.32687 epoch total loss 1.28504395\n",
      "Trained batch 836 batch loss 1.28436458 epoch total loss 1.28504324\n",
      "Trained batch 837 batch loss 1.45702291 epoch total loss 1.28524876\n",
      "Trained batch 838 batch loss 1.56780601 epoch total loss 1.28558588\n",
      "Trained batch 839 batch loss 1.31837547 epoch total loss 1.28562486\n",
      "Trained batch 840 batch loss 1.35738802 epoch total loss 1.28571033\n",
      "Trained batch 841 batch loss 1.41464162 epoch total loss 1.28586376\n",
      "Trained batch 842 batch loss 1.35580659 epoch total loss 1.28594685\n",
      "Trained batch 843 batch loss 1.39421439 epoch total loss 1.28607523\n",
      "Trained batch 844 batch loss 1.3542788 epoch total loss 1.28615594\n",
      "Trained batch 845 batch loss 1.11018801 epoch total loss 1.2859478\n",
      "Trained batch 846 batch loss 1.06756532 epoch total loss 1.28568959\n",
      "Trained batch 847 batch loss 1.10549819 epoch total loss 1.2854768\n",
      "Trained batch 848 batch loss 1.08098042 epoch total loss 1.28523552\n",
      "Trained batch 849 batch loss 1.27444541 epoch total loss 1.28522277\n",
      "Trained batch 850 batch loss 1.38849545 epoch total loss 1.28534436\n",
      "Trained batch 851 batch loss 1.58296442 epoch total loss 1.28569412\n",
      "Trained batch 852 batch loss 1.41234231 epoch total loss 1.28584278\n",
      "Trained batch 853 batch loss 1.2465378 epoch total loss 1.28579676\n",
      "Trained batch 854 batch loss 1.24011362 epoch total loss 1.28574336\n",
      "Trained batch 855 batch loss 1.22757 epoch total loss 1.28567517\n",
      "Trained batch 856 batch loss 1.39554977 epoch total loss 1.28580356\n",
      "Trained batch 857 batch loss 1.29365253 epoch total loss 1.28581274\n",
      "Trained batch 858 batch loss 1.35311747 epoch total loss 1.28589118\n",
      "Trained batch 859 batch loss 1.30722606 epoch total loss 1.28591609\n",
      "Trained batch 860 batch loss 1.39078236 epoch total loss 1.28603804\n",
      "Trained batch 861 batch loss 1.21384192 epoch total loss 1.28595412\n",
      "Trained batch 862 batch loss 1.21839714 epoch total loss 1.2858758\n",
      "Trained batch 863 batch loss 1.21142304 epoch total loss 1.28578949\n",
      "Trained batch 864 batch loss 1.20470166 epoch total loss 1.28569567\n",
      "Trained batch 865 batch loss 1.36174 epoch total loss 1.28578353\n",
      "Trained batch 866 batch loss 1.18403018 epoch total loss 1.28566611\n",
      "Trained batch 867 batch loss 1.06446815 epoch total loss 1.285411\n",
      "Trained batch 868 batch loss 1.2016381 epoch total loss 1.28531444\n",
      "Trained batch 869 batch loss 1.31006289 epoch total loss 1.28534293\n",
      "Trained batch 870 batch loss 1.27085328 epoch total loss 1.28532636\n",
      "Trained batch 871 batch loss 1.34901762 epoch total loss 1.28539944\n",
      "Trained batch 872 batch loss 1.3184011 epoch total loss 1.28543723\n",
      "Trained batch 873 batch loss 1.26431894 epoch total loss 1.28541303\n",
      "Trained batch 874 batch loss 1.34986675 epoch total loss 1.2854867\n",
      "Trained batch 875 batch loss 1.31678665 epoch total loss 1.28552246\n",
      "Trained batch 876 batch loss 1.39953184 epoch total loss 1.28565264\n",
      "Trained batch 877 batch loss 1.38875747 epoch total loss 1.28577018\n",
      "Trained batch 878 batch loss 1.23017478 epoch total loss 1.285707\n",
      "Trained batch 879 batch loss 1.31767941 epoch total loss 1.28574324\n",
      "Trained batch 880 batch loss 1.28904343 epoch total loss 1.28574705\n",
      "Trained batch 881 batch loss 1.30917394 epoch total loss 1.28577363\n",
      "Trained batch 882 batch loss 1.38613069 epoch total loss 1.28588748\n",
      "Trained batch 883 batch loss 1.27118325 epoch total loss 1.28587079\n",
      "Trained batch 884 batch loss 1.24665225 epoch total loss 1.28582656\n",
      "Trained batch 885 batch loss 1.31312811 epoch total loss 1.28585732\n",
      "Trained batch 886 batch loss 1.32606673 epoch total loss 1.28590274\n",
      "Trained batch 887 batch loss 1.31243527 epoch total loss 1.28593254\n",
      "Trained batch 888 batch loss 1.20195162 epoch total loss 1.28583789\n",
      "Trained batch 889 batch loss 1.36141431 epoch total loss 1.285923\n",
      "Trained batch 890 batch loss 1.50371599 epoch total loss 1.28616762\n",
      "Trained batch 891 batch loss 1.44555664 epoch total loss 1.28634655\n",
      "Trained batch 892 batch loss 1.37016261 epoch total loss 1.28644049\n",
      "Trained batch 893 batch loss 1.13171506 epoch total loss 1.28626716\n",
      "Trained batch 894 batch loss 1.24802804 epoch total loss 1.28622448\n",
      "Trained batch 895 batch loss 1.23961055 epoch total loss 1.28617239\n",
      "Trained batch 896 batch loss 1.32678843 epoch total loss 1.28621769\n",
      "Trained batch 897 batch loss 1.26593328 epoch total loss 1.28619516\n",
      "Trained batch 898 batch loss 1.27152312 epoch total loss 1.28617871\n",
      "Trained batch 899 batch loss 1.38500631 epoch total loss 1.28628874\n",
      "Trained batch 900 batch loss 1.38434184 epoch total loss 1.2863977\n",
      "Trained batch 901 batch loss 1.34448123 epoch total loss 1.28646219\n",
      "Trained batch 902 batch loss 1.35677063 epoch total loss 1.28654015\n",
      "Trained batch 903 batch loss 1.25826955 epoch total loss 1.28650892\n",
      "Trained batch 904 batch loss 1.27335823 epoch total loss 1.28649426\n",
      "Trained batch 905 batch loss 1.19243479 epoch total loss 1.2863903\n",
      "Trained batch 906 batch loss 1.31294358 epoch total loss 1.28641963\n",
      "Trained batch 907 batch loss 1.22716808 epoch total loss 1.2863543\n",
      "Trained batch 908 batch loss 1.22466063 epoch total loss 1.28628635\n",
      "Trained batch 909 batch loss 1.16141307 epoch total loss 1.28614891\n",
      "Trained batch 910 batch loss 1.21003926 epoch total loss 1.28606534\n",
      "Trained batch 911 batch loss 1.26326025 epoch total loss 1.28604031\n",
      "Trained batch 912 batch loss 1.24484479 epoch total loss 1.28599524\n",
      "Trained batch 913 batch loss 1.20314074 epoch total loss 1.28590441\n",
      "Trained batch 914 batch loss 1.36832476 epoch total loss 1.28599453\n",
      "Trained batch 915 batch loss 1.31061935 epoch total loss 1.28602159\n",
      "Trained batch 916 batch loss 1.26835549 epoch total loss 1.28600216\n",
      "Trained batch 917 batch loss 1.32653904 epoch total loss 1.28604639\n",
      "Trained batch 918 batch loss 1.05269885 epoch total loss 1.28579223\n",
      "Trained batch 919 batch loss 1.13415658 epoch total loss 1.28562725\n",
      "Trained batch 920 batch loss 1.16240656 epoch total loss 1.28549325\n",
      "Trained batch 921 batch loss 1.37592077 epoch total loss 1.28559148\n",
      "Trained batch 922 batch loss 1.29511285 epoch total loss 1.28560185\n",
      "Trained batch 923 batch loss 1.18471408 epoch total loss 1.28549254\n",
      "Trained batch 924 batch loss 1.15399766 epoch total loss 1.28535032\n",
      "Trained batch 925 batch loss 1.16944444 epoch total loss 1.28522503\n",
      "Trained batch 926 batch loss 1.32533598 epoch total loss 1.28526831\n",
      "Trained batch 927 batch loss 1.28750563 epoch total loss 1.28527069\n",
      "Trained batch 928 batch loss 1.38956666 epoch total loss 1.28538299\n",
      "Trained batch 929 batch loss 1.15945125 epoch total loss 1.28524745\n",
      "Trained batch 930 batch loss 1.01694095 epoch total loss 1.28495896\n",
      "Trained batch 931 batch loss 0.972142 epoch total loss 1.28462303\n",
      "Trained batch 932 batch loss 1.04799783 epoch total loss 1.28436911\n",
      "Trained batch 933 batch loss 1.29108834 epoch total loss 1.28437638\n",
      "Trained batch 934 batch loss 1.23012638 epoch total loss 1.28431821\n",
      "Trained batch 935 batch loss 1.23989987 epoch total loss 1.28427064\n",
      "Trained batch 936 batch loss 1.18791914 epoch total loss 1.28416765\n",
      "Trained batch 937 batch loss 1.2449553 epoch total loss 1.28412592\n",
      "Trained batch 938 batch loss 1.21452296 epoch total loss 1.28405166\n",
      "Trained batch 939 batch loss 1.34394383 epoch total loss 1.28411543\n",
      "Trained batch 940 batch loss 1.39807522 epoch total loss 1.28423667\n",
      "Trained batch 941 batch loss 1.30830622 epoch total loss 1.2842623\n",
      "Trained batch 942 batch loss 1.42011714 epoch total loss 1.28440654\n",
      "Trained batch 943 batch loss 1.32425642 epoch total loss 1.28444886\n",
      "Trained batch 944 batch loss 1.35066307 epoch total loss 1.28451896\n",
      "Trained batch 945 batch loss 1.3666954 epoch total loss 1.28460598\n",
      "Trained batch 946 batch loss 1.21333647 epoch total loss 1.28453064\n",
      "Trained batch 947 batch loss 1.2907517 epoch total loss 1.28453732\n",
      "Trained batch 948 batch loss 1.24948704 epoch total loss 1.28450036\n",
      "Trained batch 949 batch loss 1.22847652 epoch total loss 1.28444135\n",
      "Trained batch 950 batch loss 1.25971246 epoch total loss 1.28441536\n",
      "Trained batch 951 batch loss 1.2893213 epoch total loss 1.28442049\n",
      "Trained batch 952 batch loss 1.33693361 epoch total loss 1.28447568\n",
      "Trained batch 953 batch loss 1.28295898 epoch total loss 1.28447402\n",
      "Trained batch 954 batch loss 1.26423621 epoch total loss 1.28445292\n",
      "Trained batch 955 batch loss 1.40955949 epoch total loss 1.28458381\n",
      "Trained batch 956 batch loss 1.28957176 epoch total loss 1.28458905\n",
      "Trained batch 957 batch loss 1.33046067 epoch total loss 1.28463697\n",
      "Trained batch 958 batch loss 1.40152311 epoch total loss 1.28475893\n",
      "Trained batch 959 batch loss 1.25052309 epoch total loss 1.28472316\n",
      "Trained batch 960 batch loss 1.34355402 epoch total loss 1.28478444\n",
      "Trained batch 961 batch loss 1.29800594 epoch total loss 1.28479815\n",
      "Trained batch 962 batch loss 1.31651115 epoch total loss 1.28483117\n",
      "Trained batch 963 batch loss 1.32178795 epoch total loss 1.28486955\n",
      "Trained batch 964 batch loss 1.28036 epoch total loss 1.2848649\n",
      "Trained batch 965 batch loss 1.30678272 epoch total loss 1.28488755\n",
      "Trained batch 966 batch loss 1.32370639 epoch total loss 1.28492773\n",
      "Trained batch 967 batch loss 1.38104594 epoch total loss 1.28502727\n",
      "Trained batch 968 batch loss 1.22796535 epoch total loss 1.28496826\n",
      "Trained batch 969 batch loss 1.1693902 epoch total loss 1.28484905\n",
      "Trained batch 970 batch loss 1.10929298 epoch total loss 1.28466797\n",
      "Trained batch 971 batch loss 1.12036383 epoch total loss 1.28449881\n",
      "Trained batch 972 batch loss 1.24197233 epoch total loss 1.28445494\n",
      "Trained batch 973 batch loss 1.24840534 epoch total loss 1.28441799\n",
      "Trained batch 974 batch loss 1.16099286 epoch total loss 1.28429127\n",
      "Trained batch 975 batch loss 1.11274779 epoch total loss 1.28411531\n",
      "Trained batch 976 batch loss 1.16682744 epoch total loss 1.28399515\n",
      "Trained batch 977 batch loss 1.3043344 epoch total loss 1.28401601\n",
      "Trained batch 978 batch loss 1.26966286 epoch total loss 1.28400135\n",
      "Trained batch 979 batch loss 1.3233403 epoch total loss 1.28404152\n",
      "Trained batch 980 batch loss 1.33141315 epoch total loss 1.28408992\n",
      "Trained batch 981 batch loss 1.29521298 epoch total loss 1.28410113\n",
      "Trained batch 982 batch loss 1.26179135 epoch total loss 1.28407848\n",
      "Trained batch 983 batch loss 1.33247733 epoch total loss 1.28412783\n",
      "Trained batch 984 batch loss 1.27605033 epoch total loss 1.28411949\n",
      "Trained batch 985 batch loss 1.28345335 epoch total loss 1.28411889\n",
      "Trained batch 986 batch loss 1.21114218 epoch total loss 1.28404486\n",
      "Trained batch 987 batch loss 1.20893812 epoch total loss 1.28396881\n",
      "Trained batch 988 batch loss 1.29150844 epoch total loss 1.28397644\n",
      "Trained batch 989 batch loss 1.17142034 epoch total loss 1.28386259\n",
      "Trained batch 990 batch loss 1.1997745 epoch total loss 1.28377771\n",
      "Trained batch 991 batch loss 1.15127695 epoch total loss 1.28364396\n",
      "Trained batch 992 batch loss 1.11844552 epoch total loss 1.28347743\n",
      "Trained batch 993 batch loss 1.24838364 epoch total loss 1.28344214\n",
      "Trained batch 994 batch loss 1.22334099 epoch total loss 1.2833817\n",
      "Trained batch 995 batch loss 1.22112393 epoch total loss 1.28331912\n",
      "Trained batch 996 batch loss 1.39004552 epoch total loss 1.28342617\n",
      "Trained batch 997 batch loss 1.31652832 epoch total loss 1.28345942\n",
      "Trained batch 998 batch loss 1.21195817 epoch total loss 1.28338766\n",
      "Trained batch 999 batch loss 1.33473706 epoch total loss 1.28343904\n",
      "Trained batch 1000 batch loss 1.45263529 epoch total loss 1.28360832\n",
      "Trained batch 1001 batch loss 1.37698555 epoch total loss 1.28370154\n",
      "Trained batch 1002 batch loss 1.27028704 epoch total loss 1.28368807\n",
      "Trained batch 1003 batch loss 1.4648701 epoch total loss 1.28386879\n",
      "Trained batch 1004 batch loss 1.40403104 epoch total loss 1.28398848\n",
      "Trained batch 1005 batch loss 1.24638808 epoch total loss 1.28395092\n",
      "Trained batch 1006 batch loss 1.17304087 epoch total loss 1.28384078\n",
      "Trained batch 1007 batch loss 1.41746891 epoch total loss 1.28397346\n",
      "Trained batch 1008 batch loss 1.38968945 epoch total loss 1.28407836\n",
      "Trained batch 1009 batch loss 1.40784287 epoch total loss 1.28420103\n",
      "Trained batch 1010 batch loss 1.32389021 epoch total loss 1.28424025\n",
      "Trained batch 1011 batch loss 1.26076138 epoch total loss 1.284217\n",
      "Trained batch 1012 batch loss 1.23609304 epoch total loss 1.28416944\n",
      "Trained batch 1013 batch loss 1.29121482 epoch total loss 1.28417647\n",
      "Trained batch 1014 batch loss 1.35570073 epoch total loss 1.28424704\n",
      "Trained batch 1015 batch loss 1.42830682 epoch total loss 1.2843889\n",
      "Trained batch 1016 batch loss 1.36197925 epoch total loss 1.28446531\n",
      "Trained batch 1017 batch loss 1.32754207 epoch total loss 1.28450763\n",
      "Trained batch 1018 batch loss 1.12492871 epoch total loss 1.28435075\n",
      "Trained batch 1019 batch loss 1.1507597 epoch total loss 1.28421974\n",
      "Trained batch 1020 batch loss 1.25841975 epoch total loss 1.28419435\n",
      "Trained batch 1021 batch loss 1.32970881 epoch total loss 1.28423893\n",
      "Trained batch 1022 batch loss 1.28104961 epoch total loss 1.28423584\n",
      "Trained batch 1023 batch loss 1.15275145 epoch total loss 1.28410721\n",
      "Trained batch 1024 batch loss 1.08864951 epoch total loss 1.28391635\n",
      "Trained batch 1025 batch loss 1.10227025 epoch total loss 1.28373921\n",
      "Trained batch 1026 batch loss 1.304286 epoch total loss 1.28375924\n",
      "Trained batch 1027 batch loss 1.28088355 epoch total loss 1.28375638\n",
      "Trained batch 1028 batch loss 1.49000633 epoch total loss 1.283957\n",
      "Trained batch 1029 batch loss 1.58501649 epoch total loss 1.28424954\n",
      "Trained batch 1030 batch loss 1.44098604 epoch total loss 1.28440177\n",
      "Trained batch 1031 batch loss 1.27189016 epoch total loss 1.28438962\n",
      "Trained batch 1032 batch loss 1.2881906 epoch total loss 1.28439331\n",
      "Trained batch 1033 batch loss 1.30067575 epoch total loss 1.28440905\n",
      "Trained batch 1034 batch loss 1.15483189 epoch total loss 1.28428364\n",
      "Trained batch 1035 batch loss 1.27911747 epoch total loss 1.28427875\n",
      "Trained batch 1036 batch loss 1.24753642 epoch total loss 1.28424335\n",
      "Trained batch 1037 batch loss 1.23415697 epoch total loss 1.28419495\n",
      "Trained batch 1038 batch loss 1.39772391 epoch total loss 1.28430438\n",
      "Trained batch 1039 batch loss 1.28493249 epoch total loss 1.28430498\n",
      "Trained batch 1040 batch loss 1.30771637 epoch total loss 1.28432751\n",
      "Trained batch 1041 batch loss 1.3378607 epoch total loss 1.28437889\n",
      "Trained batch 1042 batch loss 1.27678812 epoch total loss 1.28437161\n",
      "Trained batch 1043 batch loss 1.21927702 epoch total loss 1.28430915\n",
      "Trained batch 1044 batch loss 1.32231784 epoch total loss 1.28434551\n",
      "Trained batch 1045 batch loss 1.31478524 epoch total loss 1.28437459\n",
      "Trained batch 1046 batch loss 1.23970532 epoch total loss 1.28433204\n",
      "Trained batch 1047 batch loss 1.17155027 epoch total loss 1.28422427\n",
      "Trained batch 1048 batch loss 1.28928185 epoch total loss 1.28422904\n",
      "Trained batch 1049 batch loss 1.14605486 epoch total loss 1.28409731\n",
      "Trained batch 1050 batch loss 1.13339651 epoch total loss 1.28395379\n",
      "Trained batch 1051 batch loss 1.12235069 epoch total loss 1.2838\n",
      "Trained batch 1052 batch loss 1.11372447 epoch total loss 1.28363836\n",
      "Trained batch 1053 batch loss 1.19546127 epoch total loss 1.28355455\n",
      "Trained batch 1054 batch loss 1.19477141 epoch total loss 1.28347039\n",
      "Trained batch 1055 batch loss 1.1611551 epoch total loss 1.28335452\n",
      "Trained batch 1056 batch loss 1.21283519 epoch total loss 1.28328776\n",
      "Trained batch 1057 batch loss 1.13280952 epoch total loss 1.28314543\n",
      "Trained batch 1058 batch loss 1.27629876 epoch total loss 1.28313887\n",
      "Trained batch 1059 batch loss 1.39322364 epoch total loss 1.28324282\n",
      "Trained batch 1060 batch loss 1.41569889 epoch total loss 1.28336763\n",
      "Trained batch 1061 batch loss 1.34116483 epoch total loss 1.28342223\n",
      "Trained batch 1062 batch loss 1.33669591 epoch total loss 1.2834723\n",
      "Trained batch 1063 batch loss 1.22526884 epoch total loss 1.28341758\n",
      "Trained batch 1064 batch loss 1.3373853 epoch total loss 1.28346825\n",
      "Trained batch 1065 batch loss 1.3421787 epoch total loss 1.28352332\n",
      "Trained batch 1066 batch loss 1.4312166 epoch total loss 1.28366196\n",
      "Trained batch 1067 batch loss 1.38251531 epoch total loss 1.28375471\n",
      "Trained batch 1068 batch loss 1.42763174 epoch total loss 1.28388941\n",
      "Trained batch 1069 batch loss 1.36500907 epoch total loss 1.28396523\n",
      "Trained batch 1070 batch loss 1.30342853 epoch total loss 1.28398347\n",
      "Trained batch 1071 batch loss 1.2611115 epoch total loss 1.28396213\n",
      "Trained batch 1072 batch loss 1.18653524 epoch total loss 1.28387117\n",
      "Trained batch 1073 batch loss 1.20164597 epoch total loss 1.28379464\n",
      "Trained batch 1074 batch loss 1.30781698 epoch total loss 1.28381705\n",
      "Trained batch 1075 batch loss 1.31505561 epoch total loss 1.28384602\n",
      "Trained batch 1076 batch loss 1.22231317 epoch total loss 1.2837888\n",
      "Trained batch 1077 batch loss 1.28151703 epoch total loss 1.28378677\n",
      "Trained batch 1078 batch loss 1.1666249 epoch total loss 1.28367805\n",
      "Trained batch 1079 batch loss 1.20508575 epoch total loss 1.28360522\n",
      "Trained batch 1080 batch loss 1.13459659 epoch total loss 1.28346729\n",
      "Trained batch 1081 batch loss 1.19309938 epoch total loss 1.28338373\n",
      "Trained batch 1082 batch loss 1.15307748 epoch total loss 1.28326321\n",
      "Trained batch 1083 batch loss 1.2038188 epoch total loss 1.28318989\n",
      "Trained batch 1084 batch loss 1.2481041 epoch total loss 1.28315747\n",
      "Trained batch 1085 batch loss 1.19447541 epoch total loss 1.28307581\n",
      "Trained batch 1086 batch loss 1.22468448 epoch total loss 1.28302205\n",
      "Trained batch 1087 batch loss 1.154549 epoch total loss 1.28290379\n",
      "Trained batch 1088 batch loss 1.07171094 epoch total loss 1.28270972\n",
      "Trained batch 1089 batch loss 1.24303555 epoch total loss 1.28267324\n",
      "Trained batch 1090 batch loss 1.14480877 epoch total loss 1.28254676\n",
      "Trained batch 1091 batch loss 1.2244302 epoch total loss 1.28249347\n",
      "Trained batch 1092 batch loss 1.26206219 epoch total loss 1.28247488\n",
      "Trained batch 1093 batch loss 1.34092677 epoch total loss 1.28252828\n",
      "Trained batch 1094 batch loss 1.32768846 epoch total loss 1.28256953\n",
      "Trained batch 1095 batch loss 1.25818992 epoch total loss 1.28254724\n",
      "Trained batch 1096 batch loss 1.2145741 epoch total loss 1.28248525\n",
      "Trained batch 1097 batch loss 1.2696681 epoch total loss 1.28247356\n",
      "Trained batch 1098 batch loss 1.31104887 epoch total loss 1.28249955\n",
      "Trained batch 1099 batch loss 1.14045334 epoch total loss 1.28237045\n",
      "Trained batch 1100 batch loss 1.04734898 epoch total loss 1.28215671\n",
      "Trained batch 1101 batch loss 0.950818062 epoch total loss 1.28185582\n",
      "Trained batch 1102 batch loss 1.19365096 epoch total loss 1.28177571\n",
      "Trained batch 1103 batch loss 1.25617349 epoch total loss 1.28175259\n",
      "Trained batch 1104 batch loss 1.61880755 epoch total loss 1.28205788\n",
      "Trained batch 1105 batch loss 1.44370937 epoch total loss 1.28220415\n",
      "Trained batch 1106 batch loss 1.34461069 epoch total loss 1.28226054\n",
      "Trained batch 1107 batch loss 1.29149389 epoch total loss 1.28226888\n",
      "Trained batch 1108 batch loss 1.14276886 epoch total loss 1.282143\n",
      "Trained batch 1109 batch loss 1.17494822 epoch total loss 1.28204632\n",
      "Trained batch 1110 batch loss 1.30337644 epoch total loss 1.28206551\n",
      "Trained batch 1111 batch loss 1.28992152 epoch total loss 1.28207266\n",
      "Trained batch 1112 batch loss 1.32926393 epoch total loss 1.28211498\n",
      "Trained batch 1113 batch loss 1.29352522 epoch total loss 1.28212535\n",
      "Trained batch 1114 batch loss 1.26698756 epoch total loss 1.28211176\n",
      "Trained batch 1115 batch loss 1.31209111 epoch total loss 1.28213871\n",
      "Trained batch 1116 batch loss 1.3600421 epoch total loss 1.28220844\n",
      "Trained batch 1117 batch loss 1.33057737 epoch total loss 1.28225172\n",
      "Trained batch 1118 batch loss 1.19815826 epoch total loss 1.28217649\n",
      "Trained batch 1119 batch loss 1.24011219 epoch total loss 1.28213882\n",
      "Trained batch 1120 batch loss 1.26933074 epoch total loss 1.28212738\n",
      "Trained batch 1121 batch loss 1.21871889 epoch total loss 1.28207088\n",
      "Trained batch 1122 batch loss 1.08017206 epoch total loss 1.28189087\n",
      "Trained batch 1123 batch loss 1.32296538 epoch total loss 1.28192759\n",
      "Trained batch 1124 batch loss 1.24966931 epoch total loss 1.28189886\n",
      "Trained batch 1125 batch loss 1.18870938 epoch total loss 1.28181601\n",
      "Trained batch 1126 batch loss 1.16546202 epoch total loss 1.28171253\n",
      "Trained batch 1127 batch loss 1.19031858 epoch total loss 1.28163147\n",
      "Trained batch 1128 batch loss 1.29388213 epoch total loss 1.28164232\n",
      "Trained batch 1129 batch loss 1.45751643 epoch total loss 1.28179812\n",
      "Trained batch 1130 batch loss 1.31002259 epoch total loss 1.28182304\n",
      "Trained batch 1131 batch loss 1.38404465 epoch total loss 1.2819134\n",
      "Trained batch 1132 batch loss 1.4674077 epoch total loss 1.28207731\n",
      "Trained batch 1133 batch loss 1.38140321 epoch total loss 1.28216493\n",
      "Trained batch 1134 batch loss 1.31579697 epoch total loss 1.28219461\n",
      "Trained batch 1135 batch loss 1.23721361 epoch total loss 1.28215492\n",
      "Trained batch 1136 batch loss 1.33854496 epoch total loss 1.28220451\n",
      "Trained batch 1137 batch loss 1.19740987 epoch total loss 1.28212988\n",
      "Trained batch 1138 batch loss 1.24968386 epoch total loss 1.28210139\n",
      "Trained batch 1139 batch loss 1.26451337 epoch total loss 1.2820859\n",
      "Trained batch 1140 batch loss 1.33468509 epoch total loss 1.28213215\n",
      "Trained batch 1141 batch loss 1.35083008 epoch total loss 1.28219235\n",
      "Trained batch 1142 batch loss 1.29706633 epoch total loss 1.28220534\n",
      "Trained batch 1143 batch loss 1.37260187 epoch total loss 1.2822845\n",
      "Trained batch 1144 batch loss 1.16744626 epoch total loss 1.28218412\n",
      "Trained batch 1145 batch loss 1.17590821 epoch total loss 1.28209126\n",
      "Trained batch 1146 batch loss 1.20684505 epoch total loss 1.28202558\n",
      "Trained batch 1147 batch loss 1.21651316 epoch total loss 1.28196847\n",
      "Trained batch 1148 batch loss 1.37001812 epoch total loss 1.28204513\n",
      "Trained batch 1149 batch loss 1.19297945 epoch total loss 1.28196764\n",
      "Trained batch 1150 batch loss 1.25376678 epoch total loss 1.2819432\n",
      "Trained batch 1151 batch loss 1.1661129 epoch total loss 1.28184259\n",
      "Trained batch 1152 batch loss 1.25496781 epoch total loss 1.28181922\n",
      "Trained batch 1153 batch loss 1.25339794 epoch total loss 1.28179455\n",
      "Trained batch 1154 batch loss 1.16242898 epoch total loss 1.28169119\n",
      "Trained batch 1155 batch loss 1.15126967 epoch total loss 1.2815783\n",
      "Trained batch 1156 batch loss 1.23456132 epoch total loss 1.28153765\n",
      "Trained batch 1157 batch loss 1.2192626 epoch total loss 1.28148377\n",
      "Trained batch 1158 batch loss 1.25503635 epoch total loss 1.28146088\n",
      "Trained batch 1159 batch loss 1.1726017 epoch total loss 1.28136706\n",
      "Trained batch 1160 batch loss 1.23505199 epoch total loss 1.28132713\n",
      "Trained batch 1161 batch loss 1.26810467 epoch total loss 1.28131568\n",
      "Trained batch 1162 batch loss 1.35395098 epoch total loss 1.28137827\n",
      "Trained batch 1163 batch loss 1.23292339 epoch total loss 1.28133655\n",
      "Trained batch 1164 batch loss 1.16708899 epoch total loss 1.28123844\n",
      "Trained batch 1165 batch loss 1.31349254 epoch total loss 1.28126609\n",
      "Trained batch 1166 batch loss 1.30884373 epoch total loss 1.28128982\n",
      "Trained batch 1167 batch loss 1.33200228 epoch total loss 1.28133321\n",
      "Trained batch 1168 batch loss 1.38751197 epoch total loss 1.28142416\n",
      "Trained batch 1169 batch loss 1.16591227 epoch total loss 1.28132534\n",
      "Trained batch 1170 batch loss 1.19613338 epoch total loss 1.2812525\n",
      "Trained batch 1171 batch loss 1.2526046 epoch total loss 1.28122795\n",
      "Trained batch 1172 batch loss 1.35119724 epoch total loss 1.28128767\n",
      "Trained batch 1173 batch loss 1.2194953 epoch total loss 1.28123498\n",
      "Trained batch 1174 batch loss 1.15857661 epoch total loss 1.28113055\n",
      "Trained batch 1175 batch loss 1.06084061 epoch total loss 1.28094304\n",
      "Trained batch 1176 batch loss 1.00690269 epoch total loss 1.28071\n",
      "Trained batch 1177 batch loss 1.30462313 epoch total loss 1.28073025\n",
      "Trained batch 1178 batch loss 1.51336026 epoch total loss 1.28092778\n",
      "Trained batch 1179 batch loss 1.3019172 epoch total loss 1.28094554\n",
      "Trained batch 1180 batch loss 1.169801 epoch total loss 1.28085136\n",
      "Trained batch 1181 batch loss 1.22735333 epoch total loss 1.28080595\n",
      "Trained batch 1182 batch loss 1.19320583 epoch total loss 1.28073192\n",
      "Trained batch 1183 batch loss 1.2382586 epoch total loss 1.28069603\n",
      "Trained batch 1184 batch loss 1.16096902 epoch total loss 1.28059494\n",
      "Trained batch 1185 batch loss 1.25031734 epoch total loss 1.28056943\n",
      "Trained batch 1186 batch loss 1.22042191 epoch total loss 1.28051865\n",
      "Trained batch 1187 batch loss 1.34232926 epoch total loss 1.28057075\n",
      "Trained batch 1188 batch loss 1.27324748 epoch total loss 1.28056455\n",
      "Trained batch 1189 batch loss 1.26878917 epoch total loss 1.28055465\n",
      "Trained batch 1190 batch loss 1.2033143 epoch total loss 1.2804898\n",
      "Trained batch 1191 batch loss 1.18844986 epoch total loss 1.28041255\n",
      "Trained batch 1192 batch loss 1.219733 epoch total loss 1.28036165\n",
      "Trained batch 1193 batch loss 1.20542848 epoch total loss 1.28029883\n",
      "Trained batch 1194 batch loss 1.12450576 epoch total loss 1.28016829\n",
      "Trained batch 1195 batch loss 1.2624166 epoch total loss 1.28015351\n",
      "Trained batch 1196 batch loss 1.22301793 epoch total loss 1.28010571\n",
      "Trained batch 1197 batch loss 1.2826525 epoch total loss 1.28010786\n",
      "Trained batch 1198 batch loss 1.23269606 epoch total loss 1.28006828\n",
      "Trained batch 1199 batch loss 1.14932203 epoch total loss 1.2799592\n",
      "Trained batch 1200 batch loss 1.28696489 epoch total loss 1.27996504\n",
      "Trained batch 1201 batch loss 1.28238344 epoch total loss 1.27996695\n",
      "Trained batch 1202 batch loss 1.30951 epoch total loss 1.27999163\n",
      "Trained batch 1203 batch loss 1.30488479 epoch total loss 1.28001237\n",
      "Trained batch 1204 batch loss 1.24684882 epoch total loss 1.27998483\n",
      "Trained batch 1205 batch loss 1.20555854 epoch total loss 1.27992308\n",
      "Trained batch 1206 batch loss 1.18281651 epoch total loss 1.2798425\n",
      "Trained batch 1207 batch loss 1.23810387 epoch total loss 1.27980804\n",
      "Trained batch 1208 batch loss 1.33636439 epoch total loss 1.27985477\n",
      "Trained batch 1209 batch loss 1.31229806 epoch total loss 1.2798816\n",
      "Trained batch 1210 batch loss 1.4218936 epoch total loss 1.2799989\n",
      "Trained batch 1211 batch loss 1.38457465 epoch total loss 1.28008521\n",
      "Trained batch 1212 batch loss 1.32910299 epoch total loss 1.28012574\n",
      "Trained batch 1213 batch loss 1.32502031 epoch total loss 1.28016269\n",
      "Trained batch 1214 batch loss 1.20661497 epoch total loss 1.28010225\n",
      "Trained batch 1215 batch loss 1.29361939 epoch total loss 1.28011334\n",
      "Trained batch 1216 batch loss 1.3126564 epoch total loss 1.28014\n",
      "Trained batch 1217 batch loss 1.27566731 epoch total loss 1.28013635\n",
      "Trained batch 1218 batch loss 1.35177279 epoch total loss 1.28019512\n",
      "Trained batch 1219 batch loss 1.19604516 epoch total loss 1.28012609\n",
      "Trained batch 1220 batch loss 1.19339848 epoch total loss 1.28005505\n",
      "Trained batch 1221 batch loss 1.19089174 epoch total loss 1.27998197\n",
      "Trained batch 1222 batch loss 1.25623369 epoch total loss 1.27996254\n",
      "Trained batch 1223 batch loss 1.30269611 epoch total loss 1.27998114\n",
      "Trained batch 1224 batch loss 1.19154632 epoch total loss 1.2799089\n",
      "Trained batch 1225 batch loss 1.20430875 epoch total loss 1.27984726\n",
      "Trained batch 1226 batch loss 1.22057295 epoch total loss 1.27979887\n",
      "Trained batch 1227 batch loss 1.28170061 epoch total loss 1.27980053\n",
      "Trained batch 1228 batch loss 1.16121554 epoch total loss 1.27970397\n",
      "Trained batch 1229 batch loss 1.29842663 epoch total loss 1.27971923\n",
      "Trained batch 1230 batch loss 1.34298873 epoch total loss 1.27977061\n",
      "Trained batch 1231 batch loss 1.21687365 epoch total loss 1.27971959\n",
      "Trained batch 1232 batch loss 1.21737909 epoch total loss 1.27966905\n",
      "Trained batch 1233 batch loss 1.19252586 epoch total loss 1.27959836\n",
      "Trained batch 1234 batch loss 1.16350102 epoch total loss 1.27950418\n",
      "Trained batch 1235 batch loss 1.26659369 epoch total loss 1.27949381\n",
      "Trained batch 1236 batch loss 1.23624229 epoch total loss 1.27945876\n",
      "Trained batch 1237 batch loss 1.28595459 epoch total loss 1.27946401\n",
      "Trained batch 1238 batch loss 1.31834626 epoch total loss 1.27949548\n",
      "Trained batch 1239 batch loss 1.26122832 epoch total loss 1.2794807\n",
      "Trained batch 1240 batch loss 1.2990731 epoch total loss 1.27949655\n",
      "Trained batch 1241 batch loss 1.44000363 epoch total loss 1.27962589\n",
      "Trained batch 1242 batch loss 1.52444983 epoch total loss 1.27982295\n",
      "Trained batch 1243 batch loss 1.32020497 epoch total loss 1.27985549\n",
      "Trained batch 1244 batch loss 1.25078607 epoch total loss 1.27983201\n",
      "Trained batch 1245 batch loss 1.19285178 epoch total loss 1.27976227\n",
      "Trained batch 1246 batch loss 1.03123152 epoch total loss 1.27956271\n",
      "Trained batch 1247 batch loss 1.1113342 epoch total loss 1.27942789\n",
      "Trained batch 1248 batch loss 1.19720483 epoch total loss 1.27936196\n",
      "Trained batch 1249 batch loss 1.06815112 epoch total loss 1.27919292\n",
      "Trained batch 1250 batch loss 0.972510397 epoch total loss 1.27894759\n",
      "Trained batch 1251 batch loss 1.037884 epoch total loss 1.27875483\n",
      "Trained batch 1252 batch loss 1.11275303 epoch total loss 1.27862227\n",
      "Trained batch 1253 batch loss 1.19580364 epoch total loss 1.27855623\n",
      "Trained batch 1254 batch loss 1.22311163 epoch total loss 1.278512\n",
      "Trained batch 1255 batch loss 1.28727746 epoch total loss 1.27851892\n",
      "Trained batch 1256 batch loss 1.3148818 epoch total loss 1.27854788\n",
      "Trained batch 1257 batch loss 1.36297774 epoch total loss 1.27861512\n",
      "Trained batch 1258 batch loss 1.27886128 epoch total loss 1.27861536\n",
      "Trained batch 1259 batch loss 1.23075962 epoch total loss 1.27857721\n",
      "Trained batch 1260 batch loss 1.30362403 epoch total loss 1.27859712\n",
      "Trained batch 1261 batch loss 1.20370603 epoch total loss 1.27853775\n",
      "Trained batch 1262 batch loss 1.13219905 epoch total loss 1.27842176\n",
      "Trained batch 1263 batch loss 1.27407885 epoch total loss 1.2784183\n",
      "Trained batch 1264 batch loss 1.19161057 epoch total loss 1.27834964\n",
      "Trained batch 1265 batch loss 1.25636363 epoch total loss 1.27833223\n",
      "Trained batch 1266 batch loss 1.24586964 epoch total loss 1.2783066\n",
      "Trained batch 1267 batch loss 1.31351602 epoch total loss 1.27833438\n",
      "Trained batch 1268 batch loss 1.17881083 epoch total loss 1.27825594\n",
      "Trained batch 1269 batch loss 1.31705046 epoch total loss 1.27828646\n",
      "Trained batch 1270 batch loss 1.24589908 epoch total loss 1.27826095\n",
      "Trained batch 1271 batch loss 1.29329014 epoch total loss 1.27827275\n",
      "Trained batch 1272 batch loss 1.30155313 epoch total loss 1.27829099\n",
      "Trained batch 1273 batch loss 1.31732571 epoch total loss 1.27832174\n",
      "Trained batch 1274 batch loss 1.24021852 epoch total loss 1.27829182\n",
      "Trained batch 1275 batch loss 1.16582537 epoch total loss 1.27820361\n",
      "Trained batch 1276 batch loss 1.16890073 epoch total loss 1.27811801\n",
      "Trained batch 1277 batch loss 1.24823344 epoch total loss 1.27809465\n",
      "Trained batch 1278 batch loss 1.23814273 epoch total loss 1.27806342\n",
      "Trained batch 1279 batch loss 1.30074203 epoch total loss 1.27808118\n",
      "Trained batch 1280 batch loss 1.2466507 epoch total loss 1.27805662\n",
      "Trained batch 1281 batch loss 1.22728229 epoch total loss 1.27801704\n",
      "Trained batch 1282 batch loss 1.2011261 epoch total loss 1.27795708\n",
      "Trained batch 1283 batch loss 1.26123238 epoch total loss 1.27794397\n",
      "Trained batch 1284 batch loss 1.24062777 epoch total loss 1.27791488\n",
      "Trained batch 1285 batch loss 1.23324275 epoch total loss 1.27788019\n",
      "Trained batch 1286 batch loss 1.18904853 epoch total loss 1.27781117\n",
      "Trained batch 1287 batch loss 1.13939285 epoch total loss 1.27770364\n",
      "Trained batch 1288 batch loss 1.32567906 epoch total loss 1.27774084\n",
      "Trained batch 1289 batch loss 1.36147928 epoch total loss 1.27780581\n",
      "Trained batch 1290 batch loss 1.31312335 epoch total loss 1.27783322\n",
      "Trained batch 1291 batch loss 1.35146463 epoch total loss 1.27789021\n",
      "Trained batch 1292 batch loss 1.34415364 epoch total loss 1.27794147\n",
      "Trained batch 1293 batch loss 1.30007851 epoch total loss 1.27795851\n",
      "Trained batch 1294 batch loss 1.30149055 epoch total loss 1.27797675\n",
      "Trained batch 1295 batch loss 1.33638453 epoch total loss 1.27802193\n",
      "Trained batch 1296 batch loss 1.22466838 epoch total loss 1.27798069\n",
      "Trained batch 1297 batch loss 1.39146495 epoch total loss 1.27806818\n",
      "Trained batch 1298 batch loss 1.15184104 epoch total loss 1.27797091\n",
      "Trained batch 1299 batch loss 1.16560924 epoch total loss 1.27788448\n",
      "Trained batch 1300 batch loss 1.09607577 epoch total loss 1.27774465\n",
      "Trained batch 1301 batch loss 1.14278805 epoch total loss 1.27764094\n",
      "Trained batch 1302 batch loss 1.32135808 epoch total loss 1.27767456\n",
      "Trained batch 1303 batch loss 1.18096852 epoch total loss 1.27760029\n",
      "Trained batch 1304 batch loss 1.18920124 epoch total loss 1.27753246\n",
      "Trained batch 1305 batch loss 0.999793351 epoch total loss 1.27731967\n",
      "Trained batch 1306 batch loss 1.04413843 epoch total loss 1.27714109\n",
      "Trained batch 1307 batch loss 1.12355661 epoch total loss 1.27702355\n",
      "Trained batch 1308 batch loss 1.25307357 epoch total loss 1.27700531\n",
      "Trained batch 1309 batch loss 1.54346478 epoch total loss 1.27720881\n",
      "Trained batch 1310 batch loss 1.32281232 epoch total loss 1.27724361\n",
      "Trained batch 1311 batch loss 1.19368792 epoch total loss 1.27717984\n",
      "Trained batch 1312 batch loss 1.16923273 epoch total loss 1.27709758\n",
      "Trained batch 1313 batch loss 1.27010119 epoch total loss 1.27709222\n",
      "Trained batch 1314 batch loss 1.20251274 epoch total loss 1.27703547\n",
      "Trained batch 1315 batch loss 1.22058511 epoch total loss 1.27699256\n",
      "Trained batch 1316 batch loss 1.3587625 epoch total loss 1.27705467\n",
      "Trained batch 1317 batch loss 1.42075813 epoch total loss 1.27716386\n",
      "Trained batch 1318 batch loss 1.36188364 epoch total loss 1.27722812\n",
      "Trained batch 1319 batch loss 1.33404732 epoch total loss 1.27727127\n",
      "Trained batch 1320 batch loss 1.34137344 epoch total loss 1.27731991\n",
      "Trained batch 1321 batch loss 1.17000628 epoch total loss 1.27723873\n",
      "Trained batch 1322 batch loss 1.19906604 epoch total loss 1.2771796\n",
      "Trained batch 1323 batch loss 1.13265252 epoch total loss 1.2770704\n",
      "Trained batch 1324 batch loss 1.12087893 epoch total loss 1.27695239\n",
      "Trained batch 1325 batch loss 1.15886557 epoch total loss 1.27686322\n",
      "Trained batch 1326 batch loss 1.17012811 epoch total loss 1.27678275\n",
      "Trained batch 1327 batch loss 1.23713756 epoch total loss 1.27675295\n",
      "Trained batch 1328 batch loss 1.34630203 epoch total loss 1.27680528\n",
      "Trained batch 1329 batch loss 1.25203085 epoch total loss 1.27678668\n",
      "Trained batch 1330 batch loss 1.30620313 epoch total loss 1.27680874\n",
      "Trained batch 1331 batch loss 1.39685452 epoch total loss 1.27689898\n",
      "Trained batch 1332 batch loss 1.39513755 epoch total loss 1.27698767\n",
      "Trained batch 1333 batch loss 1.35632145 epoch total loss 1.27704728\n",
      "Trained batch 1334 batch loss 1.32241559 epoch total loss 1.27708125\n",
      "Trained batch 1335 batch loss 1.2154423 epoch total loss 1.277035\n",
      "Trained batch 1336 batch loss 1.30563521 epoch total loss 1.27705646\n",
      "Trained batch 1337 batch loss 1.3588376 epoch total loss 1.27711773\n",
      "Trained batch 1338 batch loss 1.18822265 epoch total loss 1.27705121\n",
      "Trained batch 1339 batch loss 1.23977232 epoch total loss 1.27702343\n",
      "Trained batch 1340 batch loss 1.1748445 epoch total loss 1.27694714\n",
      "Trained batch 1341 batch loss 1.20495164 epoch total loss 1.27689338\n",
      "Trained batch 1342 batch loss 1.12716007 epoch total loss 1.27678192\n",
      "Trained batch 1343 batch loss 1.16128206 epoch total loss 1.27669585\n",
      "Trained batch 1344 batch loss 1.277215 epoch total loss 1.27669621\n",
      "Trained batch 1345 batch loss 1.25247109 epoch total loss 1.2766782\n",
      "Trained batch 1346 batch loss 1.26695573 epoch total loss 1.27667105\n",
      "Trained batch 1347 batch loss 1.24948645 epoch total loss 1.27665079\n",
      "Trained batch 1348 batch loss 1.3056047 epoch total loss 1.27667236\n",
      "Trained batch 1349 batch loss 1.24902236 epoch total loss 1.27665186\n",
      "Trained batch 1350 batch loss 1.40284538 epoch total loss 1.27674532\n",
      "Trained batch 1351 batch loss 1.20795906 epoch total loss 1.27669442\n",
      "Trained batch 1352 batch loss 1.16440952 epoch total loss 1.27661145\n",
      "Trained batch 1353 batch loss 1.20789647 epoch total loss 1.27656066\n",
      "Trained batch 1354 batch loss 1.06415141 epoch total loss 1.27640378\n",
      "Trained batch 1355 batch loss 1.15025687 epoch total loss 1.27631068\n",
      "Trained batch 1356 batch loss 1.16908705 epoch total loss 1.27623165\n",
      "Trained batch 1357 batch loss 1.19489038 epoch total loss 1.27617168\n",
      "Trained batch 1358 batch loss 1.20279288 epoch total loss 1.27611768\n",
      "Trained batch 1359 batch loss 1.14949441 epoch total loss 1.27602446\n",
      "Trained batch 1360 batch loss 1.29395533 epoch total loss 1.27603769\n",
      "Trained batch 1361 batch loss 1.13016129 epoch total loss 1.27593052\n",
      "Trained batch 1362 batch loss 1.25920987 epoch total loss 1.27591813\n",
      "Trained batch 1363 batch loss 1.21162963 epoch total loss 1.27587104\n",
      "Trained batch 1364 batch loss 1.29672647 epoch total loss 1.2758863\n",
      "Trained batch 1365 batch loss 1.2984848 epoch total loss 1.27590287\n",
      "Trained batch 1366 batch loss 1.22811317 epoch total loss 1.27586794\n",
      "Trained batch 1367 batch loss 1.24555874 epoch total loss 1.27584577\n",
      "Trained batch 1368 batch loss 1.28567052 epoch total loss 1.27585292\n",
      "Trained batch 1369 batch loss 1.3224473 epoch total loss 1.27588689\n",
      "Trained batch 1370 batch loss 1.35224092 epoch total loss 1.27594268\n",
      "Trained batch 1371 batch loss 1.27567399 epoch total loss 1.27594244\n",
      "Trained batch 1372 batch loss 1.19979 epoch total loss 1.27588701\n",
      "Trained batch 1373 batch loss 1.37682867 epoch total loss 1.27596056\n",
      "Trained batch 1374 batch loss 1.26102734 epoch total loss 1.2759496\n",
      "Trained batch 1375 batch loss 1.32798076 epoch total loss 1.27598751\n",
      "Trained batch 1376 batch loss 1.23384845 epoch total loss 1.27595687\n",
      "Trained batch 1377 batch loss 1.27570415 epoch total loss 1.27595675\n",
      "Trained batch 1378 batch loss 1.30082822 epoch total loss 1.27597475\n",
      "Trained batch 1379 batch loss 1.38127422 epoch total loss 1.27605104\n",
      "Trained batch 1380 batch loss 1.32062852 epoch total loss 1.27608347\n",
      "Trained batch 1381 batch loss 1.26928937 epoch total loss 1.27607846\n",
      "Trained batch 1382 batch loss 1.17822206 epoch total loss 1.27600765\n",
      "Trained batch 1383 batch loss 1.03157425 epoch total loss 1.27583098\n",
      "Trained batch 1384 batch loss 1.16280818 epoch total loss 1.27574933\n",
      "Trained batch 1385 batch loss 1.25443876 epoch total loss 1.27573395\n",
      "Trained batch 1386 batch loss 1.24621022 epoch total loss 1.27571261\n",
      "Trained batch 1387 batch loss 1.2907182 epoch total loss 1.27572346\n",
      "Trained batch 1388 batch loss 1.29838562 epoch total loss 1.27573979\n",
      "Epoch 3 train loss 1.2757397890090942\n",
      "Validated batch 1 batch loss 1.21613526\n",
      "Validated batch 2 batch loss 1.2557354\n",
      "Validated batch 3 batch loss 1.1885035\n",
      "Validated batch 4 batch loss 1.15753031\n",
      "Validated batch 5 batch loss 1.19934297\n",
      "Validated batch 6 batch loss 1.29631197\n",
      "Validated batch 7 batch loss 1.23841202\n",
      "Validated batch 8 batch loss 1.04204452\n",
      "Validated batch 9 batch loss 1.23226678\n",
      "Validated batch 10 batch loss 1.25643587\n",
      "Validated batch 11 batch loss 1.20666742\n",
      "Validated batch 12 batch loss 1.23587298\n",
      "Validated batch 13 batch loss 1.25561428\n",
      "Validated batch 14 batch loss 1.22613239\n",
      "Validated batch 15 batch loss 1.32268655\n",
      "Validated batch 16 batch loss 1.31364405\n",
      "Validated batch 17 batch loss 1.27808857\n",
      "Validated batch 18 batch loss 1.32004905\n",
      "Validated batch 19 batch loss 1.07953382\n",
      "Validated batch 20 batch loss 1.20924175\n",
      "Validated batch 21 batch loss 1.1509223\n",
      "Validated batch 22 batch loss 1.28673816\n",
      "Validated batch 23 batch loss 1.37918139\n",
      "Validated batch 24 batch loss 1.40111947\n",
      "Validated batch 25 batch loss 1.33127141\n",
      "Validated batch 26 batch loss 1.20865941\n",
      "Validated batch 27 batch loss 1.23270583\n",
      "Validated batch 28 batch loss 1.19006157\n",
      "Validated batch 29 batch loss 1.31381536\n",
      "Validated batch 30 batch loss 1.29366922\n",
      "Validated batch 31 batch loss 1.14638054\n",
      "Validated batch 32 batch loss 1.29506469\n",
      "Validated batch 33 batch loss 1.24717796\n",
      "Validated batch 34 batch loss 1.27175879\n",
      "Validated batch 35 batch loss 1.26005387\n",
      "Validated batch 36 batch loss 1.28360295\n",
      "Validated batch 37 batch loss 1.23113418\n",
      "Validated batch 38 batch loss 1.23373342\n",
      "Validated batch 39 batch loss 1.29316151\n",
      "Validated batch 40 batch loss 1.2737124\n",
      "Validated batch 41 batch loss 1.2979095\n",
      "Validated batch 42 batch loss 1.34892166\n",
      "Validated batch 43 batch loss 1.52762544\n",
      "Validated batch 44 batch loss 1.32098937\n",
      "Validated batch 45 batch loss 1.25837421\n",
      "Validated batch 46 batch loss 1.16894472\n",
      "Validated batch 47 batch loss 1.19068325\n",
      "Validated batch 48 batch loss 1.27017283\n",
      "Validated batch 49 batch loss 1.19310403\n",
      "Validated batch 50 batch loss 1.29269707\n",
      "Validated batch 51 batch loss 1.21417868\n",
      "Validated batch 52 batch loss 1.29776359\n",
      "Validated batch 53 batch loss 1.33085358\n",
      "Validated batch 54 batch loss 1.31562591\n",
      "Validated batch 55 batch loss 1.3189708\n",
      "Validated batch 56 batch loss 1.23454976\n",
      "Validated batch 57 batch loss 1.32473648\n",
      "Validated batch 58 batch loss 1.27767444\n",
      "Validated batch 59 batch loss 1.24173808\n",
      "Validated batch 60 batch loss 1.36094737\n",
      "Validated batch 61 batch loss 1.31967092\n",
      "Validated batch 62 batch loss 1.26808965\n",
      "Validated batch 63 batch loss 1.46185696\n",
      "Validated batch 64 batch loss 1.10001338\n",
      "Validated batch 65 batch loss 1.30275273\n",
      "Validated batch 66 batch loss 1.15849304\n",
      "Validated batch 67 batch loss 1.23844135\n",
      "Validated batch 68 batch loss 1.37145662\n",
      "Validated batch 69 batch loss 1.18516445\n",
      "Validated batch 70 batch loss 1.33701777\n",
      "Validated batch 71 batch loss 1.26708126\n",
      "Validated batch 72 batch loss 1.28826547\n",
      "Validated batch 73 batch loss 1.23691416\n",
      "Validated batch 74 batch loss 1.2961086\n",
      "Validated batch 75 batch loss 1.44929266\n",
      "Validated batch 76 batch loss 1.24129677\n",
      "Validated batch 77 batch loss 1.35012245\n",
      "Validated batch 78 batch loss 1.2736299\n",
      "Validated batch 79 batch loss 1.33138704\n",
      "Validated batch 80 batch loss 1.28857851\n",
      "Validated batch 81 batch loss 1.18824863\n",
      "Validated batch 82 batch loss 1.4025532\n",
      "Validated batch 83 batch loss 1.28355598\n",
      "Validated batch 84 batch loss 1.30878007\n",
      "Validated batch 85 batch loss 1.25064373\n",
      "Validated batch 86 batch loss 1.31002867\n",
      "Validated batch 87 batch loss 1.17948914\n",
      "Validated batch 88 batch loss 1.23011327\n",
      "Validated batch 89 batch loss 1.25991035\n",
      "Validated batch 90 batch loss 1.20704687\n",
      "Validated batch 91 batch loss 1.31306684\n",
      "Validated batch 92 batch loss 1.24845994\n",
      "Validated batch 93 batch loss 1.29856539\n",
      "Validated batch 94 batch loss 1.22316134\n",
      "Validated batch 95 batch loss 1.24019551\n",
      "Validated batch 96 batch loss 1.17323041\n",
      "Validated batch 97 batch loss 1.22862613\n",
      "Validated batch 98 batch loss 1.34905386\n",
      "Validated batch 99 batch loss 1.26386452\n",
      "Validated batch 100 batch loss 1.34964204\n",
      "Validated batch 101 batch loss 1.30048358\n",
      "Validated batch 102 batch loss 1.31508183\n",
      "Validated batch 103 batch loss 1.22942662\n",
      "Validated batch 104 batch loss 1.38217843\n",
      "Validated batch 105 batch loss 1.22434485\n",
      "Validated batch 106 batch loss 1.28521371\n",
      "Validated batch 107 batch loss 1.32862926\n",
      "Validated batch 108 batch loss 1.35955429\n",
      "Validated batch 109 batch loss 1.33052647\n",
      "Validated batch 110 batch loss 1.15028203\n",
      "Validated batch 111 batch loss 1.24657726\n",
      "Validated batch 112 batch loss 1.30685139\n",
      "Validated batch 113 batch loss 1.33838153\n",
      "Validated batch 114 batch loss 1.20737433\n",
      "Validated batch 115 batch loss 1.24444211\n",
      "Validated batch 116 batch loss 1.20848536\n",
      "Validated batch 117 batch loss 1.26443577\n",
      "Validated batch 118 batch loss 1.31386435\n",
      "Validated batch 119 batch loss 1.26183426\n",
      "Validated batch 120 batch loss 1.30912912\n",
      "Validated batch 121 batch loss 1.43531013\n",
      "Validated batch 122 batch loss 1.1689657\n",
      "Validated batch 123 batch loss 1.30452251\n",
      "Validated batch 124 batch loss 1.27215862\n",
      "Validated batch 125 batch loss 1.31918836\n",
      "Validated batch 126 batch loss 1.33339322\n",
      "Validated batch 127 batch loss 1.2539221\n",
      "Validated batch 128 batch loss 1.05238891\n",
      "Validated batch 129 batch loss 1.27692056\n",
      "Validated batch 130 batch loss 1.24965048\n",
      "Validated batch 131 batch loss 1.25274742\n",
      "Validated batch 132 batch loss 1.33130157\n",
      "Validated batch 133 batch loss 1.20770526\n",
      "Validated batch 134 batch loss 1.29995632\n",
      "Validated batch 135 batch loss 1.3619287\n",
      "Validated batch 136 batch loss 1.26701665\n",
      "Validated batch 137 batch loss 1.30102134\n",
      "Validated batch 138 batch loss 1.18237364\n",
      "Validated batch 139 batch loss 1.24568081\n",
      "Validated batch 140 batch loss 1.13972521\n",
      "Validated batch 141 batch loss 1.23260164\n",
      "Validated batch 142 batch loss 1.20945859\n",
      "Validated batch 143 batch loss 1.20424628\n",
      "Validated batch 144 batch loss 1.23847222\n",
      "Validated batch 145 batch loss 1.2176944\n",
      "Validated batch 146 batch loss 1.27094555\n",
      "Validated batch 147 batch loss 1.32221174\n",
      "Validated batch 148 batch loss 1.15654349\n",
      "Validated batch 149 batch loss 1.35668719\n",
      "Validated batch 150 batch loss 1.27884567\n",
      "Validated batch 151 batch loss 1.16153944\n",
      "Validated batch 152 batch loss 1.27010226\n",
      "Validated batch 153 batch loss 1.24797797\n",
      "Validated batch 154 batch loss 1.19824743\n",
      "Validated batch 155 batch loss 1.38235915\n",
      "Validated batch 156 batch loss 1.26162994\n",
      "Validated batch 157 batch loss 1.29047537\n",
      "Validated batch 158 batch loss 1.21014333\n",
      "Validated batch 159 batch loss 1.22534633\n",
      "Validated batch 160 batch loss 1.29161561\n",
      "Validated batch 161 batch loss 1.2309916\n",
      "Validated batch 162 batch loss 1.2585144\n",
      "Validated batch 163 batch loss 1.33787823\n",
      "Validated batch 164 batch loss 1.23162496\n",
      "Validated batch 165 batch loss 1.19801855\n",
      "Validated batch 166 batch loss 1.23185802\n",
      "Validated batch 167 batch loss 1.23399711\n",
      "Validated batch 168 batch loss 1.27498603\n",
      "Validated batch 169 batch loss 1.20825744\n",
      "Validated batch 170 batch loss 1.16286826\n",
      "Validated batch 171 batch loss 1.38144255\n",
      "Validated batch 172 batch loss 1.24098635\n",
      "Validated batch 173 batch loss 1.11821795\n",
      "Validated batch 174 batch loss 1.20911372\n",
      "Validated batch 175 batch loss 1.36127555\n",
      "Validated batch 176 batch loss 1.35350907\n",
      "Validated batch 177 batch loss 1.35418105\n",
      "Validated batch 178 batch loss 1.2097466\n",
      "Validated batch 179 batch loss 1.40487969\n",
      "Validated batch 180 batch loss 1.24005246\n",
      "Validated batch 181 batch loss 1.33579206\n",
      "Validated batch 182 batch loss 1.31678581\n",
      "Validated batch 183 batch loss 1.09240556\n",
      "Validated batch 184 batch loss 1.16627383\n",
      "Validated batch 185 batch loss 1.40638661\n",
      "Epoch 3 val loss 1.2657544612884521\n",
      "Model /aiffel/aiffel/mpii/models1/model-epoch-3-loss-1.2658.h5 saved.\n",
      "Start epoch 4 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.297791 epoch total loss 1.297791\n",
      "Trained batch 2 batch loss 1.22650123 epoch total loss 1.26214612\n",
      "Trained batch 3 batch loss 1.19853246 epoch total loss 1.24094152\n",
      "Trained batch 4 batch loss 1.19274664 epoch total loss 1.2288928\n",
      "Trained batch 5 batch loss 1.24258447 epoch total loss 1.23163104\n",
      "Trained batch 6 batch loss 1.45732737 epoch total loss 1.26924717\n",
      "Trained batch 7 batch loss 1.45830321 epoch total loss 1.29625511\n",
      "Trained batch 8 batch loss 1.35813737 epoch total loss 1.30399036\n",
      "Trained batch 9 batch loss 1.3358196 epoch total loss 1.30752695\n",
      "Trained batch 10 batch loss 1.2823503 epoch total loss 1.30500925\n",
      "Trained batch 11 batch loss 1.37454748 epoch total loss 1.31133091\n",
      "Trained batch 12 batch loss 1.32742429 epoch total loss 1.31267202\n",
      "Trained batch 13 batch loss 1.21521044 epoch total loss 1.30517507\n",
      "Trained batch 14 batch loss 1.27247381 epoch total loss 1.30283928\n",
      "Trained batch 15 batch loss 1.18660414 epoch total loss 1.2950902\n",
      "Trained batch 16 batch loss 1.2340436 epoch total loss 1.29127479\n",
      "Trained batch 17 batch loss 1.35358381 epoch total loss 1.29494\n",
      "Trained batch 18 batch loss 1.30301058 epoch total loss 1.29538846\n",
      "Trained batch 19 batch loss 1.19163227 epoch total loss 1.2899276\n",
      "Trained batch 20 batch loss 1.11397624 epoch total loss 1.28113008\n",
      "Trained batch 21 batch loss 1.23697424 epoch total loss 1.27902734\n",
      "Trained batch 22 batch loss 1.16233671 epoch total loss 1.27372324\n",
      "Trained batch 23 batch loss 1.30960739 epoch total loss 1.27528346\n",
      "Trained batch 24 batch loss 1.3168664 epoch total loss 1.27701604\n",
      "Trained batch 25 batch loss 1.36319149 epoch total loss 1.28046298\n",
      "Trained batch 26 batch loss 1.30829072 epoch total loss 1.28153336\n",
      "Trained batch 27 batch loss 1.35944831 epoch total loss 1.28441906\n",
      "Trained batch 28 batch loss 1.28347957 epoch total loss 1.28438544\n",
      "Trained batch 29 batch loss 1.16924918 epoch total loss 1.2804153\n",
      "Trained batch 30 batch loss 1.17480707 epoch total loss 1.27689505\n",
      "Trained batch 31 batch loss 1.29777491 epoch total loss 1.27756858\n",
      "Trained batch 32 batch loss 1.43196964 epoch total loss 1.28239357\n",
      "Trained batch 33 batch loss 1.32080162 epoch total loss 1.28355742\n",
      "Trained batch 34 batch loss 1.278808 epoch total loss 1.2834177\n",
      "Trained batch 35 batch loss 1.34678364 epoch total loss 1.28522813\n",
      "Trained batch 36 batch loss 1.23884511 epoch total loss 1.28393984\n",
      "Trained batch 37 batch loss 1.20980167 epoch total loss 1.28193605\n",
      "Trained batch 38 batch loss 1.34639096 epoch total loss 1.28363216\n",
      "Trained batch 39 batch loss 1.33420873 epoch total loss 1.28492904\n",
      "Trained batch 40 batch loss 1.43854964 epoch total loss 1.28876948\n",
      "Trained batch 41 batch loss 1.28822637 epoch total loss 1.28875625\n",
      "Trained batch 42 batch loss 1.12408018 epoch total loss 1.28483546\n",
      "Trained batch 43 batch loss 1.08852315 epoch total loss 1.2802701\n",
      "Trained batch 44 batch loss 1.19284642 epoch total loss 1.27828324\n",
      "Trained batch 45 batch loss 1.28526306 epoch total loss 1.27843833\n",
      "Trained batch 46 batch loss 1.52505279 epoch total loss 1.28379941\n",
      "Trained batch 47 batch loss 1.32279873 epoch total loss 1.28462923\n",
      "Trained batch 48 batch loss 1.37042916 epoch total loss 1.28641677\n",
      "Trained batch 49 batch loss 1.25765646 epoch total loss 1.28582978\n",
      "Trained batch 50 batch loss 1.21150804 epoch total loss 1.28434336\n",
      "Trained batch 51 batch loss 1.17011797 epoch total loss 1.28210378\n",
      "Trained batch 52 batch loss 1.23276162 epoch total loss 1.28115487\n",
      "Trained batch 53 batch loss 1.24818099 epoch total loss 1.28053284\n",
      "Trained batch 54 batch loss 1.1927259 epoch total loss 1.27890682\n",
      "Trained batch 55 batch loss 1.1186496 epoch total loss 1.27599311\n",
      "Trained batch 56 batch loss 1.08020878 epoch total loss 1.27249694\n",
      "Trained batch 57 batch loss 1.10125494 epoch total loss 1.26949275\n",
      "Trained batch 58 batch loss 1.07167923 epoch total loss 1.26608205\n",
      "Trained batch 59 batch loss 1.25755239 epoch total loss 1.26593757\n",
      "Trained batch 60 batch loss 1.48810923 epoch total loss 1.26964033\n",
      "Trained batch 61 batch loss 1.45861936 epoch total loss 1.27273834\n",
      "Trained batch 62 batch loss 1.37738335 epoch total loss 1.2744261\n",
      "Trained batch 63 batch loss 1.38438451 epoch total loss 1.27617145\n",
      "Trained batch 64 batch loss 1.3632319 epoch total loss 1.27753186\n",
      "Trained batch 65 batch loss 1.41411579 epoch total loss 1.27963316\n",
      "Trained batch 66 batch loss 1.40923357 epoch total loss 1.28159678\n",
      "Trained batch 67 batch loss 1.28189754 epoch total loss 1.28160131\n",
      "Trained batch 68 batch loss 1.24494433 epoch total loss 1.28106213\n",
      "Trained batch 69 batch loss 1.27418613 epoch total loss 1.28096247\n",
      "Trained batch 70 batch loss 1.29824913 epoch total loss 1.28120947\n",
      "Trained batch 71 batch loss 1.20142841 epoch total loss 1.2800858\n",
      "Trained batch 72 batch loss 1.25180316 epoch total loss 1.27969301\n",
      "Trained batch 73 batch loss 1.31919074 epoch total loss 1.28023398\n",
      "Trained batch 74 batch loss 1.38024616 epoch total loss 1.28158557\n",
      "Trained batch 75 batch loss 1.43979871 epoch total loss 1.2836951\n",
      "Trained batch 76 batch loss 1.32488549 epoch total loss 1.28423703\n",
      "Trained batch 77 batch loss 1.32080317 epoch total loss 1.28471184\n",
      "Trained batch 78 batch loss 1.30709887 epoch total loss 1.28499889\n",
      "Trained batch 79 batch loss 1.14759326 epoch total loss 1.28325951\n",
      "Trained batch 80 batch loss 1.29094064 epoch total loss 1.28335547\n",
      "Trained batch 81 batch loss 1.16754866 epoch total loss 1.2819258\n",
      "Trained batch 82 batch loss 1.27123415 epoch total loss 1.28179538\n",
      "Trained batch 83 batch loss 1.25797868 epoch total loss 1.28150845\n",
      "Trained batch 84 batch loss 1.28565788 epoch total loss 1.28155792\n",
      "Trained batch 85 batch loss 1.34445679 epoch total loss 1.28229797\n",
      "Trained batch 86 batch loss 1.17979622 epoch total loss 1.281106\n",
      "Trained batch 87 batch loss 1.34345853 epoch total loss 1.28182268\n",
      "Trained batch 88 batch loss 1.16365063 epoch total loss 1.28047991\n",
      "Trained batch 89 batch loss 1.29799318 epoch total loss 1.28067672\n",
      "Trained batch 90 batch loss 1.28995967 epoch total loss 1.28077984\n",
      "Trained batch 91 batch loss 1.39082611 epoch total loss 1.2819891\n",
      "Trained batch 92 batch loss 1.41574836 epoch total loss 1.28344309\n",
      "Trained batch 93 batch loss 1.36787581 epoch total loss 1.28435087\n",
      "Trained batch 94 batch loss 1.32688904 epoch total loss 1.28480339\n",
      "Trained batch 95 batch loss 1.22499752 epoch total loss 1.28417385\n",
      "Trained batch 96 batch loss 1.21088326 epoch total loss 1.28341043\n",
      "Trained batch 97 batch loss 1.26714146 epoch total loss 1.28324282\n",
      "Trained batch 98 batch loss 1.26946306 epoch total loss 1.28310215\n",
      "Trained batch 99 batch loss 1.33805418 epoch total loss 1.28365719\n",
      "Trained batch 100 batch loss 1.32710958 epoch total loss 1.28409159\n",
      "Trained batch 101 batch loss 1.38395381 epoch total loss 1.28508043\n",
      "Trained batch 102 batch loss 1.40238738 epoch total loss 1.28623044\n",
      "Trained batch 103 batch loss 1.48722434 epoch total loss 1.2881819\n",
      "Trained batch 104 batch loss 1.44874191 epoch total loss 1.28972578\n",
      "Trained batch 105 batch loss 1.37074852 epoch total loss 1.29049742\n",
      "Trained batch 106 batch loss 1.35595775 epoch total loss 1.29111493\n",
      "Trained batch 107 batch loss 1.39388227 epoch total loss 1.29207528\n",
      "Trained batch 108 batch loss 1.43470073 epoch total loss 1.293396\n",
      "Trained batch 109 batch loss 1.47118163 epoch total loss 1.29502702\n",
      "Trained batch 110 batch loss 1.37849486 epoch total loss 1.29578578\n",
      "Trained batch 111 batch loss 1.34981656 epoch total loss 1.29627264\n",
      "Trained batch 112 batch loss 1.34180212 epoch total loss 1.29667914\n",
      "Trained batch 113 batch loss 1.3318367 epoch total loss 1.29699016\n",
      "Trained batch 114 batch loss 1.34258473 epoch total loss 1.29739022\n",
      "Trained batch 115 batch loss 1.33743382 epoch total loss 1.29773843\n",
      "Trained batch 116 batch loss 1.1985575 epoch total loss 1.29688346\n",
      "Trained batch 117 batch loss 1.19937313 epoch total loss 1.29605\n",
      "Trained batch 118 batch loss 1.2004807 epoch total loss 1.29524016\n",
      "Trained batch 119 batch loss 1.37788379 epoch total loss 1.29593456\n",
      "Trained batch 120 batch loss 1.25515687 epoch total loss 1.29559481\n",
      "Trained batch 121 batch loss 1.29893053 epoch total loss 1.29562235\n",
      "Trained batch 122 batch loss 1.28410172 epoch total loss 1.29552794\n",
      "Trained batch 123 batch loss 1.29567373 epoch total loss 1.29552913\n",
      "Trained batch 124 batch loss 1.35296988 epoch total loss 1.29599237\n",
      "Trained batch 125 batch loss 1.17171705 epoch total loss 1.29499817\n",
      "Trained batch 126 batch loss 1.12703586 epoch total loss 1.29366505\n",
      "Trained batch 127 batch loss 1.28017163 epoch total loss 1.29355884\n",
      "Trained batch 128 batch loss 1.17752922 epoch total loss 1.29265237\n",
      "Trained batch 129 batch loss 1.20561671 epoch total loss 1.29197764\n",
      "Trained batch 130 batch loss 1.19324982 epoch total loss 1.29121816\n",
      "Trained batch 131 batch loss 1.24119341 epoch total loss 1.29083633\n",
      "Trained batch 132 batch loss 1.17914391 epoch total loss 1.28999019\n",
      "Trained batch 133 batch loss 1.18088722 epoch total loss 1.28916991\n",
      "Trained batch 134 batch loss 1.0362947 epoch total loss 1.28728282\n",
      "Trained batch 135 batch loss 1.01225019 epoch total loss 1.28524554\n",
      "Trained batch 136 batch loss 1.38372219 epoch total loss 1.28596973\n",
      "Trained batch 137 batch loss 1.49052501 epoch total loss 1.28746283\n",
      "Trained batch 138 batch loss 1.16664648 epoch total loss 1.28658724\n",
      "Trained batch 139 batch loss 1.16537738 epoch total loss 1.28571522\n",
      "Trained batch 140 batch loss 1.19230211 epoch total loss 1.28504801\n",
      "Trained batch 141 batch loss 1.21634483 epoch total loss 1.28456068\n",
      "Trained batch 142 batch loss 1.08145535 epoch total loss 1.28313041\n",
      "Trained batch 143 batch loss 1.14022136 epoch total loss 1.28213108\n",
      "Trained batch 144 batch loss 1.23164213 epoch total loss 1.28178048\n",
      "Trained batch 145 batch loss 1.1920799 epoch total loss 1.28116179\n",
      "Trained batch 146 batch loss 1.26656866 epoch total loss 1.28106189\n",
      "Trained batch 147 batch loss 1.17333555 epoch total loss 1.28032911\n",
      "Trained batch 148 batch loss 1.20832932 epoch total loss 1.27984262\n",
      "Trained batch 149 batch loss 1.08922517 epoch total loss 1.27856326\n",
      "Trained batch 150 batch loss 1.21981263 epoch total loss 1.27817154\n",
      "Trained batch 151 batch loss 1.20113122 epoch total loss 1.27766132\n",
      "Trained batch 152 batch loss 1.25929928 epoch total loss 1.27754056\n",
      "Trained batch 153 batch loss 1.22574687 epoch total loss 1.27720201\n",
      "Trained batch 154 batch loss 1.26528943 epoch total loss 1.27712464\n",
      "Trained batch 155 batch loss 1.21187973 epoch total loss 1.27670372\n",
      "Trained batch 156 batch loss 1.33395183 epoch total loss 1.27707076\n",
      "Trained batch 157 batch loss 1.35664225 epoch total loss 1.27757764\n",
      "Trained batch 158 batch loss 1.24499118 epoch total loss 1.27737141\n",
      "Trained batch 159 batch loss 1.17165089 epoch total loss 1.27670646\n",
      "Trained batch 160 batch loss 1.20783043 epoch total loss 1.27627587\n",
      "Trained batch 161 batch loss 1.20853615 epoch total loss 1.27585518\n",
      "Trained batch 162 batch loss 1.13543463 epoch total loss 1.27498841\n",
      "Trained batch 163 batch loss 1.11506963 epoch total loss 1.27400732\n",
      "Trained batch 164 batch loss 1.24449468 epoch total loss 1.27382731\n",
      "Trained batch 165 batch loss 1.35719728 epoch total loss 1.27433264\n",
      "Trained batch 166 batch loss 1.49140239 epoch total loss 1.27564025\n",
      "Trained batch 167 batch loss 1.37823176 epoch total loss 1.27625465\n",
      "Trained batch 168 batch loss 1.36487675 epoch total loss 1.27678216\n",
      "Trained batch 169 batch loss 1.1839757 epoch total loss 1.27623308\n",
      "Trained batch 170 batch loss 1.17255032 epoch total loss 1.27562308\n",
      "Trained batch 171 batch loss 1.10017979 epoch total loss 1.27459705\n",
      "Trained batch 172 batch loss 0.972689033 epoch total loss 1.27284181\n",
      "Trained batch 173 batch loss 1.03428435 epoch total loss 1.2714628\n",
      "Trained batch 174 batch loss 1.18102741 epoch total loss 1.27094316\n",
      "Trained batch 175 batch loss 1.15047383 epoch total loss 1.27025473\n",
      "Trained batch 176 batch loss 1.22215223 epoch total loss 1.26998138\n",
      "Trained batch 177 batch loss 1.29034066 epoch total loss 1.27009642\n",
      "Trained batch 178 batch loss 1.28446436 epoch total loss 1.27017713\n",
      "Trained batch 179 batch loss 1.32736206 epoch total loss 1.27049661\n",
      "Trained batch 180 batch loss 1.06809795 epoch total loss 1.26937222\n",
      "Trained batch 181 batch loss 1.16358638 epoch total loss 1.26878774\n",
      "Trained batch 182 batch loss 1.20665276 epoch total loss 1.26844633\n",
      "Trained batch 183 batch loss 1.02570975 epoch total loss 1.26712\n",
      "Trained batch 184 batch loss 1.07407117 epoch total loss 1.26607072\n",
      "Trained batch 185 batch loss 1.10799241 epoch total loss 1.26521623\n",
      "Trained batch 186 batch loss 1.1608094 epoch total loss 1.26465487\n",
      "Trained batch 187 batch loss 1.0779227 epoch total loss 1.26365638\n",
      "Trained batch 188 batch loss 1.22471404 epoch total loss 1.26344919\n",
      "Trained batch 189 batch loss 1.17850471 epoch total loss 1.26299977\n",
      "Trained batch 190 batch loss 1.01285064 epoch total loss 1.26168323\n",
      "Trained batch 191 batch loss 1.22600174 epoch total loss 1.26149631\n",
      "Trained batch 192 batch loss 1.35856342 epoch total loss 1.26200187\n",
      "Trained batch 193 batch loss 1.27775443 epoch total loss 1.26208353\n",
      "Trained batch 194 batch loss 1.18180442 epoch total loss 1.26166975\n",
      "Trained batch 195 batch loss 1.21733928 epoch total loss 1.26144242\n",
      "Trained batch 196 batch loss 1.16948879 epoch total loss 1.26097333\n",
      "Trained batch 197 batch loss 1.12923622 epoch total loss 1.26030469\n",
      "Trained batch 198 batch loss 1.3405093 epoch total loss 1.26070976\n",
      "Trained batch 199 batch loss 1.31347919 epoch total loss 1.26097488\n",
      "Trained batch 200 batch loss 1.33523226 epoch total loss 1.26134622\n",
      "Trained batch 201 batch loss 1.20147896 epoch total loss 1.26104832\n",
      "Trained batch 202 batch loss 1.2870183 epoch total loss 1.26117694\n",
      "Trained batch 203 batch loss 1.32053041 epoch total loss 1.26146936\n",
      "Trained batch 204 batch loss 1.36792862 epoch total loss 1.26199114\n",
      "Trained batch 205 batch loss 1.29713821 epoch total loss 1.26216269\n",
      "Trained batch 206 batch loss 1.29603338 epoch total loss 1.26232708\n",
      "Trained batch 207 batch loss 1.21081781 epoch total loss 1.26207817\n",
      "Trained batch 208 batch loss 1.35677218 epoch total loss 1.26253343\n",
      "Trained batch 209 batch loss 1.26774478 epoch total loss 1.26255834\n",
      "Trained batch 210 batch loss 1.24212146 epoch total loss 1.26246107\n",
      "Trained batch 211 batch loss 1.22826266 epoch total loss 1.26229906\n",
      "Trained batch 212 batch loss 1.28532934 epoch total loss 1.26240766\n",
      "Trained batch 213 batch loss 1.28339076 epoch total loss 1.26250625\n",
      "Trained batch 214 batch loss 1.24340928 epoch total loss 1.26241696\n",
      "Trained batch 215 batch loss 1.22292948 epoch total loss 1.26223326\n",
      "Trained batch 216 batch loss 1.1662662 epoch total loss 1.26178896\n",
      "Trained batch 217 batch loss 1.14019156 epoch total loss 1.26122868\n",
      "Trained batch 218 batch loss 1.14481604 epoch total loss 1.26069462\n",
      "Trained batch 219 batch loss 1.08888745 epoch total loss 1.25991011\n",
      "Trained batch 220 batch loss 1.0838542 epoch total loss 1.25910985\n",
      "Trained batch 221 batch loss 1.32034898 epoch total loss 1.25938702\n",
      "Trained batch 222 batch loss 1.26935422 epoch total loss 1.25943184\n",
      "Trained batch 223 batch loss 1.33019829 epoch total loss 1.25974917\n",
      "Trained batch 224 batch loss 1.22621107 epoch total loss 1.25959945\n",
      "Trained batch 225 batch loss 1.21308386 epoch total loss 1.25939262\n",
      "Trained batch 226 batch loss 1.36818194 epoch total loss 1.25987411\n",
      "Trained batch 227 batch loss 1.29683673 epoch total loss 1.26003695\n",
      "Trained batch 228 batch loss 1.26034379 epoch total loss 1.26003826\n",
      "Trained batch 229 batch loss 1.22499645 epoch total loss 1.25988531\n",
      "Trained batch 230 batch loss 1.13611579 epoch total loss 1.25934708\n",
      "Trained batch 231 batch loss 1.24031305 epoch total loss 1.25926483\n",
      "Trained batch 232 batch loss 1.0937376 epoch total loss 1.25855136\n",
      "Trained batch 233 batch loss 1.24048352 epoch total loss 1.25847375\n",
      "Trained batch 234 batch loss 1.19326854 epoch total loss 1.25819516\n",
      "Trained batch 235 batch loss 1.0842948 epoch total loss 1.25745511\n",
      "Trained batch 236 batch loss 1.17888904 epoch total loss 1.25712228\n",
      "Trained batch 237 batch loss 1.10446417 epoch total loss 1.25647807\n",
      "Trained batch 238 batch loss 1.10450947 epoch total loss 1.25583959\n",
      "Trained batch 239 batch loss 1.15671563 epoch total loss 1.25542486\n",
      "Trained batch 240 batch loss 1.26824367 epoch total loss 1.25547826\n",
      "Trained batch 241 batch loss 1.34270656 epoch total loss 1.2558403\n",
      "Trained batch 242 batch loss 1.18455291 epoch total loss 1.25554562\n",
      "Trained batch 243 batch loss 1.28223586 epoch total loss 1.25565541\n",
      "Trained batch 244 batch loss 1.34695435 epoch total loss 1.25602961\n",
      "Trained batch 245 batch loss 1.17135525 epoch total loss 1.25568402\n",
      "Trained batch 246 batch loss 1.37189889 epoch total loss 1.25615633\n",
      "Trained batch 247 batch loss 1.34008586 epoch total loss 1.25649619\n",
      "Trained batch 248 batch loss 1.36409354 epoch total loss 1.25693011\n",
      "Trained batch 249 batch loss 1.23291063 epoch total loss 1.25683355\n",
      "Trained batch 250 batch loss 1.32434809 epoch total loss 1.25710368\n",
      "Trained batch 251 batch loss 1.29621899 epoch total loss 1.25725949\n",
      "Trained batch 252 batch loss 1.26586556 epoch total loss 1.2572937\n",
      "Trained batch 253 batch loss 1.32191813 epoch total loss 1.25754917\n",
      "Trained batch 254 batch loss 1.21425891 epoch total loss 1.25737882\n",
      "Trained batch 255 batch loss 1.2751019 epoch total loss 1.25744832\n",
      "Trained batch 256 batch loss 1.18382716 epoch total loss 1.25716078\n",
      "Trained batch 257 batch loss 1.32239842 epoch total loss 1.25741458\n",
      "Trained batch 258 batch loss 1.30001426 epoch total loss 1.25757968\n",
      "Trained batch 259 batch loss 1.24378335 epoch total loss 1.2575264\n",
      "Trained batch 260 batch loss 1.26547301 epoch total loss 1.25755692\n",
      "Trained batch 261 batch loss 1.33152175 epoch total loss 1.25784028\n",
      "Trained batch 262 batch loss 1.25503135 epoch total loss 1.25782967\n",
      "Trained batch 263 batch loss 1.27702212 epoch total loss 1.2579025\n",
      "Trained batch 264 batch loss 1.2668736 epoch total loss 1.25793648\n",
      "Trained batch 265 batch loss 1.31474674 epoch total loss 1.25815094\n",
      "Trained batch 266 batch loss 1.27266932 epoch total loss 1.25820553\n",
      "Trained batch 267 batch loss 1.27102 epoch total loss 1.25825357\n",
      "Trained batch 268 batch loss 1.30378 epoch total loss 1.25842345\n",
      "Trained batch 269 batch loss 1.23109627 epoch total loss 1.25832188\n",
      "Trained batch 270 batch loss 1.2662282 epoch total loss 1.25835121\n",
      "Trained batch 271 batch loss 1.19806719 epoch total loss 1.25812876\n",
      "Trained batch 272 batch loss 1.27423918 epoch total loss 1.25818789\n",
      "Trained batch 273 batch loss 1.26821876 epoch total loss 1.25822461\n",
      "Trained batch 274 batch loss 1.24102211 epoch total loss 1.2581619\n",
      "Trained batch 275 batch loss 1.08506775 epoch total loss 1.25753236\n",
      "Trained batch 276 batch loss 1.0933857 epoch total loss 1.25693762\n",
      "Trained batch 277 batch loss 1.07864809 epoch total loss 1.25629401\n",
      "Trained batch 278 batch loss 1.11168218 epoch total loss 1.2557739\n",
      "Trained batch 279 batch loss 1.1620878 epoch total loss 1.25543809\n",
      "Trained batch 280 batch loss 1.18023467 epoch total loss 1.25516951\n",
      "Trained batch 281 batch loss 1.07782125 epoch total loss 1.2545383\n",
      "Trained batch 282 batch loss 1.14343953 epoch total loss 1.25414431\n",
      "Trained batch 283 batch loss 1.36724353 epoch total loss 1.25454402\n",
      "Trained batch 284 batch loss 1.29262817 epoch total loss 1.25467813\n",
      "Trained batch 285 batch loss 1.26116729 epoch total loss 1.2547009\n",
      "Trained batch 286 batch loss 1.30084896 epoch total loss 1.25486219\n",
      "Trained batch 287 batch loss 1.30899274 epoch total loss 1.25505078\n",
      "Trained batch 288 batch loss 1.18211687 epoch total loss 1.25479758\n",
      "Trained batch 289 batch loss 1.22904313 epoch total loss 1.25470853\n",
      "Trained batch 290 batch loss 1.13144445 epoch total loss 1.25428343\n",
      "Trained batch 291 batch loss 1.0395689 epoch total loss 1.25354564\n",
      "Trained batch 292 batch loss 1.06538796 epoch total loss 1.25290132\n",
      "Trained batch 293 batch loss 1.17837012 epoch total loss 1.25264692\n",
      "Trained batch 294 batch loss 1.09238458 epoch total loss 1.25210178\n",
      "Trained batch 295 batch loss 0.990750909 epoch total loss 1.25121582\n",
      "Trained batch 296 batch loss 0.949566305 epoch total loss 1.2501967\n",
      "Trained batch 297 batch loss 0.988917351 epoch total loss 1.24931705\n",
      "Trained batch 298 batch loss 0.913615 epoch total loss 1.2481904\n",
      "Trained batch 299 batch loss 1.10454845 epoch total loss 1.24771011\n",
      "Trained batch 300 batch loss 1.21306384 epoch total loss 1.24759459\n",
      "Trained batch 301 batch loss 1.20652962 epoch total loss 1.24745822\n",
      "Trained batch 302 batch loss 1.20045066 epoch total loss 1.24730253\n",
      "Trained batch 303 batch loss 1.20210922 epoch total loss 1.2471534\n",
      "Trained batch 304 batch loss 1.27103484 epoch total loss 1.24723196\n",
      "Trained batch 305 batch loss 1.23953593 epoch total loss 1.24720669\n",
      "Trained batch 306 batch loss 1.25760174 epoch total loss 1.24724066\n",
      "Trained batch 307 batch loss 1.32522583 epoch total loss 1.2474947\n",
      "Trained batch 308 batch loss 1.24030375 epoch total loss 1.24747133\n",
      "Trained batch 309 batch loss 1.25297785 epoch total loss 1.24748921\n",
      "Trained batch 310 batch loss 1.16138792 epoch total loss 1.24721134\n",
      "Trained batch 311 batch loss 1.25987315 epoch total loss 1.24725211\n",
      "Trained batch 312 batch loss 1.36029077 epoch total loss 1.2476145\n",
      "Trained batch 313 batch loss 1.10902786 epoch total loss 1.24717176\n",
      "Trained batch 314 batch loss 1.05388498 epoch total loss 1.24655616\n",
      "Trained batch 315 batch loss 1.08261168 epoch total loss 1.2460357\n",
      "Trained batch 316 batch loss 1.19185507 epoch total loss 1.24586427\n",
      "Trained batch 317 batch loss 1.15938771 epoch total loss 1.24559152\n",
      "Trained batch 318 batch loss 1.19736922 epoch total loss 1.24543989\n",
      "Trained batch 319 batch loss 1.29571581 epoch total loss 1.24559748\n",
      "Trained batch 320 batch loss 1.29098499 epoch total loss 1.24573922\n",
      "Trained batch 321 batch loss 1.29855883 epoch total loss 1.24590385\n",
      "Trained batch 322 batch loss 1.30784166 epoch total loss 1.24609613\n",
      "Trained batch 323 batch loss 1.29779327 epoch total loss 1.24625611\n",
      "Trained batch 324 batch loss 1.40322626 epoch total loss 1.2467407\n",
      "Trained batch 325 batch loss 1.44662941 epoch total loss 1.2473557\n",
      "Trained batch 326 batch loss 1.22768104 epoch total loss 1.24729538\n",
      "Trained batch 327 batch loss 1.22186804 epoch total loss 1.24721754\n",
      "Trained batch 328 batch loss 1.22517037 epoch total loss 1.2471503\n",
      "Trained batch 329 batch loss 1.19531047 epoch total loss 1.24699271\n",
      "Trained batch 330 batch loss 1.15551114 epoch total loss 1.24671555\n",
      "Trained batch 331 batch loss 1.18635964 epoch total loss 1.24653327\n",
      "Trained batch 332 batch loss 1.26013601 epoch total loss 1.24657416\n",
      "Trained batch 333 batch loss 1.16457748 epoch total loss 1.246328\n",
      "Trained batch 334 batch loss 1.07808638 epoch total loss 1.24582434\n",
      "Trained batch 335 batch loss 0.919298053 epoch total loss 1.24484968\n",
      "Trained batch 336 batch loss 1.03569579 epoch total loss 1.24422717\n",
      "Trained batch 337 batch loss 1.27064252 epoch total loss 1.24430549\n",
      "Trained batch 338 batch loss 1.25984371 epoch total loss 1.24435151\n",
      "Trained batch 339 batch loss 1.19246066 epoch total loss 1.24419856\n",
      "Trained batch 340 batch loss 1.29968905 epoch total loss 1.24436164\n",
      "Trained batch 341 batch loss 1.23321784 epoch total loss 1.24432898\n",
      "Trained batch 342 batch loss 1.08636713 epoch total loss 1.24386716\n",
      "Trained batch 343 batch loss 1.17790556 epoch total loss 1.24367487\n",
      "Trained batch 344 batch loss 1.17149043 epoch total loss 1.24346495\n",
      "Trained batch 345 batch loss 1.13731956 epoch total loss 1.24315739\n",
      "Trained batch 346 batch loss 1.22486889 epoch total loss 1.24310458\n",
      "Trained batch 347 batch loss 1.10970438 epoch total loss 1.24272013\n",
      "Trained batch 348 batch loss 1.36874127 epoch total loss 1.24308228\n",
      "Trained batch 349 batch loss 1.09260356 epoch total loss 1.24265099\n",
      "Trained batch 350 batch loss 1.05437195 epoch total loss 1.24211311\n",
      "Trained batch 351 batch loss 1.05853879 epoch total loss 1.24159014\n",
      "Trained batch 352 batch loss 1.09853971 epoch total loss 1.24118376\n",
      "Trained batch 353 batch loss 1.29648983 epoch total loss 1.2413404\n",
      "Trained batch 354 batch loss 1.2614181 epoch total loss 1.24139702\n",
      "Trained batch 355 batch loss 1.29305816 epoch total loss 1.24154258\n",
      "Trained batch 356 batch loss 1.41928053 epoch total loss 1.24204183\n",
      "Trained batch 357 batch loss 1.14704549 epoch total loss 1.24177575\n",
      "Trained batch 358 batch loss 1.11347008 epoch total loss 1.24141729\n",
      "Trained batch 359 batch loss 1.14956582 epoch total loss 1.24116147\n",
      "Trained batch 360 batch loss 1.28663683 epoch total loss 1.24128783\n",
      "Trained batch 361 batch loss 1.33568609 epoch total loss 1.24154937\n",
      "Trained batch 362 batch loss 1.25359106 epoch total loss 1.24158263\n",
      "Trained batch 363 batch loss 1.40045166 epoch total loss 1.24202025\n",
      "Trained batch 364 batch loss 1.3837285 epoch total loss 1.24240959\n",
      "Trained batch 365 batch loss 1.25863 epoch total loss 1.24245405\n",
      "Trained batch 366 batch loss 1.22603989 epoch total loss 1.24240923\n",
      "Trained batch 367 batch loss 1.17659 epoch total loss 1.24222994\n",
      "Trained batch 368 batch loss 1.15128613 epoch total loss 1.2419827\n",
      "Trained batch 369 batch loss 1.07553506 epoch total loss 1.24153161\n",
      "Trained batch 370 batch loss 1.11452377 epoch total loss 1.24118841\n",
      "Trained batch 371 batch loss 1.10986733 epoch total loss 1.24083447\n",
      "Trained batch 372 batch loss 1.1453445 epoch total loss 1.24057782\n",
      "Trained batch 373 batch loss 1.20860422 epoch total loss 1.24049211\n",
      "Trained batch 374 batch loss 1.26397872 epoch total loss 1.24055493\n",
      "Trained batch 375 batch loss 1.30452478 epoch total loss 1.24072552\n",
      "Trained batch 376 batch loss 1.24230146 epoch total loss 1.24072969\n",
      "Trained batch 377 batch loss 1.37042332 epoch total loss 1.24107373\n",
      "Trained batch 378 batch loss 1.28038406 epoch total loss 1.2411778\n",
      "Trained batch 379 batch loss 1.3055923 epoch total loss 1.24134779\n",
      "Trained batch 380 batch loss 1.2622478 epoch total loss 1.24140275\n",
      "Trained batch 381 batch loss 1.1688776 epoch total loss 1.24121237\n",
      "Trained batch 382 batch loss 1.18712401 epoch total loss 1.24107087\n",
      "Trained batch 383 batch loss 1.14349914 epoch total loss 1.240816\n",
      "Trained batch 384 batch loss 1.22118056 epoch total loss 1.24076498\n",
      "Trained batch 385 batch loss 1.36635447 epoch total loss 1.24109113\n",
      "Trained batch 386 batch loss 1.33282375 epoch total loss 1.24132884\n",
      "Trained batch 387 batch loss 1.31508434 epoch total loss 1.24151945\n",
      "Trained batch 388 batch loss 1.22879887 epoch total loss 1.24148667\n",
      "Trained batch 389 batch loss 1.1730243 epoch total loss 1.2413106\n",
      "Trained batch 390 batch loss 1.25421023 epoch total loss 1.24134374\n",
      "Trained batch 391 batch loss 1.18656135 epoch total loss 1.24120355\n",
      "Trained batch 392 batch loss 1.30044866 epoch total loss 1.2413547\n",
      "Trained batch 393 batch loss 1.19345355 epoch total loss 1.24123287\n",
      "Trained batch 394 batch loss 1.14106357 epoch total loss 1.2409786\n",
      "Trained batch 395 batch loss 1.15385652 epoch total loss 1.24075806\n",
      "Trained batch 396 batch loss 1.06495523 epoch total loss 1.24031401\n",
      "Trained batch 397 batch loss 1.14534 epoch total loss 1.24007475\n",
      "Trained batch 398 batch loss 1.01924574 epoch total loss 1.23952\n",
      "Trained batch 399 batch loss 1.17969418 epoch total loss 1.23937\n",
      "Trained batch 400 batch loss 1.21752906 epoch total loss 1.23931539\n",
      "Trained batch 401 batch loss 1.18989253 epoch total loss 1.23919213\n",
      "Trained batch 402 batch loss 1.12653089 epoch total loss 1.23891187\n",
      "Trained batch 403 batch loss 1.19837618 epoch total loss 1.23881125\n",
      "Trained batch 404 batch loss 1.16605103 epoch total loss 1.23863113\n",
      "Trained batch 405 batch loss 1.25293612 epoch total loss 1.23866642\n",
      "Trained batch 406 batch loss 1.40835989 epoch total loss 1.23908436\n",
      "Trained batch 407 batch loss 1.30076993 epoch total loss 1.239236\n",
      "Trained batch 408 batch loss 1.11801434 epoch total loss 1.23893893\n",
      "Trained batch 409 batch loss 1.24327087 epoch total loss 1.23894954\n",
      "Trained batch 410 batch loss 1.23461509 epoch total loss 1.23893893\n",
      "Trained batch 411 batch loss 1.19534 epoch total loss 1.23883283\n",
      "Trained batch 412 batch loss 1.15378475 epoch total loss 1.23862648\n",
      "Trained batch 413 batch loss 1.28114462 epoch total loss 1.23872936\n",
      "Trained batch 414 batch loss 1.18982196 epoch total loss 1.23861134\n",
      "Trained batch 415 batch loss 1.19556832 epoch total loss 1.23850763\n",
      "Trained batch 416 batch loss 1.25888515 epoch total loss 1.23855662\n",
      "Trained batch 417 batch loss 1.3613342 epoch total loss 1.23885107\n",
      "Trained batch 418 batch loss 1.34947157 epoch total loss 1.23911572\n",
      "Trained batch 419 batch loss 1.32615137 epoch total loss 1.2393235\n",
      "Trained batch 420 batch loss 1.20396185 epoch total loss 1.23923934\n",
      "Trained batch 421 batch loss 1.20468092 epoch total loss 1.2391572\n",
      "Trained batch 422 batch loss 1.159024 epoch total loss 1.2389673\n",
      "Trained batch 423 batch loss 1.29346204 epoch total loss 1.23909605\n",
      "Trained batch 424 batch loss 1.40725493 epoch total loss 1.23949265\n",
      "Trained batch 425 batch loss 1.49693882 epoch total loss 1.24009836\n",
      "Trained batch 426 batch loss 1.40753317 epoch total loss 1.24049139\n",
      "Trained batch 427 batch loss 1.20951271 epoch total loss 1.24041891\n",
      "Trained batch 428 batch loss 1.33701658 epoch total loss 1.24064469\n",
      "Trained batch 429 batch loss 1.2571404 epoch total loss 1.24068308\n",
      "Trained batch 430 batch loss 1.31175733 epoch total loss 1.24084842\n",
      "Trained batch 431 batch loss 1.40228069 epoch total loss 1.24122298\n",
      "Trained batch 432 batch loss 1.27313507 epoch total loss 1.24129689\n",
      "Trained batch 433 batch loss 1.0739615 epoch total loss 1.24091041\n",
      "Trained batch 434 batch loss 1.16085851 epoch total loss 1.24072599\n",
      "Trained batch 435 batch loss 1.2732923 epoch total loss 1.24080098\n",
      "Trained batch 436 batch loss 1.40145278 epoch total loss 1.24116933\n",
      "Trained batch 437 batch loss 1.43846965 epoch total loss 1.2416209\n",
      "Trained batch 438 batch loss 1.40174437 epoch total loss 1.24198639\n",
      "Trained batch 439 batch loss 1.32522786 epoch total loss 1.24217606\n",
      "Trained batch 440 batch loss 1.26187825 epoch total loss 1.24222088\n",
      "Trained batch 441 batch loss 1.27027273 epoch total loss 1.24228454\n",
      "Trained batch 442 batch loss 1.19382238 epoch total loss 1.24217498\n",
      "Trained batch 443 batch loss 1.31365633 epoch total loss 1.24233627\n",
      "Trained batch 444 batch loss 1.20760274 epoch total loss 1.24225807\n",
      "Trained batch 445 batch loss 1.27167225 epoch total loss 1.24232411\n",
      "Trained batch 446 batch loss 1.25494397 epoch total loss 1.24235237\n",
      "Trained batch 447 batch loss 1.15890861 epoch total loss 1.2421658\n",
      "Trained batch 448 batch loss 1.26273894 epoch total loss 1.2422117\n",
      "Trained batch 449 batch loss 1.14538956 epoch total loss 1.24199605\n",
      "Trained batch 450 batch loss 1.02773643 epoch total loss 1.24151993\n",
      "Trained batch 451 batch loss 1.08702731 epoch total loss 1.24117732\n",
      "Trained batch 452 batch loss 1.2351625 epoch total loss 1.24116409\n",
      "Trained batch 453 batch loss 1.27316356 epoch total loss 1.24123478\n",
      "Trained batch 454 batch loss 1.36630273 epoch total loss 1.24151039\n",
      "Trained batch 455 batch loss 1.3654952 epoch total loss 1.24178278\n",
      "Trained batch 456 batch loss 1.23991227 epoch total loss 1.24177873\n",
      "Trained batch 457 batch loss 1.2663548 epoch total loss 1.24183249\n",
      "Trained batch 458 batch loss 1.42126977 epoch total loss 1.24222434\n",
      "Trained batch 459 batch loss 1.31412458 epoch total loss 1.24238098\n",
      "Trained batch 460 batch loss 1.35956383 epoch total loss 1.24263573\n",
      "Trained batch 461 batch loss 1.42199624 epoch total loss 1.24302483\n",
      "Trained batch 462 batch loss 1.41082656 epoch total loss 1.24338794\n",
      "Trained batch 463 batch loss 1.1795243 epoch total loss 1.24325\n",
      "Trained batch 464 batch loss 1.13877845 epoch total loss 1.24302495\n",
      "Trained batch 465 batch loss 1.0805366 epoch total loss 1.24267554\n",
      "Trained batch 466 batch loss 1.09266853 epoch total loss 1.24235356\n",
      "Trained batch 467 batch loss 1.22917676 epoch total loss 1.24232543\n",
      "Trained batch 468 batch loss 1.08734059 epoch total loss 1.24199426\n",
      "Trained batch 469 batch loss 0.973579407 epoch total loss 1.24142194\n",
      "Trained batch 470 batch loss 0.90921849 epoch total loss 1.24071515\n",
      "Trained batch 471 batch loss 1.08102787 epoch total loss 1.24037611\n",
      "Trained batch 472 batch loss 1.09112656 epoch total loss 1.24006\n",
      "Trained batch 473 batch loss 1.17630267 epoch total loss 1.23992515\n",
      "Trained batch 474 batch loss 1.30487132 epoch total loss 1.24006224\n",
      "Trained batch 475 batch loss 1.20955229 epoch total loss 1.23999798\n",
      "Trained batch 476 batch loss 1.23992884 epoch total loss 1.23999774\n",
      "Trained batch 477 batch loss 1.33989286 epoch total loss 1.2402072\n",
      "Trained batch 478 batch loss 1.21527696 epoch total loss 1.2401551\n",
      "Trained batch 479 batch loss 1.27064335 epoch total loss 1.24021876\n",
      "Trained batch 480 batch loss 1.26060748 epoch total loss 1.2402612\n",
      "Trained batch 481 batch loss 1.24161828 epoch total loss 1.24026406\n",
      "Trained batch 482 batch loss 1.27921271 epoch total loss 1.24034488\n",
      "Trained batch 483 batch loss 1.3382597 epoch total loss 1.24054766\n",
      "Trained batch 484 batch loss 1.16389072 epoch total loss 1.24038923\n",
      "Trained batch 485 batch loss 1.18129098 epoch total loss 1.2402674\n",
      "Trained batch 486 batch loss 1.16239667 epoch total loss 1.24010718\n",
      "Trained batch 487 batch loss 1.18453693 epoch total loss 1.23999298\n",
      "Trained batch 488 batch loss 1.2364409 epoch total loss 1.2399857\n",
      "Trained batch 489 batch loss 1.37459183 epoch total loss 1.24026096\n",
      "Trained batch 490 batch loss 1.27383745 epoch total loss 1.2403295\n",
      "Trained batch 491 batch loss 1.24145925 epoch total loss 1.24033189\n",
      "Trained batch 492 batch loss 1.20887721 epoch total loss 1.24026787\n",
      "Trained batch 493 batch loss 1.27525127 epoch total loss 1.24033892\n",
      "Trained batch 494 batch loss 1.1285156 epoch total loss 1.24011254\n",
      "Trained batch 495 batch loss 1.13070583 epoch total loss 1.23989141\n",
      "Trained batch 496 batch loss 1.27229619 epoch total loss 1.23995674\n",
      "Trained batch 497 batch loss 1.36137056 epoch total loss 1.24020112\n",
      "Trained batch 498 batch loss 1.28069723 epoch total loss 1.24028242\n",
      "Trained batch 499 batch loss 1.19143343 epoch total loss 1.24018443\n",
      "Trained batch 500 batch loss 1.17564738 epoch total loss 1.24005544\n",
      "Trained batch 501 batch loss 1.098387 epoch total loss 1.23977268\n",
      "Trained batch 502 batch loss 1.18063641 epoch total loss 1.2396549\n",
      "Trained batch 503 batch loss 1.20301282 epoch total loss 1.23958206\n",
      "Trained batch 504 batch loss 1.21999216 epoch total loss 1.23954308\n",
      "Trained batch 505 batch loss 1.23893774 epoch total loss 1.23954201\n",
      "Trained batch 506 batch loss 1.30664611 epoch total loss 1.23967457\n",
      "Trained batch 507 batch loss 1.15374017 epoch total loss 1.23950505\n",
      "Trained batch 508 batch loss 1.14606118 epoch total loss 1.23932111\n",
      "Trained batch 509 batch loss 1.0993222 epoch total loss 1.2390461\n",
      "Trained batch 510 batch loss 1.19723809 epoch total loss 1.23896408\n",
      "Trained batch 511 batch loss 1.19462836 epoch total loss 1.23887742\n",
      "Trained batch 512 batch loss 1.35586345 epoch total loss 1.23910582\n",
      "Trained batch 513 batch loss 1.25685024 epoch total loss 1.23914039\n",
      "Trained batch 514 batch loss 1.26152468 epoch total loss 1.2391839\n",
      "Trained batch 515 batch loss 1.20659697 epoch total loss 1.23912072\n",
      "Trained batch 516 batch loss 1.31144607 epoch total loss 1.23926091\n",
      "Trained batch 517 batch loss 1.1732831 epoch total loss 1.23913324\n",
      "Trained batch 518 batch loss 1.2534647 epoch total loss 1.23916101\n",
      "Trained batch 519 batch loss 1.20313263 epoch total loss 1.23909152\n",
      "Trained batch 520 batch loss 1.29256022 epoch total loss 1.23919427\n",
      "Trained batch 521 batch loss 1.30416703 epoch total loss 1.23931897\n",
      "Trained batch 522 batch loss 1.19647992 epoch total loss 1.23923683\n",
      "Trained batch 523 batch loss 1.26638591 epoch total loss 1.23928869\n",
      "Trained batch 524 batch loss 1.26717651 epoch total loss 1.23934186\n",
      "Trained batch 525 batch loss 1.38607883 epoch total loss 1.23962152\n",
      "Trained batch 526 batch loss 1.37394369 epoch total loss 1.23987687\n",
      "Trained batch 527 batch loss 1.26389551 epoch total loss 1.23992252\n",
      "Trained batch 528 batch loss 1.27148592 epoch total loss 1.23998225\n",
      "Trained batch 529 batch loss 1.28436399 epoch total loss 1.24006617\n",
      "Trained batch 530 batch loss 1.29071307 epoch total loss 1.24016166\n",
      "Trained batch 531 batch loss 1.23221719 epoch total loss 1.24014676\n",
      "Trained batch 532 batch loss 1.24087334 epoch total loss 1.24014807\n",
      "Trained batch 533 batch loss 1.21786427 epoch total loss 1.24010623\n",
      "Trained batch 534 batch loss 1.20788527 epoch total loss 1.24004591\n",
      "Trained batch 535 batch loss 1.21115637 epoch total loss 1.2399919\n",
      "Trained batch 536 batch loss 1.30287337 epoch total loss 1.24010921\n",
      "Trained batch 537 batch loss 1.28221166 epoch total loss 1.24018764\n",
      "Trained batch 538 batch loss 1.16147327 epoch total loss 1.24004138\n",
      "Trained batch 539 batch loss 1.20751882 epoch total loss 1.23998106\n",
      "Trained batch 540 batch loss 1.13802445 epoch total loss 1.23979223\n",
      "Trained batch 541 batch loss 1.17531991 epoch total loss 1.23967302\n",
      "Trained batch 542 batch loss 1.27412641 epoch total loss 1.23973656\n",
      "Trained batch 543 batch loss 1.11987674 epoch total loss 1.23951578\n",
      "Trained batch 544 batch loss 1.21818757 epoch total loss 1.23947656\n",
      "Trained batch 545 batch loss 1.33729613 epoch total loss 1.23965609\n",
      "Trained batch 546 batch loss 1.48533034 epoch total loss 1.24010599\n",
      "Trained batch 547 batch loss 1.39439404 epoch total loss 1.24038815\n",
      "Trained batch 548 batch loss 1.39360356 epoch total loss 1.2406677\n",
      "Trained batch 549 batch loss 1.37986279 epoch total loss 1.24092138\n",
      "Trained batch 550 batch loss 1.19593132 epoch total loss 1.24083948\n",
      "Trained batch 551 batch loss 1.12810767 epoch total loss 1.24063492\n",
      "Trained batch 552 batch loss 1.16455519 epoch total loss 1.24049711\n",
      "Trained batch 553 batch loss 1.205845 epoch total loss 1.24043453\n",
      "Trained batch 554 batch loss 1.30421472 epoch total loss 1.24054956\n",
      "Trained batch 555 batch loss 1.32795644 epoch total loss 1.24070704\n",
      "Trained batch 556 batch loss 1.16878176 epoch total loss 1.2405777\n",
      "Trained batch 557 batch loss 1.13380909 epoch total loss 1.24038589\n",
      "Trained batch 558 batch loss 1.14871526 epoch total loss 1.24022174\n",
      "Trained batch 559 batch loss 1.03017926 epoch total loss 1.23984587\n",
      "Trained batch 560 batch loss 1.16547215 epoch total loss 1.23971307\n",
      "Trained batch 561 batch loss 1.15321398 epoch total loss 1.23955882\n",
      "Trained batch 562 batch loss 1.12473607 epoch total loss 1.23935461\n",
      "Trained batch 563 batch loss 1.15508974 epoch total loss 1.23920488\n",
      "Trained batch 564 batch loss 1.0554105 epoch total loss 1.23887908\n",
      "Trained batch 565 batch loss 0.992959619 epoch total loss 1.23844385\n",
      "Trained batch 566 batch loss 1.29357791 epoch total loss 1.23854125\n",
      "Trained batch 567 batch loss 1.22230625 epoch total loss 1.23851264\n",
      "Trained batch 568 batch loss 1.30659044 epoch total loss 1.23863244\n",
      "Trained batch 569 batch loss 1.23844528 epoch total loss 1.23863208\n",
      "Trained batch 570 batch loss 1.24211264 epoch total loss 1.23863828\n",
      "Trained batch 571 batch loss 1.31704164 epoch total loss 1.23877549\n",
      "Trained batch 572 batch loss 1.07468402 epoch total loss 1.23848867\n",
      "Trained batch 573 batch loss 1.11842775 epoch total loss 1.2382791\n",
      "Trained batch 574 batch loss 1.17016 epoch total loss 1.23816049\n",
      "Trained batch 575 batch loss 1.17565334 epoch total loss 1.23805177\n",
      "Trained batch 576 batch loss 1.23564 epoch total loss 1.2380476\n",
      "Trained batch 577 batch loss 1.41075873 epoch total loss 1.23834693\n",
      "Trained batch 578 batch loss 1.28000855 epoch total loss 1.23841906\n",
      "Trained batch 579 batch loss 1.33680129 epoch total loss 1.23858893\n",
      "Trained batch 580 batch loss 1.28340709 epoch total loss 1.23866618\n",
      "Trained batch 581 batch loss 1.35413027 epoch total loss 1.2388649\n",
      "Trained batch 582 batch loss 1.35605633 epoch total loss 1.23906636\n",
      "Trained batch 583 batch loss 1.36158574 epoch total loss 1.23927641\n",
      "Trained batch 584 batch loss 1.43798923 epoch total loss 1.23961675\n",
      "Trained batch 585 batch loss 1.28556871 epoch total loss 1.23969531\n",
      "Trained batch 586 batch loss 1.26374102 epoch total loss 1.23973632\n",
      "Trained batch 587 batch loss 1.23282087 epoch total loss 1.23972452\n",
      "Trained batch 588 batch loss 1.29639721 epoch total loss 1.23982096\n",
      "Trained batch 589 batch loss 1.29519701 epoch total loss 1.23991501\n",
      "Trained batch 590 batch loss 1.27357292 epoch total loss 1.239972\n",
      "Trained batch 591 batch loss 1.09443069 epoch total loss 1.23972571\n",
      "Trained batch 592 batch loss 1.22308636 epoch total loss 1.23969769\n",
      "Trained batch 593 batch loss 1.20413947 epoch total loss 1.23963773\n",
      "Trained batch 594 batch loss 1.21248746 epoch total loss 1.23959196\n",
      "Trained batch 595 batch loss 1.16234136 epoch total loss 1.23946214\n",
      "Trained batch 596 batch loss 1.33872366 epoch total loss 1.23962879\n",
      "Trained batch 597 batch loss 1.20051169 epoch total loss 1.23956323\n",
      "Trained batch 598 batch loss 1.16813993 epoch total loss 1.23944378\n",
      "Trained batch 599 batch loss 1.19516635 epoch total loss 1.23936987\n",
      "Trained batch 600 batch loss 1.1845175 epoch total loss 1.23927844\n",
      "Trained batch 601 batch loss 1.1529634 epoch total loss 1.23913479\n",
      "Trained batch 602 batch loss 1.31548595 epoch total loss 1.23926163\n",
      "Trained batch 603 batch loss 1.22287774 epoch total loss 1.23923457\n",
      "Trained batch 604 batch loss 1.1456455 epoch total loss 1.23907959\n",
      "Trained batch 605 batch loss 1.10230875 epoch total loss 1.23885345\n",
      "Trained batch 606 batch loss 1.26837277 epoch total loss 1.23890221\n",
      "Trained batch 607 batch loss 1.25548625 epoch total loss 1.23892951\n",
      "Trained batch 608 batch loss 1.29112697 epoch total loss 1.23901534\n",
      "Trained batch 609 batch loss 1.17125762 epoch total loss 1.23890412\n",
      "Trained batch 610 batch loss 1.25279117 epoch total loss 1.23892689\n",
      "Trained batch 611 batch loss 1.31160963 epoch total loss 1.23904586\n",
      "Trained batch 612 batch loss 1.12759924 epoch total loss 1.23886383\n",
      "Trained batch 613 batch loss 1.1644429 epoch total loss 1.23874235\n",
      "Trained batch 614 batch loss 1.20979047 epoch total loss 1.23869514\n",
      "Trained batch 615 batch loss 1.12129951 epoch total loss 1.23850429\n",
      "Trained batch 616 batch loss 1.10655046 epoch total loss 1.23829007\n",
      "Trained batch 617 batch loss 1.04614925 epoch total loss 1.2379787\n",
      "Trained batch 618 batch loss 1.03917229 epoch total loss 1.23765695\n",
      "Trained batch 619 batch loss 1.1715368 epoch total loss 1.23755014\n",
      "Trained batch 620 batch loss 1.08785248 epoch total loss 1.23730862\n",
      "Trained batch 621 batch loss 1.12546444 epoch total loss 1.23712862\n",
      "Trained batch 622 batch loss 1.12016273 epoch total loss 1.2369405\n",
      "Trained batch 623 batch loss 1.16231108 epoch total loss 1.2368207\n",
      "Trained batch 624 batch loss 1.17046022 epoch total loss 1.23671436\n",
      "Trained batch 625 batch loss 1.2714349 epoch total loss 1.23676991\n",
      "Trained batch 626 batch loss 1.42547655 epoch total loss 1.23707139\n",
      "Trained batch 627 batch loss 1.24029136 epoch total loss 1.23707652\n",
      "Trained batch 628 batch loss 1.29297972 epoch total loss 1.23716557\n",
      "Trained batch 629 batch loss 1.23021042 epoch total loss 1.23715448\n",
      "Trained batch 630 batch loss 1.32120776 epoch total loss 1.23728788\n",
      "Trained batch 631 batch loss 1.26105428 epoch total loss 1.23732555\n",
      "Trained batch 632 batch loss 1.13805425 epoch total loss 1.23716855\n",
      "Trained batch 633 batch loss 1.25898671 epoch total loss 1.237203\n",
      "Trained batch 634 batch loss 1.29628611 epoch total loss 1.2372961\n",
      "Trained batch 635 batch loss 1.12655091 epoch total loss 1.2371217\n",
      "Trained batch 636 batch loss 1.17847991 epoch total loss 1.23702943\n",
      "Trained batch 637 batch loss 1.13651776 epoch total loss 1.23687172\n",
      "Trained batch 638 batch loss 1.16389394 epoch total loss 1.23675728\n",
      "Trained batch 639 batch loss 1.17655993 epoch total loss 1.2366631\n",
      "Trained batch 640 batch loss 1.35263944 epoch total loss 1.2368443\n",
      "Trained batch 641 batch loss 1.25741637 epoch total loss 1.23687649\n",
      "Trained batch 642 batch loss 1.1777668 epoch total loss 1.23678446\n",
      "Trained batch 643 batch loss 1.27997196 epoch total loss 1.23685157\n",
      "Trained batch 644 batch loss 1.30904508 epoch total loss 1.23696363\n",
      "Trained batch 645 batch loss 1.24143207 epoch total loss 1.23697066\n",
      "Trained batch 646 batch loss 1.20561743 epoch total loss 1.23692214\n",
      "Trained batch 647 batch loss 1.14296865 epoch total loss 1.23677683\n",
      "Trained batch 648 batch loss 1.19395792 epoch total loss 1.23671079\n",
      "Trained batch 649 batch loss 1.22108221 epoch total loss 1.23668671\n",
      "Trained batch 650 batch loss 1.21567643 epoch total loss 1.2366544\n",
      "Trained batch 651 batch loss 1.32045209 epoch total loss 1.23678315\n",
      "Trained batch 652 batch loss 1.19242764 epoch total loss 1.23671508\n",
      "Trained batch 653 batch loss 1.12961 epoch total loss 1.23655117\n",
      "Trained batch 654 batch loss 1.24685156 epoch total loss 1.2365669\n",
      "Trained batch 655 batch loss 1.2306056 epoch total loss 1.23655772\n",
      "Trained batch 656 batch loss 1.23143339 epoch total loss 1.23655\n",
      "Trained batch 657 batch loss 1.11859739 epoch total loss 1.23637044\n",
      "Trained batch 658 batch loss 1.11064517 epoch total loss 1.23617935\n",
      "Trained batch 659 batch loss 1.19805896 epoch total loss 1.23612154\n",
      "Trained batch 660 batch loss 1.23427796 epoch total loss 1.23611867\n",
      "Trained batch 661 batch loss 1.28804612 epoch total loss 1.23619723\n",
      "Trained batch 662 batch loss 1.23482299 epoch total loss 1.23619509\n",
      "Trained batch 663 batch loss 1.08195496 epoch total loss 1.23596251\n",
      "Trained batch 664 batch loss 1.17766619 epoch total loss 1.23587465\n",
      "Trained batch 665 batch loss 1.2635175 epoch total loss 1.23591626\n",
      "Trained batch 666 batch loss 1.17054987 epoch total loss 1.23581803\n",
      "Trained batch 667 batch loss 1.23212981 epoch total loss 1.23581243\n",
      "Trained batch 668 batch loss 1.20978522 epoch total loss 1.23577356\n",
      "Trained batch 669 batch loss 1.17866516 epoch total loss 1.23568809\n",
      "Trained batch 670 batch loss 1.05839825 epoch total loss 1.23542356\n",
      "Trained batch 671 batch loss 1.17392826 epoch total loss 1.23533189\n",
      "Trained batch 672 batch loss 1.19661796 epoch total loss 1.23527431\n",
      "Trained batch 673 batch loss 1.28761125 epoch total loss 1.23535204\n",
      "Trained batch 674 batch loss 1.27743161 epoch total loss 1.23541439\n",
      "Trained batch 675 batch loss 1.31886673 epoch total loss 1.23553801\n",
      "Trained batch 676 batch loss 1.19344485 epoch total loss 1.23547566\n",
      "Trained batch 677 batch loss 1.09979391 epoch total loss 1.23527527\n",
      "Trained batch 678 batch loss 1.28895283 epoch total loss 1.23535442\n",
      "Trained batch 679 batch loss 1.15077186 epoch total loss 1.23522985\n",
      "Trained batch 680 batch loss 1.25964737 epoch total loss 1.23526573\n",
      "Trained batch 681 batch loss 1.24221373 epoch total loss 1.23527586\n",
      "Trained batch 682 batch loss 1.20062137 epoch total loss 1.23522508\n",
      "Trained batch 683 batch loss 1.17682254 epoch total loss 1.23513961\n",
      "Trained batch 684 batch loss 1.18306172 epoch total loss 1.23506343\n",
      "Trained batch 685 batch loss 1.18009579 epoch total loss 1.23498321\n",
      "Trained batch 686 batch loss 1.18179452 epoch total loss 1.23490572\n",
      "Trained batch 687 batch loss 1.19323969 epoch total loss 1.23484504\n",
      "Trained batch 688 batch loss 1.14785016 epoch total loss 1.23471856\n",
      "Trained batch 689 batch loss 1.26242352 epoch total loss 1.23475885\n",
      "Trained batch 690 batch loss 1.22899473 epoch total loss 1.23475051\n",
      "Trained batch 691 batch loss 1.21297443 epoch total loss 1.23471892\n",
      "Trained batch 692 batch loss 1.18235302 epoch total loss 1.23464334\n",
      "Trained batch 693 batch loss 1.18126154 epoch total loss 1.23456633\n",
      "Trained batch 694 batch loss 1.22600198 epoch total loss 1.23455393\n",
      "Trained batch 695 batch loss 1.25131035 epoch total loss 1.23457801\n",
      "Trained batch 696 batch loss 1.43146682 epoch total loss 1.2348609\n",
      "Trained batch 697 batch loss 1.21950984 epoch total loss 1.23483884\n",
      "Trained batch 698 batch loss 1.12219 epoch total loss 1.23467743\n",
      "Trained batch 699 batch loss 1.28944016 epoch total loss 1.23475575\n",
      "Trained batch 700 batch loss 1.23893142 epoch total loss 1.23476183\n",
      "Trained batch 701 batch loss 1.12951994 epoch total loss 1.23461163\n",
      "Trained batch 702 batch loss 1.09217417 epoch total loss 1.23440874\n",
      "Trained batch 703 batch loss 1.00353062 epoch total loss 1.23408031\n",
      "Trained batch 704 batch loss 1.13024199 epoch total loss 1.23393285\n",
      "Trained batch 705 batch loss 1.17902279 epoch total loss 1.23385489\n",
      "Trained batch 706 batch loss 1.01793182 epoch total loss 1.23354912\n",
      "Trained batch 707 batch loss 1.13197374 epoch total loss 1.23340547\n",
      "Trained batch 708 batch loss 1.1735127 epoch total loss 1.23332083\n",
      "Trained batch 709 batch loss 1.25128365 epoch total loss 1.23334622\n",
      "Trained batch 710 batch loss 1.19392467 epoch total loss 1.23329067\n",
      "Trained batch 711 batch loss 1.18302763 epoch total loss 1.23322\n",
      "Trained batch 712 batch loss 1.09415257 epoch total loss 1.23302472\n",
      "Trained batch 713 batch loss 1.40655077 epoch total loss 1.23326802\n",
      "Trained batch 714 batch loss 1.26677918 epoch total loss 1.23331499\n",
      "Trained batch 715 batch loss 1.26253319 epoch total loss 1.23335588\n",
      "Trained batch 716 batch loss 1.12645578 epoch total loss 1.23320651\n",
      "Trained batch 717 batch loss 1.09458697 epoch total loss 1.23301327\n",
      "Trained batch 718 batch loss 1.13010383 epoch total loss 1.23287\n",
      "Trained batch 719 batch loss 1.23855782 epoch total loss 1.23287785\n",
      "Trained batch 720 batch loss 1.16959202 epoch total loss 1.23279\n",
      "Trained batch 721 batch loss 1.26416326 epoch total loss 1.2328335\n",
      "Trained batch 722 batch loss 1.26997817 epoch total loss 1.232885\n",
      "Trained batch 723 batch loss 1.30096626 epoch total loss 1.23297918\n",
      "Trained batch 724 batch loss 1.31498432 epoch total loss 1.23309243\n",
      "Trained batch 725 batch loss 1.38196719 epoch total loss 1.23329771\n",
      "Trained batch 726 batch loss 1.33686924 epoch total loss 1.2334404\n",
      "Trained batch 727 batch loss 1.15812445 epoch total loss 1.23333681\n",
      "Trained batch 728 batch loss 1.18088388 epoch total loss 1.2332648\n",
      "Trained batch 729 batch loss 1.3424356 epoch total loss 1.23341453\n",
      "Trained batch 730 batch loss 1.32565367 epoch total loss 1.23354089\n",
      "Trained batch 731 batch loss 1.18666852 epoch total loss 1.23347676\n",
      "Trained batch 732 batch loss 1.11634731 epoch total loss 1.23331678\n",
      "Trained batch 733 batch loss 1.15685356 epoch total loss 1.23321247\n",
      "Trained batch 734 batch loss 1.15430772 epoch total loss 1.23310494\n",
      "Trained batch 735 batch loss 1.05245626 epoch total loss 1.23285913\n",
      "Trained batch 736 batch loss 1.20620513 epoch total loss 1.23282278\n",
      "Trained batch 737 batch loss 1.12160671 epoch total loss 1.23267186\n",
      "Trained batch 738 batch loss 1.18164587 epoch total loss 1.23260272\n",
      "Trained batch 739 batch loss 1.29182816 epoch total loss 1.23268282\n",
      "Trained batch 740 batch loss 1.2084614 epoch total loss 1.23265\n",
      "Trained batch 741 batch loss 1.10641956 epoch total loss 1.23247981\n",
      "Trained batch 742 batch loss 1.17828131 epoch total loss 1.23240674\n",
      "Trained batch 743 batch loss 1.28787184 epoch total loss 1.23248136\n",
      "Trained batch 744 batch loss 1.23143291 epoch total loss 1.23247993\n",
      "Trained batch 745 batch loss 1.29032111 epoch total loss 1.23255765\n",
      "Trained batch 746 batch loss 1.27049387 epoch total loss 1.23260856\n",
      "Trained batch 747 batch loss 1.27991343 epoch total loss 1.23267186\n",
      "Trained batch 748 batch loss 1.33913112 epoch total loss 1.23281407\n",
      "Trained batch 749 batch loss 1.26889324 epoch total loss 1.23286235\n",
      "Trained batch 750 batch loss 1.32162714 epoch total loss 1.23298073\n",
      "Trained batch 751 batch loss 1.35161972 epoch total loss 1.23313868\n",
      "Trained batch 752 batch loss 1.28811955 epoch total loss 1.23321187\n",
      "Trained batch 753 batch loss 1.18538976 epoch total loss 1.23314834\n",
      "Trained batch 754 batch loss 1.1638298 epoch total loss 1.23305631\n",
      "Trained batch 755 batch loss 1.25540495 epoch total loss 1.23308599\n",
      "Trained batch 756 batch loss 1.10490108 epoch total loss 1.23291647\n",
      "Trained batch 757 batch loss 1.09804 epoch total loss 1.23273826\n",
      "Trained batch 758 batch loss 1.19525719 epoch total loss 1.23268878\n",
      "Trained batch 759 batch loss 1.24537349 epoch total loss 1.23270547\n",
      "Trained batch 760 batch loss 1.39573097 epoch total loss 1.23292\n",
      "Trained batch 761 batch loss 1.06112218 epoch total loss 1.23269427\n",
      "Trained batch 762 batch loss 1.20811033 epoch total loss 1.23266196\n",
      "Trained batch 763 batch loss 1.33005428 epoch total loss 1.23278964\n",
      "Trained batch 764 batch loss 1.18884289 epoch total loss 1.23273218\n",
      "Trained batch 765 batch loss 1.11182714 epoch total loss 1.23257411\n",
      "Trained batch 766 batch loss 1.26631737 epoch total loss 1.23261809\n",
      "Trained batch 767 batch loss 1.44796181 epoch total loss 1.23289883\n",
      "Trained batch 768 batch loss 1.29353058 epoch total loss 1.23297775\n",
      "Trained batch 769 batch loss 1.09458303 epoch total loss 1.23279786\n",
      "Trained batch 770 batch loss 1.05193949 epoch total loss 1.23256302\n",
      "Trained batch 771 batch loss 1.06942952 epoch total loss 1.23235142\n",
      "Trained batch 772 batch loss 1.0560106 epoch total loss 1.23212302\n",
      "Trained batch 773 batch loss 1.10033703 epoch total loss 1.23195255\n",
      "Trained batch 774 batch loss 1.00070703 epoch total loss 1.23165381\n",
      "Trained batch 775 batch loss 1.19620192 epoch total loss 1.23160815\n",
      "Trained batch 776 batch loss 1.14965391 epoch total loss 1.23150253\n",
      "Trained batch 777 batch loss 1.10377634 epoch total loss 1.23133814\n",
      "Trained batch 778 batch loss 1.26882744 epoch total loss 1.23138618\n",
      "Trained batch 779 batch loss 1.2914952 epoch total loss 1.23146343\n",
      "Trained batch 780 batch loss 1.27240276 epoch total loss 1.23151588\n",
      "Trained batch 781 batch loss 1.19724095 epoch total loss 1.23147202\n",
      "Trained batch 782 batch loss 1.22412205 epoch total loss 1.2314626\n",
      "Trained batch 783 batch loss 1.24022985 epoch total loss 1.2314738\n",
      "Trained batch 784 batch loss 1.343207 epoch total loss 1.23161638\n",
      "Trained batch 785 batch loss 1.22921205 epoch total loss 1.23161328\n",
      "Trained batch 786 batch loss 1.07120466 epoch total loss 1.23140919\n",
      "Trained batch 787 batch loss 1.06702518 epoch total loss 1.23120034\n",
      "Trained batch 788 batch loss 1.09318566 epoch total loss 1.23102522\n",
      "Trained batch 789 batch loss 1.30752325 epoch total loss 1.23112214\n",
      "Trained batch 790 batch loss 1.39455056 epoch total loss 1.23132896\n",
      "Trained batch 791 batch loss 1.24886763 epoch total loss 1.23135114\n",
      "Trained batch 792 batch loss 1.39155269 epoch total loss 1.23155332\n",
      "Trained batch 793 batch loss 1.31471932 epoch total loss 1.23165822\n",
      "Trained batch 794 batch loss 1.34132361 epoch total loss 1.23179626\n",
      "Trained batch 795 batch loss 1.27487242 epoch total loss 1.2318505\n",
      "Trained batch 796 batch loss 1.25802469 epoch total loss 1.23188341\n",
      "Trained batch 797 batch loss 1.22639644 epoch total loss 1.23187649\n",
      "Trained batch 798 batch loss 1.37087548 epoch total loss 1.23205066\n",
      "Trained batch 799 batch loss 1.34083021 epoch total loss 1.23218679\n",
      "Trained batch 800 batch loss 1.29138231 epoch total loss 1.2322607\n",
      "Trained batch 801 batch loss 1.30119181 epoch total loss 1.23234677\n",
      "Trained batch 802 batch loss 1.222489 epoch total loss 1.23233449\n",
      "Trained batch 803 batch loss 1.15621066 epoch total loss 1.23223972\n",
      "Trained batch 804 batch loss 1.1387856 epoch total loss 1.23212349\n",
      "Trained batch 805 batch loss 1.1914885 epoch total loss 1.23207295\n",
      "Trained batch 806 batch loss 1.17940474 epoch total loss 1.23200762\n",
      "Trained batch 807 batch loss 1.13602662 epoch total loss 1.23188865\n",
      "Trained batch 808 batch loss 1.02098846 epoch total loss 1.2316277\n",
      "Trained batch 809 batch loss 1.16907585 epoch total loss 1.23155034\n",
      "Trained batch 810 batch loss 1.08207583 epoch total loss 1.2313658\n",
      "Trained batch 811 batch loss 1.10661781 epoch total loss 1.23121202\n",
      "Trained batch 812 batch loss 1.12038612 epoch total loss 1.23107553\n",
      "Trained batch 813 batch loss 1.07946515 epoch total loss 1.23088896\n",
      "Trained batch 814 batch loss 1.13810945 epoch total loss 1.230775\n",
      "Trained batch 815 batch loss 1.1425252 epoch total loss 1.23066676\n",
      "Trained batch 816 batch loss 1.34803236 epoch total loss 1.23081052\n",
      "Trained batch 817 batch loss 1.35593867 epoch total loss 1.23096371\n",
      "Trained batch 818 batch loss 1.31092966 epoch total loss 1.23106146\n",
      "Trained batch 819 batch loss 1.36365008 epoch total loss 1.23122334\n",
      "Trained batch 820 batch loss 1.36372113 epoch total loss 1.23138499\n",
      "Trained batch 821 batch loss 1.28465796 epoch total loss 1.23144984\n",
      "Trained batch 822 batch loss 1.350968 epoch total loss 1.23159528\n",
      "Trained batch 823 batch loss 1.12082791 epoch total loss 1.23146069\n",
      "Trained batch 824 batch loss 1.07954347 epoch total loss 1.23127627\n",
      "Trained batch 825 batch loss 1.2548784 epoch total loss 1.23130488\n",
      "Trained batch 826 batch loss 1.28075588 epoch total loss 1.23136473\n",
      "Trained batch 827 batch loss 1.23522639 epoch total loss 1.2313695\n",
      "Trained batch 828 batch loss 1.24255908 epoch total loss 1.23138297\n",
      "Trained batch 829 batch loss 1.17968273 epoch total loss 1.23132062\n",
      "Trained batch 830 batch loss 1.0530982 epoch total loss 1.23110592\n",
      "Trained batch 831 batch loss 1.1825676 epoch total loss 1.23104739\n",
      "Trained batch 832 batch loss 1.10156858 epoch total loss 1.23089194\n",
      "Trained batch 833 batch loss 1.14976919 epoch total loss 1.23079455\n",
      "Trained batch 834 batch loss 1.09639394 epoch total loss 1.23063338\n",
      "Trained batch 835 batch loss 1.14520121 epoch total loss 1.23053098\n",
      "Trained batch 836 batch loss 1.06225836 epoch total loss 1.23032975\n",
      "Trained batch 837 batch loss 1.20890272 epoch total loss 1.23030412\n",
      "Trained batch 838 batch loss 1.26399696 epoch total loss 1.2303443\n",
      "Trained batch 839 batch loss 1.23976099 epoch total loss 1.2303555\n",
      "Trained batch 840 batch loss 1.19297171 epoch total loss 1.23031104\n",
      "Trained batch 841 batch loss 1.23933625 epoch total loss 1.23032188\n",
      "Trained batch 842 batch loss 1.24869227 epoch total loss 1.23034358\n",
      "Trained batch 843 batch loss 1.18158114 epoch total loss 1.23028588\n",
      "Trained batch 844 batch loss 1.14063191 epoch total loss 1.23017967\n",
      "Trained batch 845 batch loss 1.26024926 epoch total loss 1.23021519\n",
      "Trained batch 846 batch loss 1.39240766 epoch total loss 1.230407\n",
      "Trained batch 847 batch loss 1.39414787 epoch total loss 1.23060036\n",
      "Trained batch 848 batch loss 1.36508727 epoch total loss 1.23075891\n",
      "Trained batch 849 batch loss 1.25811481 epoch total loss 1.23079109\n",
      "Trained batch 850 batch loss 1.25898147 epoch total loss 1.23082435\n",
      "Trained batch 851 batch loss 1.21612203 epoch total loss 1.23080695\n",
      "Trained batch 852 batch loss 1.22611415 epoch total loss 1.23080146\n",
      "Trained batch 853 batch loss 1.14781928 epoch total loss 1.23070419\n",
      "Trained batch 854 batch loss 1.26591611 epoch total loss 1.23074532\n",
      "Trained batch 855 batch loss 1.22013903 epoch total loss 1.23073292\n",
      "Trained batch 856 batch loss 1.27325 epoch total loss 1.23078251\n",
      "Trained batch 857 batch loss 1.26381993 epoch total loss 1.23082101\n",
      "Trained batch 858 batch loss 1.20417547 epoch total loss 1.23079\n",
      "Trained batch 859 batch loss 1.20094287 epoch total loss 1.23075521\n",
      "Trained batch 860 batch loss 1.11607265 epoch total loss 1.23062193\n",
      "Trained batch 861 batch loss 1.09190011 epoch total loss 1.23046076\n",
      "Trained batch 862 batch loss 1.21168756 epoch total loss 1.23043907\n",
      "Trained batch 863 batch loss 1.15578079 epoch total loss 1.23035252\n",
      "Trained batch 864 batch loss 1.06985474 epoch total loss 1.23016667\n",
      "Trained batch 865 batch loss 1.15238547 epoch total loss 1.23007667\n",
      "Trained batch 866 batch loss 1.14541507 epoch total loss 1.22997892\n",
      "Trained batch 867 batch loss 1.22691989 epoch total loss 1.22997534\n",
      "Trained batch 868 batch loss 1.03921354 epoch total loss 1.22975564\n",
      "Trained batch 869 batch loss 0.983626068 epoch total loss 1.2294724\n",
      "Trained batch 870 batch loss 1.29309869 epoch total loss 1.22954547\n",
      "Trained batch 871 batch loss 1.30659676 epoch total loss 1.22963405\n",
      "Trained batch 872 batch loss 1.26485085 epoch total loss 1.22967446\n",
      "Trained batch 873 batch loss 1.29229939 epoch total loss 1.22974622\n",
      "Trained batch 874 batch loss 1.29121923 epoch total loss 1.22981668\n",
      "Trained batch 875 batch loss 1.39270711 epoch total loss 1.23000276\n",
      "Trained batch 876 batch loss 1.26475215 epoch total loss 1.23004246\n",
      "Trained batch 877 batch loss 1.19729674 epoch total loss 1.23000515\n",
      "Trained batch 878 batch loss 1.42635262 epoch total loss 1.23022878\n",
      "Trained batch 879 batch loss 1.22628498 epoch total loss 1.23022437\n",
      "Trained batch 880 batch loss 1.16195512 epoch total loss 1.23014677\n",
      "Trained batch 881 batch loss 1.13952398 epoch total loss 1.23004389\n",
      "Trained batch 882 batch loss 1.05481791 epoch total loss 1.22984529\n",
      "Trained batch 883 batch loss 1.13253653 epoch total loss 1.22973514\n",
      "Trained batch 884 batch loss 1.13999093 epoch total loss 1.22963357\n",
      "Trained batch 885 batch loss 1.21210313 epoch total loss 1.2296139\n",
      "Trained batch 886 batch loss 1.30261266 epoch total loss 1.22969627\n",
      "Trained batch 887 batch loss 1.26828408 epoch total loss 1.22973979\n",
      "Trained batch 888 batch loss 1.33336282 epoch total loss 1.22985649\n",
      "Trained batch 889 batch loss 1.31724548 epoch total loss 1.22995484\n",
      "Trained batch 890 batch loss 1.19165301 epoch total loss 1.2299118\n",
      "Trained batch 891 batch loss 1.1822679 epoch total loss 1.22985828\n",
      "Trained batch 892 batch loss 1.24112797 epoch total loss 1.2298708\n",
      "Trained batch 893 batch loss 1.16472614 epoch total loss 1.22979784\n",
      "Trained batch 894 batch loss 1.27656162 epoch total loss 1.22985017\n",
      "Trained batch 895 batch loss 1.22239161 epoch total loss 1.22984195\n",
      "Trained batch 896 batch loss 1.07811093 epoch total loss 1.22967255\n",
      "Trained batch 897 batch loss 1.16900623 epoch total loss 1.22960484\n",
      "Trained batch 898 batch loss 1.31767964 epoch total loss 1.22970283\n",
      "Trained batch 899 batch loss 1.2508471 epoch total loss 1.22972643\n",
      "Trained batch 900 batch loss 1.26910901 epoch total loss 1.22977018\n",
      "Trained batch 901 batch loss 1.17408562 epoch total loss 1.22970843\n",
      "Trained batch 902 batch loss 1.13971722 epoch total loss 1.22960865\n",
      "Trained batch 903 batch loss 1.20243287 epoch total loss 1.22957861\n",
      "Trained batch 904 batch loss 1.19563401 epoch total loss 1.22954106\n",
      "Trained batch 905 batch loss 1.28269124 epoch total loss 1.22959983\n",
      "Trained batch 906 batch loss 1.33095384 epoch total loss 1.22971165\n",
      "Trained batch 907 batch loss 1.37485766 epoch total loss 1.22987175\n",
      "Trained batch 908 batch loss 1.33395958 epoch total loss 1.22998643\n",
      "Trained batch 909 batch loss 1.28523684 epoch total loss 1.23004723\n",
      "Trained batch 910 batch loss 1.1982038 epoch total loss 1.2300123\n",
      "Trained batch 911 batch loss 1.10154939 epoch total loss 1.22987127\n",
      "Trained batch 912 batch loss 1.1603148 epoch total loss 1.22979498\n",
      "Trained batch 913 batch loss 1.15566349 epoch total loss 1.22971368\n",
      "Trained batch 914 batch loss 1.24944007 epoch total loss 1.22973526\n",
      "Trained batch 915 batch loss 1.10261118 epoch total loss 1.22959638\n",
      "Trained batch 916 batch loss 1.18919086 epoch total loss 1.22955227\n",
      "Trained batch 917 batch loss 1.13190722 epoch total loss 1.22944582\n",
      "Trained batch 918 batch loss 1.10544038 epoch total loss 1.22931087\n",
      "Trained batch 919 batch loss 1.17282438 epoch total loss 1.22924936\n",
      "Trained batch 920 batch loss 1.28985047 epoch total loss 1.22931516\n",
      "Trained batch 921 batch loss 1.21517909 epoch total loss 1.2292999\n",
      "Trained batch 922 batch loss 1.18394482 epoch total loss 1.22925067\n",
      "Trained batch 923 batch loss 1.19743419 epoch total loss 1.22921622\n",
      "Trained batch 924 batch loss 1.31262267 epoch total loss 1.22930646\n",
      "Trained batch 925 batch loss 1.19986105 epoch total loss 1.22927463\n",
      "Trained batch 926 batch loss 1.15893853 epoch total loss 1.22919858\n",
      "Trained batch 927 batch loss 1.31526303 epoch total loss 1.22929156\n",
      "Trained batch 928 batch loss 1.29008305 epoch total loss 1.229357\n",
      "Trained batch 929 batch loss 1.18489659 epoch total loss 1.2293092\n",
      "Trained batch 930 batch loss 1.13815415 epoch total loss 1.22921121\n",
      "Trained batch 931 batch loss 1.14077628 epoch total loss 1.2291162\n",
      "Trained batch 932 batch loss 1.18547904 epoch total loss 1.22906923\n",
      "Trained batch 933 batch loss 1.22650361 epoch total loss 1.22906661\n",
      "Trained batch 934 batch loss 1.03937125 epoch total loss 1.2288636\n",
      "Trained batch 935 batch loss 1.17847323 epoch total loss 1.2288096\n",
      "Trained batch 936 batch loss 1.31468582 epoch total loss 1.22890139\n",
      "Trained batch 937 batch loss 1.18403339 epoch total loss 1.22885358\n",
      "Trained batch 938 batch loss 1.23883259 epoch total loss 1.22886431\n",
      "Trained batch 939 batch loss 1.23499072 epoch total loss 1.22887075\n",
      "Trained batch 940 batch loss 1.14885736 epoch total loss 1.22878563\n",
      "Trained batch 941 batch loss 1.30076909 epoch total loss 1.22886217\n",
      "Trained batch 942 batch loss 1.17703092 epoch total loss 1.22880709\n",
      "Trained batch 943 batch loss 1.17188585 epoch total loss 1.22874665\n",
      "Trained batch 944 batch loss 1.12847495 epoch total loss 1.22864044\n",
      "Trained batch 945 batch loss 1.05527949 epoch total loss 1.22845697\n",
      "Trained batch 946 batch loss 1.20531714 epoch total loss 1.22843254\n",
      "Trained batch 947 batch loss 1.23490465 epoch total loss 1.22843933\n",
      "Trained batch 948 batch loss 1.26693392 epoch total loss 1.22848\n",
      "Trained batch 949 batch loss 1.24269915 epoch total loss 1.22849488\n",
      "Trained batch 950 batch loss 1.09014964 epoch total loss 1.22834933\n",
      "Trained batch 951 batch loss 0.999413729 epoch total loss 1.22810864\n",
      "Trained batch 952 batch loss 1.00092649 epoch total loss 1.22787\n",
      "Trained batch 953 batch loss 1.09964323 epoch total loss 1.2277354\n",
      "Trained batch 954 batch loss 1.03820705 epoch total loss 1.2275368\n",
      "Trained batch 955 batch loss 1.1790365 epoch total loss 1.22748601\n",
      "Trained batch 956 batch loss 1.29805684 epoch total loss 1.22755992\n",
      "Trained batch 957 batch loss 1.33876801 epoch total loss 1.22767603\n",
      "Trained batch 958 batch loss 1.18104863 epoch total loss 1.2276274\n",
      "Trained batch 959 batch loss 1.22524118 epoch total loss 1.22762489\n",
      "Trained batch 960 batch loss 1.1485709 epoch total loss 1.22754252\n",
      "Trained batch 961 batch loss 1.14528179 epoch total loss 1.22745693\n",
      "Trained batch 962 batch loss 1.11322308 epoch total loss 1.22733819\n",
      "Trained batch 963 batch loss 1.26566744 epoch total loss 1.22737789\n",
      "Trained batch 964 batch loss 1.23837614 epoch total loss 1.22738934\n",
      "Trained batch 965 batch loss 1.12930763 epoch total loss 1.22728777\n",
      "Trained batch 966 batch loss 1.22765207 epoch total loss 1.22728813\n",
      "Trained batch 967 batch loss 1.11819601 epoch total loss 1.22717524\n",
      "Trained batch 968 batch loss 1.19259882 epoch total loss 1.22713959\n",
      "Trained batch 969 batch loss 1.16307223 epoch total loss 1.22707343\n",
      "Trained batch 970 batch loss 1.15862846 epoch total loss 1.22700286\n",
      "Trained batch 971 batch loss 1.12874341 epoch total loss 1.22690165\n",
      "Trained batch 972 batch loss 1.11829126 epoch total loss 1.22679\n",
      "Trained batch 973 batch loss 1.19703269 epoch total loss 1.22675931\n",
      "Trained batch 974 batch loss 1.12851334 epoch total loss 1.22665846\n",
      "Trained batch 975 batch loss 1.29760373 epoch total loss 1.2267313\n",
      "Trained batch 976 batch loss 1.31124187 epoch total loss 1.22681785\n",
      "Trained batch 977 batch loss 1.18391871 epoch total loss 1.22677398\n",
      "Trained batch 978 batch loss 1.26939404 epoch total loss 1.22681761\n",
      "Trained batch 979 batch loss 1.2141211 epoch total loss 1.22680461\n",
      "Trained batch 980 batch loss 1.05188787 epoch total loss 1.22662616\n",
      "Trained batch 981 batch loss 1.10316014 epoch total loss 1.22650027\n",
      "Trained batch 982 batch loss 1.21322215 epoch total loss 1.2264868\n",
      "Trained batch 983 batch loss 1.12545896 epoch total loss 1.22638404\n",
      "Trained batch 984 batch loss 1.26199007 epoch total loss 1.22642016\n",
      "Trained batch 985 batch loss 1.26996613 epoch total loss 1.22646451\n",
      "Trained batch 986 batch loss 1.20743454 epoch total loss 1.22644508\n",
      "Trained batch 987 batch loss 1.14438343 epoch total loss 1.22636199\n",
      "Trained batch 988 batch loss 1.30480218 epoch total loss 1.22644138\n",
      "Trained batch 989 batch loss 1.22423697 epoch total loss 1.22643924\n",
      "Trained batch 990 batch loss 1.18376 epoch total loss 1.22639608\n",
      "Trained batch 991 batch loss 1.28771615 epoch total loss 1.22645795\n",
      "Trained batch 992 batch loss 1.18213725 epoch total loss 1.22641325\n",
      "Trained batch 993 batch loss 1.12995625 epoch total loss 1.22631609\n",
      "Trained batch 994 batch loss 1.13583887 epoch total loss 1.22622514\n",
      "Trained batch 995 batch loss 1.24818039 epoch total loss 1.22624719\n",
      "Trained batch 996 batch loss 1.09743083 epoch total loss 1.22611785\n",
      "Trained batch 997 batch loss 1.25071466 epoch total loss 1.22614253\n",
      "Trained batch 998 batch loss 1.33231735 epoch total loss 1.22624886\n",
      "Trained batch 999 batch loss 1.39156246 epoch total loss 1.22641444\n",
      "Trained batch 1000 batch loss 1.13517761 epoch total loss 1.22632313\n",
      "Trained batch 1001 batch loss 1.06110179 epoch total loss 1.22615814\n",
      "Trained batch 1002 batch loss 1.15200293 epoch total loss 1.22608411\n",
      "Trained batch 1003 batch loss 1.21474457 epoch total loss 1.22607279\n",
      "Trained batch 1004 batch loss 1.34963024 epoch total loss 1.22619581\n",
      "Trained batch 1005 batch loss 1.32243073 epoch total loss 1.22629154\n",
      "Trained batch 1006 batch loss 1.27027297 epoch total loss 1.22633517\n",
      "Trained batch 1007 batch loss 1.16122913 epoch total loss 1.22627056\n",
      "Trained batch 1008 batch loss 1.25072551 epoch total loss 1.22629488\n",
      "Trained batch 1009 batch loss 1.28909588 epoch total loss 1.2263571\n",
      "Trained batch 1010 batch loss 1.23294353 epoch total loss 1.22636354\n",
      "Trained batch 1011 batch loss 1.25271416 epoch total loss 1.22638965\n",
      "Trained batch 1012 batch loss 1.17823875 epoch total loss 1.22634196\n",
      "Trained batch 1013 batch loss 1.16509533 epoch total loss 1.22628152\n",
      "Trained batch 1014 batch loss 1.25591469 epoch total loss 1.22631061\n",
      "Trained batch 1015 batch loss 1.29316175 epoch total loss 1.22637653\n",
      "Trained batch 1016 batch loss 1.22189224 epoch total loss 1.22637224\n",
      "Trained batch 1017 batch loss 1.31015742 epoch total loss 1.22645462\n",
      "Trained batch 1018 batch loss 1.28572965 epoch total loss 1.22651291\n",
      "Trained batch 1019 batch loss 1.23675382 epoch total loss 1.2265228\n",
      "Trained batch 1020 batch loss 1.24088621 epoch total loss 1.22653687\n",
      "Trained batch 1021 batch loss 1.21178246 epoch total loss 1.22652245\n",
      "Trained batch 1022 batch loss 1.26085699 epoch total loss 1.22655606\n",
      "Trained batch 1023 batch loss 1.17657971 epoch total loss 1.22650731\n",
      "Trained batch 1024 batch loss 1.21787775 epoch total loss 1.22649884\n",
      "Trained batch 1025 batch loss 1.16639972 epoch total loss 1.22644019\n",
      "Trained batch 1026 batch loss 1.19043207 epoch total loss 1.22640514\n",
      "Trained batch 1027 batch loss 1.18893373 epoch total loss 1.22636867\n",
      "Trained batch 1028 batch loss 1.22393107 epoch total loss 1.22636616\n",
      "Trained batch 1029 batch loss 1.30032 epoch total loss 1.22643805\n",
      "Trained batch 1030 batch loss 1.33799195 epoch total loss 1.22654641\n",
      "Trained batch 1031 batch loss 1.38111448 epoch total loss 1.22669625\n",
      "Trained batch 1032 batch loss 1.21575546 epoch total loss 1.22668564\n",
      "Trained batch 1033 batch loss 1.18607354 epoch total loss 1.2266463\n",
      "Trained batch 1034 batch loss 1.30705369 epoch total loss 1.22672403\n",
      "Trained batch 1035 batch loss 1.28052759 epoch total loss 1.226776\n",
      "Trained batch 1036 batch loss 1.23469663 epoch total loss 1.22678363\n",
      "Trained batch 1037 batch loss 1.15090656 epoch total loss 1.22671044\n",
      "Trained batch 1038 batch loss 1.27203166 epoch total loss 1.22675407\n",
      "Trained batch 1039 batch loss 1.18676162 epoch total loss 1.22671556\n",
      "Trained batch 1040 batch loss 0.958960772 epoch total loss 1.22645819\n",
      "Trained batch 1041 batch loss 1.16697049 epoch total loss 1.22640097\n",
      "Trained batch 1042 batch loss 1.11334848 epoch total loss 1.22629261\n",
      "Trained batch 1043 batch loss 1.21967185 epoch total loss 1.22628629\n",
      "Trained batch 1044 batch loss 1.27892244 epoch total loss 1.22633672\n",
      "Trained batch 1045 batch loss 1.28091073 epoch total loss 1.22638893\n",
      "Trained batch 1046 batch loss 1.25890601 epoch total loss 1.22642\n",
      "Trained batch 1047 batch loss 1.30501485 epoch total loss 1.22649515\n",
      "Trained batch 1048 batch loss 1.27213216 epoch total loss 1.22653866\n",
      "Trained batch 1049 batch loss 1.2509079 epoch total loss 1.22656178\n",
      "Trained batch 1050 batch loss 1.27225912 epoch total loss 1.2266053\n",
      "Trained batch 1051 batch loss 1.20813012 epoch total loss 1.22658765\n",
      "Trained batch 1052 batch loss 1.23311198 epoch total loss 1.22659397\n",
      "Trained batch 1053 batch loss 1.32084656 epoch total loss 1.22668338\n",
      "Trained batch 1054 batch loss 1.28709424 epoch total loss 1.22674072\n",
      "Trained batch 1055 batch loss 1.25151825 epoch total loss 1.2267642\n",
      "Trained batch 1056 batch loss 1.22905362 epoch total loss 1.22676635\n",
      "Trained batch 1057 batch loss 0.954239845 epoch total loss 1.2265085\n",
      "Trained batch 1058 batch loss 1.10918736 epoch total loss 1.22639751\n",
      "Trained batch 1059 batch loss 1.12029982 epoch total loss 1.22629726\n",
      "Trained batch 1060 batch loss 1.15877652 epoch total loss 1.2262336\n",
      "Trained batch 1061 batch loss 1.31418335 epoch total loss 1.22631657\n",
      "Trained batch 1062 batch loss 1.19920707 epoch total loss 1.22629106\n",
      "Trained batch 1063 batch loss 1.0438025 epoch total loss 1.2261194\n",
      "Trained batch 1064 batch loss 0.970948458 epoch total loss 1.22587955\n",
      "Trained batch 1065 batch loss 1.07590318 epoch total loss 1.22573876\n",
      "Trained batch 1066 batch loss 1.24617386 epoch total loss 1.22575796\n",
      "Trained batch 1067 batch loss 1.33357227 epoch total loss 1.22585905\n",
      "Trained batch 1068 batch loss 1.65517616 epoch total loss 1.22626102\n",
      "Trained batch 1069 batch loss 1.22694397 epoch total loss 1.22626162\n",
      "Trained batch 1070 batch loss 1.22348702 epoch total loss 1.22625899\n",
      "Trained batch 1071 batch loss 1.16464138 epoch total loss 1.22620153\n",
      "Trained batch 1072 batch loss 1.29489446 epoch total loss 1.22626567\n",
      "Trained batch 1073 batch loss 1.24757624 epoch total loss 1.22628546\n",
      "Trained batch 1074 batch loss 1.27061057 epoch total loss 1.22632682\n",
      "Trained batch 1075 batch loss 1.23492861 epoch total loss 1.22633481\n",
      "Trained batch 1076 batch loss 1.27777541 epoch total loss 1.22638273\n",
      "Trained batch 1077 batch loss 1.26535749 epoch total loss 1.22641885\n",
      "Trained batch 1078 batch loss 1.23283482 epoch total loss 1.22642481\n",
      "Trained batch 1079 batch loss 1.06478107 epoch total loss 1.22627509\n",
      "Trained batch 1080 batch loss 1.14795 epoch total loss 1.22620249\n",
      "Trained batch 1081 batch loss 1.17700279 epoch total loss 1.22615695\n",
      "Trained batch 1082 batch loss 1.25301933 epoch total loss 1.22618186\n",
      "Trained batch 1083 batch loss 1.0844605 epoch total loss 1.22605097\n",
      "Trained batch 1084 batch loss 1.05173492 epoch total loss 1.22589016\n",
      "Trained batch 1085 batch loss 1.196118 epoch total loss 1.22586286\n",
      "Trained batch 1086 batch loss 1.258991 epoch total loss 1.22589338\n",
      "Trained batch 1087 batch loss 1.30225945 epoch total loss 1.22596359\n",
      "Trained batch 1088 batch loss 1.32185245 epoch total loss 1.22605181\n",
      "Trained batch 1089 batch loss 1.09367359 epoch total loss 1.22593021\n",
      "Trained batch 1090 batch loss 1.0493958 epoch total loss 1.22576821\n",
      "Trained batch 1091 batch loss 1.07576644 epoch total loss 1.22563076\n",
      "Trained batch 1092 batch loss 1.17128074 epoch total loss 1.22558105\n",
      "Trained batch 1093 batch loss 1.3360343 epoch total loss 1.22568214\n",
      "Trained batch 1094 batch loss 1.239254 epoch total loss 1.22569454\n",
      "Trained batch 1095 batch loss 1.1918118 epoch total loss 1.22566354\n",
      "Trained batch 1096 batch loss 1.18336058 epoch total loss 1.22562492\n",
      "Trained batch 1097 batch loss 1.2773447 epoch total loss 1.22567201\n",
      "Trained batch 1098 batch loss 1.20769882 epoch total loss 1.22565567\n",
      "Trained batch 1099 batch loss 1.10386515 epoch total loss 1.22554481\n",
      "Trained batch 1100 batch loss 1.28110886 epoch total loss 1.22559536\n",
      "Trained batch 1101 batch loss 1.37190628 epoch total loss 1.22572827\n",
      "Trained batch 1102 batch loss 1.22802269 epoch total loss 1.22573042\n",
      "Trained batch 1103 batch loss 1.21186745 epoch total loss 1.2257179\n",
      "Trained batch 1104 batch loss 1.09587121 epoch total loss 1.22560024\n",
      "Trained batch 1105 batch loss 1.15651011 epoch total loss 1.22553766\n",
      "Trained batch 1106 batch loss 1.31252754 epoch total loss 1.22561634\n",
      "Trained batch 1107 batch loss 1.37250519 epoch total loss 1.22574902\n",
      "Trained batch 1108 batch loss 1.14592862 epoch total loss 1.22567689\n",
      "Trained batch 1109 batch loss 1.10990787 epoch total loss 1.22557247\n",
      "Trained batch 1110 batch loss 1.02065277 epoch total loss 1.22538793\n",
      "Trained batch 1111 batch loss 1.01748061 epoch total loss 1.22520077\n",
      "Trained batch 1112 batch loss 1.17808962 epoch total loss 1.22515833\n",
      "Trained batch 1113 batch loss 1.10716689 epoch total loss 1.22505236\n",
      "Trained batch 1114 batch loss 1.14346814 epoch total loss 1.22497904\n",
      "Trained batch 1115 batch loss 1.08604801 epoch total loss 1.22485447\n",
      "Trained batch 1116 batch loss 1.32738018 epoch total loss 1.22494638\n",
      "Trained batch 1117 batch loss 1.33538485 epoch total loss 1.2250452\n",
      "Trained batch 1118 batch loss 1.31745863 epoch total loss 1.22512794\n",
      "Trained batch 1119 batch loss 1.20537794 epoch total loss 1.22511017\n",
      "Trained batch 1120 batch loss 1.0884347 epoch total loss 1.2249881\n",
      "Trained batch 1121 batch loss 1.17123985 epoch total loss 1.22494018\n",
      "Trained batch 1122 batch loss 1.22287059 epoch total loss 1.22493839\n",
      "Trained batch 1123 batch loss 1.29713213 epoch total loss 1.22500265\n",
      "Trained batch 1124 batch loss 1.39698195 epoch total loss 1.22515559\n",
      "Trained batch 1125 batch loss 1.25424111 epoch total loss 1.22518158\n",
      "Trained batch 1126 batch loss 1.2553519 epoch total loss 1.2252084\n",
      "Trained batch 1127 batch loss 1.13055313 epoch total loss 1.22512436\n",
      "Trained batch 1128 batch loss 1.20813632 epoch total loss 1.22510922\n",
      "Trained batch 1129 batch loss 1.14116335 epoch total loss 1.22503483\n",
      "Trained batch 1130 batch loss 1.22211659 epoch total loss 1.22503233\n",
      "Trained batch 1131 batch loss 1.19803393 epoch total loss 1.22500837\n",
      "Trained batch 1132 batch loss 1.02953637 epoch total loss 1.22483575\n",
      "Trained batch 1133 batch loss 1.17012429 epoch total loss 1.22478747\n",
      "Trained batch 1134 batch loss 1.24224722 epoch total loss 1.22480285\n",
      "Trained batch 1135 batch loss 1.1020422 epoch total loss 1.22469461\n",
      "Trained batch 1136 batch loss 1.17122126 epoch total loss 1.22464764\n",
      "Trained batch 1137 batch loss 1.17633832 epoch total loss 1.2246052\n",
      "Trained batch 1138 batch loss 1.11355543 epoch total loss 1.22450757\n",
      "Trained batch 1139 batch loss 1.08751535 epoch total loss 1.22438729\n",
      "Trained batch 1140 batch loss 1.13682079 epoch total loss 1.22431052\n",
      "Trained batch 1141 batch loss 1.17270541 epoch total loss 1.22426534\n",
      "Trained batch 1142 batch loss 1.13534367 epoch total loss 1.22418749\n",
      "Trained batch 1143 batch loss 1.15071237 epoch total loss 1.22412324\n",
      "Trained batch 1144 batch loss 1.29199409 epoch total loss 1.22418261\n",
      "Trained batch 1145 batch loss 1.21169579 epoch total loss 1.22417164\n",
      "Trained batch 1146 batch loss 1.26776373 epoch total loss 1.22420967\n",
      "Trained batch 1147 batch loss 1.26758504 epoch total loss 1.22424757\n",
      "Trained batch 1148 batch loss 1.38325047 epoch total loss 1.2243861\n",
      "Trained batch 1149 batch loss 1.18965924 epoch total loss 1.22435594\n",
      "Trained batch 1150 batch loss 1.25728309 epoch total loss 1.22438455\n",
      "Trained batch 1151 batch loss 1.35566258 epoch total loss 1.22449863\n",
      "Trained batch 1152 batch loss 1.22294474 epoch total loss 1.22449732\n",
      "Trained batch 1153 batch loss 1.20969558 epoch total loss 1.22448444\n",
      "Trained batch 1154 batch loss 1.30203485 epoch total loss 1.22455168\n",
      "Trained batch 1155 batch loss 1.29664886 epoch total loss 1.22461402\n",
      "Trained batch 1156 batch loss 1.24045634 epoch total loss 1.22462773\n",
      "Trained batch 1157 batch loss 1.2263577 epoch total loss 1.22462916\n",
      "Trained batch 1158 batch loss 1.22028565 epoch total loss 1.22462547\n",
      "Trained batch 1159 batch loss 1.15740132 epoch total loss 1.22456741\n",
      "Trained batch 1160 batch loss 1.15175045 epoch total loss 1.22450471\n",
      "Trained batch 1161 batch loss 1.19182348 epoch total loss 1.22447646\n",
      "Trained batch 1162 batch loss 1.2160033 epoch total loss 1.22446918\n",
      "Trained batch 1163 batch loss 1.18498743 epoch total loss 1.22443509\n",
      "Trained batch 1164 batch loss 1.10695755 epoch total loss 1.22433424\n",
      "Trained batch 1165 batch loss 1.10251749 epoch total loss 1.22422969\n",
      "Trained batch 1166 batch loss 1.05769181 epoch total loss 1.22408688\n",
      "Trained batch 1167 batch loss 1.24066913 epoch total loss 1.22410107\n",
      "Trained batch 1168 batch loss 1.25732517 epoch total loss 1.22412956\n",
      "Trained batch 1169 batch loss 1.14512908 epoch total loss 1.22406197\n",
      "Trained batch 1170 batch loss 1.21430802 epoch total loss 1.22405374\n",
      "Trained batch 1171 batch loss 1.19207931 epoch total loss 1.22402644\n",
      "Trained batch 1172 batch loss 1.11843348 epoch total loss 1.22393632\n",
      "Trained batch 1173 batch loss 1.02685094 epoch total loss 1.22376835\n",
      "Trained batch 1174 batch loss 1.06516194 epoch total loss 1.22363317\n",
      "Trained batch 1175 batch loss 1.17424905 epoch total loss 1.22359121\n",
      "Trained batch 1176 batch loss 1.24535847 epoch total loss 1.22360969\n",
      "Trained batch 1177 batch loss 1.31578636 epoch total loss 1.22368801\n",
      "Trained batch 1178 batch loss 1.32790184 epoch total loss 1.22377646\n",
      "Trained batch 1179 batch loss 1.35164011 epoch total loss 1.22388494\n",
      "Trained batch 1180 batch loss 1.24448347 epoch total loss 1.22390234\n",
      "Trained batch 1181 batch loss 1.26017451 epoch total loss 1.2239331\n",
      "Trained batch 1182 batch loss 1.17736328 epoch total loss 1.22389364\n",
      "Trained batch 1183 batch loss 1.14534211 epoch total loss 1.22382736\n",
      "Trained batch 1184 batch loss 1.26059461 epoch total loss 1.22385836\n",
      "Trained batch 1185 batch loss 1.24430907 epoch total loss 1.22387564\n",
      "Trained batch 1186 batch loss 1.37127662 epoch total loss 1.22399986\n",
      "Trained batch 1187 batch loss 1.23580682 epoch total loss 1.22400987\n",
      "Trained batch 1188 batch loss 1.1531167 epoch total loss 1.22395015\n",
      "Trained batch 1189 batch loss 1.37876546 epoch total loss 1.22408032\n",
      "Trained batch 1190 batch loss 1.35919273 epoch total loss 1.22419393\n",
      "Trained batch 1191 batch loss 1.32472968 epoch total loss 1.22427833\n",
      "Trained batch 1192 batch loss 1.1472019 epoch total loss 1.22421372\n",
      "Trained batch 1193 batch loss 1.3425976 epoch total loss 1.2243129\n",
      "Trained batch 1194 batch loss 1.2459693 epoch total loss 1.22433114\n",
      "Trained batch 1195 batch loss 1.16118801 epoch total loss 1.22427821\n",
      "Trained batch 1196 batch loss 1.25686312 epoch total loss 1.22430539\n",
      "Trained batch 1197 batch loss 1.13554907 epoch total loss 1.22423124\n",
      "Trained batch 1198 batch loss 1.27080035 epoch total loss 1.22427011\n",
      "Trained batch 1199 batch loss 1.24233055 epoch total loss 1.22428513\n",
      "Trained batch 1200 batch loss 1.36913085 epoch total loss 1.22440577\n",
      "Trained batch 1201 batch loss 1.19069409 epoch total loss 1.22437775\n",
      "Trained batch 1202 batch loss 1.26580024 epoch total loss 1.2244122\n",
      "Trained batch 1203 batch loss 1.22508347 epoch total loss 1.22441268\n",
      "Trained batch 1204 batch loss 1.15238547 epoch total loss 1.22435284\n",
      "Trained batch 1205 batch loss 1.17591703 epoch total loss 1.22431266\n",
      "Trained batch 1206 batch loss 1.20966625 epoch total loss 1.2243005\n",
      "Trained batch 1207 batch loss 1.23500752 epoch total loss 1.22430944\n",
      "Trained batch 1208 batch loss 1.23646009 epoch total loss 1.22431946\n",
      "Trained batch 1209 batch loss 1.35481501 epoch total loss 1.22442746\n",
      "Trained batch 1210 batch loss 1.28487921 epoch total loss 1.22447741\n",
      "Trained batch 1211 batch loss 1.2553637 epoch total loss 1.22450292\n",
      "Trained batch 1212 batch loss 1.22174025 epoch total loss 1.22450066\n",
      "Trained batch 1213 batch loss 1.38397908 epoch total loss 1.22463214\n",
      "Trained batch 1214 batch loss 1.15480149 epoch total loss 1.22457457\n",
      "Trained batch 1215 batch loss 1.19331217 epoch total loss 1.22454894\n",
      "Trained batch 1216 batch loss 1.12778211 epoch total loss 1.2244693\n",
      "Trained batch 1217 batch loss 1.1104 epoch total loss 1.22437561\n",
      "Trained batch 1218 batch loss 1.16262162 epoch total loss 1.22432482\n",
      "Trained batch 1219 batch loss 1.14782298 epoch total loss 1.22426212\n",
      "Trained batch 1220 batch loss 1.21019518 epoch total loss 1.22425056\n",
      "Trained batch 1221 batch loss 1.18986368 epoch total loss 1.22422242\n",
      "Trained batch 1222 batch loss 1.28865719 epoch total loss 1.22427511\n",
      "Trained batch 1223 batch loss 1.33420336 epoch total loss 1.224365\n",
      "Trained batch 1224 batch loss 1.2525152 epoch total loss 1.22438812\n",
      "Trained batch 1225 batch loss 1.18181562 epoch total loss 1.22435331\n",
      "Trained batch 1226 batch loss 1.18917501 epoch total loss 1.22432458\n",
      "Trained batch 1227 batch loss 1.01230085 epoch total loss 1.22415185\n",
      "Trained batch 1228 batch loss 1.06957281 epoch total loss 1.22402596\n",
      "Trained batch 1229 batch loss 1.15900898 epoch total loss 1.22397316\n",
      "Trained batch 1230 batch loss 1.33039 epoch total loss 1.2240597\n",
      "Trained batch 1231 batch loss 1.3628279 epoch total loss 1.22417235\n",
      "Trained batch 1232 batch loss 1.14721918 epoch total loss 1.22410989\n",
      "Trained batch 1233 batch loss 1.21513665 epoch total loss 1.22410262\n",
      "Trained batch 1234 batch loss 1.20487583 epoch total loss 1.224087\n",
      "Trained batch 1235 batch loss 1.10183251 epoch total loss 1.22398794\n",
      "Trained batch 1236 batch loss 1.10441697 epoch total loss 1.22389114\n",
      "Trained batch 1237 batch loss 1.19775414 epoch total loss 1.22387\n",
      "Trained batch 1238 batch loss 1.20049512 epoch total loss 1.22385108\n",
      "Trained batch 1239 batch loss 1.16050947 epoch total loss 1.22380006\n",
      "Trained batch 1240 batch loss 1.10964513 epoch total loss 1.22370791\n",
      "Trained batch 1241 batch loss 1.02042782 epoch total loss 1.22354412\n",
      "Trained batch 1242 batch loss 1.03383172 epoch total loss 1.22339129\n",
      "Trained batch 1243 batch loss 1.18452287 epoch total loss 1.22336006\n",
      "Trained batch 1244 batch loss 1.30538917 epoch total loss 1.2234261\n",
      "Trained batch 1245 batch loss 1.35040784 epoch total loss 1.22352815\n",
      "Trained batch 1246 batch loss 1.41620231 epoch total loss 1.22368276\n",
      "Trained batch 1247 batch loss 1.24951684 epoch total loss 1.2237035\n",
      "Trained batch 1248 batch loss 1.33241904 epoch total loss 1.22379053\n",
      "Trained batch 1249 batch loss 1.2543118 epoch total loss 1.22381496\n",
      "Trained batch 1250 batch loss 1.11339486 epoch total loss 1.22372663\n",
      "Trained batch 1251 batch loss 1.15353465 epoch total loss 1.2236706\n",
      "Trained batch 1252 batch loss 1.20294559 epoch total loss 1.22365403\n",
      "Trained batch 1253 batch loss 1.13798547 epoch total loss 1.22358561\n",
      "Trained batch 1254 batch loss 1.23846984 epoch total loss 1.22359753\n",
      "Trained batch 1255 batch loss 1.2910943 epoch total loss 1.22365141\n",
      "Trained batch 1256 batch loss 1.23165774 epoch total loss 1.22365785\n",
      "Trained batch 1257 batch loss 1.20037341 epoch total loss 1.22363925\n",
      "Trained batch 1258 batch loss 1.21018946 epoch total loss 1.22362852\n",
      "Trained batch 1259 batch loss 1.21781027 epoch total loss 1.22362387\n",
      "Trained batch 1260 batch loss 1.10056615 epoch total loss 1.22352624\n",
      "Trained batch 1261 batch loss 1.04682434 epoch total loss 1.22338617\n",
      "Trained batch 1262 batch loss 1.07393909 epoch total loss 1.22326779\n",
      "Trained batch 1263 batch loss 1.18363452 epoch total loss 1.22323632\n",
      "Trained batch 1264 batch loss 1.12441707 epoch total loss 1.22315812\n",
      "Trained batch 1265 batch loss 1.25049603 epoch total loss 1.2231797\n",
      "Trained batch 1266 batch loss 1.29790902 epoch total loss 1.22323871\n",
      "Trained batch 1267 batch loss 1.35422575 epoch total loss 1.22334218\n",
      "Trained batch 1268 batch loss 1.16641164 epoch total loss 1.22329724\n",
      "Trained batch 1269 batch loss 1.16141748 epoch total loss 1.22324836\n",
      "Trained batch 1270 batch loss 1.15220904 epoch total loss 1.22319245\n",
      "Trained batch 1271 batch loss 1.15957475 epoch total loss 1.22314239\n",
      "Trained batch 1272 batch loss 1.28712225 epoch total loss 1.22319269\n",
      "Trained batch 1273 batch loss 0.930779338 epoch total loss 1.22296298\n",
      "Trained batch 1274 batch loss 0.972401738 epoch total loss 1.2227664\n",
      "Trained batch 1275 batch loss 1.03175819 epoch total loss 1.22261655\n",
      "Trained batch 1276 batch loss 1.10999453 epoch total loss 1.22252822\n",
      "Trained batch 1277 batch loss 1.28593922 epoch total loss 1.22257781\n",
      "Trained batch 1278 batch loss 1.54108453 epoch total loss 1.22282708\n",
      "Trained batch 1279 batch loss 1.3309257 epoch total loss 1.2229116\n",
      "Trained batch 1280 batch loss 1.22928202 epoch total loss 1.2229166\n",
      "Trained batch 1281 batch loss 1.16170168 epoch total loss 1.2228688\n",
      "Trained batch 1282 batch loss 1.18402851 epoch total loss 1.22283864\n",
      "Trained batch 1283 batch loss 1.37956953 epoch total loss 1.22296071\n",
      "Trained batch 1284 batch loss 1.27517867 epoch total loss 1.22300136\n",
      "Trained batch 1285 batch loss 1.18543398 epoch total loss 1.22297215\n",
      "Trained batch 1286 batch loss 1.13811016 epoch total loss 1.22290611\n",
      "Trained batch 1287 batch loss 1.11629391 epoch total loss 1.22282326\n",
      "Trained batch 1288 batch loss 1.06581903 epoch total loss 1.22270131\n",
      "Trained batch 1289 batch loss 1.21072936 epoch total loss 1.22269201\n",
      "Trained batch 1290 batch loss 1.21243823 epoch total loss 1.22268403\n",
      "Trained batch 1291 batch loss 1.17777491 epoch total loss 1.22264922\n",
      "Trained batch 1292 batch loss 1.04571688 epoch total loss 1.22251236\n",
      "Trained batch 1293 batch loss 1.10867918 epoch total loss 1.22242427\n",
      "Trained batch 1294 batch loss 1.25505793 epoch total loss 1.22244942\n",
      "Trained batch 1295 batch loss 1.31416464 epoch total loss 1.22252035\n",
      "Trained batch 1296 batch loss 1.2400552 epoch total loss 1.22253394\n",
      "Trained batch 1297 batch loss 1.19039059 epoch total loss 1.22250915\n",
      "Trained batch 1298 batch loss 1.05469179 epoch total loss 1.2223798\n",
      "Trained batch 1299 batch loss 0.988503516 epoch total loss 1.2221998\n",
      "Trained batch 1300 batch loss 0.895221353 epoch total loss 1.22194839\n",
      "Trained batch 1301 batch loss 0.980704069 epoch total loss 1.2217629\n",
      "Trained batch 1302 batch loss 1.25902474 epoch total loss 1.22179151\n",
      "Trained batch 1303 batch loss 1.12371016 epoch total loss 1.22171617\n",
      "Trained batch 1304 batch loss 1.10251141 epoch total loss 1.22162485\n",
      "Trained batch 1305 batch loss 1.06014311 epoch total loss 1.22150111\n",
      "Trained batch 1306 batch loss 1.18620145 epoch total loss 1.22147405\n",
      "Trained batch 1307 batch loss 1.06919384 epoch total loss 1.22135758\n",
      "Trained batch 1308 batch loss 1.09231925 epoch total loss 1.22125888\n",
      "Trained batch 1309 batch loss 1.19882441 epoch total loss 1.22124171\n",
      "Trained batch 1310 batch loss 1.33693838 epoch total loss 1.22133\n",
      "Trained batch 1311 batch loss 1.12396359 epoch total loss 1.2212559\n",
      "Trained batch 1312 batch loss 1.2736975 epoch total loss 1.22129583\n",
      "Trained batch 1313 batch loss 1.20078111 epoch total loss 1.22128022\n",
      "Trained batch 1314 batch loss 1.28991866 epoch total loss 1.22133243\n",
      "Trained batch 1315 batch loss 1.40512991 epoch total loss 1.22147226\n",
      "Trained batch 1316 batch loss 1.60111785 epoch total loss 1.22176063\n",
      "Trained batch 1317 batch loss 1.45645034 epoch total loss 1.22193885\n",
      "Trained batch 1318 batch loss 1.08525586 epoch total loss 1.22183514\n",
      "Trained batch 1319 batch loss 1.15989971 epoch total loss 1.22178817\n",
      "Trained batch 1320 batch loss 1.31568277 epoch total loss 1.22185934\n",
      "Trained batch 1321 batch loss 1.38619936 epoch total loss 1.22198367\n",
      "Trained batch 1322 batch loss 1.329898 epoch total loss 1.22206533\n",
      "Trained batch 1323 batch loss 1.13245165 epoch total loss 1.22199762\n",
      "Trained batch 1324 batch loss 1.02758014 epoch total loss 1.22185075\n",
      "Trained batch 1325 batch loss 1.09177947 epoch total loss 1.22175264\n",
      "Trained batch 1326 batch loss 1.16100192 epoch total loss 1.22170687\n",
      "Trained batch 1327 batch loss 1.1419971 epoch total loss 1.22164679\n",
      "Trained batch 1328 batch loss 1.21081686 epoch total loss 1.22163856\n",
      "Trained batch 1329 batch loss 1.18915021 epoch total loss 1.22161424\n",
      "Trained batch 1330 batch loss 1.03857315 epoch total loss 1.22147655\n",
      "Trained batch 1331 batch loss 1.2648077 epoch total loss 1.2215091\n",
      "Trained batch 1332 batch loss 1.1504221 epoch total loss 1.22145569\n",
      "Trained batch 1333 batch loss 1.21362662 epoch total loss 1.22144985\n",
      "Trained batch 1334 batch loss 1.14340711 epoch total loss 1.22139132\n",
      "Trained batch 1335 batch loss 1.11102986 epoch total loss 1.22130871\n",
      "Trained batch 1336 batch loss 1.11071908 epoch total loss 1.22122598\n",
      "Trained batch 1337 batch loss 1.15180695 epoch total loss 1.221174\n",
      "Trained batch 1338 batch loss 1.16821313 epoch total loss 1.22113442\n",
      "Trained batch 1339 batch loss 1.22596014 epoch total loss 1.22113812\n",
      "Trained batch 1340 batch loss 1.45709908 epoch total loss 1.22131419\n",
      "Trained batch 1341 batch loss 1.45877504 epoch total loss 1.22149122\n",
      "Trained batch 1342 batch loss 1.23580384 epoch total loss 1.22150195\n",
      "Trained batch 1343 batch loss 1.18033 epoch total loss 1.22147131\n",
      "Trained batch 1344 batch loss 1.13086462 epoch total loss 1.22140384\n",
      "Trained batch 1345 batch loss 1.21761203 epoch total loss 1.2214011\n",
      "Trained batch 1346 batch loss 1.15102744 epoch total loss 1.22134876\n",
      "Trained batch 1347 batch loss 1.20246685 epoch total loss 1.22133482\n",
      "Trained batch 1348 batch loss 1.285218 epoch total loss 1.22138226\n",
      "Trained batch 1349 batch loss 1.43378901 epoch total loss 1.22153974\n",
      "Trained batch 1350 batch loss 1.31836724 epoch total loss 1.22161138\n",
      "Trained batch 1351 batch loss 1.4919939 epoch total loss 1.22181153\n",
      "Trained batch 1352 batch loss 1.41701913 epoch total loss 1.2219559\n",
      "Trained batch 1353 batch loss 1.10695446 epoch total loss 1.2218709\n",
      "Trained batch 1354 batch loss 1.1608355 epoch total loss 1.22182584\n",
      "Trained batch 1355 batch loss 1.20561314 epoch total loss 1.2218138\n",
      "Trained batch 1356 batch loss 1.0884347 epoch total loss 1.22171545\n",
      "Trained batch 1357 batch loss 1.10733891 epoch total loss 1.22163117\n",
      "Trained batch 1358 batch loss 1.07933664 epoch total loss 1.22152638\n",
      "Trained batch 1359 batch loss 1.19553113 epoch total loss 1.22150719\n",
      "Trained batch 1360 batch loss 1.07508969 epoch total loss 1.22139955\n",
      "Trained batch 1361 batch loss 1.06017745 epoch total loss 1.22128105\n",
      "Trained batch 1362 batch loss 1.03528643 epoch total loss 1.22114456\n",
      "Trained batch 1363 batch loss 1.28320408 epoch total loss 1.22119009\n",
      "Trained batch 1364 batch loss 1.12400389 epoch total loss 1.22111881\n",
      "Trained batch 1365 batch loss 1.0172565 epoch total loss 1.22096944\n",
      "Trained batch 1366 batch loss 1.22695184 epoch total loss 1.22097385\n",
      "Trained batch 1367 batch loss 1.235533 epoch total loss 1.22098446\n",
      "Trained batch 1368 batch loss 1.48514211 epoch total loss 1.22117746\n",
      "Trained batch 1369 batch loss 1.27347755 epoch total loss 1.22121561\n",
      "Trained batch 1370 batch loss 1.14209521 epoch total loss 1.22115791\n",
      "Trained batch 1371 batch loss 1.23231828 epoch total loss 1.22116601\n",
      "Trained batch 1372 batch loss 1.26890492 epoch total loss 1.22120082\n",
      "Trained batch 1373 batch loss 1.23746669 epoch total loss 1.22121263\n",
      "Trained batch 1374 batch loss 1.21776831 epoch total loss 1.22121012\n",
      "Trained batch 1375 batch loss 1.21487498 epoch total loss 1.22120547\n",
      "Trained batch 1376 batch loss 1.29931605 epoch total loss 1.22126234\n",
      "Trained batch 1377 batch loss 1.37449026 epoch total loss 1.22137356\n",
      "Trained batch 1378 batch loss 1.36446857 epoch total loss 1.22147739\n",
      "Trained batch 1379 batch loss 1.3077184 epoch total loss 1.22154\n",
      "Trained batch 1380 batch loss 1.27547991 epoch total loss 1.22157907\n",
      "Trained batch 1381 batch loss 1.19243741 epoch total loss 1.22155797\n",
      "Trained batch 1382 batch loss 1.19520497 epoch total loss 1.2215389\n",
      "Trained batch 1383 batch loss 1.17836261 epoch total loss 1.22150767\n",
      "Trained batch 1384 batch loss 1.25609314 epoch total loss 1.2215327\n",
      "Trained batch 1385 batch loss 1.10432053 epoch total loss 1.22144806\n",
      "Trained batch 1386 batch loss 1.13485789 epoch total loss 1.2213856\n",
      "Trained batch 1387 batch loss 1.23370242 epoch total loss 1.22139442\n",
      "Trained batch 1388 batch loss 1.15506494 epoch total loss 1.22134662\n",
      "Epoch 4 train loss 1.2213466167449951\n",
      "Validated batch 1 batch loss 1.20340216\n",
      "Validated batch 2 batch loss 1.10914505\n",
      "Validated batch 3 batch loss 1.24318647\n",
      "Validated batch 4 batch loss 1.13000309\n",
      "Validated batch 5 batch loss 1.2144537\n",
      "Validated batch 6 batch loss 1.2475729\n",
      "Validated batch 7 batch loss 1.2413913\n",
      "Validated batch 8 batch loss 1.32265627\n",
      "Validated batch 9 batch loss 1.32237136\n",
      "Validated batch 10 batch loss 1.21016169\n",
      "Validated batch 11 batch loss 1.24310231\n",
      "Validated batch 12 batch loss 1.32180512\n",
      "Validated batch 13 batch loss 1.33009052\n",
      "Validated batch 14 batch loss 1.31931591\n",
      "Validated batch 15 batch loss 1.31234431\n",
      "Validated batch 16 batch loss 1.34189332\n",
      "Validated batch 17 batch loss 1.30045784\n",
      "Validated batch 18 batch loss 1.1465224\n",
      "Validated batch 19 batch loss 1.27610397\n",
      "Validated batch 20 batch loss 1.32599509\n",
      "Validated batch 21 batch loss 1.22433162\n",
      "Validated batch 22 batch loss 1.24968\n",
      "Validated batch 23 batch loss 1.19213247\n",
      "Validated batch 24 batch loss 1.25510955\n",
      "Validated batch 25 batch loss 1.21720135\n",
      "Validated batch 26 batch loss 1.18065858\n",
      "Validated batch 27 batch loss 1.19135821\n",
      "Validated batch 28 batch loss 1.27534461\n",
      "Validated batch 29 batch loss 1.34432888\n",
      "Validated batch 30 batch loss 1.14092684\n",
      "Validated batch 31 batch loss 1.23731208\n",
      "Validated batch 32 batch loss 1.2055881\n",
      "Validated batch 33 batch loss 1.2452513\n",
      "Validated batch 34 batch loss 1.23690212\n",
      "Validated batch 35 batch loss 1.11937511\n",
      "Validated batch 36 batch loss 1.38455033\n",
      "Validated batch 37 batch loss 1.12651479\n",
      "Validated batch 38 batch loss 1.28251505\n",
      "Validated batch 39 batch loss 1.21870136\n",
      "Validated batch 40 batch loss 1.3055644\n",
      "Validated batch 41 batch loss 1.1003263\n",
      "Validated batch 42 batch loss 1.24936521\n",
      "Validated batch 43 batch loss 1.14204657\n",
      "Validated batch 44 batch loss 1.25391757\n",
      "Validated batch 45 batch loss 1.22220182\n",
      "Validated batch 46 batch loss 1.22341239\n",
      "Validated batch 47 batch loss 1.17523146\n",
      "Validated batch 48 batch loss 1.22927547\n",
      "Validated batch 49 batch loss 1.26634264\n",
      "Validated batch 50 batch loss 1.14617014\n",
      "Validated batch 51 batch loss 1.27613306\n",
      "Validated batch 52 batch loss 1.33927953\n",
      "Validated batch 53 batch loss 1.05400932\n",
      "Validated batch 54 batch loss 1.2232883\n",
      "Validated batch 55 batch loss 1.2057277\n",
      "Validated batch 56 batch loss 1.29360926\n",
      "Validated batch 57 batch loss 1.2704463\n",
      "Validated batch 58 batch loss 1.08899355\n",
      "Validated batch 59 batch loss 1.10703683\n",
      "Validated batch 60 batch loss 1.19207788\n",
      "Validated batch 61 batch loss 1.18619287\n",
      "Validated batch 62 batch loss 1.15369618\n",
      "Validated batch 63 batch loss 1.22535563\n",
      "Validated batch 64 batch loss 1.15694571\n",
      "Validated batch 65 batch loss 1.22462761\n",
      "Validated batch 66 batch loss 1.3009367\n",
      "Validated batch 67 batch loss 1.26315236\n",
      "Validated batch 68 batch loss 1.20824516\n",
      "Validated batch 69 batch loss 1.1144352\n",
      "Validated batch 70 batch loss 1.20730829\n",
      "Validated batch 71 batch loss 1.2418623\n",
      "Validated batch 72 batch loss 1.14931238\n",
      "Validated batch 73 batch loss 1.218503\n",
      "Validated batch 74 batch loss 1.24029195\n",
      "Validated batch 75 batch loss 1.28569353\n",
      "Validated batch 76 batch loss 1.28153563\n",
      "Validated batch 77 batch loss 1.33058739\n",
      "Validated batch 78 batch loss 1.24068475\n",
      "Validated batch 79 batch loss 1.21518385\n",
      "Validated batch 80 batch loss 1.30318952\n",
      "Validated batch 81 batch loss 1.22068453\n",
      "Validated batch 82 batch loss 1.26446629\n",
      "Validated batch 83 batch loss 1.34783602\n",
      "Validated batch 84 batch loss 1.2745775\n",
      "Validated batch 85 batch loss 1.26675272\n",
      "Validated batch 86 batch loss 1.37843931\n",
      "Validated batch 87 batch loss 1.11740816\n",
      "Validated batch 88 batch loss 1.26405442\n",
      "Validated batch 89 batch loss 1.08978295\n",
      "Validated batch 90 batch loss 1.21801186\n",
      "Validated batch 91 batch loss 1.31550896\n",
      "Validated batch 92 batch loss 1.17586946\n",
      "Validated batch 93 batch loss 1.16764557\n",
      "Validated batch 94 batch loss 1.22900319\n",
      "Validated batch 95 batch loss 1.20717859\n",
      "Validated batch 96 batch loss 1.10598326\n",
      "Validated batch 97 batch loss 1.14522564\n",
      "Validated batch 98 batch loss 1.31041551\n",
      "Validated batch 99 batch loss 1.13182735\n",
      "Validated batch 100 batch loss 1.1506238\n",
      "Validated batch 101 batch loss 1.16324019\n",
      "Validated batch 102 batch loss 1.16981\n",
      "Validated batch 103 batch loss 1.1059227\n",
      "Validated batch 104 batch loss 1.22059941\n",
      "Validated batch 105 batch loss 1.22222936\n",
      "Validated batch 106 batch loss 1.12880266\n",
      "Validated batch 107 batch loss 1.25230098\n",
      "Validated batch 108 batch loss 1.36829686\n",
      "Validated batch 109 batch loss 1.14056277\n",
      "Validated batch 110 batch loss 1.30962336\n",
      "Validated batch 111 batch loss 1.02555072\n",
      "Validated batch 112 batch loss 1.12904406\n",
      "Validated batch 113 batch loss 1.1521188\n",
      "Validated batch 114 batch loss 1.17021966\n",
      "Validated batch 115 batch loss 1.3584559\n",
      "Validated batch 116 batch loss 1.3625071\n",
      "Validated batch 117 batch loss 1.20707083\n",
      "Validated batch 118 batch loss 1.20455313\n",
      "Validated batch 119 batch loss 1.21571159\n",
      "Validated batch 120 batch loss 1.13266039\n",
      "Validated batch 121 batch loss 1.23271906\n",
      "Validated batch 122 batch loss 1.24356222\n",
      "Validated batch 123 batch loss 1.1768471\n",
      "Validated batch 124 batch loss 1.20628333\n",
      "Validated batch 125 batch loss 1.21762919\n",
      "Validated batch 126 batch loss 1.24571633\n",
      "Validated batch 127 batch loss 1.27414\n",
      "Validated batch 128 batch loss 1.23183692\n",
      "Validated batch 129 batch loss 1.14459181\n",
      "Validated batch 130 batch loss 1.17398202\n",
      "Validated batch 131 batch loss 1.23083162\n",
      "Validated batch 132 batch loss 1.1864481\n",
      "Validated batch 133 batch loss 1.2631489\n",
      "Validated batch 134 batch loss 1.24272454\n",
      "Validated batch 135 batch loss 1.40354502\n",
      "Validated batch 136 batch loss 1.35075402\n",
      "Validated batch 137 batch loss 1.23531759\n",
      "Validated batch 138 batch loss 1.1359781\n",
      "Validated batch 139 batch loss 1.18617511\n",
      "Validated batch 140 batch loss 1.24107397\n",
      "Validated batch 141 batch loss 1.1522541\n",
      "Validated batch 142 batch loss 1.19979572\n",
      "Validated batch 143 batch loss 1.23538244\n",
      "Validated batch 144 batch loss 1.21876156\n",
      "Validated batch 145 batch loss 1.23666084\n",
      "Validated batch 146 batch loss 1.22725642\n",
      "Validated batch 147 batch loss 1.16609621\n",
      "Validated batch 148 batch loss 1.34247482\n",
      "Validated batch 149 batch loss 1.15822804\n",
      "Validated batch 150 batch loss 1.09144175\n",
      "Validated batch 151 batch loss 1.21079254\n",
      "Validated batch 152 batch loss 1.32841027\n",
      "Validated batch 153 batch loss 1.28787279\n",
      "Validated batch 154 batch loss 1.36403871\n",
      "Validated batch 155 batch loss 1.18769407\n",
      "Validated batch 156 batch loss 1.37402904\n",
      "Validated batch 157 batch loss 1.21330154\n",
      "Validated batch 158 batch loss 1.30661345\n",
      "Validated batch 159 batch loss 1.29912794\n",
      "Validated batch 160 batch loss 1.02815938\n",
      "Validated batch 161 batch loss 1.21436656\n",
      "Validated batch 162 batch loss 1.22877896\n",
      "Validated batch 163 batch loss 1.13811672\n",
      "Validated batch 164 batch loss 1.22561\n",
      "Validated batch 165 batch loss 1.16286707\n",
      "Validated batch 166 batch loss 1.17497492\n",
      "Validated batch 167 batch loss 1.24979806\n",
      "Validated batch 168 batch loss 1.18653035\n",
      "Validated batch 169 batch loss 1.24980342\n",
      "Validated batch 170 batch loss 1.31997144\n",
      "Validated batch 171 batch loss 1.10020971\n",
      "Validated batch 172 batch loss 1.31848884\n",
      "Validated batch 173 batch loss 1.26793873\n",
      "Validated batch 174 batch loss 1.10374212\n",
      "Validated batch 175 batch loss 1.25041115\n",
      "Validated batch 176 batch loss 1.26037312\n",
      "Validated batch 177 batch loss 1.16902399\n",
      "Validated batch 178 batch loss 1.29570723\n",
      "Validated batch 179 batch loss 1.24362707\n",
      "Validated batch 180 batch loss 1.30031705\n",
      "Validated batch 181 batch loss 1.17492509\n",
      "Validated batch 182 batch loss 1.2919991\n",
      "Validated batch 183 batch loss 1.23356497\n",
      "Validated batch 184 batch loss 1.14592969\n",
      "Validated batch 185 batch loss 1.25143814\n",
      "Epoch 4 val loss 1.2250419855117798\n",
      "Model /aiffel/aiffel/mpii/models1/model-epoch-4-loss-1.2250.h5 saved.\n",
      "Start epoch 5 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.41048956 epoch total loss 1.41048956\n",
      "Trained batch 2 batch loss 1.30399084 epoch total loss 1.3572402\n",
      "Trained batch 3 batch loss 1.07669926 epoch total loss 1.26372659\n",
      "Trained batch 4 batch loss 1.09112573 epoch total loss 1.22057629\n",
      "Trained batch 5 batch loss 1.23681259 epoch total loss 1.22382355\n",
      "Trained batch 6 batch loss 1.31628823 epoch total loss 1.23923433\n",
      "Trained batch 7 batch loss 1.27028263 epoch total loss 1.24366975\n",
      "Trained batch 8 batch loss 1.26374972 epoch total loss 1.24617982\n",
      "Trained batch 9 batch loss 1.23479044 epoch total loss 1.24491441\n",
      "Trained batch 10 batch loss 1.29817224 epoch total loss 1.25024009\n",
      "Trained batch 11 batch loss 1.25886965 epoch total loss 1.2510246\n",
      "Trained batch 12 batch loss 1.24692178 epoch total loss 1.25068271\n",
      "Trained batch 13 batch loss 1.11990213 epoch total loss 1.24062264\n",
      "Trained batch 14 batch loss 1.26877928 epoch total loss 1.24263382\n",
      "Trained batch 15 batch loss 1.12103939 epoch total loss 1.23452759\n",
      "Trained batch 16 batch loss 1.23001802 epoch total loss 1.23424578\n",
      "Trained batch 17 batch loss 1.19525373 epoch total loss 1.23195207\n",
      "Trained batch 18 batch loss 1.25596333 epoch total loss 1.23328614\n",
      "Trained batch 19 batch loss 1.26650071 epoch total loss 1.23503423\n",
      "Trained batch 20 batch loss 1.27332926 epoch total loss 1.23694897\n",
      "Trained batch 21 batch loss 1.21885514 epoch total loss 1.23608732\n",
      "Trained batch 22 batch loss 1.16407561 epoch total loss 1.23281407\n",
      "Trained batch 23 batch loss 1.18514502 epoch total loss 1.2307415\n",
      "Trained batch 24 batch loss 1.18144119 epoch total loss 1.22868729\n",
      "Trained batch 25 batch loss 1.281896 epoch total loss 1.23081565\n",
      "Trained batch 26 batch loss 1.21459472 epoch total loss 1.23019171\n",
      "Trained batch 27 batch loss 1.21920872 epoch total loss 1.22978497\n",
      "Trained batch 28 batch loss 1.11084545 epoch total loss 1.22553706\n",
      "Trained batch 29 batch loss 1.18210256 epoch total loss 1.22403932\n",
      "Trained batch 30 batch loss 1.2245326 epoch total loss 1.22405577\n",
      "Trained batch 31 batch loss 1.255741 epoch total loss 1.22507787\n",
      "Trained batch 32 batch loss 1.09777856 epoch total loss 1.22109973\n",
      "Trained batch 33 batch loss 1.07580745 epoch total loss 1.21669686\n",
      "Trained batch 34 batch loss 1.10814655 epoch total loss 1.2135042\n",
      "Trained batch 35 batch loss 1.08512509 epoch total loss 1.20983624\n",
      "Trained batch 36 batch loss 1.2237401 epoch total loss 1.21022248\n",
      "Trained batch 37 batch loss 1.23680031 epoch total loss 1.21094084\n",
      "Trained batch 38 batch loss 1.13896775 epoch total loss 1.20904684\n",
      "Trained batch 39 batch loss 1.0814898 epoch total loss 1.2057761\n",
      "Trained batch 40 batch loss 0.995288551 epoch total loss 1.20051396\n",
      "Trained batch 41 batch loss 0.905550241 epoch total loss 1.1933198\n",
      "Trained batch 42 batch loss 1.11342 epoch total loss 1.19141734\n",
      "Trained batch 43 batch loss 1.02359903 epoch total loss 1.18751454\n",
      "Trained batch 44 batch loss 1.08297253 epoch total loss 1.18513858\n",
      "Trained batch 45 batch loss 1.13911939 epoch total loss 1.18411589\n",
      "Trained batch 46 batch loss 1.0471487 epoch total loss 1.1811384\n",
      "Trained batch 47 batch loss 1.22977531 epoch total loss 1.18217325\n",
      "Trained batch 48 batch loss 1.17770576 epoch total loss 1.18208015\n",
      "Trained batch 49 batch loss 1.1724689 epoch total loss 1.18188393\n",
      "Trained batch 50 batch loss 1.13336086 epoch total loss 1.18091357\n",
      "Trained batch 51 batch loss 1.16247785 epoch total loss 1.18055212\n",
      "Trained batch 52 batch loss 1.1149565 epoch total loss 1.17929065\n",
      "Trained batch 53 batch loss 1.21184671 epoch total loss 1.17990482\n",
      "Trained batch 54 batch loss 1.23340631 epoch total loss 1.18089569\n",
      "Trained batch 55 batch loss 1.17291844 epoch total loss 1.18075061\n",
      "Trained batch 56 batch loss 1.03366303 epoch total loss 1.17812407\n",
      "Trained batch 57 batch loss 1.16236055 epoch total loss 1.1778475\n",
      "Trained batch 58 batch loss 1.19978809 epoch total loss 1.17822576\n",
      "Trained batch 59 batch loss 1.21042275 epoch total loss 1.17877162\n",
      "Trained batch 60 batch loss 1.18168557 epoch total loss 1.17882013\n",
      "Trained batch 61 batch loss 1.12183881 epoch total loss 1.17788613\n",
      "Trained batch 62 batch loss 1.0591414 epoch total loss 1.17597091\n",
      "Trained batch 63 batch loss 1.15914071 epoch total loss 1.17570376\n",
      "Trained batch 64 batch loss 1.15364289 epoch total loss 1.17535901\n",
      "Trained batch 65 batch loss 1.05722904 epoch total loss 1.17354167\n",
      "Trained batch 66 batch loss 1.1645 epoch total loss 1.17340457\n",
      "Trained batch 67 batch loss 1.22585154 epoch total loss 1.17418742\n",
      "Trained batch 68 batch loss 1.33248305 epoch total loss 1.17651522\n",
      "Trained batch 69 batch loss 1.17141879 epoch total loss 1.17644131\n",
      "Trained batch 70 batch loss 1.11950934 epoch total loss 1.17562807\n",
      "Trained batch 71 batch loss 1.35204 epoch total loss 1.17811275\n",
      "Trained batch 72 batch loss 1.28387642 epoch total loss 1.17958164\n",
      "Trained batch 73 batch loss 1.26219022 epoch total loss 1.1807133\n",
      "Trained batch 74 batch loss 1.25845659 epoch total loss 1.18176389\n",
      "Trained batch 75 batch loss 1.21379685 epoch total loss 1.18219101\n",
      "Trained batch 76 batch loss 1.22011495 epoch total loss 1.18269\n",
      "Trained batch 77 batch loss 1.29328978 epoch total loss 1.18412638\n",
      "Trained batch 78 batch loss 1.30490696 epoch total loss 1.18567479\n",
      "Trained batch 79 batch loss 1.26272094 epoch total loss 1.18665\n",
      "Trained batch 80 batch loss 1.17596614 epoch total loss 1.18651652\n",
      "Trained batch 81 batch loss 1.01789701 epoch total loss 1.18443477\n",
      "Trained batch 82 batch loss 1.02612591 epoch total loss 1.18250418\n",
      "Trained batch 83 batch loss 1.12278342 epoch total loss 1.18178463\n",
      "Trained batch 84 batch loss 1.11675906 epoch total loss 1.18101048\n",
      "Trained batch 85 batch loss 1.17711139 epoch total loss 1.18096459\n",
      "Trained batch 86 batch loss 1.30000448 epoch total loss 1.18234873\n",
      "Trained batch 87 batch loss 1.21678257 epoch total loss 1.1827445\n",
      "Trained batch 88 batch loss 1.14447474 epoch total loss 1.18230963\n",
      "Trained batch 89 batch loss 1.16452646 epoch total loss 1.18210983\n",
      "Trained batch 90 batch loss 1.08632135 epoch total loss 1.18104553\n",
      "Trained batch 91 batch loss 1.25604725 epoch total loss 1.18186975\n",
      "Trained batch 92 batch loss 1.23125088 epoch total loss 1.18240654\n",
      "Trained batch 93 batch loss 1.16207778 epoch total loss 1.18218791\n",
      "Trained batch 94 batch loss 1.25410342 epoch total loss 1.182953\n",
      "Trained batch 95 batch loss 1.30102229 epoch total loss 1.18419588\n",
      "Trained batch 96 batch loss 1.23212433 epoch total loss 1.18469512\n",
      "Trained batch 97 batch loss 1.28419638 epoch total loss 1.18572092\n",
      "Trained batch 98 batch loss 1.16964328 epoch total loss 1.18555689\n",
      "Trained batch 99 batch loss 1.07800984 epoch total loss 1.18447053\n",
      "Trained batch 100 batch loss 1.21544218 epoch total loss 1.18478024\n",
      "Trained batch 101 batch loss 1.31907201 epoch total loss 1.18610978\n",
      "Trained batch 102 batch loss 1.22963524 epoch total loss 1.18653655\n",
      "Trained batch 103 batch loss 1.15899205 epoch total loss 1.18626904\n",
      "Trained batch 104 batch loss 1.24324036 epoch total loss 1.18681693\n",
      "Trained batch 105 batch loss 1.40133059 epoch total loss 1.18885982\n",
      "Trained batch 106 batch loss 1.34018981 epoch total loss 1.19028747\n",
      "Trained batch 107 batch loss 1.17080534 epoch total loss 1.19010544\n",
      "Trained batch 108 batch loss 1.1389792 epoch total loss 1.18963194\n",
      "Trained batch 109 batch loss 1.17646039 epoch total loss 1.18951118\n",
      "Trained batch 110 batch loss 1.13007569 epoch total loss 1.18897092\n",
      "Trained batch 111 batch loss 1.07009304 epoch total loss 1.18790007\n",
      "Trained batch 112 batch loss 1.00577652 epoch total loss 1.18627393\n",
      "Trained batch 113 batch loss 1.08020866 epoch total loss 1.1853354\n",
      "Trained batch 114 batch loss 1.18162584 epoch total loss 1.18530285\n",
      "Trained batch 115 batch loss 1.17207265 epoch total loss 1.18518782\n",
      "Trained batch 116 batch loss 1.21749866 epoch total loss 1.18546641\n",
      "Trained batch 117 batch loss 1.24862194 epoch total loss 1.18600619\n",
      "Trained batch 118 batch loss 1.21246457 epoch total loss 1.18623042\n",
      "Trained batch 119 batch loss 1.16531658 epoch total loss 1.18605459\n",
      "Trained batch 120 batch loss 1.04056358 epoch total loss 1.18484223\n",
      "Trained batch 121 batch loss 1.15048826 epoch total loss 1.18455815\n",
      "Trained batch 122 batch loss 1.19394124 epoch total loss 1.18463504\n",
      "Trained batch 123 batch loss 1.10292065 epoch total loss 1.18397081\n",
      "Trained batch 124 batch loss 0.940812945 epoch total loss 1.18200982\n",
      "Trained batch 125 batch loss 0.88710165 epoch total loss 1.17965055\n",
      "Trained batch 126 batch loss 1.13610125 epoch total loss 1.17930496\n",
      "Trained batch 127 batch loss 1.31744528 epoch total loss 1.18039262\n",
      "Trained batch 128 batch loss 1.2026639 epoch total loss 1.18056667\n",
      "Trained batch 129 batch loss 1.3206507 epoch total loss 1.18165255\n",
      "Trained batch 130 batch loss 1.34310091 epoch total loss 1.18289447\n",
      "Trained batch 131 batch loss 1.43604302 epoch total loss 1.18482697\n",
      "Trained batch 132 batch loss 1.41278791 epoch total loss 1.18655384\n",
      "Trained batch 133 batch loss 1.12421381 epoch total loss 1.1860851\n",
      "Trained batch 134 batch loss 1.22029293 epoch total loss 1.18634033\n",
      "Trained batch 135 batch loss 1.1232667 epoch total loss 1.18587303\n",
      "Trained batch 136 batch loss 1.16039681 epoch total loss 1.18568575\n",
      "Trained batch 137 batch loss 1.23949528 epoch total loss 1.18607855\n",
      "Trained batch 138 batch loss 1.20223832 epoch total loss 1.18619573\n",
      "Trained batch 139 batch loss 1.28661847 epoch total loss 1.18691814\n",
      "Trained batch 140 batch loss 1.25055575 epoch total loss 1.18737268\n",
      "Trained batch 141 batch loss 1.32899594 epoch total loss 1.18837714\n",
      "Trained batch 142 batch loss 1.23622131 epoch total loss 1.18871403\n",
      "Trained batch 143 batch loss 1.3123436 epoch total loss 1.18957865\n",
      "Trained batch 144 batch loss 1.2574203 epoch total loss 1.19004965\n",
      "Trained batch 145 batch loss 1.15001655 epoch total loss 1.18977356\n",
      "Trained batch 146 batch loss 1.18795097 epoch total loss 1.18976116\n",
      "Trained batch 147 batch loss 1.2509377 epoch total loss 1.1901772\n",
      "Trained batch 148 batch loss 1.16390729 epoch total loss 1.18999982\n",
      "Trained batch 149 batch loss 1.16430068 epoch total loss 1.18982732\n",
      "Trained batch 150 batch loss 1.07762182 epoch total loss 1.18907928\n",
      "Trained batch 151 batch loss 1.14809 epoch total loss 1.18880785\n",
      "Trained batch 152 batch loss 1.23050416 epoch total loss 1.18908215\n",
      "Trained batch 153 batch loss 1.26758552 epoch total loss 1.1895951\n",
      "Trained batch 154 batch loss 1.26883507 epoch total loss 1.19010961\n",
      "Trained batch 155 batch loss 1.2791934 epoch total loss 1.19068432\n",
      "Trained batch 156 batch loss 1.26694083 epoch total loss 1.1911732\n",
      "Trained batch 157 batch loss 1.33553123 epoch total loss 1.19209266\n",
      "Trained batch 158 batch loss 1.29938936 epoch total loss 1.19277167\n",
      "Trained batch 159 batch loss 1.11239457 epoch total loss 1.19226623\n",
      "Trained batch 160 batch loss 1.12021184 epoch total loss 1.19181585\n",
      "Trained batch 161 batch loss 1.23984432 epoch total loss 1.19211411\n",
      "Trained batch 162 batch loss 1.36901438 epoch total loss 1.19320607\n",
      "Trained batch 163 batch loss 1.35321045 epoch total loss 1.19418776\n",
      "Trained batch 164 batch loss 1.26649034 epoch total loss 1.1946286\n",
      "Trained batch 165 batch loss 1.24122083 epoch total loss 1.194911\n",
      "Trained batch 166 batch loss 1.25154805 epoch total loss 1.19525218\n",
      "Trained batch 167 batch loss 1.13979673 epoch total loss 1.19492018\n",
      "Trained batch 168 batch loss 1.25686646 epoch total loss 1.1952889\n",
      "Trained batch 169 batch loss 1.3817482 epoch total loss 1.19639218\n",
      "Trained batch 170 batch loss 1.28958106 epoch total loss 1.1969403\n",
      "Trained batch 171 batch loss 1.30092192 epoch total loss 1.19754839\n",
      "Trained batch 172 batch loss 1.08535 epoch total loss 1.19689608\n",
      "Trained batch 173 batch loss 1.04601061 epoch total loss 1.19602382\n",
      "Trained batch 174 batch loss 1.2078 epoch total loss 1.19609153\n",
      "Trained batch 175 batch loss 1.37585986 epoch total loss 1.19711876\n",
      "Trained batch 176 batch loss 1.33371711 epoch total loss 1.19789481\n",
      "Trained batch 177 batch loss 1.23089671 epoch total loss 1.19808125\n",
      "Trained batch 178 batch loss 1.21003771 epoch total loss 1.19814837\n",
      "Trained batch 179 batch loss 1.24636459 epoch total loss 1.19841778\n",
      "Trained batch 180 batch loss 1.14279401 epoch total loss 1.19810879\n",
      "Trained batch 181 batch loss 1.2013607 epoch total loss 1.19812667\n",
      "Trained batch 182 batch loss 1.21722484 epoch total loss 1.19823158\n",
      "Trained batch 183 batch loss 1.32139301 epoch total loss 1.19890463\n",
      "Trained batch 184 batch loss 1.22287822 epoch total loss 1.19903493\n",
      "Trained batch 185 batch loss 1.23901761 epoch total loss 1.19925106\n",
      "Trained batch 186 batch loss 1.24560606 epoch total loss 1.19950032\n",
      "Trained batch 187 batch loss 1.20258892 epoch total loss 1.19951677\n",
      "Trained batch 188 batch loss 1.06513047 epoch total loss 1.19880199\n",
      "Trained batch 189 batch loss 1.21386886 epoch total loss 1.19888163\n",
      "Trained batch 190 batch loss 1.15627742 epoch total loss 1.19865751\n",
      "Trained batch 191 batch loss 1.09369612 epoch total loss 1.19810784\n",
      "Trained batch 192 batch loss 1.068681 epoch total loss 1.19743383\n",
      "Trained batch 193 batch loss 1.02102971 epoch total loss 1.19651973\n",
      "Trained batch 194 batch loss 1.20726085 epoch total loss 1.19657516\n",
      "Trained batch 195 batch loss 1.25358272 epoch total loss 1.19686747\n",
      "Trained batch 196 batch loss 1.30186522 epoch total loss 1.19740319\n",
      "Trained batch 197 batch loss 1.13700771 epoch total loss 1.19709659\n",
      "Trained batch 198 batch loss 1.25648499 epoch total loss 1.19739652\n",
      "Trained batch 199 batch loss 1.1790967 epoch total loss 1.19730461\n",
      "Trained batch 200 batch loss 1.252702 epoch total loss 1.19758153\n",
      "Trained batch 201 batch loss 1.02808857 epoch total loss 1.19673836\n",
      "Trained batch 202 batch loss 1.20045364 epoch total loss 1.19675672\n",
      "Trained batch 203 batch loss 1.18908525 epoch total loss 1.19671893\n",
      "Trained batch 204 batch loss 1.18359613 epoch total loss 1.19665456\n",
      "Trained batch 205 batch loss 1.1220808 epoch total loss 1.19629085\n",
      "Trained batch 206 batch loss 1.22171211 epoch total loss 1.19641423\n",
      "Trained batch 207 batch loss 1.20672417 epoch total loss 1.19646406\n",
      "Trained batch 208 batch loss 1.13907874 epoch total loss 1.19618821\n",
      "Trained batch 209 batch loss 1.18921149 epoch total loss 1.19615483\n",
      "Trained batch 210 batch loss 1.25888479 epoch total loss 1.19645345\n",
      "Trained batch 211 batch loss 1.1291883 epoch total loss 1.19613469\n",
      "Trained batch 212 batch loss 1.22742796 epoch total loss 1.19628227\n",
      "Trained batch 213 batch loss 1.22612047 epoch total loss 1.19642234\n",
      "Trained batch 214 batch loss 1.06287956 epoch total loss 1.1957984\n",
      "Trained batch 215 batch loss 1.12161756 epoch total loss 1.19545329\n",
      "Trained batch 216 batch loss 1.16025496 epoch total loss 1.19529033\n",
      "Trained batch 217 batch loss 1.24055123 epoch total loss 1.19549882\n",
      "Trained batch 218 batch loss 1.36472845 epoch total loss 1.19627512\n",
      "Trained batch 219 batch loss 1.36142468 epoch total loss 1.19702911\n",
      "Trained batch 220 batch loss 1.21944356 epoch total loss 1.19713104\n",
      "Trained batch 221 batch loss 1.24921525 epoch total loss 1.19736671\n",
      "Trained batch 222 batch loss 1.3503592 epoch total loss 1.19805586\n",
      "Trained batch 223 batch loss 1.19105196 epoch total loss 1.19802451\n",
      "Trained batch 224 batch loss 1.15088975 epoch total loss 1.19781399\n",
      "Trained batch 225 batch loss 1.252388 epoch total loss 1.19805646\n",
      "Trained batch 226 batch loss 0.985998094 epoch total loss 1.19711816\n",
      "Trained batch 227 batch loss 1.0357058 epoch total loss 1.19640708\n",
      "Trained batch 228 batch loss 1.06223691 epoch total loss 1.19581854\n",
      "Trained batch 229 batch loss 1.12523878 epoch total loss 1.19551039\n",
      "Trained batch 230 batch loss 0.96341306 epoch total loss 1.19450128\n",
      "Trained batch 231 batch loss 0.943308771 epoch total loss 1.19341385\n",
      "Trained batch 232 batch loss 0.928927779 epoch total loss 1.19227374\n",
      "Trained batch 233 batch loss 0.889275312 epoch total loss 1.1909734\n",
      "Trained batch 234 batch loss 1.12246406 epoch total loss 1.19068062\n",
      "Trained batch 235 batch loss 1.11987686 epoch total loss 1.19037926\n",
      "Trained batch 236 batch loss 1.12622654 epoch total loss 1.19010746\n",
      "Trained batch 237 batch loss 1.1618458 epoch total loss 1.18998814\n",
      "Trained batch 238 batch loss 1.17350864 epoch total loss 1.18991899\n",
      "Trained batch 239 batch loss 1.05598617 epoch total loss 1.18935859\n",
      "Trained batch 240 batch loss 1.00107276 epoch total loss 1.18857408\n",
      "Trained batch 241 batch loss 0.991695881 epoch total loss 1.18775713\n",
      "Trained batch 242 batch loss 1.07007074 epoch total loss 1.18727088\n",
      "Trained batch 243 batch loss 1.16739631 epoch total loss 1.1871891\n",
      "Trained batch 244 batch loss 1.07164478 epoch total loss 1.1867156\n",
      "Trained batch 245 batch loss 1.08679926 epoch total loss 1.18630767\n",
      "Trained batch 246 batch loss 1.03509665 epoch total loss 1.18569303\n",
      "Trained batch 247 batch loss 1.17111647 epoch total loss 1.18563402\n",
      "Trained batch 248 batch loss 1.19271266 epoch total loss 1.18566251\n",
      "Trained batch 249 batch loss 1.31058705 epoch total loss 1.18616426\n",
      "Trained batch 250 batch loss 0.925157905 epoch total loss 1.18512022\n",
      "Trained batch 251 batch loss 1.02307689 epoch total loss 1.18447459\n",
      "Trained batch 252 batch loss 1.08748114 epoch total loss 1.18408978\n",
      "Trained batch 253 batch loss 1.19294763 epoch total loss 1.18412483\n",
      "Trained batch 254 batch loss 1.14245629 epoch total loss 1.1839608\n",
      "Trained batch 255 batch loss 1.24809074 epoch total loss 1.18421221\n",
      "Trained batch 256 batch loss 1.46704793 epoch total loss 1.18531704\n",
      "Trained batch 257 batch loss 1.28888333 epoch total loss 1.18572\n",
      "Trained batch 258 batch loss 1.15311384 epoch total loss 1.18559361\n",
      "Trained batch 259 batch loss 1.00224531 epoch total loss 1.18488574\n",
      "Trained batch 260 batch loss 1.24480534 epoch total loss 1.18511617\n",
      "Trained batch 261 batch loss 1.35508883 epoch total loss 1.18576753\n",
      "Trained batch 262 batch loss 1.1630106 epoch total loss 1.18568075\n",
      "Trained batch 263 batch loss 1.21246529 epoch total loss 1.18578255\n",
      "Trained batch 264 batch loss 1.14942157 epoch total loss 1.18564475\n",
      "Trained batch 265 batch loss 1.30642176 epoch total loss 1.1861006\n",
      "Trained batch 266 batch loss 1.25824499 epoch total loss 1.1863718\n",
      "Trained batch 267 batch loss 1.25998378 epoch total loss 1.18664742\n",
      "Trained batch 268 batch loss 1.19102 epoch total loss 1.18666375\n",
      "Trained batch 269 batch loss 1.13806522 epoch total loss 1.18648303\n",
      "Trained batch 270 batch loss 1.11024046 epoch total loss 1.18620062\n",
      "Trained batch 271 batch loss 1.2721293 epoch total loss 1.18651772\n",
      "Trained batch 272 batch loss 1.35929799 epoch total loss 1.18715286\n",
      "Trained batch 273 batch loss 1.2911762 epoch total loss 1.18753386\n",
      "Trained batch 274 batch loss 1.22913074 epoch total loss 1.18768561\n",
      "Trained batch 275 batch loss 1.14711523 epoch total loss 1.18753815\n",
      "Trained batch 276 batch loss 1.23412251 epoch total loss 1.18770695\n",
      "Trained batch 277 batch loss 1.13880038 epoch total loss 1.1875304\n",
      "Trained batch 278 batch loss 1.0898906 epoch total loss 1.18717921\n",
      "Trained batch 279 batch loss 1.18454492 epoch total loss 1.18716979\n",
      "Trained batch 280 batch loss 1.37871754 epoch total loss 1.18785393\n",
      "Trained batch 281 batch loss 1.21479738 epoch total loss 1.18794978\n",
      "Trained batch 282 batch loss 1.1291815 epoch total loss 1.18774128\n",
      "Trained batch 283 batch loss 1.10969007 epoch total loss 1.18746555\n",
      "Trained batch 284 batch loss 1.12516165 epoch total loss 1.18724608\n",
      "Trained batch 285 batch loss 1.15615344 epoch total loss 1.18713701\n",
      "Trained batch 286 batch loss 1.21285725 epoch total loss 1.18722689\n",
      "Trained batch 287 batch loss 1.18994546 epoch total loss 1.18723643\n",
      "Trained batch 288 batch loss 1.31545115 epoch total loss 1.18768167\n",
      "Trained batch 289 batch loss 1.20625925 epoch total loss 1.18774593\n",
      "Trained batch 290 batch loss 1.34931874 epoch total loss 1.18830299\n",
      "Trained batch 291 batch loss 1.3354919 epoch total loss 1.1888088\n",
      "Trained batch 292 batch loss 1.34927082 epoch total loss 1.18935835\n",
      "Trained batch 293 batch loss 1.2121594 epoch total loss 1.1894362\n",
      "Trained batch 294 batch loss 1.12016022 epoch total loss 1.18920052\n",
      "Trained batch 295 batch loss 1.27164888 epoch total loss 1.18948\n",
      "Trained batch 296 batch loss 1.27619243 epoch total loss 1.18977284\n",
      "Trained batch 297 batch loss 1.14017689 epoch total loss 1.18960583\n",
      "Trained batch 298 batch loss 1.1578052 epoch total loss 1.18949914\n",
      "Trained batch 299 batch loss 1.06863809 epoch total loss 1.1890949\n",
      "Trained batch 300 batch loss 1.13700545 epoch total loss 1.18892121\n",
      "Trained batch 301 batch loss 1.08323503 epoch total loss 1.18857\n",
      "Trained batch 302 batch loss 1.13529062 epoch total loss 1.18839359\n",
      "Trained batch 303 batch loss 1.12921989 epoch total loss 1.18819833\n",
      "Trained batch 304 batch loss 1.20665872 epoch total loss 1.18825901\n",
      "Trained batch 305 batch loss 1.19773 epoch total loss 1.18829\n",
      "Trained batch 306 batch loss 1.37648487 epoch total loss 1.18890512\n",
      "Trained batch 307 batch loss 1.11636055 epoch total loss 1.18866885\n",
      "Trained batch 308 batch loss 1.08355021 epoch total loss 1.18832755\n",
      "Trained batch 309 batch loss 1.06222606 epoch total loss 1.1879195\n",
      "Trained batch 310 batch loss 1.06816 epoch total loss 1.18753302\n",
      "Trained batch 311 batch loss 1.06843257 epoch total loss 1.18715012\n",
      "Trained batch 312 batch loss 1.01958048 epoch total loss 1.18661308\n",
      "Trained batch 313 batch loss 1.12283731 epoch total loss 1.18640924\n",
      "Trained batch 314 batch loss 1.14344943 epoch total loss 1.1862725\n",
      "Trained batch 315 batch loss 1.03667128 epoch total loss 1.18579757\n",
      "Trained batch 316 batch loss 1.08183527 epoch total loss 1.18546867\n",
      "Trained batch 317 batch loss 1.22040796 epoch total loss 1.18557882\n",
      "Trained batch 318 batch loss 1.24874544 epoch total loss 1.18577743\n",
      "Trained batch 319 batch loss 1.12211573 epoch total loss 1.18557787\n",
      "Trained batch 320 batch loss 1.21366405 epoch total loss 1.18566561\n",
      "Trained batch 321 batch loss 1.20346248 epoch total loss 1.18572104\n",
      "Trained batch 322 batch loss 1.17217016 epoch total loss 1.18567896\n",
      "Trained batch 323 batch loss 1.11179209 epoch total loss 1.1854502\n",
      "Trained batch 324 batch loss 1.22315788 epoch total loss 1.18556654\n",
      "Trained batch 325 batch loss 1.32708311 epoch total loss 1.18600202\n",
      "Trained batch 326 batch loss 1.22142732 epoch total loss 1.18611073\n",
      "Trained batch 327 batch loss 1.05449224 epoch total loss 1.18570828\n",
      "Trained batch 328 batch loss 1.30827975 epoch total loss 1.18608201\n",
      "Trained batch 329 batch loss 1.27044976 epoch total loss 1.18633842\n",
      "Trained batch 330 batch loss 1.32471299 epoch total loss 1.18675768\n",
      "Trained batch 331 batch loss 1.43386078 epoch total loss 1.18750429\n",
      "Trained batch 332 batch loss 1.30417752 epoch total loss 1.1878556\n",
      "Trained batch 333 batch loss 1.15673423 epoch total loss 1.18776214\n",
      "Trained batch 334 batch loss 1.23345637 epoch total loss 1.18789899\n",
      "Trained batch 335 batch loss 1.18932891 epoch total loss 1.18790329\n",
      "Trained batch 336 batch loss 1.16912198 epoch total loss 1.18784738\n",
      "Trained batch 337 batch loss 1.27887058 epoch total loss 1.1881175\n",
      "Trained batch 338 batch loss 1.33841324 epoch total loss 1.18856215\n",
      "Trained batch 339 batch loss 1.33543372 epoch total loss 1.18899536\n",
      "Trained batch 340 batch loss 1.32290733 epoch total loss 1.18938923\n",
      "Trained batch 341 batch loss 1.40102947 epoch total loss 1.19000983\n",
      "Trained batch 342 batch loss 1.36497438 epoch total loss 1.19052136\n",
      "Trained batch 343 batch loss 1.41756332 epoch total loss 1.19118333\n",
      "Trained batch 344 batch loss 1.31237638 epoch total loss 1.19153571\n",
      "Trained batch 345 batch loss 1.33533525 epoch total loss 1.19195247\n",
      "Trained batch 346 batch loss 1.2937448 epoch total loss 1.19224668\n",
      "Trained batch 347 batch loss 1.23440325 epoch total loss 1.19236815\n",
      "Trained batch 348 batch loss 1.22449636 epoch total loss 1.19246042\n",
      "Trained batch 349 batch loss 1.10136318 epoch total loss 1.19219935\n",
      "Trained batch 350 batch loss 1.04729819 epoch total loss 1.19178534\n",
      "Trained batch 351 batch loss 1.06870294 epoch total loss 1.19143462\n",
      "Trained batch 352 batch loss 1.22238231 epoch total loss 1.1915226\n",
      "Trained batch 353 batch loss 1.00871706 epoch total loss 1.19100475\n",
      "Trained batch 354 batch loss 1.06650305 epoch total loss 1.19065309\n",
      "Trained batch 355 batch loss 1.0235213 epoch total loss 1.19018233\n",
      "Trained batch 356 batch loss 1.04280496 epoch total loss 1.18976831\n",
      "Trained batch 357 batch loss 1.09992015 epoch total loss 1.18951666\n",
      "Trained batch 358 batch loss 1.07496393 epoch total loss 1.18919659\n",
      "Trained batch 359 batch loss 1.09716749 epoch total loss 1.18894029\n",
      "Trained batch 360 batch loss 1.06570745 epoch total loss 1.18859792\n",
      "Trained batch 361 batch loss 1.5318929 epoch total loss 1.18954885\n",
      "Trained batch 362 batch loss 1.18920183 epoch total loss 1.18954802\n",
      "Trained batch 363 batch loss 1.19182086 epoch total loss 1.18955421\n",
      "Trained batch 364 batch loss 1.24461484 epoch total loss 1.18970561\n",
      "Trained batch 365 batch loss 1.51416707 epoch total loss 1.19059443\n",
      "Trained batch 366 batch loss 1.15936911 epoch total loss 1.1905092\n",
      "Trained batch 367 batch loss 1.29494321 epoch total loss 1.19079375\n",
      "Trained batch 368 batch loss 1.08130121 epoch total loss 1.19049621\n",
      "Trained batch 369 batch loss 0.958475173 epoch total loss 1.18986738\n",
      "Trained batch 370 batch loss 0.926744878 epoch total loss 1.18915629\n",
      "Trained batch 371 batch loss 1.21234775 epoch total loss 1.18921876\n",
      "Trained batch 372 batch loss 1.19127178 epoch total loss 1.18922436\n",
      "Trained batch 373 batch loss 1.26120877 epoch total loss 1.18941724\n",
      "Trained batch 374 batch loss 1.30621266 epoch total loss 1.18972957\n",
      "Trained batch 375 batch loss 1.25201797 epoch total loss 1.18989563\n",
      "Trained batch 376 batch loss 1.11357939 epoch total loss 1.18969274\n",
      "Trained batch 377 batch loss 1.08658636 epoch total loss 1.18941915\n",
      "Trained batch 378 batch loss 1.06597948 epoch total loss 1.18909264\n",
      "Trained batch 379 batch loss 1.2400136 epoch total loss 1.18922698\n",
      "Trained batch 380 batch loss 1.15330601 epoch total loss 1.18913257\n",
      "Trained batch 381 batch loss 1.26072669 epoch total loss 1.18932045\n",
      "Trained batch 382 batch loss 1.27957845 epoch total loss 1.18955672\n",
      "Trained batch 383 batch loss 1.24765754 epoch total loss 1.18970835\n",
      "Trained batch 384 batch loss 1.25880957 epoch total loss 1.18988836\n",
      "Trained batch 385 batch loss 1.3744669 epoch total loss 1.19036782\n",
      "Trained batch 386 batch loss 1.28446114 epoch total loss 1.19061148\n",
      "Trained batch 387 batch loss 1.28526878 epoch total loss 1.1908561\n",
      "Trained batch 388 batch loss 1.29003417 epoch total loss 1.1911118\n",
      "Trained batch 389 batch loss 1.41895771 epoch total loss 1.19169748\n",
      "Trained batch 390 batch loss 1.21687257 epoch total loss 1.19176197\n",
      "Trained batch 391 batch loss 1.37205422 epoch total loss 1.19222307\n",
      "Trained batch 392 batch loss 1.35377181 epoch total loss 1.19263518\n",
      "Trained batch 393 batch loss 1.20819378 epoch total loss 1.19267476\n",
      "Trained batch 394 batch loss 1.18039656 epoch total loss 1.19264352\n",
      "Trained batch 395 batch loss 1.17150545 epoch total loss 1.19259\n",
      "Trained batch 396 batch loss 1.22435236 epoch total loss 1.19267023\n",
      "Trained batch 397 batch loss 1.23227906 epoch total loss 1.19277\n",
      "Trained batch 398 batch loss 1.1110431 epoch total loss 1.19256473\n",
      "Trained batch 399 batch loss 1.03573823 epoch total loss 1.19217169\n",
      "Trained batch 400 batch loss 1.02008224 epoch total loss 1.19174147\n",
      "Trained batch 401 batch loss 1.0866 epoch total loss 1.19147921\n",
      "Trained batch 402 batch loss 1.08651233 epoch total loss 1.19121814\n",
      "Trained batch 403 batch loss 1.08092642 epoch total loss 1.19094443\n",
      "Trained batch 404 batch loss 1.14645 epoch total loss 1.1908344\n",
      "Trained batch 405 batch loss 1.16883564 epoch total loss 1.19078\n",
      "Trained batch 406 batch loss 1.19034123 epoch total loss 1.19077885\n",
      "Trained batch 407 batch loss 1.13568 epoch total loss 1.19064355\n",
      "Trained batch 408 batch loss 1.20428753 epoch total loss 1.19067693\n",
      "Trained batch 409 batch loss 1.1949693 epoch total loss 1.19068754\n",
      "Trained batch 410 batch loss 1.25884974 epoch total loss 1.19085371\n",
      "Trained batch 411 batch loss 1.22647977 epoch total loss 1.19094038\n",
      "Trained batch 412 batch loss 1.10953212 epoch total loss 1.19074273\n",
      "Trained batch 413 batch loss 0.996658683 epoch total loss 1.19027293\n",
      "Trained batch 414 batch loss 1.06167293 epoch total loss 1.18996227\n",
      "Trained batch 415 batch loss 1.2242676 epoch total loss 1.190045\n",
      "Trained batch 416 batch loss 1.23548079 epoch total loss 1.19015419\n",
      "Trained batch 417 batch loss 1.3147366 epoch total loss 1.19045293\n",
      "Trained batch 418 batch loss 1.20507026 epoch total loss 1.19048786\n",
      "Trained batch 419 batch loss 1.27972698 epoch total loss 1.19070089\n",
      "Trained batch 420 batch loss 1.38198817 epoch total loss 1.19115627\n",
      "Trained batch 421 batch loss 1.18254757 epoch total loss 1.19113588\n",
      "Trained batch 422 batch loss 1.28651822 epoch total loss 1.1913619\n",
      "Trained batch 423 batch loss 1.31663203 epoch total loss 1.19165802\n",
      "Trained batch 424 batch loss 1.21025074 epoch total loss 1.19170189\n",
      "Trained batch 425 batch loss 1.08492959 epoch total loss 1.1914506\n",
      "Trained batch 426 batch loss 1.11858571 epoch total loss 1.19127965\n",
      "Trained batch 427 batch loss 0.977720857 epoch total loss 1.19077945\n",
      "Trained batch 428 batch loss 1.07071006 epoch total loss 1.19049895\n",
      "Trained batch 429 batch loss 1.11216927 epoch total loss 1.19031632\n",
      "Trained batch 430 batch loss 1.20903552 epoch total loss 1.19036\n",
      "Trained batch 431 batch loss 1.27657652 epoch total loss 1.19056\n",
      "Trained batch 432 batch loss 1.2683351 epoch total loss 1.19074\n",
      "Trained batch 433 batch loss 1.18097305 epoch total loss 1.19071734\n",
      "Trained batch 434 batch loss 1.25280166 epoch total loss 1.19086039\n",
      "Trained batch 435 batch loss 1.10976028 epoch total loss 1.19067395\n",
      "Trained batch 436 batch loss 1.25356007 epoch total loss 1.19081819\n",
      "Trained batch 437 batch loss 1.18416095 epoch total loss 1.19080293\n",
      "Trained batch 438 batch loss 1.10677958 epoch total loss 1.190611\n",
      "Trained batch 439 batch loss 1.22985959 epoch total loss 1.19070041\n",
      "Trained batch 440 batch loss 1.101349 epoch total loss 1.1904974\n",
      "Trained batch 441 batch loss 1.02167022 epoch total loss 1.1901145\n",
      "Trained batch 442 batch loss 1.14213324 epoch total loss 1.19000602\n",
      "Trained batch 443 batch loss 1.26872993 epoch total loss 1.19018376\n",
      "Trained batch 444 batch loss 1.36621451 epoch total loss 1.19058025\n",
      "Trained batch 445 batch loss 1.26149881 epoch total loss 1.19073951\n",
      "Trained batch 446 batch loss 1.17503512 epoch total loss 1.19070435\n",
      "Trained batch 447 batch loss 1.26944435 epoch total loss 1.19088054\n",
      "Trained batch 448 batch loss 1.27028418 epoch total loss 1.1910578\n",
      "Trained batch 449 batch loss 1.23485661 epoch total loss 1.19115531\n",
      "Trained batch 450 batch loss 1.15457916 epoch total loss 1.19107413\n",
      "Trained batch 451 batch loss 1.17684352 epoch total loss 1.19104242\n",
      "Trained batch 452 batch loss 1.24341297 epoch total loss 1.19115829\n",
      "Trained batch 453 batch loss 1.12653089 epoch total loss 1.1910156\n",
      "Trained batch 454 batch loss 1.059165 epoch total loss 1.19072521\n",
      "Trained batch 455 batch loss 1.10153461 epoch total loss 1.19052923\n",
      "Trained batch 456 batch loss 1.20213151 epoch total loss 1.19055474\n",
      "Trained batch 457 batch loss 1.0760498 epoch total loss 1.19030416\n",
      "Trained batch 458 batch loss 1.14976704 epoch total loss 1.19021571\n",
      "Trained batch 459 batch loss 1.06938028 epoch total loss 1.18995249\n",
      "Trained batch 460 batch loss 1.17285514 epoch total loss 1.1899153\n",
      "Trained batch 461 batch loss 1.34807038 epoch total loss 1.19025838\n",
      "Trained batch 462 batch loss 1.27987528 epoch total loss 1.19045234\n",
      "Trained batch 463 batch loss 1.25396848 epoch total loss 1.19058943\n",
      "Trained batch 464 batch loss 1.48211432 epoch total loss 1.19121778\n",
      "Trained batch 465 batch loss 1.24761081 epoch total loss 1.19133902\n",
      "Trained batch 466 batch loss 1.28688192 epoch total loss 1.19154406\n",
      "Trained batch 467 batch loss 1.27111721 epoch total loss 1.19171441\n",
      "Trained batch 468 batch loss 1.23010921 epoch total loss 1.19179642\n",
      "Trained batch 469 batch loss 1.20296121 epoch total loss 1.19182026\n",
      "Trained batch 470 batch loss 1.15915513 epoch total loss 1.19175076\n",
      "Trained batch 471 batch loss 1.19332922 epoch total loss 1.19175422\n",
      "Trained batch 472 batch loss 1.23565161 epoch total loss 1.19184721\n",
      "Trained batch 473 batch loss 1.175179 epoch total loss 1.19181192\n",
      "Trained batch 474 batch loss 1.16514444 epoch total loss 1.19175577\n",
      "Trained batch 475 batch loss 1.12799466 epoch total loss 1.19162142\n",
      "Trained batch 476 batch loss 1.12663531 epoch total loss 1.19148493\n",
      "Trained batch 477 batch loss 1.08356166 epoch total loss 1.19125867\n",
      "Trained batch 478 batch loss 1.14045334 epoch total loss 1.19115245\n",
      "Trained batch 479 batch loss 1.05351102 epoch total loss 1.19086504\n",
      "Trained batch 480 batch loss 1.13191259 epoch total loss 1.19074225\n",
      "Trained batch 481 batch loss 1.07306707 epoch total loss 1.19049752\n",
      "Trained batch 482 batch loss 1.09273291 epoch total loss 1.19029474\n",
      "Trained batch 483 batch loss 1.20864785 epoch total loss 1.19033265\n",
      "Trained batch 484 batch loss 1.26023269 epoch total loss 1.19047713\n",
      "Trained batch 485 batch loss 1.20016634 epoch total loss 1.19049716\n",
      "Trained batch 486 batch loss 1.33228958 epoch total loss 1.19078887\n",
      "Trained batch 487 batch loss 1.19164658 epoch total loss 1.19079065\n",
      "Trained batch 488 batch loss 1.17509258 epoch total loss 1.19075847\n",
      "Trained batch 489 batch loss 1.08232403 epoch total loss 1.19053674\n",
      "Trained batch 490 batch loss 1.0115943 epoch total loss 1.1901716\n",
      "Trained batch 491 batch loss 1.15422106 epoch total loss 1.1900984\n",
      "Trained batch 492 batch loss 1.17190385 epoch total loss 1.19006133\n",
      "Trained batch 493 batch loss 1.29702842 epoch total loss 1.19027841\n",
      "Trained batch 494 batch loss 1.26055908 epoch total loss 1.19042063\n",
      "Trained batch 495 batch loss 1.19013929 epoch total loss 1.19042\n",
      "Trained batch 496 batch loss 1.1598053 epoch total loss 1.19035828\n",
      "Trained batch 497 batch loss 1.19088173 epoch total loss 1.19035935\n",
      "Trained batch 498 batch loss 1.02807736 epoch total loss 1.19003344\n",
      "Trained batch 499 batch loss 0.916418374 epoch total loss 1.18948519\n",
      "Trained batch 500 batch loss 0.905167103 epoch total loss 1.18891644\n",
      "Trained batch 501 batch loss 0.912507296 epoch total loss 1.18836486\n",
      "Trained batch 502 batch loss 1.14033842 epoch total loss 1.18826914\n",
      "Trained batch 503 batch loss 1.33443046 epoch total loss 1.18855965\n",
      "Trained batch 504 batch loss 1.60932732 epoch total loss 1.18939447\n",
      "Trained batch 505 batch loss 1.2270242 epoch total loss 1.1894691\n",
      "Trained batch 506 batch loss 1.23665535 epoch total loss 1.18956232\n",
      "Trained batch 507 batch loss 1.1429199 epoch total loss 1.18947029\n",
      "Trained batch 508 batch loss 1.26695204 epoch total loss 1.18962288\n",
      "Trained batch 509 batch loss 1.25948405 epoch total loss 1.18976009\n",
      "Trained batch 510 batch loss 1.1933682 epoch total loss 1.18976712\n",
      "Trained batch 511 batch loss 1.2635653 epoch total loss 1.1899116\n",
      "Trained batch 512 batch loss 1.23336601 epoch total loss 1.18999636\n",
      "Trained batch 513 batch loss 1.16198945 epoch total loss 1.18994176\n",
      "Trained batch 514 batch loss 1.18926799 epoch total loss 1.18994045\n",
      "Trained batch 515 batch loss 1.19415689 epoch total loss 1.18994868\n",
      "Trained batch 516 batch loss 1.10504544 epoch total loss 1.18978405\n",
      "Trained batch 517 batch loss 1.11656547 epoch total loss 1.18964243\n",
      "Trained batch 518 batch loss 1.22710061 epoch total loss 1.18971479\n",
      "Trained batch 519 batch loss 1.12100291 epoch total loss 1.18958247\n",
      "Trained batch 520 batch loss 1.00308788 epoch total loss 1.18922389\n",
      "Trained batch 521 batch loss 1.1554606 epoch total loss 1.18915904\n",
      "Trained batch 522 batch loss 1.09138107 epoch total loss 1.18897176\n",
      "Trained batch 523 batch loss 1.04473221 epoch total loss 1.18869591\n",
      "Trained batch 524 batch loss 0.978808761 epoch total loss 1.18829548\n",
      "Trained batch 525 batch loss 0.944748044 epoch total loss 1.18783152\n",
      "Trained batch 526 batch loss 1.17532957 epoch total loss 1.1878078\n",
      "Trained batch 527 batch loss 1.2344985 epoch total loss 1.18789649\n",
      "Trained batch 528 batch loss 1.25598729 epoch total loss 1.18802536\n",
      "Trained batch 529 batch loss 1.37224567 epoch total loss 1.18837368\n",
      "Trained batch 530 batch loss 1.10719061 epoch total loss 1.1882205\n",
      "Trained batch 531 batch loss 1.08790445 epoch total loss 1.18803155\n",
      "Trained batch 532 batch loss 1.07551944 epoch total loss 1.18782\n",
      "Trained batch 533 batch loss 1.06604767 epoch total loss 1.18759155\n",
      "Trained batch 534 batch loss 1.29016805 epoch total loss 1.1877836\n",
      "Trained batch 535 batch loss 1.26633096 epoch total loss 1.18793046\n",
      "Trained batch 536 batch loss 1.24422598 epoch total loss 1.18803537\n",
      "Trained batch 537 batch loss 1.34982705 epoch total loss 1.18833673\n",
      "Trained batch 538 batch loss 1.21449471 epoch total loss 1.18838537\n",
      "Trained batch 539 batch loss 1.20113134 epoch total loss 1.18840897\n",
      "Trained batch 540 batch loss 1.23441648 epoch total loss 1.18849421\n",
      "Trained batch 541 batch loss 1.13001323 epoch total loss 1.18838608\n",
      "Trained batch 542 batch loss 1.07999992 epoch total loss 1.18818617\n",
      "Trained batch 543 batch loss 1.25559187 epoch total loss 1.18831027\n",
      "Trained batch 544 batch loss 1.18232334 epoch total loss 1.1882993\n",
      "Trained batch 545 batch loss 1.14356947 epoch total loss 1.18821716\n",
      "Trained batch 546 batch loss 1.13143063 epoch total loss 1.18811309\n",
      "Trained batch 547 batch loss 1.03651416 epoch total loss 1.18783593\n",
      "Trained batch 548 batch loss 1.15577924 epoch total loss 1.1877774\n",
      "Trained batch 549 batch loss 1.05963993 epoch total loss 1.18754399\n",
      "Trained batch 550 batch loss 1.05325639 epoch total loss 1.1873\n",
      "Trained batch 551 batch loss 1.13609409 epoch total loss 1.18720698\n",
      "Trained batch 552 batch loss 1.14464414 epoch total loss 1.18713\n",
      "Trained batch 553 batch loss 1.15912521 epoch total loss 1.18707931\n",
      "Trained batch 554 batch loss 1.06779742 epoch total loss 1.18686402\n",
      "Trained batch 555 batch loss 1.17632771 epoch total loss 1.18684494\n",
      "Trained batch 556 batch loss 1.16319489 epoch total loss 1.18680251\n",
      "Trained batch 557 batch loss 1.23911595 epoch total loss 1.18689644\n",
      "Trained batch 558 batch loss 1.31042576 epoch total loss 1.18711782\n",
      "Trained batch 559 batch loss 1.23290408 epoch total loss 1.18719971\n",
      "Trained batch 560 batch loss 1.2081604 epoch total loss 1.18723714\n",
      "Trained batch 561 batch loss 1.18623459 epoch total loss 1.18723536\n",
      "Trained batch 562 batch loss 1.1329335 epoch total loss 1.18713868\n",
      "Trained batch 563 batch loss 1.10982621 epoch total loss 1.18700135\n",
      "Trained batch 564 batch loss 1.1007452 epoch total loss 1.1868484\n",
      "Trained batch 565 batch loss 1.15629196 epoch total loss 1.1867944\n",
      "Trained batch 566 batch loss 1.27243829 epoch total loss 1.18694568\n",
      "Trained batch 567 batch loss 1.27155447 epoch total loss 1.18709493\n",
      "Trained batch 568 batch loss 1.27315426 epoch total loss 1.18724644\n",
      "Trained batch 569 batch loss 1.42365813 epoch total loss 1.18766189\n",
      "Trained batch 570 batch loss 1.37566233 epoch total loss 1.18799174\n",
      "Trained batch 571 batch loss 1.42535639 epoch total loss 1.18840742\n",
      "Trained batch 572 batch loss 1.16413844 epoch total loss 1.18836498\n",
      "Trained batch 573 batch loss 1.05619252 epoch total loss 1.18813431\n",
      "Trained batch 574 batch loss 1.22683299 epoch total loss 1.18820167\n",
      "Trained batch 575 batch loss 1.09194136 epoch total loss 1.1880343\n",
      "Trained batch 576 batch loss 1.00242114 epoch total loss 1.18771207\n",
      "Trained batch 577 batch loss 1.08578515 epoch total loss 1.18753541\n",
      "Trained batch 578 batch loss 1.05683613 epoch total loss 1.18730927\n",
      "Trained batch 579 batch loss 1.03356159 epoch total loss 1.18704379\n",
      "Trained batch 580 batch loss 0.987125278 epoch total loss 1.18669903\n",
      "Trained batch 581 batch loss 1.04246044 epoch total loss 1.18645084\n",
      "Trained batch 582 batch loss 1.18705213 epoch total loss 1.18645191\n",
      "Trained batch 583 batch loss 1.13242 epoch total loss 1.18635929\n",
      "Trained batch 584 batch loss 0.981617868 epoch total loss 1.18600869\n",
      "Trained batch 585 batch loss 1.03718281 epoch total loss 1.1857543\n",
      "Trained batch 586 batch loss 1.18704581 epoch total loss 1.18575656\n",
      "Trained batch 587 batch loss 1.21493554 epoch total loss 1.18580627\n",
      "Trained batch 588 batch loss 1.18568575 epoch total loss 1.18580604\n",
      "Trained batch 589 batch loss 1.20940149 epoch total loss 1.18584609\n",
      "Trained batch 590 batch loss 1.18220592 epoch total loss 1.18583989\n",
      "Trained batch 591 batch loss 1.15062129 epoch total loss 1.18578041\n",
      "Trained batch 592 batch loss 1.13836 epoch total loss 1.1857003\n",
      "Trained batch 593 batch loss 1.16778374 epoch total loss 1.18567\n",
      "Trained batch 594 batch loss 1.01411033 epoch total loss 1.18538129\n",
      "Trained batch 595 batch loss 0.94920069 epoch total loss 1.18498433\n",
      "Trained batch 596 batch loss 1.00861657 epoch total loss 1.18468833\n",
      "Trained batch 597 batch loss 1.04914463 epoch total loss 1.18446136\n",
      "Trained batch 598 batch loss 1.05567431 epoch total loss 1.18424594\n",
      "Trained batch 599 batch loss 1.04550397 epoch total loss 1.18401432\n",
      "Trained batch 600 batch loss 1.04232657 epoch total loss 1.18377817\n",
      "Trained batch 601 batch loss 1.17847085 epoch total loss 1.18376935\n",
      "Trained batch 602 batch loss 1.03868806 epoch total loss 1.1835283\n",
      "Trained batch 603 batch loss 1.264992 epoch total loss 1.18366349\n",
      "Trained batch 604 batch loss 1.34803438 epoch total loss 1.18393564\n",
      "Trained batch 605 batch loss 1.18535972 epoch total loss 1.18393803\n",
      "Trained batch 606 batch loss 1.27422917 epoch total loss 1.18408692\n",
      "Trained batch 607 batch loss 1.2177614 epoch total loss 1.18414247\n",
      "Trained batch 608 batch loss 1.24194729 epoch total loss 1.18423748\n",
      "Trained batch 609 batch loss 1.19733369 epoch total loss 1.18425906\n",
      "Trained batch 610 batch loss 1.28617382 epoch total loss 1.18442619\n",
      "Trained batch 611 batch loss 1.19307911 epoch total loss 1.18444026\n",
      "Trained batch 612 batch loss 1.35171115 epoch total loss 1.18471348\n",
      "Trained batch 613 batch loss 1.38027596 epoch total loss 1.18503249\n",
      "Trained batch 614 batch loss 1.14571333 epoch total loss 1.18496847\n",
      "Trained batch 615 batch loss 1.32619393 epoch total loss 1.18519807\n",
      "Trained batch 616 batch loss 1.29584968 epoch total loss 1.1853776\n",
      "Trained batch 617 batch loss 1.35695326 epoch total loss 1.18565571\n",
      "Trained batch 618 batch loss 1.15129197 epoch total loss 1.18560016\n",
      "Trained batch 619 batch loss 1.20752561 epoch total loss 1.18563557\n",
      "Trained batch 620 batch loss 1.23967266 epoch total loss 1.18572271\n",
      "Trained batch 621 batch loss 1.16902721 epoch total loss 1.18569577\n",
      "Trained batch 622 batch loss 1.20355654 epoch total loss 1.1857245\n",
      "Trained batch 623 batch loss 1.22933638 epoch total loss 1.18579447\n",
      "Trained batch 624 batch loss 1.23173583 epoch total loss 1.18586814\n",
      "Trained batch 625 batch loss 1.20557201 epoch total loss 1.18589962\n",
      "Trained batch 626 batch loss 1.2339679 epoch total loss 1.18597639\n",
      "Trained batch 627 batch loss 1.12487364 epoch total loss 1.18587887\n",
      "Trained batch 628 batch loss 1.05590034 epoch total loss 1.18567193\n",
      "Trained batch 629 batch loss 1.19089985 epoch total loss 1.18568027\n",
      "Trained batch 630 batch loss 1.28977275 epoch total loss 1.18584561\n",
      "Trained batch 631 batch loss 1.19172478 epoch total loss 1.18585491\n",
      "Trained batch 632 batch loss 1.26042199 epoch total loss 1.18597281\n",
      "Trained batch 633 batch loss 1.2197274 epoch total loss 1.18602622\n",
      "Trained batch 634 batch loss 1.26422811 epoch total loss 1.18614948\n",
      "Trained batch 635 batch loss 1.21258497 epoch total loss 1.1861912\n",
      "Trained batch 636 batch loss 1.14603114 epoch total loss 1.18612802\n",
      "Trained batch 637 batch loss 1.227036 epoch total loss 1.18619227\n",
      "Trained batch 638 batch loss 1.11814237 epoch total loss 1.1860857\n",
      "Trained batch 639 batch loss 1.0876739 epoch total loss 1.18593156\n",
      "Trained batch 640 batch loss 1.1179657 epoch total loss 1.18582547\n",
      "Trained batch 641 batch loss 1.16943 epoch total loss 1.18579984\n",
      "Trained batch 642 batch loss 1.41385162 epoch total loss 1.18615508\n",
      "Trained batch 643 batch loss 1.34985185 epoch total loss 1.18640971\n",
      "Trained batch 644 batch loss 1.34326804 epoch total loss 1.18665326\n",
      "Trained batch 645 batch loss 1.34528184 epoch total loss 1.18689919\n",
      "Trained batch 646 batch loss 1.25399244 epoch total loss 1.18700302\n",
      "Trained batch 647 batch loss 1.06763101 epoch total loss 1.18681848\n",
      "Trained batch 648 batch loss 1.06800926 epoch total loss 1.18663514\n",
      "Trained batch 649 batch loss 0.947090268 epoch total loss 1.18626606\n",
      "Trained batch 650 batch loss 1.02770567 epoch total loss 1.18602216\n",
      "Trained batch 651 batch loss 1.16861677 epoch total loss 1.18599546\n",
      "Trained batch 652 batch loss 1.08151114 epoch total loss 1.18583512\n",
      "Trained batch 653 batch loss 1.15648913 epoch total loss 1.18579018\n",
      "Trained batch 654 batch loss 1.07563722 epoch total loss 1.18562174\n",
      "Trained batch 655 batch loss 1.03438401 epoch total loss 1.18539083\n",
      "Trained batch 656 batch loss 0.984105945 epoch total loss 1.18508399\n",
      "Trained batch 657 batch loss 1.38535297 epoch total loss 1.1853888\n",
      "Trained batch 658 batch loss 1.2637074 epoch total loss 1.18550789\n",
      "Trained batch 659 batch loss 1.12900507 epoch total loss 1.18542218\n",
      "Trained batch 660 batch loss 1.14182711 epoch total loss 1.18535614\n",
      "Trained batch 661 batch loss 1.138448 epoch total loss 1.18528521\n",
      "Trained batch 662 batch loss 1.11965632 epoch total loss 1.18518603\n",
      "Trained batch 663 batch loss 1.17723608 epoch total loss 1.18517399\n",
      "Trained batch 664 batch loss 1.12674868 epoch total loss 1.18508613\n",
      "Trained batch 665 batch loss 1.11298561 epoch total loss 1.18497765\n",
      "Trained batch 666 batch loss 1.21277595 epoch total loss 1.18501937\n",
      "Trained batch 667 batch loss 1.2808845 epoch total loss 1.18516314\n",
      "Trained batch 668 batch loss 1.20305955 epoch total loss 1.18518984\n",
      "Trained batch 669 batch loss 1.14131439 epoch total loss 1.18512428\n",
      "Trained batch 670 batch loss 1.02751327 epoch total loss 1.18488908\n",
      "Trained batch 671 batch loss 1.12189686 epoch total loss 1.18479514\n",
      "Trained batch 672 batch loss 1.13209641 epoch total loss 1.1847167\n",
      "Trained batch 673 batch loss 1.13600922 epoch total loss 1.18464434\n",
      "Trained batch 674 batch loss 1.08855295 epoch total loss 1.18450177\n",
      "Trained batch 675 batch loss 1.21282828 epoch total loss 1.18454373\n",
      "Trained batch 676 batch loss 1.09956264 epoch total loss 1.18441796\n",
      "Trained batch 677 batch loss 1.1130594 epoch total loss 1.18431258\n",
      "Trained batch 678 batch loss 1.04978132 epoch total loss 1.18411422\n",
      "Trained batch 679 batch loss 1.16844273 epoch total loss 1.18409109\n",
      "Trained batch 680 batch loss 1.11831832 epoch total loss 1.18399441\n",
      "Trained batch 681 batch loss 1.16390836 epoch total loss 1.18396485\n",
      "Trained batch 682 batch loss 1.1083982 epoch total loss 1.1838541\n",
      "Trained batch 683 batch loss 1.21954799 epoch total loss 1.18390632\n",
      "Trained batch 684 batch loss 1.05302989 epoch total loss 1.18371499\n",
      "Trained batch 685 batch loss 1.18241286 epoch total loss 1.1837132\n",
      "Trained batch 686 batch loss 1.19734848 epoch total loss 1.18373299\n",
      "Trained batch 687 batch loss 1.18514347 epoch total loss 1.18373501\n",
      "Trained batch 688 batch loss 1.18915284 epoch total loss 1.18374288\n",
      "Trained batch 689 batch loss 1.22250021 epoch total loss 1.18379915\n",
      "Trained batch 690 batch loss 1.22806156 epoch total loss 1.18386328\n",
      "Trained batch 691 batch loss 1.12695241 epoch total loss 1.18378091\n",
      "Trained batch 692 batch loss 1.17435122 epoch total loss 1.18376732\n",
      "Trained batch 693 batch loss 1.0660888 epoch total loss 1.18359756\n",
      "Trained batch 694 batch loss 1.2417767 epoch total loss 1.18368137\n",
      "Trained batch 695 batch loss 1.2436347 epoch total loss 1.18376768\n",
      "Trained batch 696 batch loss 1.25375021 epoch total loss 1.18386817\n",
      "Trained batch 697 batch loss 1.23342991 epoch total loss 1.18393934\n",
      "Trained batch 698 batch loss 1.33151579 epoch total loss 1.18415082\n",
      "Trained batch 699 batch loss 1.20470679 epoch total loss 1.18418014\n",
      "Trained batch 700 batch loss 1.17024994 epoch total loss 1.18416023\n",
      "Trained batch 701 batch loss 1.23257887 epoch total loss 1.18422937\n",
      "Trained batch 702 batch loss 1.23861456 epoch total loss 1.18430674\n",
      "Trained batch 703 batch loss 1.13827288 epoch total loss 1.18424129\n",
      "Trained batch 704 batch loss 1.16492224 epoch total loss 1.18421376\n",
      "Trained batch 705 batch loss 1.17392373 epoch total loss 1.18419921\n",
      "Trained batch 706 batch loss 1.09045434 epoch total loss 1.18406641\n",
      "Trained batch 707 batch loss 1.14994383 epoch total loss 1.18401825\n",
      "Trained batch 708 batch loss 1.1223489 epoch total loss 1.18393111\n",
      "Trained batch 709 batch loss 0.995894551 epoch total loss 1.18366599\n",
      "Trained batch 710 batch loss 1.02317774 epoch total loss 1.18344\n",
      "Trained batch 711 batch loss 1.0931704 epoch total loss 1.18331301\n",
      "Trained batch 712 batch loss 1.23649669 epoch total loss 1.18338776\n",
      "Trained batch 713 batch loss 1.18095863 epoch total loss 1.18338442\n",
      "Trained batch 714 batch loss 1.25545931 epoch total loss 1.18348527\n",
      "Trained batch 715 batch loss 1.15210259 epoch total loss 1.1834414\n",
      "Trained batch 716 batch loss 1.23178136 epoch total loss 1.18350887\n",
      "Trained batch 717 batch loss 1.22805023 epoch total loss 1.18357098\n",
      "Trained batch 718 batch loss 1.24667323 epoch total loss 1.18365884\n",
      "Trained batch 719 batch loss 0.985782 epoch total loss 1.1833837\n",
      "Trained batch 720 batch loss 1.10590303 epoch total loss 1.18327606\n",
      "Trained batch 721 batch loss 1.02829552 epoch total loss 1.18306112\n",
      "Trained batch 722 batch loss 1.08658421 epoch total loss 1.18292749\n",
      "Trained batch 723 batch loss 1.07670832 epoch total loss 1.18278062\n",
      "Trained batch 724 batch loss 1.23929918 epoch total loss 1.18285871\n",
      "Trained batch 725 batch loss 1.08227229 epoch total loss 1.18272\n",
      "Trained batch 726 batch loss 1.20085609 epoch total loss 1.18274498\n",
      "Trained batch 727 batch loss 1.29305208 epoch total loss 1.18289661\n",
      "Trained batch 728 batch loss 1.21460426 epoch total loss 1.18294024\n",
      "Trained batch 729 batch loss 1.27305877 epoch total loss 1.18306386\n",
      "Trained batch 730 batch loss 1.45255125 epoch total loss 1.18343306\n",
      "Trained batch 731 batch loss 1.50785708 epoch total loss 1.18387687\n",
      "Trained batch 732 batch loss 1.22336197 epoch total loss 1.18393087\n",
      "Trained batch 733 batch loss 1.02539706 epoch total loss 1.18371463\n",
      "Trained batch 734 batch loss 1.18391299 epoch total loss 1.18371487\n",
      "Trained batch 735 batch loss 1.40531099 epoch total loss 1.18401635\n",
      "Trained batch 736 batch loss 1.41045427 epoch total loss 1.18432403\n",
      "Trained batch 737 batch loss 1.21437526 epoch total loss 1.1843648\n",
      "Trained batch 738 batch loss 1.15166628 epoch total loss 1.18432045\n",
      "Trained batch 739 batch loss 1.08144903 epoch total loss 1.18418121\n",
      "Trained batch 740 batch loss 1.12629318 epoch total loss 1.18410301\n",
      "Trained batch 741 batch loss 1.1473701 epoch total loss 1.18405342\n",
      "Trained batch 742 batch loss 1.22933316 epoch total loss 1.18411446\n",
      "Trained batch 743 batch loss 1.23325372 epoch total loss 1.18418062\n",
      "Trained batch 744 batch loss 1.18065834 epoch total loss 1.18417585\n",
      "Trained batch 745 batch loss 1.2643832 epoch total loss 1.18428361\n",
      "Trained batch 746 batch loss 1.05085325 epoch total loss 1.18410468\n",
      "Trained batch 747 batch loss 1.01913846 epoch total loss 1.18388391\n",
      "Trained batch 748 batch loss 1.18122208 epoch total loss 1.18388033\n",
      "Trained batch 749 batch loss 1.07557786 epoch total loss 1.18373573\n",
      "Trained batch 750 batch loss 1.31219268 epoch total loss 1.18390703\n",
      "Trained batch 751 batch loss 1.21038878 epoch total loss 1.1839422\n",
      "Trained batch 752 batch loss 1.17306697 epoch total loss 1.18392777\n",
      "Trained batch 753 batch loss 1.2286582 epoch total loss 1.18398714\n",
      "Trained batch 754 batch loss 1.20497513 epoch total loss 1.18401504\n",
      "Trained batch 755 batch loss 1.12251985 epoch total loss 1.1839335\n",
      "Trained batch 756 batch loss 1.15674043 epoch total loss 1.1838975\n",
      "Trained batch 757 batch loss 1.18122816 epoch total loss 1.18389404\n",
      "Trained batch 758 batch loss 1.19520676 epoch total loss 1.18390894\n",
      "Trained batch 759 batch loss 1.16407406 epoch total loss 1.18388271\n",
      "Trained batch 760 batch loss 1.28479469 epoch total loss 1.18401551\n",
      "Trained batch 761 batch loss 1.18020117 epoch total loss 1.18401051\n",
      "Trained batch 762 batch loss 1.12362552 epoch total loss 1.18393123\n",
      "Trained batch 763 batch loss 1.21692324 epoch total loss 1.18397439\n",
      "Trained batch 764 batch loss 1.30572617 epoch total loss 1.18413377\n",
      "Trained batch 765 batch loss 1.23485744 epoch total loss 1.18420017\n",
      "Trained batch 766 batch loss 1.29487169 epoch total loss 1.18434453\n",
      "Trained batch 767 batch loss 1.18534875 epoch total loss 1.18434596\n",
      "Trained batch 768 batch loss 1.18836188 epoch total loss 1.18435109\n",
      "Trained batch 769 batch loss 1.13331366 epoch total loss 1.18428469\n",
      "Trained batch 770 batch loss 1.31580174 epoch total loss 1.18445551\n",
      "Trained batch 771 batch loss 1.28209305 epoch total loss 1.18458223\n",
      "Trained batch 772 batch loss 1.39392722 epoch total loss 1.18485332\n",
      "Trained batch 773 batch loss 1.41896379 epoch total loss 1.18515623\n",
      "Trained batch 774 batch loss 1.27333236 epoch total loss 1.18527007\n",
      "Trained batch 775 batch loss 1.37110913 epoch total loss 1.1855098\n",
      "Trained batch 776 batch loss 1.15285778 epoch total loss 1.18546772\n",
      "Trained batch 777 batch loss 1.33740497 epoch total loss 1.18566334\n",
      "Trained batch 778 batch loss 1.25354505 epoch total loss 1.18575048\n",
      "Trained batch 779 batch loss 1.3276062 epoch total loss 1.18593264\n",
      "Trained batch 780 batch loss 0.970772207 epoch total loss 1.18565679\n",
      "Trained batch 781 batch loss 1.29024839 epoch total loss 1.18579066\n",
      "Trained batch 782 batch loss 1.1793294 epoch total loss 1.18578243\n",
      "Trained batch 783 batch loss 1.24571526 epoch total loss 1.18585896\n",
      "Trained batch 784 batch loss 1.30417943 epoch total loss 1.18600988\n",
      "Trained batch 785 batch loss 1.16059327 epoch total loss 1.18597758\n",
      "Trained batch 786 batch loss 1.04710376 epoch total loss 1.18580091\n",
      "Trained batch 787 batch loss 1.15612388 epoch total loss 1.18576312\n",
      "Trained batch 788 batch loss 1.25753438 epoch total loss 1.1858542\n",
      "Trained batch 789 batch loss 1.23617792 epoch total loss 1.18591809\n",
      "Trained batch 790 batch loss 1.18576 epoch total loss 1.18591785\n",
      "Trained batch 791 batch loss 1.21375132 epoch total loss 1.18595302\n",
      "Trained batch 792 batch loss 1.08440745 epoch total loss 1.18582475\n",
      "Trained batch 793 batch loss 1.16508782 epoch total loss 1.18579865\n",
      "Trained batch 794 batch loss 1.11445498 epoch total loss 1.18570876\n",
      "Trained batch 795 batch loss 1.15977693 epoch total loss 1.18567622\n",
      "Trained batch 796 batch loss 1.10389233 epoch total loss 1.18557346\n",
      "Trained batch 797 batch loss 1.17572427 epoch total loss 1.18556106\n",
      "Trained batch 798 batch loss 1.14939737 epoch total loss 1.18551576\n",
      "Trained batch 799 batch loss 1.22381496 epoch total loss 1.18556368\n",
      "Trained batch 800 batch loss 1.21363938 epoch total loss 1.18559873\n",
      "Trained batch 801 batch loss 1.11371207 epoch total loss 1.18550897\n",
      "Trained batch 802 batch loss 1.09091878 epoch total loss 1.18539107\n",
      "Trained batch 803 batch loss 1.10566533 epoch total loss 1.18529177\n",
      "Trained batch 804 batch loss 1.25503039 epoch total loss 1.18537855\n",
      "Trained batch 805 batch loss 1.3771 epoch total loss 1.18561661\n",
      "Trained batch 806 batch loss 1.37309289 epoch total loss 1.18584919\n",
      "Trained batch 807 batch loss 1.40628719 epoch total loss 1.18612242\n",
      "Trained batch 808 batch loss 1.26792169 epoch total loss 1.18622375\n",
      "Trained batch 809 batch loss 1.2584132 epoch total loss 1.18631291\n",
      "Trained batch 810 batch loss 1.17990971 epoch total loss 1.18630505\n",
      "Trained batch 811 batch loss 1.25211215 epoch total loss 1.18638623\n",
      "Trained batch 812 batch loss 1.18143034 epoch total loss 1.18638015\n",
      "Trained batch 813 batch loss 1.23091769 epoch total loss 1.18643498\n",
      "Trained batch 814 batch loss 1.22791612 epoch total loss 1.18648589\n",
      "Trained batch 815 batch loss 1.18640947 epoch total loss 1.18648577\n",
      "Trained batch 816 batch loss 1.11759341 epoch total loss 1.18640137\n",
      "Trained batch 817 batch loss 1.17561376 epoch total loss 1.18638813\n",
      "Trained batch 818 batch loss 1.11441791 epoch total loss 1.18630016\n",
      "Trained batch 819 batch loss 1.02581632 epoch total loss 1.1861043\n",
      "Trained batch 820 batch loss 1.10680485 epoch total loss 1.1860075\n",
      "Trained batch 821 batch loss 1.28312147 epoch total loss 1.18612587\n",
      "Trained batch 822 batch loss 1.21918797 epoch total loss 1.18616605\n",
      "Trained batch 823 batch loss 1.36476159 epoch total loss 1.18638301\n",
      "Trained batch 824 batch loss 1.25997 epoch total loss 1.1864723\n",
      "Trained batch 825 batch loss 1.22018456 epoch total loss 1.18651319\n",
      "Trained batch 826 batch loss 1.19481444 epoch total loss 1.18652332\n",
      "Trained batch 827 batch loss 1.22618711 epoch total loss 1.18657124\n",
      "Trained batch 828 batch loss 1.14595008 epoch total loss 1.18652213\n",
      "Trained batch 829 batch loss 1.32886219 epoch total loss 1.18669391\n",
      "Trained batch 830 batch loss 1.2153517 epoch total loss 1.18672836\n",
      "Trained batch 831 batch loss 1.08039606 epoch total loss 1.18660045\n",
      "Trained batch 832 batch loss 0.9924528 epoch total loss 1.18636703\n",
      "Trained batch 833 batch loss 1.14349627 epoch total loss 1.18631554\n",
      "Trained batch 834 batch loss 1.13932407 epoch total loss 1.18625927\n",
      "Trained batch 835 batch loss 1.20950472 epoch total loss 1.18628716\n",
      "Trained batch 836 batch loss 1.06124544 epoch total loss 1.18613756\n",
      "Trained batch 837 batch loss 1.15479946 epoch total loss 1.1861\n",
      "Trained batch 838 batch loss 1.14252269 epoch total loss 1.18604803\n",
      "Trained batch 839 batch loss 1.18249631 epoch total loss 1.18604386\n",
      "Trained batch 840 batch loss 1.28800988 epoch total loss 1.18616521\n",
      "Trained batch 841 batch loss 1.23360634 epoch total loss 1.1862216\n",
      "Trained batch 842 batch loss 1.12785316 epoch total loss 1.18615234\n",
      "Trained batch 843 batch loss 0.99391216 epoch total loss 1.18592429\n",
      "Trained batch 844 batch loss 0.816325486 epoch total loss 1.18548632\n",
      "Trained batch 845 batch loss 0.90341866 epoch total loss 1.18515253\n",
      "Trained batch 846 batch loss 0.959437311 epoch total loss 1.18488574\n",
      "Trained batch 847 batch loss 1.22259593 epoch total loss 1.18493021\n",
      "Trained batch 848 batch loss 1.00107205 epoch total loss 1.18471348\n",
      "Trained batch 849 batch loss 1.24259543 epoch total loss 1.18478167\n",
      "Trained batch 850 batch loss 1.32136405 epoch total loss 1.18494236\n",
      "Trained batch 851 batch loss 1.05397332 epoch total loss 1.18478847\n",
      "Trained batch 852 batch loss 1.17259598 epoch total loss 1.18477416\n",
      "Trained batch 853 batch loss 1.35391676 epoch total loss 1.18497241\n",
      "Trained batch 854 batch loss 1.26530898 epoch total loss 1.18506658\n",
      "Trained batch 855 batch loss 1.1713655 epoch total loss 1.18505049\n",
      "Trained batch 856 batch loss 1.07052016 epoch total loss 1.18491673\n",
      "Trained batch 857 batch loss 0.975186586 epoch total loss 1.184672\n",
      "Trained batch 858 batch loss 1.00193226 epoch total loss 1.18445897\n",
      "Trained batch 859 batch loss 1.0059855 epoch total loss 1.18425119\n",
      "Trained batch 860 batch loss 1.06499898 epoch total loss 1.18411255\n",
      "Trained batch 861 batch loss 1.05936337 epoch total loss 1.18396771\n",
      "Trained batch 862 batch loss 1.05320609 epoch total loss 1.18381596\n",
      "Trained batch 863 batch loss 1.15255129 epoch total loss 1.18377972\n",
      "Trained batch 864 batch loss 1.1541338 epoch total loss 1.18374538\n",
      "Trained batch 865 batch loss 1.19425178 epoch total loss 1.18375754\n",
      "Trained batch 866 batch loss 1.26321054 epoch total loss 1.18384933\n",
      "Trained batch 867 batch loss 1.22164738 epoch total loss 1.18389297\n",
      "Trained batch 868 batch loss 1.16796362 epoch total loss 1.18387461\n",
      "Trained batch 869 batch loss 1.17215645 epoch total loss 1.18386102\n",
      "Trained batch 870 batch loss 1.09246683 epoch total loss 1.18375599\n",
      "Trained batch 871 batch loss 1.14808655 epoch total loss 1.18371499\n",
      "Trained batch 872 batch loss 0.975840569 epoch total loss 1.18347657\n",
      "Trained batch 873 batch loss 0.93320787 epoch total loss 1.18318987\n",
      "Trained batch 874 batch loss 1.20367587 epoch total loss 1.18321347\n",
      "Trained batch 875 batch loss 1.20163655 epoch total loss 1.18323457\n",
      "Trained batch 876 batch loss 1.26565623 epoch total loss 1.18332851\n",
      "Trained batch 877 batch loss 1.37625623 epoch total loss 1.18354857\n",
      "Trained batch 878 batch loss 1.37475538 epoch total loss 1.18376625\n",
      "Trained batch 879 batch loss 1.31214702 epoch total loss 1.18391228\n",
      "Trained batch 880 batch loss 1.2296226 epoch total loss 1.18396425\n",
      "Trained batch 881 batch loss 1.14737463 epoch total loss 1.18392265\n",
      "Trained batch 882 batch loss 1.13291085 epoch total loss 1.18386483\n",
      "Trained batch 883 batch loss 1.14595819 epoch total loss 1.18382204\n",
      "Trained batch 884 batch loss 1.16099775 epoch total loss 1.18379617\n",
      "Trained batch 885 batch loss 1.20325184 epoch total loss 1.18381822\n",
      "Trained batch 886 batch loss 1.19042814 epoch total loss 1.18382561\n",
      "Trained batch 887 batch loss 1.22963166 epoch total loss 1.18387723\n",
      "Trained batch 888 batch loss 1.16117465 epoch total loss 1.1838516\n",
      "Trained batch 889 batch loss 1.20885301 epoch total loss 1.18387973\n",
      "Trained batch 890 batch loss 1.15392423 epoch total loss 1.18384612\n",
      "Trained batch 891 batch loss 1.1584146 epoch total loss 1.18381763\n",
      "Trained batch 892 batch loss 1.32525611 epoch total loss 1.18397605\n",
      "Trained batch 893 batch loss 1.23095512 epoch total loss 1.18402874\n",
      "Trained batch 894 batch loss 1.32495427 epoch total loss 1.18418634\n",
      "Trained batch 895 batch loss 1.50701034 epoch total loss 1.18454695\n",
      "Trained batch 896 batch loss 1.23171568 epoch total loss 1.18459964\n",
      "Trained batch 897 batch loss 1.12982881 epoch total loss 1.1845386\n",
      "Trained batch 898 batch loss 1.05233383 epoch total loss 1.18439138\n",
      "Trained batch 899 batch loss 0.984743834 epoch total loss 1.18416929\n",
      "Trained batch 900 batch loss 1.07737565 epoch total loss 1.18405068\n",
      "Trained batch 901 batch loss 1.11657143 epoch total loss 1.18397582\n",
      "Trained batch 902 batch loss 0.939626098 epoch total loss 1.18370485\n",
      "Trained batch 903 batch loss 0.936653435 epoch total loss 1.18343127\n",
      "Trained batch 904 batch loss 0.942360044 epoch total loss 1.1831646\n",
      "Trained batch 905 batch loss 1.00598717 epoch total loss 1.18296885\n",
      "Trained batch 906 batch loss 1.12997568 epoch total loss 1.18291032\n",
      "Trained batch 907 batch loss 1.17864048 epoch total loss 1.18290555\n",
      "Trained batch 908 batch loss 1.1579982 epoch total loss 1.18287814\n",
      "Trained batch 909 batch loss 1.16155648 epoch total loss 1.18285465\n",
      "Trained batch 910 batch loss 1.2043885 epoch total loss 1.18287826\n",
      "Trained batch 911 batch loss 1.14451623 epoch total loss 1.18283617\n",
      "Trained batch 912 batch loss 1.14939117 epoch total loss 1.18279946\n",
      "Trained batch 913 batch loss 1.31774211 epoch total loss 1.18294728\n",
      "Trained batch 914 batch loss 1.29629397 epoch total loss 1.18307126\n",
      "Trained batch 915 batch loss 1.20414627 epoch total loss 1.18309426\n",
      "Trained batch 916 batch loss 1.21768641 epoch total loss 1.18313193\n",
      "Trained batch 917 batch loss 1.309811 epoch total loss 1.1832701\n",
      "Trained batch 918 batch loss 1.24136066 epoch total loss 1.1833334\n",
      "Trained batch 919 batch loss 1.20172882 epoch total loss 1.18335342\n",
      "Trained batch 920 batch loss 1.37811375 epoch total loss 1.18356526\n",
      "Trained batch 921 batch loss 1.26737559 epoch total loss 1.18365622\n",
      "Trained batch 922 batch loss 1.14935 epoch total loss 1.1836189\n",
      "Trained batch 923 batch loss 1.2478137 epoch total loss 1.1836884\n",
      "Trained batch 924 batch loss 1.1696198 epoch total loss 1.18367326\n",
      "Trained batch 925 batch loss 1.18866038 epoch total loss 1.18367875\n",
      "Trained batch 926 batch loss 1.22911978 epoch total loss 1.18372786\n",
      "Trained batch 927 batch loss 1.28463364 epoch total loss 1.1838367\n",
      "Trained batch 928 batch loss 1.21409631 epoch total loss 1.18386936\n",
      "Trained batch 929 batch loss 1.10848355 epoch total loss 1.18378818\n",
      "Trained batch 930 batch loss 1.29147708 epoch total loss 1.18390405\n",
      "Trained batch 931 batch loss 1.21566832 epoch total loss 1.18393815\n",
      "Trained batch 932 batch loss 1.19929349 epoch total loss 1.18395472\n",
      "Trained batch 933 batch loss 1.08479118 epoch total loss 1.1838485\n",
      "Trained batch 934 batch loss 1.22924399 epoch total loss 1.18389714\n",
      "Trained batch 935 batch loss 1.20929372 epoch total loss 1.18392432\n",
      "Trained batch 936 batch loss 1.21700931 epoch total loss 1.18395972\n",
      "Trained batch 937 batch loss 1.14003921 epoch total loss 1.18391275\n",
      "Trained batch 938 batch loss 1.08553517 epoch total loss 1.18380797\n",
      "Trained batch 939 batch loss 1.03533316 epoch total loss 1.18364978\n",
      "Trained batch 940 batch loss 1.09139967 epoch total loss 1.18355167\n",
      "Trained batch 941 batch loss 1.22979832 epoch total loss 1.1836009\n",
      "Trained batch 942 batch loss 1.35984921 epoch total loss 1.18378794\n",
      "Trained batch 943 batch loss 1.21047413 epoch total loss 1.18381631\n",
      "Trained batch 944 batch loss 1.37318563 epoch total loss 1.18401682\n",
      "Trained batch 945 batch loss 1.23087847 epoch total loss 1.18406641\n",
      "Trained batch 946 batch loss 1.25427341 epoch total loss 1.18414056\n",
      "Trained batch 947 batch loss 1.25274658 epoch total loss 1.18421304\n",
      "Trained batch 948 batch loss 1.26174569 epoch total loss 1.1842947\n",
      "Trained batch 949 batch loss 1.21138179 epoch total loss 1.18432331\n",
      "Trained batch 950 batch loss 1.24306273 epoch total loss 1.18438518\n",
      "Trained batch 951 batch loss 1.21430659 epoch total loss 1.18441665\n",
      "Trained batch 952 batch loss 1.28072143 epoch total loss 1.18451786\n",
      "Trained batch 953 batch loss 1.23437619 epoch total loss 1.18457019\n",
      "Trained batch 954 batch loss 1.29849744 epoch total loss 1.18468952\n",
      "Trained batch 955 batch loss 1.15122402 epoch total loss 1.18465459\n",
      "Trained batch 956 batch loss 1.08718443 epoch total loss 1.18455255\n",
      "Trained batch 957 batch loss 1.23781621 epoch total loss 1.18460822\n",
      "Trained batch 958 batch loss 1.0824995 epoch total loss 1.18450165\n",
      "Trained batch 959 batch loss 1.05706954 epoch total loss 1.18436885\n",
      "Trained batch 960 batch loss 1.22075438 epoch total loss 1.18440664\n",
      "Trained batch 961 batch loss 1.09733236 epoch total loss 1.18431604\n",
      "Trained batch 962 batch loss 1.02610481 epoch total loss 1.18415153\n",
      "Trained batch 963 batch loss 1.08880651 epoch total loss 1.18405259\n",
      "Trained batch 964 batch loss 1.12504375 epoch total loss 1.18399131\n",
      "Trained batch 965 batch loss 1.0909878 epoch total loss 1.18389499\n",
      "Trained batch 966 batch loss 1.11371624 epoch total loss 1.18382239\n",
      "Trained batch 967 batch loss 0.992025375 epoch total loss 1.18362403\n",
      "Trained batch 968 batch loss 1.1199708 epoch total loss 1.18355834\n",
      "Trained batch 969 batch loss 1.15092552 epoch total loss 1.18352461\n",
      "Trained batch 970 batch loss 1.17271781 epoch total loss 1.1835134\n",
      "Trained batch 971 batch loss 1.23856139 epoch total loss 1.18357015\n",
      "Trained batch 972 batch loss 1.29513884 epoch total loss 1.18368495\n",
      "Trained batch 973 batch loss 1.20538533 epoch total loss 1.18370724\n",
      "Trained batch 974 batch loss 1.21794009 epoch total loss 1.1837424\n",
      "Trained batch 975 batch loss 1.27001953 epoch total loss 1.18383086\n",
      "Trained batch 976 batch loss 1.3010056 epoch total loss 1.1839509\n",
      "Trained batch 977 batch loss 1.27411819 epoch total loss 1.18404329\n",
      "Trained batch 978 batch loss 1.12456918 epoch total loss 1.18398237\n",
      "Trained batch 979 batch loss 1.19382811 epoch total loss 1.18399251\n",
      "Trained batch 980 batch loss 1.21100128 epoch total loss 1.18402016\n",
      "Trained batch 981 batch loss 1.16930938 epoch total loss 1.18400514\n",
      "Trained batch 982 batch loss 1.19626057 epoch total loss 1.18401766\n",
      "Trained batch 983 batch loss 1.24085379 epoch total loss 1.18407547\n",
      "Trained batch 984 batch loss 1.22090602 epoch total loss 1.18411291\n",
      "Trained batch 985 batch loss 1.31557345 epoch total loss 1.18424642\n",
      "Trained batch 986 batch loss 1.27346194 epoch total loss 1.18433678\n",
      "Trained batch 987 batch loss 1.36305439 epoch total loss 1.18451786\n",
      "Trained batch 988 batch loss 1.30266047 epoch total loss 1.18463743\n",
      "Trained batch 989 batch loss 1.191818 epoch total loss 1.18464458\n",
      "Trained batch 990 batch loss 1.19769788 epoch total loss 1.18465781\n",
      "Trained batch 991 batch loss 1.15030384 epoch total loss 1.18462312\n",
      "Trained batch 992 batch loss 1.16749609 epoch total loss 1.18460584\n",
      "Trained batch 993 batch loss 1.2681309 epoch total loss 1.18469\n",
      "Trained batch 994 batch loss 1.16250849 epoch total loss 1.18466771\n",
      "Trained batch 995 batch loss 1.29189539 epoch total loss 1.18477547\n",
      "Trained batch 996 batch loss 1.19546878 epoch total loss 1.1847862\n",
      "Trained batch 997 batch loss 1.18218207 epoch total loss 1.18478346\n",
      "Trained batch 998 batch loss 1.17755866 epoch total loss 1.18477631\n",
      "Trained batch 999 batch loss 1.20035887 epoch total loss 1.1847918\n",
      "Trained batch 1000 batch loss 1.42872977 epoch total loss 1.18503582\n",
      "Trained batch 1001 batch loss 1.34615552 epoch total loss 1.18519676\n",
      "Trained batch 1002 batch loss 1.32205534 epoch total loss 1.18533337\n",
      "Trained batch 1003 batch loss 1.34522343 epoch total loss 1.18549275\n",
      "Trained batch 1004 batch loss 1.18377936 epoch total loss 1.18549109\n",
      "Trained batch 1005 batch loss 1.19371152 epoch total loss 1.18549931\n",
      "Trained batch 1006 batch loss 1.06704855 epoch total loss 1.18538153\n",
      "Trained batch 1007 batch loss 1.28455329 epoch total loss 1.18548\n",
      "Trained batch 1008 batch loss 1.13845408 epoch total loss 1.18543327\n",
      "Trained batch 1009 batch loss 1.08767056 epoch total loss 1.18533635\n",
      "Trained batch 1010 batch loss 1.05804849 epoch total loss 1.18521035\n",
      "Trained batch 1011 batch loss 1.02943313 epoch total loss 1.18505633\n",
      "Trained batch 1012 batch loss 0.985748 epoch total loss 1.18485928\n",
      "Trained batch 1013 batch loss 1.30407405 epoch total loss 1.18497705\n",
      "Trained batch 1014 batch loss 1.32065248 epoch total loss 1.18511081\n",
      "Trained batch 1015 batch loss 1.41814542 epoch total loss 1.1853404\n",
      "Trained batch 1016 batch loss 1.46895206 epoch total loss 1.18561959\n",
      "Trained batch 1017 batch loss 1.1967665 epoch total loss 1.18563056\n",
      "Trained batch 1018 batch loss 1.37998629 epoch total loss 1.18582141\n",
      "Trained batch 1019 batch loss 1.33732522 epoch total loss 1.18597007\n",
      "Trained batch 1020 batch loss 1.17334163 epoch total loss 1.18595767\n",
      "Trained batch 1021 batch loss 1.22392905 epoch total loss 1.18599486\n",
      "Trained batch 1022 batch loss 1.2565167 epoch total loss 1.18606377\n",
      "Trained batch 1023 batch loss 1.18057442 epoch total loss 1.1860584\n",
      "Trained batch 1024 batch loss 1.19057214 epoch total loss 1.18606281\n",
      "Trained batch 1025 batch loss 1.16179562 epoch total loss 1.18603909\n",
      "Trained batch 1026 batch loss 1.09935451 epoch total loss 1.18595457\n",
      "Trained batch 1027 batch loss 1.08971584 epoch total loss 1.18586087\n",
      "Trained batch 1028 batch loss 1.21445704 epoch total loss 1.18588877\n",
      "Trained batch 1029 batch loss 1.12585282 epoch total loss 1.18583035\n",
      "Trained batch 1030 batch loss 1.15742528 epoch total loss 1.18580282\n",
      "Trained batch 1031 batch loss 1.13357759 epoch total loss 1.18575215\n",
      "Trained batch 1032 batch loss 1.09740508 epoch total loss 1.18566656\n",
      "Trained batch 1033 batch loss 1.10851407 epoch total loss 1.18559194\n",
      "Trained batch 1034 batch loss 1.1256187 epoch total loss 1.18553388\n",
      "Trained batch 1035 batch loss 1.14925909 epoch total loss 1.18549883\n",
      "Trained batch 1036 batch loss 1.0953784 epoch total loss 1.18541181\n",
      "Trained batch 1037 batch loss 1.1667937 epoch total loss 1.18539381\n",
      "Trained batch 1038 batch loss 1.14451218 epoch total loss 1.18535447\n",
      "Trained batch 1039 batch loss 1.24201894 epoch total loss 1.18540907\n",
      "Trained batch 1040 batch loss 1.14142513 epoch total loss 1.18536687\n",
      "Trained batch 1041 batch loss 1.23642933 epoch total loss 1.18541586\n",
      "Trained batch 1042 batch loss 1.41066551 epoch total loss 1.18563199\n",
      "Trained batch 1043 batch loss 1.2693789 epoch total loss 1.18571234\n",
      "Trained batch 1044 batch loss 1.28134227 epoch total loss 1.18580401\n",
      "Trained batch 1045 batch loss 1.34465098 epoch total loss 1.185956\n",
      "Trained batch 1046 batch loss 1.25170803 epoch total loss 1.18601882\n",
      "Trained batch 1047 batch loss 1.31005 epoch total loss 1.18613732\n",
      "Trained batch 1048 batch loss 1.14075232 epoch total loss 1.18609393\n",
      "Trained batch 1049 batch loss 1.13248348 epoch total loss 1.18604279\n",
      "Trained batch 1050 batch loss 1.12187827 epoch total loss 1.18598163\n",
      "Trained batch 1051 batch loss 1.28488719 epoch total loss 1.18607581\n",
      "Trained batch 1052 batch loss 1.19657481 epoch total loss 1.1860857\n",
      "Trained batch 1053 batch loss 1.20822954 epoch total loss 1.1861068\n",
      "Trained batch 1054 batch loss 1.30732441 epoch total loss 1.18622184\n",
      "Trained batch 1055 batch loss 1.12542892 epoch total loss 1.18616426\n",
      "Trained batch 1056 batch loss 1.34737134 epoch total loss 1.18631697\n",
      "Trained batch 1057 batch loss 1.19506371 epoch total loss 1.18632531\n",
      "Trained batch 1058 batch loss 1.03243327 epoch total loss 1.18617988\n",
      "Trained batch 1059 batch loss 1.05369508 epoch total loss 1.18605471\n",
      "Trained batch 1060 batch loss 1.14554286 epoch total loss 1.18601656\n",
      "Trained batch 1061 batch loss 1.26712668 epoch total loss 1.18609285\n",
      "Trained batch 1062 batch loss 1.12268662 epoch total loss 1.18603325\n",
      "Trained batch 1063 batch loss 1.18845201 epoch total loss 1.18603551\n",
      "Trained batch 1064 batch loss 1.11281264 epoch total loss 1.18596661\n",
      "Trained batch 1065 batch loss 1.04960704 epoch total loss 1.18583858\n",
      "Trained batch 1066 batch loss 1.16524827 epoch total loss 1.18581927\n",
      "Trained batch 1067 batch loss 1.17959046 epoch total loss 1.18581343\n",
      "Trained batch 1068 batch loss 1.22568226 epoch total loss 1.18585074\n",
      "Trained batch 1069 batch loss 1.27159214 epoch total loss 1.18593097\n",
      "Trained batch 1070 batch loss 1.19100714 epoch total loss 1.18593574\n",
      "Trained batch 1071 batch loss 1.16738081 epoch total loss 1.18591845\n",
      "Trained batch 1072 batch loss 1.24664605 epoch total loss 1.18597519\n",
      "Trained batch 1073 batch loss 1.306229 epoch total loss 1.18608725\n",
      "Trained batch 1074 batch loss 1.1706152 epoch total loss 1.18607295\n",
      "Trained batch 1075 batch loss 1.08813727 epoch total loss 1.18598175\n",
      "Trained batch 1076 batch loss 1.11983728 epoch total loss 1.18592036\n",
      "Trained batch 1077 batch loss 1.14332247 epoch total loss 1.18588078\n",
      "Trained batch 1078 batch loss 1.01706338 epoch total loss 1.18572426\n",
      "Trained batch 1079 batch loss 1.18103898 epoch total loss 1.18571985\n",
      "Trained batch 1080 batch loss 1.11376619 epoch total loss 1.18565321\n",
      "Trained batch 1081 batch loss 1.123456 epoch total loss 1.18559563\n",
      "Trained batch 1082 batch loss 1.06287014 epoch total loss 1.18548226\n",
      "Trained batch 1083 batch loss 1.03752029 epoch total loss 1.18534553\n",
      "Trained batch 1084 batch loss 1.1459651 epoch total loss 1.18530929\n",
      "Trained batch 1085 batch loss 1.17114484 epoch total loss 1.18529618\n",
      "Trained batch 1086 batch loss 1.076478 epoch total loss 1.18519604\n",
      "Trained batch 1087 batch loss 1.50178432 epoch total loss 1.18548739\n",
      "Trained batch 1088 batch loss 1.16450024 epoch total loss 1.18546808\n",
      "Trained batch 1089 batch loss 1.07313097 epoch total loss 1.18536496\n",
      "Trained batch 1090 batch loss 0.989074 epoch total loss 1.18518484\n",
      "Trained batch 1091 batch loss 1.09197962 epoch total loss 1.18509936\n",
      "Trained batch 1092 batch loss 1.16684139 epoch total loss 1.18508267\n",
      "Trained batch 1093 batch loss 1.24568915 epoch total loss 1.18513811\n",
      "Trained batch 1094 batch loss 1.30154037 epoch total loss 1.18524444\n",
      "Trained batch 1095 batch loss 1.22182357 epoch total loss 1.18527782\n",
      "Trained batch 1096 batch loss 1.24767423 epoch total loss 1.1853348\n",
      "Trained batch 1097 batch loss 1.11213505 epoch total loss 1.18526816\n",
      "Trained batch 1098 batch loss 1.17979848 epoch total loss 1.18526316\n",
      "Trained batch 1099 batch loss 1.06555152 epoch total loss 1.1851542\n",
      "Trained batch 1100 batch loss 1.30459476 epoch total loss 1.1852628\n",
      "Trained batch 1101 batch loss 1.24808919 epoch total loss 1.18531978\n",
      "Trained batch 1102 batch loss 1.15154886 epoch total loss 1.18528914\n",
      "Trained batch 1103 batch loss 1.13334846 epoch total loss 1.18524194\n",
      "Trained batch 1104 batch loss 0.963419557 epoch total loss 1.18504107\n",
      "Trained batch 1105 batch loss 1.13623369 epoch total loss 1.18499684\n",
      "Trained batch 1106 batch loss 1.27390182 epoch total loss 1.18507719\n",
      "Trained batch 1107 batch loss 1.07755184 epoch total loss 1.18498\n",
      "Trained batch 1108 batch loss 1.12710035 epoch total loss 1.18492782\n",
      "Trained batch 1109 batch loss 1.15462327 epoch total loss 1.18490052\n",
      "Trained batch 1110 batch loss 1.15979016 epoch total loss 1.18487787\n",
      "Trained batch 1111 batch loss 1.33055663 epoch total loss 1.185009\n",
      "Trained batch 1112 batch loss 1.20404136 epoch total loss 1.18502617\n",
      "Trained batch 1113 batch loss 1.14892757 epoch total loss 1.18499374\n",
      "Trained batch 1114 batch loss 1.18908572 epoch total loss 1.18499744\n",
      "Trained batch 1115 batch loss 1.25787973 epoch total loss 1.18506289\n",
      "Trained batch 1116 batch loss 1.24279785 epoch total loss 1.18511462\n",
      "Trained batch 1117 batch loss 1.30188036 epoch total loss 1.18521917\n",
      "Trained batch 1118 batch loss 1.18512058 epoch total loss 1.18521905\n",
      "Trained batch 1119 batch loss 1.16060495 epoch total loss 1.18519711\n",
      "Trained batch 1120 batch loss 1.0445224 epoch total loss 1.18507159\n",
      "Trained batch 1121 batch loss 1.26500058 epoch total loss 1.18514287\n",
      "Trained batch 1122 batch loss 1.20724332 epoch total loss 1.18516254\n",
      "Trained batch 1123 batch loss 1.33176541 epoch total loss 1.1852932\n",
      "Trained batch 1124 batch loss 1.22585154 epoch total loss 1.1853292\n",
      "Trained batch 1125 batch loss 1.20397806 epoch total loss 1.18534577\n",
      "Trained batch 1126 batch loss 1.09985638 epoch total loss 1.18526983\n",
      "Trained batch 1127 batch loss 1.19059432 epoch total loss 1.1852746\n",
      "Trained batch 1128 batch loss 1.25649059 epoch total loss 1.18533766\n",
      "Trained batch 1129 batch loss 1.14367032 epoch total loss 1.18530083\n",
      "Trained batch 1130 batch loss 1.1188792 epoch total loss 1.18524206\n",
      "Trained batch 1131 batch loss 1.12998247 epoch total loss 1.18519318\n",
      "Trained batch 1132 batch loss 1.1787858 epoch total loss 1.18518758\n",
      "Trained batch 1133 batch loss 1.08153987 epoch total loss 1.18509614\n",
      "Trained batch 1134 batch loss 1.21792638 epoch total loss 1.18512499\n",
      "Trained batch 1135 batch loss 1.08365607 epoch total loss 1.18503559\n",
      "Trained batch 1136 batch loss 1.05198622 epoch total loss 1.18491852\n",
      "Trained batch 1137 batch loss 0.985481381 epoch total loss 1.18474305\n",
      "Trained batch 1138 batch loss 0.944620371 epoch total loss 1.18453205\n",
      "Trained batch 1139 batch loss 1.16326261 epoch total loss 1.18451333\n",
      "Trained batch 1140 batch loss 1.1194011 epoch total loss 1.18445611\n",
      "Trained batch 1141 batch loss 1.24381399 epoch total loss 1.1845082\n",
      "Trained batch 1142 batch loss 1.20968246 epoch total loss 1.18453026\n",
      "Trained batch 1143 batch loss 1.20049727 epoch total loss 1.18454421\n",
      "Trained batch 1144 batch loss 1.06782258 epoch total loss 1.18444216\n",
      "Trained batch 1145 batch loss 0.980598 epoch total loss 1.18426418\n",
      "Trained batch 1146 batch loss 1.05572033 epoch total loss 1.18415189\n",
      "Trained batch 1147 batch loss 1.18344808 epoch total loss 1.18415129\n",
      "Trained batch 1148 batch loss 1.20410812 epoch total loss 1.1841687\n",
      "Trained batch 1149 batch loss 1.19685686 epoch total loss 1.18417978\n",
      "Trained batch 1150 batch loss 1.09626555 epoch total loss 1.18410337\n",
      "Trained batch 1151 batch loss 1.26962149 epoch total loss 1.18417764\n",
      "Trained batch 1152 batch loss 1.05501461 epoch total loss 1.18406558\n",
      "Trained batch 1153 batch loss 0.987244606 epoch total loss 1.18389499\n",
      "Trained batch 1154 batch loss 0.94950974 epoch total loss 1.18369186\n",
      "Trained batch 1155 batch loss 1.04365325 epoch total loss 1.18357062\n",
      "Trained batch 1156 batch loss 1.04298198 epoch total loss 1.18344903\n",
      "Trained batch 1157 batch loss 1.15786278 epoch total loss 1.18342686\n",
      "Trained batch 1158 batch loss 1.12058675 epoch total loss 1.18337262\n",
      "Trained batch 1159 batch loss 1.16446042 epoch total loss 1.18335629\n",
      "Trained batch 1160 batch loss 1.33256066 epoch total loss 1.18348479\n",
      "Trained batch 1161 batch loss 1.25020087 epoch total loss 1.18354237\n",
      "Trained batch 1162 batch loss 1.29034114 epoch total loss 1.18363416\n",
      "Trained batch 1163 batch loss 1.06260669 epoch total loss 1.18353009\n",
      "Trained batch 1164 batch loss 1.11516011 epoch total loss 1.18347132\n",
      "Trained batch 1165 batch loss 1.16733217 epoch total loss 1.18345749\n",
      "Trained batch 1166 batch loss 1.29266047 epoch total loss 1.18355119\n",
      "Trained batch 1167 batch loss 1.31037045 epoch total loss 1.18365991\n",
      "Trained batch 1168 batch loss 1.24432671 epoch total loss 1.18371189\n",
      "Trained batch 1169 batch loss 1.30486298 epoch total loss 1.18381548\n",
      "Trained batch 1170 batch loss 1.15552604 epoch total loss 1.18379128\n",
      "Trained batch 1171 batch loss 1.04010928 epoch total loss 1.18366861\n",
      "Trained batch 1172 batch loss 1.1666106 epoch total loss 1.18365407\n",
      "Trained batch 1173 batch loss 1.24083328 epoch total loss 1.18370283\n",
      "Trained batch 1174 batch loss 1.33210194 epoch total loss 1.18382931\n",
      "Trained batch 1175 batch loss 1.41396058 epoch total loss 1.18402505\n",
      "Trained batch 1176 batch loss 1.29459429 epoch total loss 1.18411911\n",
      "Trained batch 1177 batch loss 1.29987752 epoch total loss 1.18421745\n",
      "Trained batch 1178 batch loss 1.28542578 epoch total loss 1.1843034\n",
      "Trained batch 1179 batch loss 1.228284 epoch total loss 1.18434072\n",
      "Trained batch 1180 batch loss 1.16730762 epoch total loss 1.18432629\n",
      "Trained batch 1181 batch loss 1.08147728 epoch total loss 1.18423915\n",
      "Trained batch 1182 batch loss 1.17868543 epoch total loss 1.1842345\n",
      "Trained batch 1183 batch loss 1.16822553 epoch total loss 1.18422091\n",
      "Trained batch 1184 batch loss 1.18303597 epoch total loss 1.18421984\n",
      "Trained batch 1185 batch loss 1.18416333 epoch total loss 1.18421984\n",
      "Trained batch 1186 batch loss 1.05578673 epoch total loss 1.1841116\n",
      "Trained batch 1187 batch loss 1.1012044 epoch total loss 1.18404174\n",
      "Trained batch 1188 batch loss 1.09942794 epoch total loss 1.18397057\n",
      "Trained batch 1189 batch loss 1.02293301 epoch total loss 1.18383515\n",
      "Trained batch 1190 batch loss 1.10165501 epoch total loss 1.18376613\n",
      "Trained batch 1191 batch loss 1.08271086 epoch total loss 1.18368125\n",
      "Trained batch 1192 batch loss 1.17279088 epoch total loss 1.18367219\n",
      "Trained batch 1193 batch loss 1.2711637 epoch total loss 1.1837455\n",
      "Trained batch 1194 batch loss 1.22368371 epoch total loss 1.18377888\n",
      "Trained batch 1195 batch loss 1.233971 epoch total loss 1.18382096\n",
      "Trained batch 1196 batch loss 1.15402913 epoch total loss 1.18379605\n",
      "Trained batch 1197 batch loss 1.22263575 epoch total loss 1.18382847\n",
      "Trained batch 1198 batch loss 1.2312001 epoch total loss 1.18386805\n",
      "Trained batch 1199 batch loss 1.30586171 epoch total loss 1.18396986\n",
      "Trained batch 1200 batch loss 1.20862544 epoch total loss 1.18399036\n",
      "Trained batch 1201 batch loss 1.24117613 epoch total loss 1.18403804\n",
      "Trained batch 1202 batch loss 1.19173455 epoch total loss 1.18404448\n",
      "Trained batch 1203 batch loss 1.13742566 epoch total loss 1.18400574\n",
      "Trained batch 1204 batch loss 1.25470328 epoch total loss 1.18406451\n",
      "Trained batch 1205 batch loss 1.25610936 epoch total loss 1.18412423\n",
      "Trained batch 1206 batch loss 1.17026567 epoch total loss 1.18411279\n",
      "Trained batch 1207 batch loss 1.14089727 epoch total loss 1.18407702\n",
      "Trained batch 1208 batch loss 1.04970825 epoch total loss 1.18396568\n",
      "Trained batch 1209 batch loss 0.925893605 epoch total loss 1.1837523\n",
      "Trained batch 1210 batch loss 1.07851636 epoch total loss 1.18366528\n",
      "Trained batch 1211 batch loss 1.08467078 epoch total loss 1.18358362\n",
      "Trained batch 1212 batch loss 1.16772676 epoch total loss 1.1835705\n",
      "Trained batch 1213 batch loss 0.98974216 epoch total loss 1.18341064\n",
      "Trained batch 1214 batch loss 1.10146713 epoch total loss 1.18334317\n",
      "Trained batch 1215 batch loss 1.12353992 epoch total loss 1.18329394\n",
      "Trained batch 1216 batch loss 1.21394145 epoch total loss 1.18331921\n",
      "Trained batch 1217 batch loss 1.18188989 epoch total loss 1.18331802\n",
      "Trained batch 1218 batch loss 1.06479192 epoch total loss 1.18322074\n",
      "Trained batch 1219 batch loss 1.08985078 epoch total loss 1.18314409\n",
      "Trained batch 1220 batch loss 1.1476109 epoch total loss 1.18311501\n",
      "Trained batch 1221 batch loss 1.197644 epoch total loss 1.18312681\n",
      "Trained batch 1222 batch loss 1.30942607 epoch total loss 1.18323028\n",
      "Trained batch 1223 batch loss 1.20202029 epoch total loss 1.18324566\n",
      "Trained batch 1224 batch loss 1.18637991 epoch total loss 1.18324816\n",
      "Trained batch 1225 batch loss 1.29730451 epoch total loss 1.18334138\n",
      "Trained batch 1226 batch loss 1.26176322 epoch total loss 1.18340528\n",
      "Trained batch 1227 batch loss 1.21970069 epoch total loss 1.18343484\n",
      "Trained batch 1228 batch loss 1.30790019 epoch total loss 1.18353617\n",
      "Trained batch 1229 batch loss 1.28960657 epoch total loss 1.18362248\n",
      "Trained batch 1230 batch loss 1.16183543 epoch total loss 1.18360472\n",
      "Trained batch 1231 batch loss 1.12295818 epoch total loss 1.18355548\n",
      "Trained batch 1232 batch loss 1.13205254 epoch total loss 1.18351364\n",
      "Trained batch 1233 batch loss 1.0728 epoch total loss 1.18342388\n",
      "Trained batch 1234 batch loss 1.07565308 epoch total loss 1.1833365\n",
      "Trained batch 1235 batch loss 1.09166884 epoch total loss 1.18326235\n",
      "Trained batch 1236 batch loss 1.25928402 epoch total loss 1.18332386\n",
      "Trained batch 1237 batch loss 1.16146481 epoch total loss 1.18330622\n",
      "Trained batch 1238 batch loss 1.13031912 epoch total loss 1.18326342\n",
      "Trained batch 1239 batch loss 1.19319332 epoch total loss 1.18327153\n",
      "Trained batch 1240 batch loss 1.05018663 epoch total loss 1.18316412\n",
      "Trained batch 1241 batch loss 1.25288439 epoch total loss 1.18322039\n",
      "Trained batch 1242 batch loss 1.3215158 epoch total loss 1.18333173\n",
      "Trained batch 1243 batch loss 1.23067689 epoch total loss 1.18336987\n",
      "Trained batch 1244 batch loss 1.20000374 epoch total loss 1.18338323\n",
      "Trained batch 1245 batch loss 1.16799223 epoch total loss 1.18337083\n",
      "Trained batch 1246 batch loss 1.16654229 epoch total loss 1.18335724\n",
      "Trained batch 1247 batch loss 1.18663859 epoch total loss 1.18335986\n",
      "Trained batch 1248 batch loss 1.23935604 epoch total loss 1.1834048\n",
      "Trained batch 1249 batch loss 1.19225454 epoch total loss 1.18341184\n",
      "Trained batch 1250 batch loss 1.15271568 epoch total loss 1.18338728\n",
      "Trained batch 1251 batch loss 1.181198 epoch total loss 1.18338549\n",
      "Trained batch 1252 batch loss 1.27860427 epoch total loss 1.18346155\n",
      "Trained batch 1253 batch loss 1.22979963 epoch total loss 1.18349862\n",
      "Trained batch 1254 batch loss 1.2675339 epoch total loss 1.18356562\n",
      "Trained batch 1255 batch loss 1.30529642 epoch total loss 1.18366265\n",
      "Trained batch 1256 batch loss 1.27040422 epoch total loss 1.18373168\n",
      "Trained batch 1257 batch loss 1.2598927 epoch total loss 1.18379223\n",
      "Trained batch 1258 batch loss 1.16892195 epoch total loss 1.18378043\n",
      "Trained batch 1259 batch loss 1.13823581 epoch total loss 1.18374419\n",
      "Trained batch 1260 batch loss 1.19702888 epoch total loss 1.1837548\n",
      "Trained batch 1261 batch loss 1.19445682 epoch total loss 1.18376327\n",
      "Trained batch 1262 batch loss 1.24137616 epoch total loss 1.18380892\n",
      "Trained batch 1263 batch loss 1.15233827 epoch total loss 1.18378401\n",
      "Trained batch 1264 batch loss 1.19414592 epoch total loss 1.18379211\n",
      "Trained batch 1265 batch loss 1.10889196 epoch total loss 1.18373287\n",
      "Trained batch 1266 batch loss 1.13033891 epoch total loss 1.18369079\n",
      "Trained batch 1267 batch loss 1.03625584 epoch total loss 1.18357444\n",
      "Trained batch 1268 batch loss 1.00111735 epoch total loss 1.18343043\n",
      "Trained batch 1269 batch loss 1.08830643 epoch total loss 1.18335545\n",
      "Trained batch 1270 batch loss 1.08519757 epoch total loss 1.1832782\n",
      "Trained batch 1271 batch loss 1.16318679 epoch total loss 1.18326235\n",
      "Trained batch 1272 batch loss 1.08813953 epoch total loss 1.1831876\n",
      "Trained batch 1273 batch loss 1.08234334 epoch total loss 1.18310845\n",
      "Trained batch 1274 batch loss 1.13642585 epoch total loss 1.18307185\n",
      "Trained batch 1275 batch loss 1.16843939 epoch total loss 1.18306041\n",
      "Trained batch 1276 batch loss 1.06865835 epoch total loss 1.18297064\n",
      "Trained batch 1277 batch loss 1.29653585 epoch total loss 1.18305957\n",
      "Trained batch 1278 batch loss 1.22835279 epoch total loss 1.1830951\n",
      "Trained batch 1279 batch loss 1.20546508 epoch total loss 1.1831125\n",
      "Trained batch 1280 batch loss 1.05440629 epoch total loss 1.18301201\n",
      "Trained batch 1281 batch loss 1.08619463 epoch total loss 1.18293643\n",
      "Trained batch 1282 batch loss 1.2211839 epoch total loss 1.18296623\n",
      "Trained batch 1283 batch loss 1.1749965 epoch total loss 1.18296\n",
      "Trained batch 1284 batch loss 1.24075651 epoch total loss 1.18300509\n",
      "Trained batch 1285 batch loss 1.27692223 epoch total loss 1.18307817\n",
      "Trained batch 1286 batch loss 1.21935678 epoch total loss 1.18310642\n",
      "Trained batch 1287 batch loss 1.25153971 epoch total loss 1.18315959\n",
      "Trained batch 1288 batch loss 1.24486756 epoch total loss 1.18320751\n",
      "Trained batch 1289 batch loss 1.17956686 epoch total loss 1.18320477\n",
      "Trained batch 1290 batch loss 1.31313682 epoch total loss 1.18330538\n",
      "Trained batch 1291 batch loss 1.22186768 epoch total loss 1.1833353\n",
      "Trained batch 1292 batch loss 1.26488638 epoch total loss 1.18339849\n",
      "Trained batch 1293 batch loss 1.28286695 epoch total loss 1.18347538\n",
      "Trained batch 1294 batch loss 1.19985747 epoch total loss 1.18348801\n",
      "Trained batch 1295 batch loss 1.14566636 epoch total loss 1.18345881\n",
      "Trained batch 1296 batch loss 1.18579078 epoch total loss 1.18346059\n",
      "Trained batch 1297 batch loss 1.2304883 epoch total loss 1.18349683\n",
      "Trained batch 1298 batch loss 1.17700601 epoch total loss 1.18349183\n",
      "Trained batch 1299 batch loss 1.18725574 epoch total loss 1.18349469\n",
      "Trained batch 1300 batch loss 1.15950501 epoch total loss 1.18347633\n",
      "Trained batch 1301 batch loss 1.09131646 epoch total loss 1.1834054\n",
      "Trained batch 1302 batch loss 1.20612991 epoch total loss 1.18342292\n",
      "Trained batch 1303 batch loss 1.12126279 epoch total loss 1.18337524\n",
      "Trained batch 1304 batch loss 1.14616477 epoch total loss 1.18334663\n",
      "Trained batch 1305 batch loss 1.25741339 epoch total loss 1.18340337\n",
      "Trained batch 1306 batch loss 1.14610779 epoch total loss 1.18337488\n",
      "Trained batch 1307 batch loss 1.19443762 epoch total loss 1.18338335\n",
      "Trained batch 1308 batch loss 1.05597448 epoch total loss 1.18328595\n",
      "Trained batch 1309 batch loss 1.13180304 epoch total loss 1.18324661\n",
      "Trained batch 1310 batch loss 1.02044654 epoch total loss 1.18312228\n",
      "Trained batch 1311 batch loss 1.14685237 epoch total loss 1.18309462\n",
      "Trained batch 1312 batch loss 1.27832317 epoch total loss 1.18316722\n",
      "Trained batch 1313 batch loss 1.20056939 epoch total loss 1.18318045\n",
      "Trained batch 1314 batch loss 1.20205903 epoch total loss 1.18319488\n",
      "Trained batch 1315 batch loss 1.16997337 epoch total loss 1.18318474\n",
      "Trained batch 1316 batch loss 1.18013191 epoch total loss 1.18318248\n",
      "Trained batch 1317 batch loss 1.28148007 epoch total loss 1.1832571\n",
      "Trained batch 1318 batch loss 1.06707215 epoch total loss 1.18316889\n",
      "Trained batch 1319 batch loss 1.10774231 epoch total loss 1.18311179\n",
      "Trained batch 1320 batch loss 1.11134446 epoch total loss 1.18305743\n",
      "Trained batch 1321 batch loss 1.23360384 epoch total loss 1.18309569\n",
      "Trained batch 1322 batch loss 1.09124982 epoch total loss 1.18302619\n",
      "Trained batch 1323 batch loss 1.15995455 epoch total loss 1.18300879\n",
      "Trained batch 1324 batch loss 1.19194233 epoch total loss 1.18301547\n",
      "Trained batch 1325 batch loss 1.22890615 epoch total loss 1.18305016\n",
      "Trained batch 1326 batch loss 1.08693862 epoch total loss 1.18297756\n",
      "Trained batch 1327 batch loss 1.07288337 epoch total loss 1.18289459\n",
      "Trained batch 1328 batch loss 1.04831374 epoch total loss 1.18279326\n",
      "Trained batch 1329 batch loss 1.15723658 epoch total loss 1.18277407\n",
      "Trained batch 1330 batch loss 1.21668363 epoch total loss 1.18279958\n",
      "Trained batch 1331 batch loss 1.1826272 epoch total loss 1.18279946\n",
      "Trained batch 1332 batch loss 1.24743581 epoch total loss 1.18284798\n",
      "Trained batch 1333 batch loss 1.19496632 epoch total loss 1.18285704\n",
      "Trained batch 1334 batch loss 1.06949067 epoch total loss 1.18277204\n",
      "Trained batch 1335 batch loss 1.25876749 epoch total loss 1.1828289\n",
      "Trained batch 1336 batch loss 1.26315713 epoch total loss 1.1828891\n",
      "Trained batch 1337 batch loss 1.23561966 epoch total loss 1.18292856\n",
      "Trained batch 1338 batch loss 1.21104789 epoch total loss 1.18294954\n",
      "Trained batch 1339 batch loss 1.17280364 epoch total loss 1.18294203\n",
      "Trained batch 1340 batch loss 1.03548312 epoch total loss 1.182832\n",
      "Trained batch 1341 batch loss 1.10843682 epoch total loss 1.18277645\n",
      "Trained batch 1342 batch loss 1.16474569 epoch total loss 1.1827631\n",
      "Trained batch 1343 batch loss 1.19120812 epoch total loss 1.1827693\n",
      "Trained batch 1344 batch loss 1.22797632 epoch total loss 1.18280303\n",
      "Trained batch 1345 batch loss 1.06084907 epoch total loss 1.18271232\n",
      "Trained batch 1346 batch loss 1.17789793 epoch total loss 1.18270874\n",
      "Trained batch 1347 batch loss 1.11351252 epoch total loss 1.18265736\n",
      "Trained batch 1348 batch loss 1.1894784 epoch total loss 1.18266237\n",
      "Trained batch 1349 batch loss 1.18240714 epoch total loss 1.18266213\n",
      "Trained batch 1350 batch loss 1.19457185 epoch total loss 1.18267095\n",
      "Trained batch 1351 batch loss 1.0874424 epoch total loss 1.1826005\n",
      "Trained batch 1352 batch loss 1.18245029 epoch total loss 1.18260038\n",
      "Trained batch 1353 batch loss 1.20028591 epoch total loss 1.18261349\n",
      "Trained batch 1354 batch loss 1.26328111 epoch total loss 1.1826731\n",
      "Trained batch 1355 batch loss 1.2192049 epoch total loss 1.1827\n",
      "Trained batch 1356 batch loss 1.13532281 epoch total loss 1.18266523\n",
      "Trained batch 1357 batch loss 1.15376115 epoch total loss 1.18264389\n",
      "Trained batch 1358 batch loss 1.06929255 epoch total loss 1.18256044\n",
      "Trained batch 1359 batch loss 1.1799767 epoch total loss 1.18255854\n",
      "Trained batch 1360 batch loss 1.23567665 epoch total loss 1.18259764\n",
      "Trained batch 1361 batch loss 1.21787179 epoch total loss 1.18262351\n",
      "Trained batch 1362 batch loss 1.32173347 epoch total loss 1.18272567\n",
      "Trained batch 1363 batch loss 1.27729249 epoch total loss 1.18279517\n",
      "Trained batch 1364 batch loss 1.30418742 epoch total loss 1.1828841\n",
      "Trained batch 1365 batch loss 1.22579455 epoch total loss 1.18291557\n",
      "Trained batch 1366 batch loss 1.11344218 epoch total loss 1.18286467\n",
      "Trained batch 1367 batch loss 1.1591742 epoch total loss 1.18284738\n",
      "Trained batch 1368 batch loss 1.17514312 epoch total loss 1.18284178\n",
      "Trained batch 1369 batch loss 1.25111294 epoch total loss 1.18289161\n",
      "Trained batch 1370 batch loss 1.14156 epoch total loss 1.18286145\n",
      "Trained batch 1371 batch loss 1.23333812 epoch total loss 1.1828984\n",
      "Trained batch 1372 batch loss 1.12289596 epoch total loss 1.18285465\n",
      "Trained batch 1373 batch loss 1.13141525 epoch total loss 1.18281722\n",
      "Trained batch 1374 batch loss 1.27041698 epoch total loss 1.182881\n",
      "Trained batch 1375 batch loss 1.20976675 epoch total loss 1.18290043\n",
      "Trained batch 1376 batch loss 1.11807621 epoch total loss 1.18285334\n",
      "Trained batch 1377 batch loss 0.986296 epoch total loss 1.18271065\n",
      "Trained batch 1378 batch loss 1.03805077 epoch total loss 1.18260562\n",
      "Trained batch 1379 batch loss 1.16706204 epoch total loss 1.18259442\n",
      "Trained batch 1380 batch loss 1.10563493 epoch total loss 1.18253863\n",
      "Trained batch 1381 batch loss 1.16712356 epoch total loss 1.18252742\n",
      "Trained batch 1382 batch loss 1.08204114 epoch total loss 1.18245471\n",
      "Trained batch 1383 batch loss 1.22454548 epoch total loss 1.1824851\n",
      "Trained batch 1384 batch loss 1.33083558 epoch total loss 1.18259227\n",
      "Trained batch 1385 batch loss 1.13345313 epoch total loss 1.18255687\n",
      "Trained batch 1386 batch loss 1.32711172 epoch total loss 1.18266118\n",
      "Trained batch 1387 batch loss 1.43183279 epoch total loss 1.18284082\n",
      "Trained batch 1388 batch loss 1.4921093 epoch total loss 1.18306363\n",
      "Epoch 5 train loss 1.1830636262893677\n",
      "Validated batch 1 batch loss 1.21115398\n",
      "Validated batch 2 batch loss 1.13207722\n",
      "Validated batch 3 batch loss 1.13606405\n",
      "Validated batch 4 batch loss 1.13240492\n",
      "Validated batch 5 batch loss 1.10261798\n",
      "Validated batch 6 batch loss 1.2281729\n",
      "Validated batch 7 batch loss 1.16048527\n",
      "Validated batch 8 batch loss 1.13539159\n",
      "Validated batch 9 batch loss 1.24568307\n",
      "Validated batch 10 batch loss 1.19490361\n",
      "Validated batch 11 batch loss 1.10090852\n",
      "Validated batch 12 batch loss 1.05895209\n",
      "Validated batch 13 batch loss 1.2029959\n",
      "Validated batch 14 batch loss 1.20988441\n",
      "Validated batch 15 batch loss 1.34292877\n",
      "Validated batch 16 batch loss 1.30058694\n",
      "Validated batch 17 batch loss 1.19011092\n",
      "Validated batch 18 batch loss 1.2899909\n",
      "Validated batch 19 batch loss 1.22350287\n",
      "Validated batch 20 batch loss 1.20608568\n",
      "Validated batch 21 batch loss 1.19243753\n",
      "Validated batch 22 batch loss 0.955132663\n",
      "Validated batch 23 batch loss 1.17688084\n",
      "Validated batch 24 batch loss 1.12814724\n",
      "Validated batch 25 batch loss 1.08808541\n",
      "Validated batch 26 batch loss 1.13898063\n",
      "Validated batch 27 batch loss 1.12570882\n",
      "Validated batch 28 batch loss 1.15148032\n",
      "Validated batch 29 batch loss 1.2038883\n",
      "Validated batch 30 batch loss 1.21334577\n",
      "Validated batch 31 batch loss 1.1119014\n",
      "Validated batch 32 batch loss 1.19004202\n",
      "Validated batch 33 batch loss 1.17403245\n",
      "Validated batch 34 batch loss 1.1878463\n",
      "Validated batch 35 batch loss 1.17915833\n",
      "Validated batch 36 batch loss 1.14060295\n",
      "Validated batch 37 batch loss 1.17084956\n",
      "Validated batch 38 batch loss 1.16994178\n",
      "Validated batch 39 batch loss 1.13990152\n",
      "Validated batch 40 batch loss 1.31484008\n",
      "Validated batch 41 batch loss 1.23388052\n",
      "Validated batch 42 batch loss 1.04858494\n",
      "Validated batch 43 batch loss 1.25835788\n",
      "Validated batch 44 batch loss 1.14899969\n",
      "Validated batch 45 batch loss 1.0830189\n",
      "Validated batch 46 batch loss 1.19416249\n",
      "Validated batch 47 batch loss 1.27845478\n",
      "Validated batch 48 batch loss 1.18990159\n",
      "Validated batch 49 batch loss 1.11942744\n",
      "Validated batch 50 batch loss 1.13243139\n",
      "Validated batch 51 batch loss 1.08795679\n",
      "Validated batch 52 batch loss 1.20304859\n",
      "Validated batch 53 batch loss 1.22455847\n",
      "Validated batch 54 batch loss 1.0985986\n",
      "Validated batch 55 batch loss 1.21450806\n",
      "Validated batch 56 batch loss 1.16790843\n",
      "Validated batch 57 batch loss 1.22054267\n",
      "Validated batch 58 batch loss 1.22821808\n",
      "Validated batch 59 batch loss 1.18946314\n",
      "Validated batch 60 batch loss 1.09151411\n",
      "Validated batch 61 batch loss 1.13509691\n",
      "Validated batch 62 batch loss 1.18512034\n",
      "Validated batch 63 batch loss 1.18210077\n",
      "Validated batch 64 batch loss 1.21110344\n",
      "Validated batch 65 batch loss 1.22199297\n",
      "Validated batch 66 batch loss 1.40395987\n",
      "Validated batch 67 batch loss 1.21385956\n",
      "Validated batch 68 batch loss 1.19353592\n",
      "Validated batch 69 batch loss 1.07939935\n",
      "Validated batch 70 batch loss 1.11272645\n",
      "Validated batch 71 batch loss 1.21594691\n",
      "Validated batch 72 batch loss 1.14043272\n",
      "Validated batch 73 batch loss 1.14925325\n",
      "Validated batch 74 batch loss 1.20996261\n",
      "Validated batch 75 batch loss 1.25518918\n",
      "Validated batch 76 batch loss 1.24537718\n",
      "Validated batch 77 batch loss 1.29476881\n",
      "Validated batch 78 batch loss 1.19065535\n",
      "Validated batch 79 batch loss 1.14278579\n",
      "Validated batch 80 batch loss 1.20664513\n",
      "Validated batch 81 batch loss 1.1443789\n",
      "Validated batch 82 batch loss 1.21120417\n",
      "Validated batch 83 batch loss 1.29998028\n",
      "Validated batch 84 batch loss 1.23051453\n",
      "Validated batch 85 batch loss 1.21852672\n",
      "Validated batch 86 batch loss 1.35810304\n",
      "Validated batch 87 batch loss 1.05445457\n",
      "Validated batch 88 batch loss 1.21926844\n",
      "Validated batch 89 batch loss 1.03920138\n",
      "Validated batch 90 batch loss 1.13615358\n",
      "Validated batch 91 batch loss 1.27461183\n",
      "Validated batch 92 batch loss 1.11381638\n",
      "Validated batch 93 batch loss 1.16391873\n",
      "Validated batch 94 batch loss 1.10843682\n",
      "Validated batch 95 batch loss 1.13341618\n",
      "Validated batch 96 batch loss 1.12489355\n",
      "Validated batch 97 batch loss 1.12891877\n",
      "Validated batch 98 batch loss 1.24958563\n",
      "Validated batch 99 batch loss 1.16819751\n",
      "Validated batch 100 batch loss 1.24987149\n",
      "Validated batch 101 batch loss 1.24467921\n",
      "Validated batch 102 batch loss 1.22624803\n",
      "Validated batch 103 batch loss 1.1899\n",
      "Validated batch 104 batch loss 1.35987711\n",
      "Validated batch 105 batch loss 1.25339794\n",
      "Validated batch 106 batch loss 1.2796104\n",
      "Validated batch 107 batch loss 1.29707468\n",
      "Validated batch 108 batch loss 1.31758404\n",
      "Validated batch 109 batch loss 1.28691125\n",
      "Validated batch 110 batch loss 1.13821483\n",
      "Validated batch 111 batch loss 1.21521783\n",
      "Validated batch 112 batch loss 1.25344443\n",
      "Validated batch 113 batch loss 1.26243591\n",
      "Validated batch 114 batch loss 1.13236153\n",
      "Validated batch 115 batch loss 1.17271948\n",
      "Validated batch 116 batch loss 1.18686724\n",
      "Validated batch 117 batch loss 1.16748416\n",
      "Validated batch 118 batch loss 1.1558336\n",
      "Validated batch 119 batch loss 1.16223633\n",
      "Validated batch 120 batch loss 1.2373389\n",
      "Validated batch 121 batch loss 1.29691482\n",
      "Validated batch 122 batch loss 1.13706613\n",
      "Validated batch 123 batch loss 1.18404078\n",
      "Validated batch 124 batch loss 1.10902143\n",
      "Validated batch 125 batch loss 1.23257732\n",
      "Validated batch 126 batch loss 1.20005941\n",
      "Validated batch 127 batch loss 1.10518265\n",
      "Validated batch 128 batch loss 1.24400902\n",
      "Validated batch 129 batch loss 1.21983182\n",
      "Validated batch 130 batch loss 1.25801563\n",
      "Validated batch 131 batch loss 1.17273986\n",
      "Validated batch 132 batch loss 1.21539056\n",
      "Validated batch 133 batch loss 1.12959528\n",
      "Validated batch 134 batch loss 1.16550493\n",
      "Validated batch 135 batch loss 1.19373262\n",
      "Validated batch 136 batch loss 1.12131476\n",
      "Validated batch 137 batch loss 1.18845809\n",
      "Validated batch 138 batch loss 1.16951132\n",
      "Validated batch 139 batch loss 1.17471218\n",
      "Validated batch 140 batch loss 1.11648905\n",
      "Validated batch 141 batch loss 1.21994007\n",
      "Validated batch 142 batch loss 1.12749863\n",
      "Validated batch 143 batch loss 1.19828224\n",
      "Validated batch 144 batch loss 1.32987475\n",
      "Validated batch 145 batch loss 1.04292715\n",
      "Validated batch 146 batch loss 1.15638041\n",
      "Validated batch 147 batch loss 1.1668402\n",
      "Validated batch 148 batch loss 1.20211494\n",
      "Validated batch 149 batch loss 1.25083303\n",
      "Validated batch 150 batch loss 1.14103663\n",
      "Validated batch 151 batch loss 0.961420536\n",
      "Validated batch 152 batch loss 1.19055736\n",
      "Validated batch 153 batch loss 1.11157107\n",
      "Validated batch 154 batch loss 1.16348052\n",
      "Validated batch 155 batch loss 1.23329556\n",
      "Validated batch 156 batch loss 1.01364708\n",
      "Validated batch 157 batch loss 1.18956614\n",
      "Validated batch 158 batch loss 1.28096306\n",
      "Validated batch 159 batch loss 1.22400236\n",
      "Validated batch 160 batch loss 1.12512219\n",
      "Validated batch 161 batch loss 1.05693579\n",
      "Validated batch 162 batch loss 1.11792815\n",
      "Validated batch 163 batch loss 1.20421267\n",
      "Validated batch 164 batch loss 1.16579878\n",
      "Validated batch 165 batch loss 1.06062829\n",
      "Validated batch 166 batch loss 1.13760936\n",
      "Validated batch 167 batch loss 1.24797082\n",
      "Validated batch 168 batch loss 1.05001712\n",
      "Validated batch 169 batch loss 1.08466864\n",
      "Validated batch 170 batch loss 1.10977292\n",
      "Validated batch 171 batch loss 1.17076302\n",
      "Validated batch 172 batch loss 1.04206467\n",
      "Validated batch 173 batch loss 1.19148088\n",
      "Validated batch 174 batch loss 1.03977311\n",
      "Validated batch 175 batch loss 1.16174221\n",
      "Validated batch 176 batch loss 1.23993266\n",
      "Validated batch 177 batch loss 1.26572371\n",
      "Validated batch 178 batch loss 1.1239078\n",
      "Validated batch 179 batch loss 1.28429127\n",
      "Validated batch 180 batch loss 1.02135909\n",
      "Validated batch 181 batch loss 1.00657678\n",
      "Validated batch 182 batch loss 1.17720532\n",
      "Validated batch 183 batch loss 1.1309371\n",
      "Validated batch 184 batch loss 1.28651929\n",
      "Validated batch 185 batch loss 1.27261853\n",
      "Epoch 5 val loss 1.1791478395462036\n",
      "Model /aiffel/aiffel/mpii/models1/model-epoch-5-loss-1.1791.h5 saved.\n"
     ]
    }
   ],
   "source": [
    "best_model_file = train(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8. 예측 엔진 만들기  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models1', 'model-epoch-5-loss-1.1791.h5')\n",
    "\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "# model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 학습할 때 라벨이 되는 좌표를 heatmap으로 바꿔서, 모델이 추론해 내놓은 결과도 heatmap임.  \n",
    "heatmap에서 최대값을 찾는 함수  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 함수만으로는 256x256 이미지에 64x64 heatmap max 값을 표현할 때 quantization 오차가 발생하기 때문에 실제 계산에서는 3x3 필터를 이용해서 근사치 사용.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image_path):\n",
    "    encoded = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(encoded)\n",
    "    inputs = tf.image.resize(image, (256, 256))\n",
    "    inputs = tf.cast(inputs, tf.float32) / 127.5 - 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    outputs = model(inputs, training=False)\n",
    "    if type(outputs) != list:\n",
    "        outputs = [outputs]\n",
    "    heatmap = tf.squeeze(outputs[-1], axis=0).numpy()\n",
    "    kp = extract_keypoints_from_heatmap(heatmap)\n",
    "    return image, kp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관절 역할 Keypoint과, keypoint들을 연결시킨 것이 뼈대를 그려줌.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_keypoints_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        if index is not None and index != i:\n",
    "            continue\n",
    "        plt.scatter(joint_x, joint_y, s=10, c='red', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def draw_skeleton_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        joints.append((joint_x, joint_y))\n",
    "    \n",
    "    for bone in MPII_BONES:\n",
    "        joint_1 = joints[bone[0]]\n",
    "        joint_2 = joints[bone[1]]\n",
    "        plt.plot([joint_1[0], joint_2[0]], [joint_1[1], joint_2[1]], linewidth=5, alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(model, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9. simplebaseline 모델 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STEP 1 : simplebaseline 모델 완성하기  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')\n",
    "\n",
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()\n",
    "\n",
    "    for i in range(num_deconv_layers):\n",
    "        seq_model.add(\n",
    "            # in_channels=self.inplanes,\n",
    "            Conv2DTranspose(\n",
    "                filters=256,\n",
    "                kernel_size=4,\n",
    "                strides=2,\n",
    "                padding='same',\n",
    "                kernel_initializer='he_normal'))\n",
    "        seq_model.add(BatchNormalization(momentum=0.9))\n",
    "        seq_model.add(ReLU())\n",
    "\n",
    "    return seq_model\n",
    "\n",
    "\n",
    "upconv = _make_deconv_layer(3)\n",
    "\n",
    "final_layer = Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            kernel_initializer='he_normal'\n",
    "        )\n",
    "\n",
    "\n",
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    x1 = resnet(inputs)\n",
    "    x2 = upconv(x1)\n",
    "    x3 = final_layer(x2)\n",
    "    \n",
    "    ys = []\n",
    "    ys.append(x3)\n",
    "\n",
    "    model = tf.keras.Model(inputs, ys, name='simple_baseline')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "STEP 2 : simplebaseline 모델로 변경하여 훈련하기  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer2(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0\n",
    "        weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "        loss += tf.math.reduce_mean( tf.math.square(labels - outputs) * weights) * ( 1. / self.global_batch_size)\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "\n",
    "        @tf.function\n",
    "        def train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.train_step(one_batch, )\n",
    "                total_loss += per_replica_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         per_replica_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.val_step(one_batch, )\n",
    "                num_val_batches += 1\n",
    "                batch_loss = per_replica_loss\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         per_replica_loss)\n",
    "                if not tf.math.is_nan(per_replica_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += per_replica_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = train_epoch( train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = val_epoch( val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH2 + '/model-epoch-{}-loss-{:.4f}.h5'.format(epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train2(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "\n",
    "    train_dataset = create_dataset(train_tfrecords, batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(val_tfrecords, batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH2):\n",
    "        os.makedirs(MODEL_PATH2)\n",
    "\n",
    "    model = Simplebaseline()\n",
    "\n",
    "    trainer = Trainer2(\n",
    "        model,\n",
    "        epochs,\n",
    "        batch_size,\n",
    "        initial_learning_rate=learning_rate)\n",
    "\n",
    "    print('Start Simplebaseline training...')\n",
    "    return trainer.run(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Simplebaseline training...\n",
      "Start epoch 1 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.602349758 epoch total loss 0.602349758\n",
      "Trained batch 2 batch loss 0.560386479 epoch total loss 0.581368089\n",
      "Trained batch 3 batch loss 0.601153 epoch total loss 0.587963045\n",
      "Trained batch 4 batch loss 0.535849333 epoch total loss 0.574934602\n",
      "Trained batch 5 batch loss 0.512817442 epoch total loss 0.562511146\n",
      "Trained batch 6 batch loss 0.495790958 epoch total loss 0.551391125\n",
      "Trained batch 7 batch loss 0.490637332 epoch total loss 0.542712033\n",
      "Trained batch 8 batch loss 0.469064176 epoch total loss 0.533506036\n",
      "Trained batch 9 batch loss 0.478782982 epoch total loss 0.527425706\n",
      "Trained batch 10 batch loss 0.469486654 epoch total loss 0.521631837\n",
      "Trained batch 11 batch loss 0.455138355 epoch total loss 0.515586913\n",
      "Trained batch 12 batch loss 0.42795977 epoch total loss 0.508284688\n",
      "Trained batch 13 batch loss 0.40301308 epoch total loss 0.500186861\n",
      "Trained batch 14 batch loss 0.416571856 epoch total loss 0.494214386\n",
      "Trained batch 15 batch loss 0.436378658 epoch total loss 0.49035868\n",
      "Trained batch 16 batch loss 0.434267372 epoch total loss 0.486852974\n",
      "Trained batch 17 batch loss 0.440361679 epoch total loss 0.484118193\n",
      "Trained batch 18 batch loss 0.408318758 epoch total loss 0.479907095\n",
      "Trained batch 19 batch loss 0.391208112 epoch total loss 0.475238711\n",
      "Trained batch 20 batch loss 0.404569238 epoch total loss 0.471705258\n",
      "Trained batch 21 batch loss 0.379799634 epoch total loss 0.467328787\n",
      "Trained batch 22 batch loss 0.389719337 epoch total loss 0.463801086\n",
      "Trained batch 23 batch loss 0.381670177 epoch total loss 0.460230172\n",
      "Trained batch 24 batch loss 0.391576022 epoch total loss 0.457369566\n",
      "Trained batch 25 batch loss 0.420540482 epoch total loss 0.455896407\n",
      "Trained batch 26 batch loss 0.423824638 epoch total loss 0.454662859\n",
      "Trained batch 27 batch loss 0.426530749 epoch total loss 0.45362094\n",
      "Trained batch 28 batch loss 0.421561152 epoch total loss 0.452475965\n",
      "Trained batch 29 batch loss 0.404286325 epoch total loss 0.450814247\n",
      "Trained batch 30 batch loss 0.43053183 epoch total loss 0.450138152\n",
      "Trained batch 31 batch loss 0.418264925 epoch total loss 0.44911\n",
      "Trained batch 32 batch loss 0.429701805 epoch total loss 0.448503494\n",
      "Trained batch 33 batch loss 0.415934086 epoch total loss 0.447516531\n",
      "Trained batch 34 batch loss 0.411710173 epoch total loss 0.446463376\n",
      "Trained batch 35 batch loss 0.419448346 epoch total loss 0.445691526\n",
      "Trained batch 36 batch loss 0.424388587 epoch total loss 0.445099771\n",
      "Trained batch 37 batch loss 0.413936943 epoch total loss 0.444257528\n",
      "Trained batch 38 batch loss 0.405082285 epoch total loss 0.443226606\n",
      "Trained batch 39 batch loss 0.40898481 epoch total loss 0.442348629\n",
      "Trained batch 40 batch loss 0.402417183 epoch total loss 0.441350371\n",
      "Trained batch 41 batch loss 0.402271092 epoch total loss 0.440397203\n",
      "Trained batch 42 batch loss 0.407032311 epoch total loss 0.439602792\n",
      "Trained batch 43 batch loss 0.411093235 epoch total loss 0.43893978\n",
      "Trained batch 44 batch loss 0.411571324 epoch total loss 0.438317776\n",
      "Trained batch 45 batch loss 0.398864686 epoch total loss 0.437441051\n",
      "Trained batch 46 batch loss 0.365491778 epoch total loss 0.435876936\n",
      "Trained batch 47 batch loss 0.388225436 epoch total loss 0.434863061\n",
      "Trained batch 48 batch loss 0.404116333 epoch total loss 0.43422249\n",
      "Trained batch 49 batch loss 0.358270407 epoch total loss 0.432672471\n",
      "Trained batch 50 batch loss 0.381916881 epoch total loss 0.431657344\n",
      "Trained batch 51 batch loss 0.382679641 epoch total loss 0.430696964\n",
      "Trained batch 52 batch loss 0.373016536 epoch total loss 0.429587722\n",
      "Trained batch 53 batch loss 0.399304837 epoch total loss 0.429016352\n",
      "Trained batch 54 batch loss 0.40109241 epoch total loss 0.428499252\n",
      "Trained batch 55 batch loss 0.391488701 epoch total loss 0.427826345\n",
      "Trained batch 56 batch loss 0.366909474 epoch total loss 0.42673853\n",
      "Trained batch 57 batch loss 0.377695024 epoch total loss 0.425878137\n",
      "Trained batch 58 batch loss 0.39643538 epoch total loss 0.425370485\n",
      "Trained batch 59 batch loss 0.383865088 epoch total loss 0.424667\n",
      "Trained batch 60 batch loss 0.391668499 epoch total loss 0.424117029\n",
      "Trained batch 61 batch loss 0.408941269 epoch total loss 0.423868239\n",
      "Trained batch 62 batch loss 0.390301704 epoch total loss 0.42332685\n",
      "Trained batch 63 batch loss 0.355038464 epoch total loss 0.42224291\n",
      "Trained batch 64 batch loss 0.395230293 epoch total loss 0.421820819\n",
      "Trained batch 65 batch loss 0.389175147 epoch total loss 0.421318591\n",
      "Trained batch 66 batch loss 0.376336694 epoch total loss 0.420637041\n",
      "Trained batch 67 batch loss 0.376604438 epoch total loss 0.419979841\n",
      "Trained batch 68 batch loss 0.364032388 epoch total loss 0.419157088\n",
      "Trained batch 69 batch loss 0.338528872 epoch total loss 0.417988569\n",
      "Trained batch 70 batch loss 0.337738276 epoch total loss 0.416842133\n",
      "Trained batch 71 batch loss 0.37277922 epoch total loss 0.416221529\n",
      "Trained batch 72 batch loss 0.366165459 epoch total loss 0.415526301\n",
      "Trained batch 73 batch loss 0.379988253 epoch total loss 0.41503948\n",
      "Trained batch 74 batch loss 0.38186416 epoch total loss 0.414591163\n",
      "Trained batch 75 batch loss 0.398186058 epoch total loss 0.414372444\n",
      "Trained batch 76 batch loss 0.397803545 epoch total loss 0.41415444\n",
      "Trained batch 77 batch loss 0.39178437 epoch total loss 0.413863927\n",
      "Trained batch 78 batch loss 0.384512186 epoch total loss 0.413487613\n",
      "Trained batch 79 batch loss 0.36913538 epoch total loss 0.412926197\n",
      "Trained batch 80 batch loss 0.366435349 epoch total loss 0.412345082\n",
      "Trained batch 81 batch loss 0.353738129 epoch total loss 0.411621511\n",
      "Trained batch 82 batch loss 0.3779625 epoch total loss 0.411211073\n",
      "Trained batch 83 batch loss 0.385607839 epoch total loss 0.41090259\n",
      "Trained batch 84 batch loss 0.380572051 epoch total loss 0.410541534\n",
      "Trained batch 85 batch loss 0.388807356 epoch total loss 0.41028586\n",
      "Trained batch 86 batch loss 0.38674137 epoch total loss 0.410012096\n",
      "Trained batch 87 batch loss 0.393963307 epoch total loss 0.40982762\n",
      "Trained batch 88 batch loss 0.397858381 epoch total loss 0.409691602\n",
      "Trained batch 89 batch loss 0.3932769 epoch total loss 0.409507155\n",
      "Trained batch 90 batch loss 0.38401866 epoch total loss 0.409223944\n",
      "Trained batch 91 batch loss 0.368674755 epoch total loss 0.40877834\n",
      "Trained batch 92 batch loss 0.370331019 epoch total loss 0.408360451\n",
      "Trained batch 93 batch loss 0.372612745 epoch total loss 0.407976061\n",
      "Trained batch 94 batch loss 0.385982931 epoch total loss 0.407742083\n",
      "Trained batch 95 batch loss 0.399545193 epoch total loss 0.407655776\n",
      "Trained batch 96 batch loss 0.409240544 epoch total loss 0.407672286\n",
      "Trained batch 97 batch loss 0.425231546 epoch total loss 0.407853305\n",
      "Trained batch 98 batch loss 0.399158716 epoch total loss 0.407764584\n",
      "Trained batch 99 batch loss 0.400481164 epoch total loss 0.407691032\n",
      "Trained batch 100 batch loss 0.376296908 epoch total loss 0.407377094\n",
      "Trained batch 101 batch loss 0.364790738 epoch total loss 0.406955451\n",
      "Trained batch 102 batch loss 0.371686339 epoch total loss 0.406609654\n",
      "Trained batch 103 batch loss 0.38138181 epoch total loss 0.406364739\n",
      "Trained batch 104 batch loss 0.396762 epoch total loss 0.406272411\n",
      "Trained batch 105 batch loss 0.378216952 epoch total loss 0.406005204\n",
      "Trained batch 106 batch loss 0.378838539 epoch total loss 0.405748904\n",
      "Trained batch 107 batch loss 0.373768419 epoch total loss 0.405450016\n",
      "Trained batch 108 batch loss 0.371887505 epoch total loss 0.405139238\n",
      "Trained batch 109 batch loss 0.385495752 epoch total loss 0.404959023\n",
      "Trained batch 110 batch loss 0.374319762 epoch total loss 0.40468049\n",
      "Trained batch 111 batch loss 0.383646578 epoch total loss 0.404491\n",
      "Trained batch 112 batch loss 0.379106641 epoch total loss 0.40426439\n",
      "Trained batch 113 batch loss 0.388914704 epoch total loss 0.404128551\n",
      "Trained batch 114 batch loss 0.411234319 epoch total loss 0.404190898\n",
      "Trained batch 115 batch loss 0.367602408 epoch total loss 0.403872758\n",
      "Trained batch 116 batch loss 0.358302534 epoch total loss 0.403479904\n",
      "Trained batch 117 batch loss 0.380269468 epoch total loss 0.40328151\n",
      "Trained batch 118 batch loss 0.393045753 epoch total loss 0.403194785\n",
      "Trained batch 119 batch loss 0.364079207 epoch total loss 0.402866066\n",
      "Trained batch 120 batch loss 0.347961605 epoch total loss 0.40240854\n",
      "Trained batch 121 batch loss 0.346802115 epoch total loss 0.401949\n",
      "Trained batch 122 batch loss 0.35074234 epoch total loss 0.401529253\n",
      "Trained batch 123 batch loss 0.376176924 epoch total loss 0.40132314\n",
      "Trained batch 124 batch loss 0.373812169 epoch total loss 0.401101291\n",
      "Trained batch 125 batch loss 0.376941442 epoch total loss 0.400908023\n",
      "Trained batch 126 batch loss 0.346191227 epoch total loss 0.400473773\n",
      "Trained batch 127 batch loss 0.345764339 epoch total loss 0.400042981\n",
      "Trained batch 128 batch loss 0.367135227 epoch total loss 0.399785876\n",
      "Trained batch 129 batch loss 0.338662267 epoch total loss 0.399312049\n",
      "Trained batch 130 batch loss 0.38128975 epoch total loss 0.399173409\n",
      "Trained batch 131 batch loss 0.376342803 epoch total loss 0.398999125\n",
      "Trained batch 132 batch loss 0.33397004 epoch total loss 0.398506492\n",
      "Trained batch 133 batch loss 0.389859915 epoch total loss 0.398441464\n",
      "Trained batch 134 batch loss 0.339864701 epoch total loss 0.398004293\n",
      "Trained batch 135 batch loss 0.35010612 epoch total loss 0.397649497\n",
      "Trained batch 136 batch loss 0.373229563 epoch total loss 0.397469938\n",
      "Trained batch 137 batch loss 0.327914476 epoch total loss 0.396962255\n",
      "Trained batch 138 batch loss 0.314121485 epoch total loss 0.396361947\n",
      "Trained batch 139 batch loss 0.299797505 epoch total loss 0.395667225\n",
      "Trained batch 140 batch loss 0.326261282 epoch total loss 0.395171463\n",
      "Trained batch 141 batch loss 0.351560414 epoch total loss 0.394862145\n",
      "Trained batch 142 batch loss 0.311251134 epoch total loss 0.394273341\n",
      "Trained batch 143 batch loss 0.321079761 epoch total loss 0.393761516\n",
      "Trained batch 144 batch loss 0.355482519 epoch total loss 0.393495679\n",
      "Trained batch 145 batch loss 0.361766428 epoch total loss 0.39327687\n",
      "Trained batch 146 batch loss 0.354201704 epoch total loss 0.393009245\n",
      "Trained batch 147 batch loss 0.339315087 epoch total loss 0.392643958\n",
      "Trained batch 148 batch loss 0.340628743 epoch total loss 0.3922925\n",
      "Trained batch 149 batch loss 0.376609147 epoch total loss 0.392187268\n",
      "Trained batch 150 batch loss 0.372150123 epoch total loss 0.392053694\n",
      "Trained batch 151 batch loss 0.385752738 epoch total loss 0.39201197\n",
      "Trained batch 152 batch loss 0.356578618 epoch total loss 0.391778857\n",
      "Trained batch 153 batch loss 0.388030738 epoch total loss 0.391754359\n",
      "Trained batch 154 batch loss 0.335425615 epoch total loss 0.391388595\n",
      "Trained batch 155 batch loss 0.367207378 epoch total loss 0.39123258\n",
      "Trained batch 156 batch loss 0.384287506 epoch total loss 0.391188055\n",
      "Trained batch 157 batch loss 0.323686361 epoch total loss 0.390758097\n",
      "Trained batch 158 batch loss 0.355102479 epoch total loss 0.390532434\n",
      "Trained batch 159 batch loss 0.379480958 epoch total loss 0.390462935\n",
      "Trained batch 160 batch loss 0.360279143 epoch total loss 0.390274286\n",
      "Trained batch 161 batch loss 0.370657951 epoch total loss 0.390152454\n",
      "Trained batch 162 batch loss 0.356617242 epoch total loss 0.389945447\n",
      "Trained batch 163 batch loss 0.361895323 epoch total loss 0.389773369\n",
      "Trained batch 164 batch loss 0.363795757 epoch total loss 0.389614969\n",
      "Trained batch 165 batch loss 0.353905022 epoch total loss 0.389398575\n",
      "Trained batch 166 batch loss 0.336781293 epoch total loss 0.389081597\n",
      "Trained batch 167 batch loss 0.342383444 epoch total loss 0.388802\n",
      "Trained batch 168 batch loss 0.34556973 epoch total loss 0.388544679\n",
      "Trained batch 169 batch loss 0.361122847 epoch total loss 0.388382405\n",
      "Trained batch 170 batch loss 0.355714142 epoch total loss 0.38819024\n",
      "Trained batch 171 batch loss 0.369565 epoch total loss 0.388081342\n",
      "Trained batch 172 batch loss 0.358355671 epoch total loss 0.387908489\n",
      "Trained batch 173 batch loss 0.357933939 epoch total loss 0.387735218\n",
      "Trained batch 174 batch loss 0.36731112 epoch total loss 0.387617826\n",
      "Trained batch 175 batch loss 0.37209034 epoch total loss 0.387529135\n",
      "Trained batch 176 batch loss 0.365900576 epoch total loss 0.38740623\n",
      "Trained batch 177 batch loss 0.357398152 epoch total loss 0.387236685\n",
      "Trained batch 178 batch loss 0.348574 epoch total loss 0.387019455\n",
      "Trained batch 179 batch loss 0.349167585 epoch total loss 0.386808\n",
      "Trained batch 180 batch loss 0.370433658 epoch total loss 0.386717021\n",
      "Trained batch 181 batch loss 0.350861371 epoch total loss 0.386518896\n",
      "Trained batch 182 batch loss 0.344128251 epoch total loss 0.38628602\n",
      "Trained batch 183 batch loss 0.370853633 epoch total loss 0.38620171\n",
      "Trained batch 184 batch loss 0.358256042 epoch total loss 0.386049807\n",
      "Trained batch 185 batch loss 0.349974573 epoch total loss 0.38585481\n",
      "Trained batch 186 batch loss 0.346374452 epoch total loss 0.385642558\n",
      "Trained batch 187 batch loss 0.37151888 epoch total loss 0.385567039\n",
      "Trained batch 188 batch loss 0.379665047 epoch total loss 0.385535628\n",
      "Trained batch 189 batch loss 0.376156151 epoch total loss 0.385486\n",
      "Trained batch 190 batch loss 0.388797015 epoch total loss 0.385503441\n",
      "Trained batch 191 batch loss 0.360260665 epoch total loss 0.385371268\n",
      "Trained batch 192 batch loss 0.376254141 epoch total loss 0.385323763\n",
      "Trained batch 193 batch loss 0.358170122 epoch total loss 0.385183066\n",
      "Trained batch 194 batch loss 0.379278898 epoch total loss 0.385152638\n",
      "Trained batch 195 batch loss 0.37755236 epoch total loss 0.385113686\n",
      "Trained batch 196 batch loss 0.368581265 epoch total loss 0.385029346\n",
      "Trained batch 197 batch loss 0.38792491 epoch total loss 0.385044038\n",
      "Trained batch 198 batch loss 0.353627354 epoch total loss 0.384885371\n",
      "Trained batch 199 batch loss 0.345689595 epoch total loss 0.384688407\n",
      "Trained batch 200 batch loss 0.3608917 epoch total loss 0.384569436\n",
      "Trained batch 201 batch loss 0.344233155 epoch total loss 0.384368747\n",
      "Trained batch 202 batch loss 0.339530855 epoch total loss 0.38414678\n",
      "Trained batch 203 batch loss 0.347631603 epoch total loss 0.383966893\n",
      "Trained batch 204 batch loss 0.354048371 epoch total loss 0.383820266\n",
      "Trained batch 205 batch loss 0.368700296 epoch total loss 0.383746475\n",
      "Trained batch 206 batch loss 0.361033618 epoch total loss 0.383636206\n",
      "Trained batch 207 batch loss 0.341788739 epoch total loss 0.383434057\n",
      "Trained batch 208 batch loss 0.374870688 epoch total loss 0.38339287\n",
      "Trained batch 209 batch loss 0.371159703 epoch total loss 0.383334368\n",
      "Trained batch 210 batch loss 0.380328029 epoch total loss 0.383320034\n",
      "Trained batch 211 batch loss 0.386859894 epoch total loss 0.383336782\n",
      "Trained batch 212 batch loss 0.382579088 epoch total loss 0.383333206\n",
      "Trained batch 213 batch loss 0.361559242 epoch total loss 0.383230984\n",
      "Trained batch 214 batch loss 0.335161656 epoch total loss 0.383006334\n",
      "Trained batch 215 batch loss 0.334833682 epoch total loss 0.38278228\n",
      "Trained batch 216 batch loss 0.348901868 epoch total loss 0.382625401\n",
      "Trained batch 217 batch loss 0.333132178 epoch total loss 0.382397324\n",
      "Trained batch 218 batch loss 0.350573272 epoch total loss 0.382251322\n",
      "Trained batch 219 batch loss 0.331336826 epoch total loss 0.382018834\n",
      "Trained batch 220 batch loss 0.292098701 epoch total loss 0.381610096\n",
      "Trained batch 221 batch loss 0.312630981 epoch total loss 0.381297976\n",
      "Trained batch 222 batch loss 0.344655305 epoch total loss 0.381132931\n",
      "Trained batch 223 batch loss 0.334577411 epoch total loss 0.380924165\n",
      "Trained batch 224 batch loss 0.343103826 epoch total loss 0.380755335\n",
      "Trained batch 225 batch loss 0.341411591 epoch total loss 0.380580455\n",
      "Trained batch 226 batch loss 0.359547317 epoch total loss 0.380487382\n",
      "Trained batch 227 batch loss 0.359013587 epoch total loss 0.38039282\n",
      "Trained batch 228 batch loss 0.326770365 epoch total loss 0.38015759\n",
      "Trained batch 229 batch loss 0.344296455 epoch total loss 0.380001\n",
      "Trained batch 230 batch loss 0.357695699 epoch total loss 0.379904032\n",
      "Trained batch 231 batch loss 0.364894092 epoch total loss 0.379839063\n",
      "Trained batch 232 batch loss 0.304580778 epoch total loss 0.379514664\n",
      "Trained batch 233 batch loss 0.287570566 epoch total loss 0.379120022\n",
      "Trained batch 234 batch loss 0.292396158 epoch total loss 0.37874943\n",
      "Trained batch 235 batch loss 0.37482059 epoch total loss 0.378732681\n",
      "Trained batch 236 batch loss 0.381726027 epoch total loss 0.378745377\n",
      "Trained batch 237 batch loss 0.404132694 epoch total loss 0.378852487\n",
      "Trained batch 238 batch loss 0.390583575 epoch total loss 0.37890178\n",
      "Trained batch 239 batch loss 0.371797264 epoch total loss 0.378872067\n",
      "Trained batch 240 batch loss 0.352032065 epoch total loss 0.378760248\n",
      "Trained batch 241 batch loss 0.354383498 epoch total loss 0.378659099\n",
      "Trained batch 242 batch loss 0.380073041 epoch total loss 0.378664941\n",
      "Trained batch 243 batch loss 0.345020592 epoch total loss 0.378526509\n",
      "Trained batch 244 batch loss 0.329036295 epoch total loss 0.378323674\n",
      "Trained batch 245 batch loss 0.329625219 epoch total loss 0.378124893\n",
      "Trained batch 246 batch loss 0.324827045 epoch total loss 0.37790826\n",
      "Trained batch 247 batch loss 0.3204256 epoch total loss 0.377675533\n",
      "Trained batch 248 batch loss 0.359646 epoch total loss 0.377602845\n",
      "Trained batch 249 batch loss 0.346360683 epoch total loss 0.377477378\n",
      "Trained batch 250 batch loss 0.371006936 epoch total loss 0.377451509\n",
      "Trained batch 251 batch loss 0.340443909 epoch total loss 0.377304077\n",
      "Trained batch 252 batch loss 0.321964562 epoch total loss 0.377084494\n",
      "Trained batch 253 batch loss 0.355186105 epoch total loss 0.376997948\n",
      "Trained batch 254 batch loss 0.372764021 epoch total loss 0.376981258\n",
      "Trained batch 255 batch loss 0.355749398 epoch total loss 0.376898021\n",
      "Trained batch 256 batch loss 0.345497251 epoch total loss 0.376775354\n",
      "Trained batch 257 batch loss 0.340000838 epoch total loss 0.376632273\n",
      "Trained batch 258 batch loss 0.336220145 epoch total loss 0.376475632\n",
      "Trained batch 259 batch loss 0.32844606 epoch total loss 0.376290202\n",
      "Trained batch 260 batch loss 0.344136745 epoch total loss 0.376166523\n",
      "Trained batch 261 batch loss 0.348974824 epoch total loss 0.376062363\n",
      "Trained batch 262 batch loss 0.362006 epoch total loss 0.376008719\n",
      "Trained batch 263 batch loss 0.358148396 epoch total loss 0.3759408\n",
      "Trained batch 264 batch loss 0.333000749 epoch total loss 0.375778139\n",
      "Trained batch 265 batch loss 0.339630395 epoch total loss 0.375641733\n",
      "Trained batch 266 batch loss 0.316920698 epoch total loss 0.375420958\n",
      "Trained batch 267 batch loss 0.324350208 epoch total loss 0.375229686\n",
      "Trained batch 268 batch loss 0.333097637 epoch total loss 0.375072479\n",
      "Trained batch 269 batch loss 0.34284693 epoch total loss 0.374952704\n",
      "Trained batch 270 batch loss 0.32744652 epoch total loss 0.374776751\n",
      "Trained batch 271 batch loss 0.342044175 epoch total loss 0.374655932\n",
      "Trained batch 272 batch loss 0.322589189 epoch total loss 0.374464512\n",
      "Trained batch 273 batch loss 0.350203127 epoch total loss 0.374375641\n",
      "Trained batch 274 batch loss 0.379666924 epoch total loss 0.374394953\n",
      "Trained batch 275 batch loss 0.346333385 epoch total loss 0.37429294\n",
      "Trained batch 276 batch loss 0.361831725 epoch total loss 0.374247789\n",
      "Trained batch 277 batch loss 0.345868558 epoch total loss 0.374145329\n",
      "Trained batch 278 batch loss 0.361814559 epoch total loss 0.374100983\n",
      "Trained batch 279 batch loss 0.34174782 epoch total loss 0.373985052\n",
      "Trained batch 280 batch loss 0.354431093 epoch total loss 0.373915195\n",
      "Trained batch 281 batch loss 0.380891085 epoch total loss 0.373940021\n",
      "Trained batch 282 batch loss 0.357206881 epoch total loss 0.373880684\n",
      "Trained batch 283 batch loss 0.353168458 epoch total loss 0.37380749\n",
      "Trained batch 284 batch loss 0.332854271 epoch total loss 0.373663306\n",
      "Trained batch 285 batch loss 0.346421957 epoch total loss 0.3735677\n",
      "Trained batch 286 batch loss 0.327746689 epoch total loss 0.373407483\n",
      "Trained batch 287 batch loss 0.327988416 epoch total loss 0.373249233\n",
      "Trained batch 288 batch loss 0.335966766 epoch total loss 0.373119771\n",
      "Trained batch 289 batch loss 0.32291618 epoch total loss 0.372946054\n",
      "Trained batch 290 batch loss 0.334780574 epoch total loss 0.372814447\n",
      "Trained batch 291 batch loss 0.340573668 epoch total loss 0.372703671\n",
      "Trained batch 292 batch loss 0.3221111 epoch total loss 0.372530401\n",
      "Trained batch 293 batch loss 0.315792948 epoch total loss 0.372336775\n",
      "Trained batch 294 batch loss 0.308452755 epoch total loss 0.372119486\n",
      "Trained batch 295 batch loss 0.302333891 epoch total loss 0.371882945\n",
      "Trained batch 296 batch loss 0.345236629 epoch total loss 0.371792912\n",
      "Trained batch 297 batch loss 0.334842712 epoch total loss 0.371668518\n",
      "Trained batch 298 batch loss 0.335550964 epoch total loss 0.371547312\n",
      "Trained batch 299 batch loss 0.360036284 epoch total loss 0.371508837\n",
      "Trained batch 300 batch loss 0.348323137 epoch total loss 0.37143153\n",
      "Trained batch 301 batch loss 0.370850623 epoch total loss 0.371429592\n",
      "Trained batch 302 batch loss 0.381726563 epoch total loss 0.371463686\n",
      "Trained batch 303 batch loss 0.347213149 epoch total loss 0.371383667\n",
      "Trained batch 304 batch loss 0.366179109 epoch total loss 0.37136656\n",
      "Trained batch 305 batch loss 0.393027931 epoch total loss 0.371437579\n",
      "Trained batch 306 batch loss 0.386978954 epoch total loss 0.371488363\n",
      "Trained batch 307 batch loss 0.372141957 epoch total loss 0.371490479\n",
      "Trained batch 308 batch loss 0.334430933 epoch total loss 0.371370167\n",
      "Trained batch 309 batch loss 0.344698936 epoch total loss 0.371283829\n",
      "Trained batch 310 batch loss 0.352071911 epoch total loss 0.37122187\n",
      "Trained batch 311 batch loss 0.338972479 epoch total loss 0.371118188\n",
      "Trained batch 312 batch loss 0.344741851 epoch total loss 0.371033639\n",
      "Trained batch 313 batch loss 0.375366151 epoch total loss 0.371047497\n",
      "Trained batch 314 batch loss 0.354833752 epoch total loss 0.370995849\n",
      "Trained batch 315 batch loss 0.345260531 epoch total loss 0.370914161\n",
      "Trained batch 316 batch loss 0.344504952 epoch total loss 0.370830595\n",
      "Trained batch 317 batch loss 0.380814582 epoch total loss 0.370862067\n",
      "Trained batch 318 batch loss 0.326420307 epoch total loss 0.370722324\n",
      "Trained batch 319 batch loss 0.356743902 epoch total loss 0.370678514\n",
      "Trained batch 320 batch loss 0.360387355 epoch total loss 0.370646358\n",
      "Trained batch 321 batch loss 0.344773561 epoch total loss 0.370565742\n",
      "Trained batch 322 batch loss 0.321703792 epoch total loss 0.370414\n",
      "Trained batch 323 batch loss 0.33122766 epoch total loss 0.370292693\n",
      "Trained batch 324 batch loss 0.331397682 epoch total loss 0.37017265\n",
      "Trained batch 325 batch loss 0.364653587 epoch total loss 0.370155662\n",
      "Trained batch 326 batch loss 0.353190303 epoch total loss 0.370103627\n",
      "Trained batch 327 batch loss 0.374212682 epoch total loss 0.370116174\n",
      "Trained batch 328 batch loss 0.383071244 epoch total loss 0.370155692\n",
      "Trained batch 329 batch loss 0.342240363 epoch total loss 0.370070845\n",
      "Trained batch 330 batch loss 0.416423202 epoch total loss 0.370211273\n",
      "Trained batch 331 batch loss 0.390917063 epoch total loss 0.370273829\n",
      "Trained batch 332 batch loss 0.359005719 epoch total loss 0.370239913\n",
      "Trained batch 333 batch loss 0.339467406 epoch total loss 0.370147496\n",
      "Trained batch 334 batch loss 0.330180883 epoch total loss 0.37002784\n",
      "Trained batch 335 batch loss 0.295522958 epoch total loss 0.369805425\n",
      "Trained batch 336 batch loss 0.31744647 epoch total loss 0.369649589\n",
      "Trained batch 337 batch loss 0.328042448 epoch total loss 0.369526118\n",
      "Trained batch 338 batch loss 0.280172378 epoch total loss 0.369261771\n",
      "Trained batch 339 batch loss 0.281807482 epoch total loss 0.369003803\n",
      "Trained batch 340 batch loss 0.281072676 epoch total loss 0.368745178\n",
      "Trained batch 341 batch loss 0.31171304 epoch total loss 0.368577927\n",
      "Trained batch 342 batch loss 0.327078164 epoch total loss 0.368456602\n",
      "Trained batch 343 batch loss 0.358210266 epoch total loss 0.36842671\n",
      "Trained batch 344 batch loss 0.381075233 epoch total loss 0.368463486\n",
      "Trained batch 345 batch loss 0.38925615 epoch total loss 0.368523747\n",
      "Trained batch 346 batch loss 0.366505116 epoch total loss 0.368517935\n",
      "Trained batch 347 batch loss 0.302437901 epoch total loss 0.368327498\n",
      "Trained batch 348 batch loss 0.305820972 epoch total loss 0.36814788\n",
      "Trained batch 349 batch loss 0.316732 epoch total loss 0.368000537\n",
      "Trained batch 350 batch loss 0.340006143 epoch total loss 0.367920578\n",
      "Trained batch 351 batch loss 0.339546084 epoch total loss 0.367839724\n",
      "Trained batch 352 batch loss 0.331502378 epoch total loss 0.367736459\n",
      "Trained batch 353 batch loss 0.327285528 epoch total loss 0.367621869\n",
      "Trained batch 354 batch loss 0.334656954 epoch total loss 0.367528766\n",
      "Trained batch 355 batch loss 0.350895166 epoch total loss 0.367481887\n",
      "Trained batch 356 batch loss 0.336949378 epoch total loss 0.367396116\n",
      "Trained batch 357 batch loss 0.371146142 epoch total loss 0.367406607\n",
      "Trained batch 358 batch loss 0.334523439 epoch total loss 0.367314726\n",
      "Trained batch 359 batch loss 0.302255213 epoch total loss 0.367133528\n",
      "Trained batch 360 batch loss 0.333120644 epoch total loss 0.367039025\n",
      "Trained batch 361 batch loss 0.321325898 epoch total loss 0.366912365\n",
      "Trained batch 362 batch loss 0.340513259 epoch total loss 0.366839468\n",
      "Trained batch 363 batch loss 0.34480828 epoch total loss 0.366778761\n",
      "Trained batch 364 batch loss 0.394118905 epoch total loss 0.366853863\n",
      "Trained batch 365 batch loss 0.37868458 epoch total loss 0.366886258\n",
      "Trained batch 366 batch loss 0.347117603 epoch total loss 0.366832256\n",
      "Trained batch 367 batch loss 0.315716803 epoch total loss 0.366693\n",
      "Trained batch 368 batch loss 0.311201483 epoch total loss 0.36654219\n",
      "Trained batch 369 batch loss 0.336279213 epoch total loss 0.366460174\n",
      "Trained batch 370 batch loss 0.357708246 epoch total loss 0.366436511\n",
      "Trained batch 371 batch loss 0.361035407 epoch total loss 0.366421968\n",
      "Trained batch 372 batch loss 0.364699185 epoch total loss 0.366417348\n",
      "Trained batch 373 batch loss 0.341187418 epoch total loss 0.366349697\n",
      "Trained batch 374 batch loss 0.362591326 epoch total loss 0.366339654\n",
      "Trained batch 375 batch loss 0.369564831 epoch total loss 0.366348267\n",
      "Trained batch 376 batch loss 0.352017254 epoch total loss 0.366310149\n",
      "Trained batch 377 batch loss 0.349513113 epoch total loss 0.366265625\n",
      "Trained batch 378 batch loss 0.369196773 epoch total loss 0.366273373\n",
      "Trained batch 379 batch loss 0.351406634 epoch total loss 0.366234154\n",
      "Trained batch 380 batch loss 0.334220737 epoch total loss 0.366149902\n",
      "Trained batch 381 batch loss 0.34436 epoch total loss 0.366092712\n",
      "Trained batch 382 batch loss 0.368608 epoch total loss 0.366099298\n",
      "Trained batch 383 batch loss 0.348721147 epoch total loss 0.366053939\n",
      "Trained batch 384 batch loss 0.348481953 epoch total loss 0.366008162\n",
      "Trained batch 385 batch loss 0.347152293 epoch total loss 0.365959197\n",
      "Trained batch 386 batch loss 0.353989959 epoch total loss 0.365928173\n",
      "Trained batch 387 batch loss 0.339913517 epoch total loss 0.365860969\n",
      "Trained batch 388 batch loss 0.380619854 epoch total loss 0.365899\n",
      "Trained batch 389 batch loss 0.33445859 epoch total loss 0.365818173\n",
      "Trained batch 390 batch loss 0.33935973 epoch total loss 0.365750313\n",
      "Trained batch 391 batch loss 0.306139052 epoch total loss 0.365597844\n",
      "Trained batch 392 batch loss 0.388781458 epoch total loss 0.365657\n",
      "Trained batch 393 batch loss 0.350882202 epoch total loss 0.365619391\n",
      "Trained batch 394 batch loss 0.36115253 epoch total loss 0.365608037\n",
      "Trained batch 395 batch loss 0.360699475 epoch total loss 0.365595609\n",
      "Trained batch 396 batch loss 0.353189826 epoch total loss 0.365564287\n",
      "Trained batch 397 batch loss 0.349669427 epoch total loss 0.365524262\n",
      "Trained batch 398 batch loss 0.324031025 epoch total loss 0.36542\n",
      "Trained batch 399 batch loss 0.3439143 epoch total loss 0.365366131\n",
      "Trained batch 400 batch loss 0.365476906 epoch total loss 0.365366399\n",
      "Trained batch 401 batch loss 0.32306087 epoch total loss 0.365260899\n",
      "Trained batch 402 batch loss 0.344564885 epoch total loss 0.365209401\n",
      "Trained batch 403 batch loss 0.351725757 epoch total loss 0.365175962\n",
      "Trained batch 404 batch loss 0.312325 epoch total loss 0.36504516\n",
      "Trained batch 405 batch loss 0.317748517 epoch total loss 0.364928365\n",
      "Trained batch 406 batch loss 0.316090673 epoch total loss 0.364808083\n",
      "Trained batch 407 batch loss 0.294236213 epoch total loss 0.364634663\n",
      "Trained batch 408 batch loss 0.315040559 epoch total loss 0.364513099\n",
      "Trained batch 409 batch loss 0.376688927 epoch total loss 0.364542872\n",
      "Trained batch 410 batch loss 0.377173722 epoch total loss 0.364573658\n",
      "Trained batch 411 batch loss 0.375487536 epoch total loss 0.364600211\n",
      "Trained batch 412 batch loss 0.381105095 epoch total loss 0.364640296\n",
      "Trained batch 413 batch loss 0.341702521 epoch total loss 0.364584744\n",
      "Trained batch 414 batch loss 0.363089532 epoch total loss 0.364581108\n",
      "Trained batch 415 batch loss 0.341048539 epoch total loss 0.364524424\n",
      "Trained batch 416 batch loss 0.348039418 epoch total loss 0.364484787\n",
      "Trained batch 417 batch loss 0.379879296 epoch total loss 0.364521712\n",
      "Trained batch 418 batch loss 0.371731639 epoch total loss 0.364538968\n",
      "Trained batch 419 batch loss 0.392668366 epoch total loss 0.364606112\n",
      "Trained batch 420 batch loss 0.349262893 epoch total loss 0.364569575\n",
      "Trained batch 421 batch loss 0.313072115 epoch total loss 0.364447236\n",
      "Trained batch 422 batch loss 0.346145689 epoch total loss 0.364403844\n",
      "Trained batch 423 batch loss 0.342960477 epoch total loss 0.36435315\n",
      "Trained batch 424 batch loss 0.347722381 epoch total loss 0.36431393\n",
      "Trained batch 425 batch loss 0.319634736 epoch total loss 0.364208817\n",
      "Trained batch 426 batch loss 0.340914935 epoch total loss 0.36415413\n",
      "Trained batch 427 batch loss 0.338776767 epoch total loss 0.364094675\n",
      "Trained batch 428 batch loss 0.326157391 epoch total loss 0.364006042\n",
      "Trained batch 429 batch loss 0.321849436 epoch total loss 0.363907784\n",
      "Trained batch 430 batch loss 0.344721705 epoch total loss 0.36386317\n",
      "Trained batch 431 batch loss 0.335587651 epoch total loss 0.363797575\n",
      "Trained batch 432 batch loss 0.32610026 epoch total loss 0.363710284\n",
      "Trained batch 433 batch loss 0.335695207 epoch total loss 0.363645583\n",
      "Trained batch 434 batch loss 0.365618557 epoch total loss 0.363650143\n",
      "Trained batch 435 batch loss 0.362021416 epoch total loss 0.363646388\n",
      "Trained batch 436 batch loss 0.339146614 epoch total loss 0.363590181\n",
      "Trained batch 437 batch loss 0.307590604 epoch total loss 0.363462031\n",
      "Trained batch 438 batch loss 0.308400631 epoch total loss 0.363336295\n",
      "Trained batch 439 batch loss 0.357587874 epoch total loss 0.363323212\n",
      "Trained batch 440 batch loss 0.36530605 epoch total loss 0.363327712\n",
      "Trained batch 441 batch loss 0.375265032 epoch total loss 0.363354772\n",
      "Trained batch 442 batch loss 0.343351543 epoch total loss 0.363309532\n",
      "Trained batch 443 batch loss 0.346637845 epoch total loss 0.363271892\n",
      "Trained batch 444 batch loss 0.345661163 epoch total loss 0.363232195\n",
      "Trained batch 445 batch loss 0.335318744 epoch total loss 0.363169461\n",
      "Trained batch 446 batch loss 0.353090823 epoch total loss 0.363146871\n",
      "Trained batch 447 batch loss 0.33129397 epoch total loss 0.363075614\n",
      "Trained batch 448 batch loss 0.345718652 epoch total loss 0.363036871\n",
      "Trained batch 449 batch loss 0.346107632 epoch total loss 0.362999171\n",
      "Trained batch 450 batch loss 0.343068063 epoch total loss 0.362954885\n",
      "Trained batch 451 batch loss 0.340472877 epoch total loss 0.362905025\n",
      "Trained batch 452 batch loss 0.340716958 epoch total loss 0.362855941\n",
      "Trained batch 453 batch loss 0.341508389 epoch total loss 0.362808794\n",
      "Trained batch 454 batch loss 0.344406664 epoch total loss 0.362768263\n",
      "Trained batch 455 batch loss 0.353558183 epoch total loss 0.362748027\n",
      "Trained batch 456 batch loss 0.371142775 epoch total loss 0.362766445\n",
      "Trained batch 457 batch loss 0.426049083 epoch total loss 0.362904936\n",
      "Trained batch 458 batch loss 0.384751141 epoch total loss 0.36295262\n",
      "Trained batch 459 batch loss 0.331581593 epoch total loss 0.362884283\n",
      "Trained batch 460 batch loss 0.337985784 epoch total loss 0.362830162\n",
      "Trained batch 461 batch loss 0.341593951 epoch total loss 0.362784088\n",
      "Trained batch 462 batch loss 0.331531793 epoch total loss 0.362716436\n",
      "Trained batch 463 batch loss 0.345898211 epoch total loss 0.362680137\n",
      "Trained batch 464 batch loss 0.322634339 epoch total loss 0.36259383\n",
      "Trained batch 465 batch loss 0.369794399 epoch total loss 0.362609297\n",
      "Trained batch 466 batch loss 0.344995379 epoch total loss 0.362571508\n",
      "Trained batch 467 batch loss 0.383971512 epoch total loss 0.362617344\n",
      "Trained batch 468 batch loss 0.358652234 epoch total loss 0.36260888\n",
      "Trained batch 469 batch loss 0.348103702 epoch total loss 0.362577945\n",
      "Trained batch 470 batch loss 0.32687366 epoch total loss 0.362501979\n",
      "Trained batch 471 batch loss 0.327529669 epoch total loss 0.362427741\n",
      "Trained batch 472 batch loss 0.350512147 epoch total loss 0.362402469\n",
      "Trained batch 473 batch loss 0.331938028 epoch total loss 0.362338066\n",
      "Trained batch 474 batch loss 0.315155059 epoch total loss 0.362238526\n",
      "Trained batch 475 batch loss 0.335981905 epoch total loss 0.362183273\n",
      "Trained batch 476 batch loss 0.334588319 epoch total loss 0.362125307\n",
      "Trained batch 477 batch loss 0.292298317 epoch total loss 0.361978918\n",
      "Trained batch 478 batch loss 0.362037033 epoch total loss 0.361979\n",
      "Trained batch 479 batch loss 0.36374408 epoch total loss 0.361982703\n",
      "Trained batch 480 batch loss 0.342222601 epoch total loss 0.361941516\n",
      "Trained batch 481 batch loss 0.3706595 epoch total loss 0.361959666\n",
      "Trained batch 482 batch loss 0.317387 epoch total loss 0.361867189\n",
      "Trained batch 483 batch loss 0.30344072 epoch total loss 0.361746222\n",
      "Trained batch 484 batch loss 0.31677705 epoch total loss 0.361653298\n",
      "Trained batch 485 batch loss 0.356228679 epoch total loss 0.361642122\n",
      "Trained batch 486 batch loss 0.360500038 epoch total loss 0.361639768\n",
      "Trained batch 487 batch loss 0.37408343 epoch total loss 0.361665308\n",
      "Trained batch 488 batch loss 0.376586229 epoch total loss 0.361695886\n",
      "Trained batch 489 batch loss 0.36629504 epoch total loss 0.361705333\n",
      "Trained batch 490 batch loss 0.362278461 epoch total loss 0.361706495\n",
      "Trained batch 491 batch loss 0.369166404 epoch total loss 0.361721694\n",
      "Trained batch 492 batch loss 0.339802355 epoch total loss 0.36167711\n",
      "Trained batch 493 batch loss 0.344186366 epoch total loss 0.361641645\n",
      "Trained batch 494 batch loss 0.351293594 epoch total loss 0.361620694\n",
      "Trained batch 495 batch loss 0.347255319 epoch total loss 0.361591697\n",
      "Trained batch 496 batch loss 0.369439 epoch total loss 0.361607522\n",
      "Trained batch 497 batch loss 0.350846112 epoch total loss 0.361585855\n",
      "Trained batch 498 batch loss 0.344033629 epoch total loss 0.361550629\n",
      "Trained batch 499 batch loss 0.34733814 epoch total loss 0.361522138\n",
      "Trained batch 500 batch loss 0.354572743 epoch total loss 0.36150825\n",
      "Trained batch 501 batch loss 0.355626613 epoch total loss 0.361496478\n",
      "Trained batch 502 batch loss 0.355311573 epoch total loss 0.36148417\n",
      "Trained batch 503 batch loss 0.345392078 epoch total loss 0.361452192\n",
      "Trained batch 504 batch loss 0.370906323 epoch total loss 0.361470968\n",
      "Trained batch 505 batch loss 0.336521536 epoch total loss 0.361421555\n",
      "Trained batch 506 batch loss 0.341590136 epoch total loss 0.361382335\n",
      "Trained batch 507 batch loss 0.320298165 epoch total loss 0.361301303\n",
      "Trained batch 508 batch loss 0.291826099 epoch total loss 0.36116454\n",
      "Trained batch 509 batch loss 0.305576622 epoch total loss 0.361055315\n",
      "Trained batch 510 batch loss 0.308834612 epoch total loss 0.360952944\n",
      "Trained batch 511 batch loss 0.311582804 epoch total loss 0.360856324\n",
      "Trained batch 512 batch loss 0.280647 epoch total loss 0.360699654\n",
      "Trained batch 513 batch loss 0.270156235 epoch total loss 0.360523164\n",
      "Trained batch 514 batch loss 0.265595078 epoch total loss 0.360338479\n",
      "Trained batch 515 batch loss 0.285808623 epoch total loss 0.360193759\n",
      "Trained batch 516 batch loss 0.314083 epoch total loss 0.360104412\n",
      "Trained batch 517 batch loss 0.359633207 epoch total loss 0.360103488\n",
      "Trained batch 518 batch loss 0.320678979 epoch total loss 0.360027373\n",
      "Trained batch 519 batch loss 0.327400625 epoch total loss 0.35996455\n",
      "Trained batch 520 batch loss 0.344604105 epoch total loss 0.359935\n",
      "Trained batch 521 batch loss 0.315621853 epoch total loss 0.35984996\n",
      "Trained batch 522 batch loss 0.333148211 epoch total loss 0.359798789\n",
      "Trained batch 523 batch loss 0.337833047 epoch total loss 0.359756798\n",
      "Trained batch 524 batch loss 0.313806832 epoch total loss 0.359669119\n",
      "Trained batch 525 batch loss 0.350449085 epoch total loss 0.359651536\n",
      "Trained batch 526 batch loss 0.335513413 epoch total loss 0.35960564\n",
      "Trained batch 527 batch loss 0.352567196 epoch total loss 0.359592289\n",
      "Trained batch 528 batch loss 0.343131661 epoch total loss 0.359561116\n",
      "Trained batch 529 batch loss 0.377639115 epoch total loss 0.359595299\n",
      "Trained batch 530 batch loss 0.327882469 epoch total loss 0.359535456\n",
      "Trained batch 531 batch loss 0.368220031 epoch total loss 0.359551817\n",
      "Trained batch 532 batch loss 0.350171357 epoch total loss 0.359534174\n",
      "Trained batch 533 batch loss 0.336713314 epoch total loss 0.359491378\n",
      "Trained batch 534 batch loss 0.296010733 epoch total loss 0.359372497\n",
      "Trained batch 535 batch loss 0.335719645 epoch total loss 0.35932827\n",
      "Trained batch 536 batch loss 0.34666422 epoch total loss 0.359304667\n",
      "Trained batch 537 batch loss 0.361630231 epoch total loss 0.359309\n",
      "Trained batch 538 batch loss 0.34692353 epoch total loss 0.35928598\n",
      "Trained batch 539 batch loss 0.355349302 epoch total loss 0.359278649\n",
      "Trained batch 540 batch loss 0.321944207 epoch total loss 0.359209538\n",
      "Trained batch 541 batch loss 0.339555591 epoch total loss 0.359173208\n",
      "Trained batch 542 batch loss 0.309805095 epoch total loss 0.359082103\n",
      "Trained batch 543 batch loss 0.305243224 epoch total loss 0.35898295\n",
      "Trained batch 544 batch loss 0.307888269 epoch total loss 0.358889\n",
      "Trained batch 545 batch loss 0.334976465 epoch total loss 0.358845145\n",
      "Trained batch 546 batch loss 0.372640938 epoch total loss 0.358870387\n",
      "Trained batch 547 batch loss 0.362238 epoch total loss 0.358876556\n",
      "Trained batch 548 batch loss 0.347536743 epoch total loss 0.358855873\n",
      "Trained batch 549 batch loss 0.314539462 epoch total loss 0.358775169\n",
      "Trained batch 550 batch loss 0.312730968 epoch total loss 0.358691424\n",
      "Trained batch 551 batch loss 0.345626205 epoch total loss 0.358667731\n",
      "Trained batch 552 batch loss 0.349767953 epoch total loss 0.358651578\n",
      "Trained batch 553 batch loss 0.323471218 epoch total loss 0.35858798\n",
      "Trained batch 554 batch loss 0.310757905 epoch total loss 0.358501643\n",
      "Trained batch 555 batch loss 0.332288891 epoch total loss 0.358454406\n",
      "Trained batch 556 batch loss 0.326826781 epoch total loss 0.358397543\n",
      "Trained batch 557 batch loss 0.361687303 epoch total loss 0.358403444\n",
      "Trained batch 558 batch loss 0.357863396 epoch total loss 0.358402491\n",
      "Trained batch 559 batch loss 0.325544536 epoch total loss 0.35834372\n",
      "Trained batch 560 batch loss 0.300386369 epoch total loss 0.358240217\n",
      "Trained batch 561 batch loss 0.307553679 epoch total loss 0.358149856\n",
      "Trained batch 562 batch loss 0.308577657 epoch total loss 0.358061671\n",
      "Trained batch 563 batch loss 0.309957325 epoch total loss 0.357976198\n",
      "Trained batch 564 batch loss 0.297320247 epoch total loss 0.357868642\n",
      "Trained batch 565 batch loss 0.316845655 epoch total loss 0.357796043\n",
      "Trained batch 566 batch loss 0.300950706 epoch total loss 0.357695609\n",
      "Trained batch 567 batch loss 0.308386832 epoch total loss 0.357608646\n",
      "Trained batch 568 batch loss 0.328990608 epoch total loss 0.35755825\n",
      "Trained batch 569 batch loss 0.35737285 epoch total loss 0.357557952\n",
      "Trained batch 570 batch loss 0.348992705 epoch total loss 0.357542932\n",
      "Trained batch 571 batch loss 0.351858556 epoch total loss 0.357532948\n",
      "Trained batch 572 batch loss 0.316445559 epoch total loss 0.357461154\n",
      "Trained batch 573 batch loss 0.308337241 epoch total loss 0.357375413\n",
      "Trained batch 574 batch loss 0.308636606 epoch total loss 0.357290506\n",
      "Trained batch 575 batch loss 0.323287219 epoch total loss 0.357231379\n",
      "Trained batch 576 batch loss 0.343354613 epoch total loss 0.357207268\n",
      "Trained batch 577 batch loss 0.354805529 epoch total loss 0.357203126\n",
      "Trained batch 578 batch loss 0.345017493 epoch total loss 0.357182026\n",
      "Trained batch 579 batch loss 0.345715106 epoch total loss 0.357162237\n",
      "Trained batch 580 batch loss 0.328720093 epoch total loss 0.357113212\n",
      "Trained batch 581 batch loss 0.350254685 epoch total loss 0.357101381\n",
      "Trained batch 582 batch loss 0.31443432 epoch total loss 0.357028097\n",
      "Trained batch 583 batch loss 0.337697685 epoch total loss 0.356994927\n",
      "Trained batch 584 batch loss 0.339441746 epoch total loss 0.356964856\n",
      "Trained batch 585 batch loss 0.330523878 epoch total loss 0.356919676\n",
      "Trained batch 586 batch loss 0.34596765 epoch total loss 0.35690096\n",
      "Trained batch 587 batch loss 0.34351638 epoch total loss 0.356878161\n",
      "Trained batch 588 batch loss 0.340546489 epoch total loss 0.356850386\n",
      "Trained batch 589 batch loss 0.330525577 epoch total loss 0.356805682\n",
      "Trained batch 590 batch loss 0.323013455 epoch total loss 0.356748432\n",
      "Trained batch 591 batch loss 0.336049557 epoch total loss 0.356713384\n",
      "Trained batch 592 batch loss 0.36220181 epoch total loss 0.356722653\n",
      "Trained batch 593 batch loss 0.327985048 epoch total loss 0.356674194\n",
      "Trained batch 594 batch loss 0.321107328 epoch total loss 0.356614321\n",
      "Trained batch 595 batch loss 0.327445805 epoch total loss 0.356565267\n",
      "Trained batch 596 batch loss 0.33451587 epoch total loss 0.356528282\n",
      "Trained batch 597 batch loss 0.342009574 epoch total loss 0.356503963\n",
      "Trained batch 598 batch loss 0.321293265 epoch total loss 0.356445074\n",
      "Trained batch 599 batch loss 0.325481921 epoch total loss 0.356393397\n",
      "Trained batch 600 batch loss 0.352198482 epoch total loss 0.356386423\n",
      "Trained batch 601 batch loss 0.333902508 epoch total loss 0.356349021\n",
      "Trained batch 602 batch loss 0.356369644 epoch total loss 0.356349051\n",
      "Trained batch 603 batch loss 0.339229 epoch total loss 0.356320649\n",
      "Trained batch 604 batch loss 0.357111782 epoch total loss 0.356322\n",
      "Trained batch 605 batch loss 0.330586314 epoch total loss 0.356279433\n",
      "Trained batch 606 batch loss 0.360040784 epoch total loss 0.356285661\n",
      "Trained batch 607 batch loss 0.315471888 epoch total loss 0.356218427\n",
      "Trained batch 608 batch loss 0.316116482 epoch total loss 0.356152445\n",
      "Trained batch 609 batch loss 0.3277978 epoch total loss 0.356105924\n",
      "Trained batch 610 batch loss 0.357064813 epoch total loss 0.356107503\n",
      "Trained batch 611 batch loss 0.340933979 epoch total loss 0.356082648\n",
      "Trained batch 612 batch loss 0.32506603 epoch total loss 0.356031984\n",
      "Trained batch 613 batch loss 0.33074367 epoch total loss 0.355990738\n",
      "Trained batch 614 batch loss 0.316081911 epoch total loss 0.355925739\n",
      "Trained batch 615 batch loss 0.338066965 epoch total loss 0.355896711\n",
      "Trained batch 616 batch loss 0.353539526 epoch total loss 0.355892897\n",
      "Trained batch 617 batch loss 0.351091 epoch total loss 0.355885118\n",
      "Trained batch 618 batch loss 0.334185243 epoch total loss 0.35585\n",
      "Trained batch 619 batch loss 0.329723716 epoch total loss 0.355807781\n",
      "Trained batch 620 batch loss 0.303699493 epoch total loss 0.355723739\n",
      "Trained batch 621 batch loss 0.357597679 epoch total loss 0.355726779\n",
      "Trained batch 622 batch loss 0.347508609 epoch total loss 0.355713546\n",
      "Trained batch 623 batch loss 0.338138 epoch total loss 0.355685323\n",
      "Trained batch 624 batch loss 0.363309681 epoch total loss 0.355697572\n",
      "Trained batch 625 batch loss 0.35232684 epoch total loss 0.355692148\n",
      "Trained batch 626 batch loss 0.356537521 epoch total loss 0.355693519\n",
      "Trained batch 627 batch loss 0.36998418 epoch total loss 0.355716288\n",
      "Trained batch 628 batch loss 0.326251179 epoch total loss 0.355669379\n",
      "Trained batch 629 batch loss 0.316937625 epoch total loss 0.355607808\n",
      "Trained batch 630 batch loss 0.335871369 epoch total loss 0.355576485\n",
      "Trained batch 631 batch loss 0.313751727 epoch total loss 0.355510205\n",
      "Trained batch 632 batch loss 0.31539 epoch total loss 0.355446696\n",
      "Trained batch 633 batch loss 0.352007955 epoch total loss 0.355441272\n",
      "Trained batch 634 batch loss 0.342415124 epoch total loss 0.355420738\n",
      "Trained batch 635 batch loss 0.365455449 epoch total loss 0.355436534\n",
      "Trained batch 636 batch loss 0.35618788 epoch total loss 0.355437696\n",
      "Trained batch 637 batch loss 0.341250539 epoch total loss 0.355415434\n",
      "Trained batch 638 batch loss 0.339733243 epoch total loss 0.355390847\n",
      "Trained batch 639 batch loss 0.355990648 epoch total loss 0.3553918\n",
      "Trained batch 640 batch loss 0.338428497 epoch total loss 0.355365276\n",
      "Trained batch 641 batch loss 0.333888084 epoch total loss 0.355331779\n",
      "Trained batch 642 batch loss 0.320192307 epoch total loss 0.355277032\n",
      "Trained batch 643 batch loss 0.33306694 epoch total loss 0.355242491\n",
      "Trained batch 644 batch loss 0.311321199 epoch total loss 0.355174303\n",
      "Trained batch 645 batch loss 0.321277827 epoch total loss 0.355121762\n",
      "Trained batch 646 batch loss 0.331160605 epoch total loss 0.355084658\n",
      "Trained batch 647 batch loss 0.329808027 epoch total loss 0.355045587\n",
      "Trained batch 648 batch loss 0.328646749 epoch total loss 0.355004847\n",
      "Trained batch 649 batch loss 0.308734775 epoch total loss 0.35493353\n",
      "Trained batch 650 batch loss 0.326656818 epoch total loss 0.354890049\n",
      "Trained batch 651 batch loss 0.329891443 epoch total loss 0.354851633\n",
      "Trained batch 652 batch loss 0.36610347 epoch total loss 0.354868919\n",
      "Trained batch 653 batch loss 0.315314919 epoch total loss 0.354808331\n",
      "Trained batch 654 batch loss 0.315989554 epoch total loss 0.354748964\n",
      "Trained batch 655 batch loss 0.299153447 epoch total loss 0.354664087\n",
      "Trained batch 656 batch loss 0.328607261 epoch total loss 0.354624391\n",
      "Trained batch 657 batch loss 0.324068338 epoch total loss 0.354577869\n",
      "Trained batch 658 batch loss 0.332106441 epoch total loss 0.354543716\n",
      "Trained batch 659 batch loss 0.296162724 epoch total loss 0.354455113\n",
      "Trained batch 660 batch loss 0.325785846 epoch total loss 0.354411691\n",
      "Trained batch 661 batch loss 0.343753576 epoch total loss 0.354395568\n",
      "Trained batch 662 batch loss 0.322922379 epoch total loss 0.354348\n",
      "Trained batch 663 batch loss 0.350536287 epoch total loss 0.354342282\n",
      "Trained batch 664 batch loss 0.305982143 epoch total loss 0.354269445\n",
      "Trained batch 665 batch loss 0.303207636 epoch total loss 0.354192644\n",
      "Trained batch 666 batch loss 0.327319115 epoch total loss 0.354152292\n",
      "Trained batch 667 batch loss 0.32702145 epoch total loss 0.354111642\n",
      "Trained batch 668 batch loss 0.364013582 epoch total loss 0.354126453\n",
      "Trained batch 669 batch loss 0.356385 epoch total loss 0.354129821\n",
      "Trained batch 670 batch loss 0.328172207 epoch total loss 0.354091078\n",
      "Trained batch 671 batch loss 0.321009248 epoch total loss 0.354041785\n",
      "Trained batch 672 batch loss 0.307538509 epoch total loss 0.353972584\n",
      "Trained batch 673 batch loss 0.343933582 epoch total loss 0.353957683\n",
      "Trained batch 674 batch loss 0.355746776 epoch total loss 0.353960335\n",
      "Trained batch 675 batch loss 0.339246035 epoch total loss 0.35393852\n",
      "Trained batch 676 batch loss 0.349837631 epoch total loss 0.35393247\n",
      "Trained batch 677 batch loss 0.339205503 epoch total loss 0.353910714\n",
      "Trained batch 678 batch loss 0.33101064 epoch total loss 0.353876919\n",
      "Trained batch 679 batch loss 0.352840066 epoch total loss 0.353875399\n",
      "Trained batch 680 batch loss 0.340927243 epoch total loss 0.353856355\n",
      "Trained batch 681 batch loss 0.354591161 epoch total loss 0.353857428\n",
      "Trained batch 682 batch loss 0.327294469 epoch total loss 0.353818506\n",
      "Trained batch 683 batch loss 0.315779626 epoch total loss 0.353762805\n",
      "Trained batch 684 batch loss 0.335229725 epoch total loss 0.353735715\n",
      "Trained batch 685 batch loss 0.321780562 epoch total loss 0.353689075\n",
      "Trained batch 686 batch loss 0.326880455 epoch total loss 0.353649974\n",
      "Trained batch 687 batch loss 0.318937033 epoch total loss 0.353599459\n",
      "Trained batch 688 batch loss 0.298065513 epoch total loss 0.353518724\n",
      "Trained batch 689 batch loss 0.342889875 epoch total loss 0.353503317\n",
      "Trained batch 690 batch loss 0.33593604 epoch total loss 0.353477865\n",
      "Trained batch 691 batch loss 0.323673427 epoch total loss 0.353434712\n",
      "Trained batch 692 batch loss 0.320597 epoch total loss 0.353387266\n",
      "Trained batch 693 batch loss 0.336721063 epoch total loss 0.353363216\n",
      "Trained batch 694 batch loss 0.348016173 epoch total loss 0.353355527\n",
      "Trained batch 695 batch loss 0.312370062 epoch total loss 0.353296548\n",
      "Trained batch 696 batch loss 0.351321638 epoch total loss 0.353293687\n",
      "Trained batch 697 batch loss 0.335183442 epoch total loss 0.353267729\n",
      "Trained batch 698 batch loss 0.31376639 epoch total loss 0.353211135\n",
      "Trained batch 699 batch loss 0.319027632 epoch total loss 0.353162229\n",
      "Trained batch 700 batch loss 0.318422139 epoch total loss 0.353112608\n",
      "Trained batch 701 batch loss 0.306131154 epoch total loss 0.353045583\n",
      "Trained batch 702 batch loss 0.316277504 epoch total loss 0.35299322\n",
      "Trained batch 703 batch loss 0.335694283 epoch total loss 0.352968603\n",
      "Trained batch 704 batch loss 0.340524852 epoch total loss 0.352950931\n",
      "Trained batch 705 batch loss 0.330345213 epoch total loss 0.352918893\n",
      "Trained batch 706 batch loss 0.32675907 epoch total loss 0.352881819\n",
      "Trained batch 707 batch loss 0.318646103 epoch total loss 0.35283339\n",
      "Trained batch 708 batch loss 0.308936715 epoch total loss 0.352771401\n",
      "Trained batch 709 batch loss 0.313983381 epoch total loss 0.352716684\n",
      "Trained batch 710 batch loss 0.344164163 epoch total loss 0.352704644\n",
      "Trained batch 711 batch loss 0.327643752 epoch total loss 0.352669388\n",
      "Trained batch 712 batch loss 0.319023967 epoch total loss 0.352622122\n",
      "Trained batch 713 batch loss 0.305400223 epoch total loss 0.352555901\n",
      "Trained batch 714 batch loss 0.322215229 epoch total loss 0.352513403\n",
      "Trained batch 715 batch loss 0.359950691 epoch total loss 0.352523834\n",
      "Trained batch 716 batch loss 0.327931583 epoch total loss 0.352489471\n",
      "Trained batch 717 batch loss 0.332174063 epoch total loss 0.352461129\n",
      "Trained batch 718 batch loss 0.391321331 epoch total loss 0.35251525\n",
      "Trained batch 719 batch loss 0.390043497 epoch total loss 0.352567464\n",
      "Trained batch 720 batch loss 0.387095511 epoch total loss 0.352615416\n",
      "Trained batch 721 batch loss 0.342095226 epoch total loss 0.352600843\n",
      "Trained batch 722 batch loss 0.327630877 epoch total loss 0.352566272\n",
      "Trained batch 723 batch loss 0.331060112 epoch total loss 0.3525365\n",
      "Trained batch 724 batch loss 0.312655151 epoch total loss 0.352481425\n",
      "Trained batch 725 batch loss 0.350077063 epoch total loss 0.352478117\n",
      "Trained batch 726 batch loss 0.372900635 epoch total loss 0.35250622\n",
      "Trained batch 727 batch loss 0.320339561 epoch total loss 0.352462\n",
      "Trained batch 728 batch loss 0.319414347 epoch total loss 0.352416605\n",
      "Trained batch 729 batch loss 0.308648527 epoch total loss 0.352356583\n",
      "Trained batch 730 batch loss 0.30391708 epoch total loss 0.352290243\n",
      "Trained batch 731 batch loss 0.323611557 epoch total loss 0.352251\n",
      "Trained batch 732 batch loss 0.389146298 epoch total loss 0.352301419\n",
      "Trained batch 733 batch loss 0.376125842 epoch total loss 0.352333933\n",
      "Trained batch 734 batch loss 0.367075652 epoch total loss 0.352354\n",
      "Trained batch 735 batch loss 0.359917194 epoch total loss 0.352364302\n",
      "Trained batch 736 batch loss 0.390221417 epoch total loss 0.35241574\n",
      "Trained batch 737 batch loss 0.367940873 epoch total loss 0.352436841\n",
      "Trained batch 738 batch loss 0.354932457 epoch total loss 0.352440178\n",
      "Trained batch 739 batch loss 0.358798444 epoch total loss 0.352448791\n",
      "Trained batch 740 batch loss 0.323558599 epoch total loss 0.35240972\n",
      "Trained batch 741 batch loss 0.341795802 epoch total loss 0.352395415\n",
      "Trained batch 742 batch loss 0.348230094 epoch total loss 0.352389812\n",
      "Trained batch 743 batch loss 0.340229928 epoch total loss 0.352373451\n",
      "Trained batch 744 batch loss 0.330800503 epoch total loss 0.352344483\n",
      "Trained batch 745 batch loss 0.343148947 epoch total loss 0.352332115\n",
      "Trained batch 746 batch loss 0.325890064 epoch total loss 0.35229668\n",
      "Trained batch 747 batch loss 0.332404226 epoch total loss 0.352270037\n",
      "Trained batch 748 batch loss 0.296747059 epoch total loss 0.352195829\n",
      "Trained batch 749 batch loss 0.332628608 epoch total loss 0.352169722\n",
      "Trained batch 750 batch loss 0.342052758 epoch total loss 0.352156222\n",
      "Trained batch 751 batch loss 0.37671876 epoch total loss 0.352188915\n",
      "Trained batch 752 batch loss 0.384757459 epoch total loss 0.352232218\n",
      "Trained batch 753 batch loss 0.367407352 epoch total loss 0.352252364\n",
      "Trained batch 754 batch loss 0.35637182 epoch total loss 0.352257848\n",
      "Trained batch 755 batch loss 0.311021239 epoch total loss 0.35220325\n",
      "Trained batch 756 batch loss 0.294855893 epoch total loss 0.352127403\n",
      "Trained batch 757 batch loss 0.274234295 epoch total loss 0.352024496\n",
      "Trained batch 758 batch loss 0.260656714 epoch total loss 0.351903945\n",
      "Trained batch 759 batch loss 0.303256661 epoch total loss 0.35183984\n",
      "Trained batch 760 batch loss 0.308735698 epoch total loss 0.351783156\n",
      "Trained batch 761 batch loss 0.331715077 epoch total loss 0.351756781\n",
      "Trained batch 762 batch loss 0.318710089 epoch total loss 0.351713419\n",
      "Trained batch 763 batch loss 0.279080182 epoch total loss 0.35161823\n",
      "Trained batch 764 batch loss 0.290597916 epoch total loss 0.35153833\n",
      "Trained batch 765 batch loss 0.331460118 epoch total loss 0.351512074\n",
      "Trained batch 766 batch loss 0.363840342 epoch total loss 0.351528168\n",
      "Trained batch 767 batch loss 0.354037523 epoch total loss 0.351531416\n",
      "Trained batch 768 batch loss 0.327937365 epoch total loss 0.35150072\n",
      "Trained batch 769 batch loss 0.335820913 epoch total loss 0.351480305\n",
      "Trained batch 770 batch loss 0.326166093 epoch total loss 0.351447433\n",
      "Trained batch 771 batch loss 0.296943128 epoch total loss 0.351376742\n",
      "Trained batch 772 batch loss 0.333341032 epoch total loss 0.351353377\n",
      "Trained batch 773 batch loss 0.320387721 epoch total loss 0.351313293\n",
      "Trained batch 774 batch loss 0.347856492 epoch total loss 0.351308852\n",
      "Trained batch 775 batch loss 0.327764958 epoch total loss 0.351278484\n",
      "Trained batch 776 batch loss 0.344197214 epoch total loss 0.351269364\n",
      "Trained batch 777 batch loss 0.330043703 epoch total loss 0.351242036\n",
      "Trained batch 778 batch loss 0.30955255 epoch total loss 0.351188451\n",
      "Trained batch 779 batch loss 0.327656 epoch total loss 0.351158261\n",
      "Trained batch 780 batch loss 0.307030916 epoch total loss 0.351101696\n",
      "Trained batch 781 batch loss 0.334573746 epoch total loss 0.351080507\n",
      "Trained batch 782 batch loss 0.317378044 epoch total loss 0.351037413\n",
      "Trained batch 783 batch loss 0.353933632 epoch total loss 0.351041138\n",
      "Trained batch 784 batch loss 0.355938613 epoch total loss 0.351047367\n",
      "Trained batch 785 batch loss 0.413079679 epoch total loss 0.351126403\n",
      "Trained batch 786 batch loss 0.367721349 epoch total loss 0.351147473\n",
      "Trained batch 787 batch loss 0.353836507 epoch total loss 0.35115093\n",
      "Trained batch 788 batch loss 0.35363102 epoch total loss 0.351154089\n",
      "Trained batch 789 batch loss 0.340190381 epoch total loss 0.351140171\n",
      "Trained batch 790 batch loss 0.304742903 epoch total loss 0.351081431\n",
      "Trained batch 791 batch loss 0.321787149 epoch total loss 0.351044387\n",
      "Trained batch 792 batch loss 0.327416062 epoch total loss 0.351014584\n",
      "Trained batch 793 batch loss 0.3381069 epoch total loss 0.350998282\n",
      "Trained batch 794 batch loss 0.335069627 epoch total loss 0.350978255\n",
      "Trained batch 795 batch loss 0.338469386 epoch total loss 0.35096252\n",
      "Trained batch 796 batch loss 0.30431205 epoch total loss 0.350903928\n",
      "Trained batch 797 batch loss 0.308988929 epoch total loss 0.350851327\n",
      "Trained batch 798 batch loss 0.281066418 epoch total loss 0.350763887\n",
      "Trained batch 799 batch loss 0.303588718 epoch total loss 0.350704849\n",
      "Trained batch 800 batch loss 0.319679499 epoch total loss 0.350666046\n",
      "Trained batch 801 batch loss 0.311989814 epoch total loss 0.350617737\n",
      "Trained batch 802 batch loss 0.318464249 epoch total loss 0.350577652\n",
      "Trained batch 803 batch loss 0.335848808 epoch total loss 0.350559294\n",
      "Trained batch 804 batch loss 0.339035124 epoch total loss 0.350545\n",
      "Trained batch 805 batch loss 0.326227903 epoch total loss 0.35051477\n",
      "Trained batch 806 batch loss 0.343637586 epoch total loss 0.350506246\n",
      "Trained batch 807 batch loss 0.367902368 epoch total loss 0.350527763\n",
      "Trained batch 808 batch loss 0.370229065 epoch total loss 0.350552171\n",
      "Trained batch 809 batch loss 0.364589214 epoch total loss 0.350569516\n",
      "Trained batch 810 batch loss 0.328154 epoch total loss 0.35054186\n",
      "Trained batch 811 batch loss 0.326313227 epoch total loss 0.350512\n",
      "Trained batch 812 batch loss 0.321274966 epoch total loss 0.350476\n",
      "Trained batch 813 batch loss 0.343495667 epoch total loss 0.350467443\n",
      "Trained batch 814 batch loss 0.348180622 epoch total loss 0.350464612\n",
      "Trained batch 815 batch loss 0.335423619 epoch total loss 0.350446165\n",
      "Trained batch 816 batch loss 0.367340326 epoch total loss 0.350466847\n",
      "Trained batch 817 batch loss 0.372802556 epoch total loss 0.350494206\n",
      "Trained batch 818 batch loss 0.376375496 epoch total loss 0.350525826\n",
      "Trained batch 819 batch loss 0.370306373 epoch total loss 0.350549966\n",
      "Trained batch 820 batch loss 0.353583276 epoch total loss 0.350553662\n",
      "Trained batch 821 batch loss 0.365053922 epoch total loss 0.350571334\n",
      "Trained batch 822 batch loss 0.354047596 epoch total loss 0.350575536\n",
      "Trained batch 823 batch loss 0.35033 epoch total loss 0.350575268\n",
      "Trained batch 824 batch loss 0.347898304 epoch total loss 0.35057202\n",
      "Trained batch 825 batch loss 0.3436248 epoch total loss 0.350563586\n",
      "Trained batch 826 batch loss 0.351611137 epoch total loss 0.350564867\n",
      "Trained batch 827 batch loss 0.341174692 epoch total loss 0.350553542\n",
      "Trained batch 828 batch loss 0.325591505 epoch total loss 0.350523382\n",
      "Trained batch 829 batch loss 0.334602684 epoch total loss 0.35050419\n",
      "Trained batch 830 batch loss 0.323005885 epoch total loss 0.35047105\n",
      "Trained batch 831 batch loss 0.324313104 epoch total loss 0.350439548\n",
      "Trained batch 832 batch loss 0.325741172 epoch total loss 0.350409865\n",
      "Trained batch 833 batch loss 0.31874308 epoch total loss 0.350371867\n",
      "Trained batch 834 batch loss 0.354897082 epoch total loss 0.350377291\n",
      "Trained batch 835 batch loss 0.343651503 epoch total loss 0.350369245\n",
      "Trained batch 836 batch loss 0.346473545 epoch total loss 0.350364566\n",
      "Trained batch 837 batch loss 0.342855513 epoch total loss 0.350355625\n",
      "Trained batch 838 batch loss 0.369509548 epoch total loss 0.350378484\n",
      "Trained batch 839 batch loss 0.346126497 epoch total loss 0.350373417\n",
      "Trained batch 840 batch loss 0.331509054 epoch total loss 0.350350946\n",
      "Trained batch 841 batch loss 0.326132983 epoch total loss 0.350322157\n",
      "Trained batch 842 batch loss 0.31563288 epoch total loss 0.35028097\n",
      "Trained batch 843 batch loss 0.30665949 epoch total loss 0.350229234\n",
      "Trained batch 844 batch loss 0.289998114 epoch total loss 0.350157887\n",
      "Trained batch 845 batch loss 0.322873324 epoch total loss 0.350125611\n",
      "Trained batch 846 batch loss 0.323089957 epoch total loss 0.350093663\n",
      "Trained batch 847 batch loss 0.321916282 epoch total loss 0.350060403\n",
      "Trained batch 848 batch loss 0.31324631 epoch total loss 0.350016981\n",
      "Trained batch 849 batch loss 0.309717476 epoch total loss 0.349969506\n",
      "Trained batch 850 batch loss 0.328937054 epoch total loss 0.34994477\n",
      "Trained batch 851 batch loss 0.299630731 epoch total loss 0.349885643\n",
      "Trained batch 852 batch loss 0.297855288 epoch total loss 0.349824578\n",
      "Trained batch 853 batch loss 0.306842864 epoch total loss 0.349774212\n",
      "Trained batch 854 batch loss 0.305680811 epoch total loss 0.349722594\n",
      "Trained batch 855 batch loss 0.31713286 epoch total loss 0.349684477\n",
      "Trained batch 856 batch loss 0.300633699 epoch total loss 0.349627167\n",
      "Trained batch 857 batch loss 0.319711477 epoch total loss 0.349592239\n",
      "Trained batch 858 batch loss 0.290173709 epoch total loss 0.349522978\n",
      "Trained batch 859 batch loss 0.331890434 epoch total loss 0.349502444\n",
      "Trained batch 860 batch loss 0.372683406 epoch total loss 0.349529386\n",
      "Trained batch 861 batch loss 0.354522824 epoch total loss 0.349535197\n",
      "Trained batch 862 batch loss 0.337935686 epoch total loss 0.349521726\n",
      "Trained batch 863 batch loss 0.375372827 epoch total loss 0.349551678\n",
      "Trained batch 864 batch loss 0.351472616 epoch total loss 0.349553883\n",
      "Trained batch 865 batch loss 0.349973202 epoch total loss 0.34955436\n",
      "Trained batch 866 batch loss 0.34563157 epoch total loss 0.34954986\n",
      "Trained batch 867 batch loss 0.325988263 epoch total loss 0.34952268\n",
      "Trained batch 868 batch loss 0.316174984 epoch total loss 0.349484235\n",
      "Trained batch 869 batch loss 0.32969895 epoch total loss 0.349461496\n",
      "Trained batch 870 batch loss 0.358683467 epoch total loss 0.349472076\n",
      "Trained batch 871 batch loss 0.331601232 epoch total loss 0.349451572\n",
      "Trained batch 872 batch loss 0.316949457 epoch total loss 0.349414289\n",
      "Trained batch 873 batch loss 0.332971931 epoch total loss 0.349395484\n",
      "Trained batch 874 batch loss 0.326174408 epoch total loss 0.3493689\n",
      "Trained batch 875 batch loss 0.329158157 epoch total loss 0.349345803\n",
      "Trained batch 876 batch loss 0.316105247 epoch total loss 0.349307865\n",
      "Trained batch 877 batch loss 0.333289921 epoch total loss 0.349289596\n",
      "Trained batch 878 batch loss 0.337783217 epoch total loss 0.349276453\n",
      "Trained batch 879 batch loss 0.322973222 epoch total loss 0.349246532\n",
      "Trained batch 880 batch loss 0.351329178 epoch total loss 0.349248886\n",
      "Trained batch 881 batch loss 0.311454982 epoch total loss 0.349206\n",
      "Trained batch 882 batch loss 0.326088488 epoch total loss 0.349179775\n",
      "Trained batch 883 batch loss 0.334902912 epoch total loss 0.349163592\n",
      "Trained batch 884 batch loss 0.34531188 epoch total loss 0.349159241\n",
      "Trained batch 885 batch loss 0.321136504 epoch total loss 0.349127591\n",
      "Trained batch 886 batch loss 0.344908893 epoch total loss 0.349122822\n",
      "Trained batch 887 batch loss 0.328871518 epoch total loss 0.349099964\n",
      "Trained batch 888 batch loss 0.323311627 epoch total loss 0.349070907\n",
      "Trained batch 889 batch loss 0.354088694 epoch total loss 0.349076569\n",
      "Trained batch 890 batch loss 0.31194973 epoch total loss 0.349034846\n",
      "Trained batch 891 batch loss 0.317070752 epoch total loss 0.348999\n",
      "Trained batch 892 batch loss 0.360780954 epoch total loss 0.349012196\n",
      "Trained batch 893 batch loss 0.330832869 epoch total loss 0.348991841\n",
      "Trained batch 894 batch loss 0.350738138 epoch total loss 0.348993808\n",
      "Trained batch 895 batch loss 0.333726287 epoch total loss 0.348976761\n",
      "Trained batch 896 batch loss 0.312756687 epoch total loss 0.348936319\n",
      "Trained batch 897 batch loss 0.347159952 epoch total loss 0.348934352\n",
      "Trained batch 898 batch loss 0.330600917 epoch total loss 0.348913938\n",
      "Trained batch 899 batch loss 0.344210863 epoch total loss 0.348908693\n",
      "Trained batch 900 batch loss 0.346668482 epoch total loss 0.348906219\n",
      "Trained batch 901 batch loss 0.336481869 epoch total loss 0.348892421\n",
      "Trained batch 902 batch loss 0.338465482 epoch total loss 0.348880887\n",
      "Trained batch 903 batch loss 0.356228173 epoch total loss 0.348889023\n",
      "Trained batch 904 batch loss 0.313031971 epoch total loss 0.348849326\n",
      "Trained batch 905 batch loss 0.342001796 epoch total loss 0.348841786\n",
      "Trained batch 906 batch loss 0.328273118 epoch total loss 0.348819077\n",
      "Trained batch 907 batch loss 0.343729556 epoch total loss 0.348813474\n",
      "Trained batch 908 batch loss 0.33975938 epoch total loss 0.34880349\n",
      "Trained batch 909 batch loss 0.30143258 epoch total loss 0.348751366\n",
      "Trained batch 910 batch loss 0.304263353 epoch total loss 0.348702461\n",
      "Trained batch 911 batch loss 0.322547793 epoch total loss 0.348673761\n",
      "Trained batch 912 batch loss 0.343784273 epoch total loss 0.348668396\n",
      "Trained batch 913 batch loss 0.317605913 epoch total loss 0.348634362\n",
      "Trained batch 914 batch loss 0.326198608 epoch total loss 0.348609805\n",
      "Trained batch 915 batch loss 0.292598486 epoch total loss 0.348548591\n",
      "Trained batch 916 batch loss 0.314723909 epoch total loss 0.348511666\n",
      "Trained batch 917 batch loss 0.29696691 epoch total loss 0.348455459\n",
      "Trained batch 918 batch loss 0.298477799 epoch total loss 0.34840104\n",
      "Trained batch 919 batch loss 0.32633546 epoch total loss 0.348377019\n",
      "Trained batch 920 batch loss 0.322293818 epoch total loss 0.348348677\n",
      "Trained batch 921 batch loss 0.308997154 epoch total loss 0.348305941\n",
      "Trained batch 922 batch loss 0.348339558 epoch total loss 0.34830597\n",
      "Trained batch 923 batch loss 0.335621983 epoch total loss 0.348292232\n",
      "Trained batch 924 batch loss 0.365041047 epoch total loss 0.348310351\n",
      "Trained batch 925 batch loss 0.394259095 epoch total loss 0.348360032\n",
      "Trained batch 926 batch loss 0.370432287 epoch total loss 0.348383874\n",
      "Trained batch 927 batch loss 0.342305303 epoch total loss 0.348377317\n",
      "Trained batch 928 batch loss 0.324722528 epoch total loss 0.348351836\n",
      "Trained batch 929 batch loss 0.307017535 epoch total loss 0.348307341\n",
      "Trained batch 930 batch loss 0.342248917 epoch total loss 0.348300815\n",
      "Trained batch 931 batch loss 0.35963732 epoch total loss 0.348313\n",
      "Trained batch 932 batch loss 0.364618331 epoch total loss 0.348330528\n",
      "Trained batch 933 batch loss 0.349505216 epoch total loss 0.348331779\n",
      "Trained batch 934 batch loss 0.361358553 epoch total loss 0.348345727\n",
      "Trained batch 935 batch loss 0.32545808 epoch total loss 0.348321259\n",
      "Trained batch 936 batch loss 0.341012567 epoch total loss 0.348313451\n",
      "Trained batch 937 batch loss 0.335793942 epoch total loss 0.34830007\n",
      "Trained batch 938 batch loss 0.355580568 epoch total loss 0.348307848\n",
      "Trained batch 939 batch loss 0.342592508 epoch total loss 0.348301768\n",
      "Trained batch 940 batch loss 0.326984406 epoch total loss 0.348279089\n",
      "Trained batch 941 batch loss 0.330645233 epoch total loss 0.348260373\n",
      "Trained batch 942 batch loss 0.323895603 epoch total loss 0.348234504\n",
      "Trained batch 943 batch loss 0.331813574 epoch total loss 0.3482171\n",
      "Trained batch 944 batch loss 0.325562924 epoch total loss 0.348193079\n",
      "Trained batch 945 batch loss 0.323126853 epoch total loss 0.348166555\n",
      "Trained batch 946 batch loss 0.323847324 epoch total loss 0.348140866\n",
      "Trained batch 947 batch loss 0.309828401 epoch total loss 0.348100394\n",
      "Trained batch 948 batch loss 0.305770427 epoch total loss 0.34805572\n",
      "Trained batch 949 batch loss 0.276161 epoch total loss 0.347979963\n",
      "Trained batch 950 batch loss 0.300888658 epoch total loss 0.347930402\n",
      "Trained batch 951 batch loss 0.302742511 epoch total loss 0.347882867\n",
      "Trained batch 952 batch loss 0.302124828 epoch total loss 0.347834796\n",
      "Trained batch 953 batch loss 0.302453578 epoch total loss 0.347787201\n",
      "Trained batch 954 batch loss 0.30904609 epoch total loss 0.347746581\n",
      "Trained batch 955 batch loss 0.293839306 epoch total loss 0.347690165\n",
      "Trained batch 956 batch loss 0.310210049 epoch total loss 0.347650945\n",
      "Trained batch 957 batch loss 0.346649498 epoch total loss 0.347649902\n",
      "Trained batch 958 batch loss 0.325313628 epoch total loss 0.347626597\n",
      "Trained batch 959 batch loss 0.314416468 epoch total loss 0.347591966\n",
      "Trained batch 960 batch loss 0.34197852 epoch total loss 0.347586125\n",
      "Trained batch 961 batch loss 0.317690551 epoch total loss 0.347555\n",
      "Trained batch 962 batch loss 0.351326138 epoch total loss 0.347558916\n",
      "Trained batch 963 batch loss 0.336833596 epoch total loss 0.34754777\n",
      "Trained batch 964 batch loss 0.249446213 epoch total loss 0.347446024\n",
      "Trained batch 965 batch loss 0.281463802 epoch total loss 0.347377628\n",
      "Trained batch 966 batch loss 0.331312299 epoch total loss 0.347361\n",
      "Trained batch 967 batch loss 0.301939249 epoch total loss 0.34731403\n",
      "Trained batch 968 batch loss 0.305531353 epoch total loss 0.347270876\n",
      "Trained batch 969 batch loss 0.319527656 epoch total loss 0.347242236\n",
      "Trained batch 970 batch loss 0.321261346 epoch total loss 0.347215444\n",
      "Trained batch 971 batch loss 0.339204222 epoch total loss 0.347207189\n",
      "Trained batch 972 batch loss 0.354391247 epoch total loss 0.34721458\n",
      "Trained batch 973 batch loss 0.316968858 epoch total loss 0.347183496\n",
      "Trained batch 974 batch loss 0.373855144 epoch total loss 0.347210854\n",
      "Trained batch 975 batch loss 0.371532708 epoch total loss 0.347235799\n",
      "Trained batch 976 batch loss 0.35201 epoch total loss 0.347240686\n",
      "Trained batch 977 batch loss 0.355788678 epoch total loss 0.347249418\n",
      "Trained batch 978 batch loss 0.312742293 epoch total loss 0.347214162\n",
      "Trained batch 979 batch loss 0.291116238 epoch total loss 0.347156852\n",
      "Trained batch 980 batch loss 0.287389636 epoch total loss 0.347095847\n",
      "Trained batch 981 batch loss 0.279775858 epoch total loss 0.347027242\n",
      "Trained batch 982 batch loss 0.320517123 epoch total loss 0.347000241\n",
      "Trained batch 983 batch loss 0.342132747 epoch total loss 0.346995294\n",
      "Trained batch 984 batch loss 0.352953047 epoch total loss 0.347001374\n",
      "Trained batch 985 batch loss 0.345321655 epoch total loss 0.346999675\n",
      "Trained batch 986 batch loss 0.304477245 epoch total loss 0.346956551\n",
      "Trained batch 987 batch loss 0.304859251 epoch total loss 0.346913904\n",
      "Trained batch 988 batch loss 0.338076085 epoch total loss 0.346904963\n",
      "Trained batch 989 batch loss 0.326855719 epoch total loss 0.346884668\n",
      "Trained batch 990 batch loss 0.326235414 epoch total loss 0.346863806\n",
      "Trained batch 991 batch loss 0.348782122 epoch total loss 0.346865743\n",
      "Trained batch 992 batch loss 0.343979627 epoch total loss 0.346862853\n",
      "Trained batch 993 batch loss 0.368063927 epoch total loss 0.346884221\n",
      "Trained batch 994 batch loss 0.336793125 epoch total loss 0.346874058\n",
      "Trained batch 995 batch loss 0.327410072 epoch total loss 0.346854508\n",
      "Trained batch 996 batch loss 0.310487241 epoch total loss 0.346818\n",
      "Trained batch 997 batch loss 0.296453834 epoch total loss 0.346767485\n",
      "Trained batch 998 batch loss 0.327494025 epoch total loss 0.346748143\n",
      "Trained batch 999 batch loss 0.307289392 epoch total loss 0.346708655\n",
      "Trained batch 1000 batch loss 0.324092567 epoch total loss 0.346686035\n",
      "Trained batch 1001 batch loss 0.309009969 epoch total loss 0.346648395\n",
      "Trained batch 1002 batch loss 0.330052853 epoch total loss 0.346631855\n",
      "Trained batch 1003 batch loss 0.323350668 epoch total loss 0.346608639\n",
      "Trained batch 1004 batch loss 0.33708474 epoch total loss 0.346599162\n",
      "Trained batch 1005 batch loss 0.318482071 epoch total loss 0.346571177\n",
      "Trained batch 1006 batch loss 0.334430546 epoch total loss 0.346559137\n",
      "Trained batch 1007 batch loss 0.349392563 epoch total loss 0.346561939\n",
      "Trained batch 1008 batch loss 0.352758646 epoch total loss 0.346568078\n",
      "Trained batch 1009 batch loss 0.314896882 epoch total loss 0.346536726\n",
      "Trained batch 1010 batch loss 0.345866978 epoch total loss 0.34653604\n",
      "Trained batch 1011 batch loss 0.322011054 epoch total loss 0.346511781\n",
      "Trained batch 1012 batch loss 0.317546189 epoch total loss 0.346483171\n",
      "Trained batch 1013 batch loss 0.315442622 epoch total loss 0.346452504\n",
      "Trained batch 1014 batch loss 0.321249425 epoch total loss 0.346427649\n",
      "Trained batch 1015 batch loss 0.318628728 epoch total loss 0.346400291\n",
      "Trained batch 1016 batch loss 0.350029469 epoch total loss 0.346403867\n",
      "Trained batch 1017 batch loss 0.3232916 epoch total loss 0.346381158\n",
      "Trained batch 1018 batch loss 0.311437458 epoch total loss 0.346346825\n",
      "Trained batch 1019 batch loss 0.334863752 epoch total loss 0.34633556\n",
      "Trained batch 1020 batch loss 0.331609368 epoch total loss 0.346321106\n",
      "Trained batch 1021 batch loss 0.328027129 epoch total loss 0.346303195\n",
      "Trained batch 1022 batch loss 0.333573669 epoch total loss 0.346290767\n",
      "Trained batch 1023 batch loss 0.333360314 epoch total loss 0.346278131\n",
      "Trained batch 1024 batch loss 0.339530259 epoch total loss 0.346271545\n",
      "Trained batch 1025 batch loss 0.314537048 epoch total loss 0.34624058\n",
      "Trained batch 1026 batch loss 0.327030361 epoch total loss 0.346221864\n",
      "Trained batch 1027 batch loss 0.321839899 epoch total loss 0.346198112\n",
      "Trained batch 1028 batch loss 0.319619685 epoch total loss 0.346172273\n",
      "Trained batch 1029 batch loss 0.30201304 epoch total loss 0.346129328\n",
      "Trained batch 1030 batch loss 0.338763833 epoch total loss 0.346122205\n",
      "Trained batch 1031 batch loss 0.345272303 epoch total loss 0.346121371\n",
      "Trained batch 1032 batch loss 0.348309189 epoch total loss 0.346123487\n",
      "Trained batch 1033 batch loss 0.351011634 epoch total loss 0.346128225\n",
      "Trained batch 1034 batch loss 0.347336113 epoch total loss 0.346129388\n",
      "Trained batch 1035 batch loss 0.330966443 epoch total loss 0.346114755\n",
      "Trained batch 1036 batch loss 0.331707269 epoch total loss 0.346100837\n",
      "Trained batch 1037 batch loss 0.319218427 epoch total loss 0.346074909\n",
      "Trained batch 1038 batch loss 0.328681052 epoch total loss 0.34605813\n",
      "Trained batch 1039 batch loss 0.323984146 epoch total loss 0.346036881\n",
      "Trained batch 1040 batch loss 0.310708702 epoch total loss 0.346002907\n",
      "Trained batch 1041 batch loss 0.30741334 epoch total loss 0.345965832\n",
      "Trained batch 1042 batch loss 0.29221189 epoch total loss 0.345914215\n",
      "Trained batch 1043 batch loss 0.287903935 epoch total loss 0.345858604\n",
      "Trained batch 1044 batch loss 0.308229953 epoch total loss 0.345822573\n",
      "Trained batch 1045 batch loss 0.299554765 epoch total loss 0.345778286\n",
      "Trained batch 1046 batch loss 0.319660097 epoch total loss 0.345753342\n",
      "Trained batch 1047 batch loss 0.323298246 epoch total loss 0.345731884\n",
      "Trained batch 1048 batch loss 0.342725754 epoch total loss 0.345729023\n",
      "Trained batch 1049 batch loss 0.359593779 epoch total loss 0.345742226\n",
      "Trained batch 1050 batch loss 0.298020869 epoch total loss 0.345696777\n",
      "Trained batch 1051 batch loss 0.323081434 epoch total loss 0.34567529\n",
      "Trained batch 1052 batch loss 0.324179858 epoch total loss 0.345654845\n",
      "Trained batch 1053 batch loss 0.328383386 epoch total loss 0.345638424\n",
      "Trained batch 1054 batch loss 0.325800925 epoch total loss 0.345619619\n",
      "Trained batch 1055 batch loss 0.340223283 epoch total loss 0.345614493\n",
      "Trained batch 1056 batch loss 0.340393662 epoch total loss 0.345609546\n",
      "Trained batch 1057 batch loss 0.321666777 epoch total loss 0.345586896\n",
      "Trained batch 1058 batch loss 0.335409373 epoch total loss 0.34557727\n",
      "Trained batch 1059 batch loss 0.343972206 epoch total loss 0.34557575\n",
      "Trained batch 1060 batch loss 0.360249609 epoch total loss 0.345589608\n",
      "Trained batch 1061 batch loss 0.333935082 epoch total loss 0.345578611\n",
      "Trained batch 1062 batch loss 0.30552426 epoch total loss 0.345540881\n",
      "Trained batch 1063 batch loss 0.325885445 epoch total loss 0.345522404\n",
      "Trained batch 1064 batch loss 0.319765896 epoch total loss 0.345498204\n",
      "Trained batch 1065 batch loss 0.331380486 epoch total loss 0.345484942\n",
      "Trained batch 1066 batch loss 0.320496023 epoch total loss 0.345461518\n",
      "Trained batch 1067 batch loss 0.330529392 epoch total loss 0.34544751\n",
      "Trained batch 1068 batch loss 0.33520031 epoch total loss 0.345437914\n",
      "Trained batch 1069 batch loss 0.295638233 epoch total loss 0.345391333\n",
      "Trained batch 1070 batch loss 0.309264481 epoch total loss 0.345357567\n",
      "Trained batch 1071 batch loss 0.305263072 epoch total loss 0.345320135\n",
      "Trained batch 1072 batch loss 0.294305384 epoch total loss 0.345272541\n",
      "Trained batch 1073 batch loss 0.291259259 epoch total loss 0.345222205\n",
      "Trained batch 1074 batch loss 0.322576702 epoch total loss 0.345201105\n",
      "Trained batch 1075 batch loss 0.297643125 epoch total loss 0.345156878\n",
      "Trained batch 1076 batch loss 0.294656128 epoch total loss 0.34510994\n",
      "Trained batch 1077 batch loss 0.280438721 epoch total loss 0.345049888\n",
      "Trained batch 1078 batch loss 0.300269514 epoch total loss 0.345008314\n",
      "Trained batch 1079 batch loss 0.321696788 epoch total loss 0.344986707\n",
      "Trained batch 1080 batch loss 0.30072397 epoch total loss 0.344945729\n",
      "Trained batch 1081 batch loss 0.340994149 epoch total loss 0.344942063\n",
      "Trained batch 1082 batch loss 0.337631911 epoch total loss 0.344935328\n",
      "Trained batch 1083 batch loss 0.325957417 epoch total loss 0.344917804\n",
      "Trained batch 1084 batch loss 0.32880041 epoch total loss 0.344902933\n",
      "Trained batch 1085 batch loss 0.315091163 epoch total loss 0.344875455\n",
      "Trained batch 1086 batch loss 0.313529432 epoch total loss 0.344846606\n",
      "Trained batch 1087 batch loss 0.291679502 epoch total loss 0.344797701\n",
      "Trained batch 1088 batch loss 0.319822729 epoch total loss 0.344774753\n",
      "Trained batch 1089 batch loss 0.300830841 epoch total loss 0.344734401\n",
      "Trained batch 1090 batch loss 0.297158509 epoch total loss 0.34469074\n",
      "Trained batch 1091 batch loss 0.343562186 epoch total loss 0.344689727\n",
      "Trained batch 1092 batch loss 0.287549466 epoch total loss 0.344637394\n",
      "Trained batch 1093 batch loss 0.318891466 epoch total loss 0.34461382\n",
      "Trained batch 1094 batch loss 0.268159956 epoch total loss 0.344543934\n",
      "Trained batch 1095 batch loss 0.26443845 epoch total loss 0.344470769\n",
      "Trained batch 1096 batch loss 0.319110841 epoch total loss 0.344447643\n",
      "Trained batch 1097 batch loss 0.319128841 epoch total loss 0.344424546\n",
      "Trained batch 1098 batch loss 0.337098479 epoch total loss 0.34441787\n",
      "Trained batch 1099 batch loss 0.299320489 epoch total loss 0.344376832\n",
      "Trained batch 1100 batch loss 0.327972561 epoch total loss 0.344361931\n",
      "Trained batch 1101 batch loss 0.28870976 epoch total loss 0.344311386\n",
      "Trained batch 1102 batch loss 0.288176119 epoch total loss 0.344260424\n",
      "Trained batch 1103 batch loss 0.295029342 epoch total loss 0.34421581\n",
      "Trained batch 1104 batch loss 0.340024829 epoch total loss 0.344212025\n",
      "Trained batch 1105 batch loss 0.33235845 epoch total loss 0.344201297\n",
      "Trained batch 1106 batch loss 0.307146788 epoch total loss 0.344167799\n",
      "Trained batch 1107 batch loss 0.312975407 epoch total loss 0.344139636\n",
      "Trained batch 1108 batch loss 0.337867796 epoch total loss 0.344133973\n",
      "Trained batch 1109 batch loss 0.295807034 epoch total loss 0.344090402\n",
      "Trained batch 1110 batch loss 0.285935968 epoch total loss 0.344038\n",
      "Trained batch 1111 batch loss 0.293564856 epoch total loss 0.343992591\n",
      "Trained batch 1112 batch loss 0.3310045 epoch total loss 0.343980908\n",
      "Trained batch 1113 batch loss 0.309149802 epoch total loss 0.343949616\n",
      "Trained batch 1114 batch loss 0.327607304 epoch total loss 0.343934953\n",
      "Trained batch 1115 batch loss 0.327564716 epoch total loss 0.343920261\n",
      "Trained batch 1116 batch loss 0.318299204 epoch total loss 0.343897313\n",
      "Trained batch 1117 batch loss 0.298923016 epoch total loss 0.34385705\n",
      "Trained batch 1118 batch loss 0.346484274 epoch total loss 0.343859404\n",
      "Trained batch 1119 batch loss 0.325525463 epoch total loss 0.343843\n",
      "Trained batch 1120 batch loss 0.331715256 epoch total loss 0.343832195\n",
      "Trained batch 1121 batch loss 0.322594494 epoch total loss 0.34381327\n",
      "Trained batch 1122 batch loss 0.325367868 epoch total loss 0.343796849\n",
      "Trained batch 1123 batch loss 0.304224819 epoch total loss 0.343761593\n",
      "Trained batch 1124 batch loss 0.310972422 epoch total loss 0.343732446\n",
      "Trained batch 1125 batch loss 0.329843074 epoch total loss 0.343720078\n",
      "Trained batch 1126 batch loss 0.308224976 epoch total loss 0.343688548\n",
      "Trained batch 1127 batch loss 0.323008925 epoch total loss 0.343670189\n",
      "Trained batch 1128 batch loss 0.317891121 epoch total loss 0.343647361\n",
      "Trained batch 1129 batch loss 0.320978254 epoch total loss 0.343627274\n",
      "Trained batch 1130 batch loss 0.316982448 epoch total loss 0.3436037\n",
      "Trained batch 1131 batch loss 0.327889085 epoch total loss 0.343589813\n",
      "Trained batch 1132 batch loss 0.330189317 epoch total loss 0.343577981\n",
      "Trained batch 1133 batch loss 0.361813366 epoch total loss 0.343594074\n",
      "Trained batch 1134 batch loss 0.356758803 epoch total loss 0.343605667\n",
      "Trained batch 1135 batch loss 0.330971569 epoch total loss 0.343594521\n",
      "Trained batch 1136 batch loss 0.320846289 epoch total loss 0.343574494\n",
      "Trained batch 1137 batch loss 0.325603306 epoch total loss 0.343558669\n",
      "Trained batch 1138 batch loss 0.306424439 epoch total loss 0.343526065\n",
      "Trained batch 1139 batch loss 0.361686 epoch total loss 0.343542\n",
      "Trained batch 1140 batch loss 0.345848083 epoch total loss 0.343544036\n",
      "Trained batch 1141 batch loss 0.39463678 epoch total loss 0.343588799\n",
      "Trained batch 1142 batch loss 0.359763891 epoch total loss 0.343603\n",
      "Trained batch 1143 batch loss 0.332648486 epoch total loss 0.343593389\n",
      "Trained batch 1144 batch loss 0.352834344 epoch total loss 0.343601465\n",
      "Trained batch 1145 batch loss 0.329320043 epoch total loss 0.343588978\n",
      "Trained batch 1146 batch loss 0.340728492 epoch total loss 0.343586504\n",
      "Trained batch 1147 batch loss 0.361715615 epoch total loss 0.3436023\n",
      "Trained batch 1148 batch loss 0.346169621 epoch total loss 0.343604535\n",
      "Trained batch 1149 batch loss 0.298113286 epoch total loss 0.343564957\n",
      "Trained batch 1150 batch loss 0.304350823 epoch total loss 0.343530864\n",
      "Trained batch 1151 batch loss 0.32441026 epoch total loss 0.343514234\n",
      "Trained batch 1152 batch loss 0.341142207 epoch total loss 0.343512177\n",
      "Trained batch 1153 batch loss 0.317545861 epoch total loss 0.343489647\n",
      "Trained batch 1154 batch loss 0.336850375 epoch total loss 0.343483925\n",
      "Trained batch 1155 batch loss 0.330646038 epoch total loss 0.343472809\n",
      "Trained batch 1156 batch loss 0.318392 epoch total loss 0.343451113\n",
      "Trained batch 1157 batch loss 0.322772563 epoch total loss 0.343433231\n",
      "Trained batch 1158 batch loss 0.332354039 epoch total loss 0.343423694\n",
      "Trained batch 1159 batch loss 0.321434289 epoch total loss 0.34340471\n",
      "Trained batch 1160 batch loss 0.332300037 epoch total loss 0.343395144\n",
      "Trained batch 1161 batch loss 0.327807754 epoch total loss 0.343381733\n",
      "Trained batch 1162 batch loss 0.3447842 epoch total loss 0.343382955\n",
      "Trained batch 1163 batch loss 0.337529659 epoch total loss 0.343377918\n",
      "Trained batch 1164 batch loss 0.338252395 epoch total loss 0.343373507\n",
      "Trained batch 1165 batch loss 0.305379 epoch total loss 0.343340904\n",
      "Trained batch 1166 batch loss 0.274378181 epoch total loss 0.343281776\n",
      "Trained batch 1167 batch loss 0.299650788 epoch total loss 0.343244374\n",
      "Trained batch 1168 batch loss 0.307787299 epoch total loss 0.343214035\n",
      "Trained batch 1169 batch loss 0.342578709 epoch total loss 0.343213499\n",
      "Trained batch 1170 batch loss 0.332219899 epoch total loss 0.343204111\n",
      "Trained batch 1171 batch loss 0.324197 epoch total loss 0.343187869\n",
      "Trained batch 1172 batch loss 0.347339422 epoch total loss 0.343191415\n",
      "Trained batch 1173 batch loss 0.327729285 epoch total loss 0.343178242\n",
      "Trained batch 1174 batch loss 0.327549279 epoch total loss 0.343164921\n",
      "Trained batch 1175 batch loss 0.334341615 epoch total loss 0.343157411\n",
      "Trained batch 1176 batch loss 0.285617918 epoch total loss 0.343108475\n",
      "Trained batch 1177 batch loss 0.313421071 epoch total loss 0.343083262\n",
      "Trained batch 1178 batch loss 0.309367776 epoch total loss 0.343054622\n",
      "Trained batch 1179 batch loss 0.322528154 epoch total loss 0.343037218\n",
      "Trained batch 1180 batch loss 0.28915441 epoch total loss 0.342991561\n",
      "Trained batch 1181 batch loss 0.296140373 epoch total loss 0.342951894\n",
      "Trained batch 1182 batch loss 0.290525943 epoch total loss 0.342907548\n",
      "Trained batch 1183 batch loss 0.294202805 epoch total loss 0.342866361\n",
      "Trained batch 1184 batch loss 0.303955048 epoch total loss 0.342833489\n",
      "Trained batch 1185 batch loss 0.310263515 epoch total loss 0.342806\n",
      "Trained batch 1186 batch loss 0.297905 epoch total loss 0.342768162\n",
      "Trained batch 1187 batch loss 0.28315407 epoch total loss 0.342717916\n",
      "Trained batch 1188 batch loss 0.340196252 epoch total loss 0.34271583\n",
      "Trained batch 1189 batch loss 0.343618274 epoch total loss 0.342716575\n",
      "Trained batch 1190 batch loss 0.343867898 epoch total loss 0.342717558\n",
      "Trained batch 1191 batch loss 0.354181021 epoch total loss 0.342727184\n",
      "Trained batch 1192 batch loss 0.326882184 epoch total loss 0.342713892\n",
      "Trained batch 1193 batch loss 0.352820098 epoch total loss 0.342722356\n",
      "Trained batch 1194 batch loss 0.319845498 epoch total loss 0.342703193\n",
      "Trained batch 1195 batch loss 0.348219365 epoch total loss 0.342707813\n",
      "Trained batch 1196 batch loss 0.315026224 epoch total loss 0.342684656\n",
      "Trained batch 1197 batch loss 0.341841698 epoch total loss 0.342683941\n",
      "Trained batch 1198 batch loss 0.338139921 epoch total loss 0.342680156\n",
      "Trained batch 1199 batch loss 0.345686495 epoch total loss 0.34268266\n",
      "Trained batch 1200 batch loss 0.332066625 epoch total loss 0.342673808\n",
      "Trained batch 1201 batch loss 0.297916532 epoch total loss 0.342636526\n",
      "Trained batch 1202 batch loss 0.330008894 epoch total loss 0.342626035\n",
      "Trained batch 1203 batch loss 0.372121841 epoch total loss 0.342650563\n",
      "Trained batch 1204 batch loss 0.340014428 epoch total loss 0.342648387\n",
      "Trained batch 1205 batch loss 0.310888082 epoch total loss 0.342622\n",
      "Trained batch 1206 batch loss 0.332473904 epoch total loss 0.342613608\n",
      "Trained batch 1207 batch loss 0.344909787 epoch total loss 0.342615515\n",
      "Trained batch 1208 batch loss 0.327424347 epoch total loss 0.342602938\n",
      "Trained batch 1209 batch loss 0.3553195 epoch total loss 0.342613459\n",
      "Trained batch 1210 batch loss 0.334716737 epoch total loss 0.342606932\n",
      "Trained batch 1211 batch loss 0.354949862 epoch total loss 0.342617124\n",
      "Trained batch 1212 batch loss 0.337999821 epoch total loss 0.34261331\n",
      "Trained batch 1213 batch loss 0.302039981 epoch total loss 0.342579871\n",
      "Trained batch 1214 batch loss 0.284622848 epoch total loss 0.342532128\n",
      "Trained batch 1215 batch loss 0.256785959 epoch total loss 0.342461556\n",
      "Trained batch 1216 batch loss 0.298899382 epoch total loss 0.342425734\n",
      "Trained batch 1217 batch loss 0.349208862 epoch total loss 0.342431307\n",
      "Trained batch 1218 batch loss 0.336004913 epoch total loss 0.342426032\n",
      "Trained batch 1219 batch loss 0.340668112 epoch total loss 0.342424572\n",
      "Trained batch 1220 batch loss 0.361653894 epoch total loss 0.342440337\n",
      "Trained batch 1221 batch loss 0.353439659 epoch total loss 0.342449367\n",
      "Trained batch 1222 batch loss 0.321929187 epoch total loss 0.342432588\n",
      "Trained batch 1223 batch loss 0.297038525 epoch total loss 0.342395455\n",
      "Trained batch 1224 batch loss 0.303129047 epoch total loss 0.342363358\n",
      "Trained batch 1225 batch loss 0.333714902 epoch total loss 0.342356294\n",
      "Trained batch 1226 batch loss 0.313912779 epoch total loss 0.342333108\n",
      "Trained batch 1227 batch loss 0.340873152 epoch total loss 0.342331916\n",
      "Trained batch 1228 batch loss 0.330454648 epoch total loss 0.34232223\n",
      "Trained batch 1229 batch loss 0.334725052 epoch total loss 0.342316031\n",
      "Trained batch 1230 batch loss 0.331516147 epoch total loss 0.34230727\n",
      "Trained batch 1231 batch loss 0.341369569 epoch total loss 0.342306495\n",
      "Trained batch 1232 batch loss 0.368841887 epoch total loss 0.342328042\n",
      "Trained batch 1233 batch loss 0.332358658 epoch total loss 0.342319965\n",
      "Trained batch 1234 batch loss 0.364319682 epoch total loss 0.342337787\n",
      "Trained batch 1235 batch loss 0.351028621 epoch total loss 0.34234482\n",
      "Trained batch 1236 batch loss 0.324441791 epoch total loss 0.342330337\n",
      "Trained batch 1237 batch loss 0.318097085 epoch total loss 0.342310727\n",
      "Trained batch 1238 batch loss 0.320451051 epoch total loss 0.342293084\n",
      "Trained batch 1239 batch loss 0.311021566 epoch total loss 0.342267871\n",
      "Trained batch 1240 batch loss 0.310706258 epoch total loss 0.34224242\n",
      "Trained batch 1241 batch loss 0.312672615 epoch total loss 0.342218578\n",
      "Trained batch 1242 batch loss 0.319548488 epoch total loss 0.342200339\n",
      "Trained batch 1243 batch loss 0.328059047 epoch total loss 0.342188954\n",
      "Trained batch 1244 batch loss 0.35243839 epoch total loss 0.34219721\n",
      "Trained batch 1245 batch loss 0.350280792 epoch total loss 0.342203707\n",
      "Trained batch 1246 batch loss 0.317390382 epoch total loss 0.342183769\n",
      "Trained batch 1247 batch loss 0.306655437 epoch total loss 0.342155278\n",
      "Trained batch 1248 batch loss 0.279725611 epoch total loss 0.34210524\n",
      "Trained batch 1249 batch loss 0.297384262 epoch total loss 0.342069447\n",
      "Trained batch 1250 batch loss 0.299123198 epoch total loss 0.342035115\n",
      "Trained batch 1251 batch loss 0.33977887 epoch total loss 0.342033297\n",
      "Trained batch 1252 batch loss 0.331400514 epoch total loss 0.342024803\n",
      "Trained batch 1253 batch loss 0.326248825 epoch total loss 0.342012227\n",
      "Trained batch 1254 batch loss 0.307158291 epoch total loss 0.341984421\n",
      "Trained batch 1255 batch loss 0.312923312 epoch total loss 0.341961294\n",
      "Trained batch 1256 batch loss 0.336134791 epoch total loss 0.341956645\n",
      "Trained batch 1257 batch loss 0.273089349 epoch total loss 0.341901839\n",
      "Trained batch 1258 batch loss 0.337496042 epoch total loss 0.341898352\n",
      "Trained batch 1259 batch loss 0.355601162 epoch total loss 0.34190923\n",
      "Trained batch 1260 batch loss 0.355095685 epoch total loss 0.34191969\n",
      "Trained batch 1261 batch loss 0.344508052 epoch total loss 0.341921747\n",
      "Trained batch 1262 batch loss 0.339304268 epoch total loss 0.341919661\n",
      "Trained batch 1263 batch loss 0.368253231 epoch total loss 0.341940522\n",
      "Trained batch 1264 batch loss 0.347783327 epoch total loss 0.341945142\n",
      "Trained batch 1265 batch loss 0.306939 epoch total loss 0.341917485\n",
      "Trained batch 1266 batch loss 0.332057983 epoch total loss 0.341909677\n",
      "Trained batch 1267 batch loss 0.307591528 epoch total loss 0.341882586\n",
      "Trained batch 1268 batch loss 0.365535 epoch total loss 0.341901243\n",
      "Trained batch 1269 batch loss 0.311533302 epoch total loss 0.341877311\n",
      "Trained batch 1270 batch loss 0.335029155 epoch total loss 0.341871917\n",
      "Trained batch 1271 batch loss 0.347233802 epoch total loss 0.341876119\n",
      "Trained batch 1272 batch loss 0.324291646 epoch total loss 0.341862291\n",
      "Trained batch 1273 batch loss 0.361940116 epoch total loss 0.341878057\n",
      "Trained batch 1274 batch loss 0.314842165 epoch total loss 0.341856867\n",
      "Trained batch 1275 batch loss 0.292267382 epoch total loss 0.341817975\n",
      "Trained batch 1276 batch loss 0.3206065 epoch total loss 0.341801345\n",
      "Trained batch 1277 batch loss 0.30185014 epoch total loss 0.341770053\n",
      "Trained batch 1278 batch loss 0.315279543 epoch total loss 0.34174934\n",
      "Trained batch 1279 batch loss 0.323458076 epoch total loss 0.341735035\n",
      "Trained batch 1280 batch loss 0.275995463 epoch total loss 0.341683686\n",
      "Trained batch 1281 batch loss 0.265625775 epoch total loss 0.34162429\n",
      "Trained batch 1282 batch loss 0.320741117 epoch total loss 0.341608018\n",
      "Trained batch 1283 batch loss 0.316603422 epoch total loss 0.341588497\n",
      "Trained batch 1284 batch loss 0.332030058 epoch total loss 0.341581076\n",
      "Trained batch 1285 batch loss 0.331241429 epoch total loss 0.34157303\n",
      "Trained batch 1286 batch loss 0.351863623 epoch total loss 0.341581017\n",
      "Trained batch 1287 batch loss 0.354386 epoch total loss 0.341590971\n",
      "Trained batch 1288 batch loss 0.330917895 epoch total loss 0.341582716\n",
      "Trained batch 1289 batch loss 0.334406734 epoch total loss 0.341577142\n",
      "Trained batch 1290 batch loss 0.356942236 epoch total loss 0.341589034\n",
      "Trained batch 1291 batch loss 0.346433371 epoch total loss 0.341592789\n",
      "Trained batch 1292 batch loss 0.293960094 epoch total loss 0.341555923\n",
      "Trained batch 1293 batch loss 0.301424801 epoch total loss 0.341524869\n",
      "Trained batch 1294 batch loss 0.285052568 epoch total loss 0.341481239\n",
      "Trained batch 1295 batch loss 0.266513199 epoch total loss 0.341423362\n",
      "Trained batch 1296 batch loss 0.303261936 epoch total loss 0.341393918\n",
      "Trained batch 1297 batch loss 0.330965459 epoch total loss 0.341385871\n",
      "Trained batch 1298 batch loss 0.298652768 epoch total loss 0.34135294\n",
      "Trained batch 1299 batch loss 0.324584067 epoch total loss 0.341340035\n",
      "Trained batch 1300 batch loss 0.340142488 epoch total loss 0.341339111\n",
      "Trained batch 1301 batch loss 0.302892059 epoch total loss 0.341309547\n",
      "Trained batch 1302 batch loss 0.272290647 epoch total loss 0.341256529\n",
      "Trained batch 1303 batch loss 0.234964743 epoch total loss 0.34117496\n",
      "Trained batch 1304 batch loss 0.279904634 epoch total loss 0.341127962\n",
      "Trained batch 1305 batch loss 0.325126916 epoch total loss 0.341115713\n",
      "Trained batch 1306 batch loss 0.376675189 epoch total loss 0.341142952\n",
      "Trained batch 1307 batch loss 0.393810272 epoch total loss 0.341183245\n",
      "Trained batch 1308 batch loss 0.307578892 epoch total loss 0.341157556\n",
      "Trained batch 1309 batch loss 0.307477266 epoch total loss 0.341131806\n",
      "Trained batch 1310 batch loss 0.314705193 epoch total loss 0.34111163\n",
      "Trained batch 1311 batch loss 0.330307633 epoch total loss 0.341103405\n",
      "Trained batch 1312 batch loss 0.353400886 epoch total loss 0.341112763\n",
      "Trained batch 1313 batch loss 0.324819475 epoch total loss 0.341100365\n",
      "Trained batch 1314 batch loss 0.304754257 epoch total loss 0.341072708\n",
      "Trained batch 1315 batch loss 0.322190166 epoch total loss 0.341058344\n",
      "Trained batch 1316 batch loss 0.309846282 epoch total loss 0.341034621\n",
      "Trained batch 1317 batch loss 0.319977701 epoch total loss 0.341018647\n",
      "Trained batch 1318 batch loss 0.318080485 epoch total loss 0.341001242\n",
      "Trained batch 1319 batch loss 0.299142212 epoch total loss 0.340969503\n",
      "Trained batch 1320 batch loss 0.31067434 epoch total loss 0.340946555\n",
      "Trained batch 1321 batch loss 0.324278682 epoch total loss 0.340933919\n",
      "Trained batch 1322 batch loss 0.28455922 epoch total loss 0.340891272\n",
      "Trained batch 1323 batch loss 0.276433289 epoch total loss 0.340842545\n",
      "Trained batch 1324 batch loss 0.327924848 epoch total loss 0.34083277\n",
      "Trained batch 1325 batch loss 0.299083769 epoch total loss 0.340801269\n",
      "Trained batch 1326 batch loss 0.289120227 epoch total loss 0.340762287\n",
      "Trained batch 1327 batch loss 0.323769242 epoch total loss 0.340749472\n",
      "Trained batch 1328 batch loss 0.311598092 epoch total loss 0.340727508\n",
      "Trained batch 1329 batch loss 0.291701794 epoch total loss 0.340690613\n",
      "Trained batch 1330 batch loss 0.295227885 epoch total loss 0.34065643\n",
      "Trained batch 1331 batch loss 0.309985518 epoch total loss 0.340633392\n",
      "Trained batch 1332 batch loss 0.318967104 epoch total loss 0.34061715\n",
      "Trained batch 1333 batch loss 0.315008253 epoch total loss 0.340597928\n",
      "Trained batch 1334 batch loss 0.314266145 epoch total loss 0.340578198\n",
      "Trained batch 1335 batch loss 0.305053264 epoch total loss 0.340551585\n",
      "Trained batch 1336 batch loss 0.321917921 epoch total loss 0.340537637\n",
      "Trained batch 1337 batch loss 0.32047075 epoch total loss 0.340522617\n",
      "Trained batch 1338 batch loss 0.315077364 epoch total loss 0.340503603\n",
      "Trained batch 1339 batch loss 0.313053429 epoch total loss 0.340483099\n",
      "Trained batch 1340 batch loss 0.331538647 epoch total loss 0.340476424\n",
      "Trained batch 1341 batch loss 0.295311123 epoch total loss 0.340442747\n",
      "Trained batch 1342 batch loss 0.294818759 epoch total loss 0.340408742\n",
      "Trained batch 1343 batch loss 0.298888475 epoch total loss 0.340377837\n",
      "Trained batch 1344 batch loss 0.28286764 epoch total loss 0.340335041\n",
      "Trained batch 1345 batch loss 0.315083116 epoch total loss 0.340316296\n",
      "Trained batch 1346 batch loss 0.343142509 epoch total loss 0.340318382\n",
      "Trained batch 1347 batch loss 0.326197237 epoch total loss 0.340307891\n",
      "Trained batch 1348 batch loss 0.324004382 epoch total loss 0.340295821\n",
      "Trained batch 1349 batch loss 0.311923 epoch total loss 0.340274781\n",
      "Trained batch 1350 batch loss 0.3248083 epoch total loss 0.340263307\n",
      "Trained batch 1351 batch loss 0.31914103 epoch total loss 0.340247691\n",
      "Trained batch 1352 batch loss 0.324726462 epoch total loss 0.340236217\n",
      "Trained batch 1353 batch loss 0.301876903 epoch total loss 0.340207875\n",
      "Trained batch 1354 batch loss 0.297309369 epoch total loss 0.340176165\n",
      "Trained batch 1355 batch loss 0.31936416 epoch total loss 0.340160817\n",
      "Trained batch 1356 batch loss 0.32560569 epoch total loss 0.340150088\n",
      "Trained batch 1357 batch loss 0.330747515 epoch total loss 0.340143144\n",
      "Trained batch 1358 batch loss 0.322104931 epoch total loss 0.340129882\n",
      "Trained batch 1359 batch loss 0.32188794 epoch total loss 0.340116441\n",
      "Trained batch 1360 batch loss 0.320824414 epoch total loss 0.340102285\n",
      "Trained batch 1361 batch loss 0.320532501 epoch total loss 0.340087891\n",
      "Trained batch 1362 batch loss 0.275464296 epoch total loss 0.340040445\n",
      "Trained batch 1363 batch loss 0.31339395 epoch total loss 0.340020865\n",
      "Trained batch 1364 batch loss 0.326782823 epoch total loss 0.340011179\n",
      "Trained batch 1365 batch loss 0.337138414 epoch total loss 0.340009063\n",
      "Trained batch 1366 batch loss 0.335215151 epoch total loss 0.340005547\n",
      "Trained batch 1367 batch loss 0.30311805 epoch total loss 0.339978576\n",
      "Trained batch 1368 batch loss 0.301348031 epoch total loss 0.339950353\n",
      "Trained batch 1369 batch loss 0.312182039 epoch total loss 0.339930058\n",
      "Trained batch 1370 batch loss 0.285269976 epoch total loss 0.339890182\n",
      "Trained batch 1371 batch loss 0.339058131 epoch total loss 0.339889556\n",
      "Trained batch 1372 batch loss 0.326028109 epoch total loss 0.339879453\n",
      "Trained batch 1373 batch loss 0.358511865 epoch total loss 0.339893\n",
      "Trained batch 1374 batch loss 0.330729067 epoch total loss 0.339886338\n",
      "Trained batch 1375 batch loss 0.364989758 epoch total loss 0.339904606\n",
      "Trained batch 1376 batch loss 0.333188146 epoch total loss 0.339899719\n",
      "Trained batch 1377 batch loss 0.343690634 epoch total loss 0.33990249\n",
      "Trained batch 1378 batch loss 0.327236593 epoch total loss 0.339893281\n",
      "Trained batch 1379 batch loss 0.331565887 epoch total loss 0.339887261\n",
      "Trained batch 1380 batch loss 0.324751943 epoch total loss 0.339876294\n",
      "Trained batch 1381 batch loss 0.307141 epoch total loss 0.339852571\n",
      "Trained batch 1382 batch loss 0.301043957 epoch total loss 0.339824498\n",
      "Trained batch 1383 batch loss 0.337320119 epoch total loss 0.33982268\n",
      "Trained batch 1384 batch loss 0.324731588 epoch total loss 0.339811772\n",
      "Trained batch 1385 batch loss 0.311655134 epoch total loss 0.339791447\n",
      "Trained batch 1386 batch loss 0.295789629 epoch total loss 0.339759678\n",
      "Trained batch 1387 batch loss 0.323595792 epoch total loss 0.339748025\n",
      "Trained batch 1388 batch loss 0.300588459 epoch total loss 0.339719832\n",
      "Epoch 1 train loss 0.33971983194351196\n",
      "Validated batch 1 batch loss 0.330517173\n",
      "Validated batch 2 batch loss 0.317076623\n",
      "Validated batch 3 batch loss 0.307892442\n",
      "Validated batch 4 batch loss 0.341638505\n",
      "Validated batch 5 batch loss 0.3331168\n",
      "Validated batch 6 batch loss 0.343347371\n",
      "Validated batch 7 batch loss 0.355647027\n",
      "Validated batch 8 batch loss 0.341626197\n",
      "Validated batch 9 batch loss 0.335360855\n",
      "Validated batch 10 batch loss 0.324978322\n",
      "Validated batch 11 batch loss 0.352286518\n",
      "Validated batch 12 batch loss 0.331365436\n",
      "Validated batch 13 batch loss 0.33317095\n",
      "Validated batch 14 batch loss 0.361322522\n",
      "Validated batch 15 batch loss 0.336047471\n",
      "Validated batch 16 batch loss 0.328152\n",
      "Validated batch 17 batch loss 0.362544924\n",
      "Validated batch 18 batch loss 0.294357\n",
      "Validated batch 19 batch loss 0.353445172\n",
      "Validated batch 20 batch loss 0.29524681\n",
      "Validated batch 21 batch loss 0.333457768\n",
      "Validated batch 22 batch loss 0.358170599\n",
      "Validated batch 23 batch loss 0.316360891\n",
      "Validated batch 24 batch loss 0.362055182\n",
      "Validated batch 25 batch loss 0.337326884\n",
      "Validated batch 26 batch loss 0.311326623\n",
      "Validated batch 27 batch loss 0.319137394\n",
      "Validated batch 28 batch loss 0.319919437\n",
      "Validated batch 29 batch loss 0.327248\n",
      "Validated batch 30 batch loss 0.343515903\n",
      "Validated batch 31 batch loss 0.293488\n",
      "Validated batch 32 batch loss 0.330275863\n",
      "Validated batch 33 batch loss 0.317764342\n",
      "Validated batch 34 batch loss 0.329285622\n",
      "Validated batch 35 batch loss 0.325367063\n",
      "Validated batch 36 batch loss 0.333992571\n",
      "Validated batch 37 batch loss 0.303883672\n",
      "Validated batch 38 batch loss 0.32410869\n",
      "Validated batch 39 batch loss 0.334502399\n",
      "Validated batch 40 batch loss 0.333834499\n",
      "Validated batch 41 batch loss 0.33780542\n",
      "Validated batch 42 batch loss 0.341782749\n",
      "Validated batch 43 batch loss 0.383508593\n",
      "Validated batch 44 batch loss 0.343692422\n",
      "Validated batch 45 batch loss 0.330928445\n",
      "Validated batch 46 batch loss 0.300650477\n",
      "Validated batch 47 batch loss 0.336428434\n",
      "Validated batch 48 batch loss 0.339648664\n",
      "Validated batch 49 batch loss 0.322434366\n",
      "Validated batch 50 batch loss 0.309485048\n",
      "Validated batch 51 batch loss 0.329268128\n",
      "Validated batch 52 batch loss 0.332522243\n",
      "Validated batch 53 batch loss 0.320263028\n",
      "Validated batch 54 batch loss 0.320329785\n",
      "Validated batch 55 batch loss 0.326292336\n",
      "Validated batch 56 batch loss 0.336749285\n",
      "Validated batch 57 batch loss 0.307382882\n",
      "Validated batch 58 batch loss 0.312262267\n",
      "Validated batch 59 batch loss 0.334216803\n",
      "Validated batch 60 batch loss 0.32992655\n",
      "Validated batch 61 batch loss 0.370385528\n",
      "Validated batch 62 batch loss 0.35682869\n",
      "Validated batch 63 batch loss 0.319167316\n",
      "Validated batch 64 batch loss 0.363068879\n",
      "Validated batch 65 batch loss 0.321523458\n",
      "Validated batch 66 batch loss 0.33721602\n",
      "Validated batch 67 batch loss 0.33790192\n",
      "Validated batch 68 batch loss 0.272097915\n",
      "Validated batch 69 batch loss 0.344397426\n",
      "Validated batch 70 batch loss 0.347778\n",
      "Validated batch 71 batch loss 0.324404836\n",
      "Validated batch 72 batch loss 0.327688575\n",
      "Validated batch 73 batch loss 0.318856448\n",
      "Validated batch 74 batch loss 0.332705826\n",
      "Validated batch 75 batch loss 0.368495584\n",
      "Validated batch 76 batch loss 0.301387757\n",
      "Validated batch 77 batch loss 0.33908993\n",
      "Validated batch 78 batch loss 0.33157891\n",
      "Validated batch 79 batch loss 0.330885708\n",
      "Validated batch 80 batch loss 0.334932745\n",
      "Validated batch 81 batch loss 0.301614493\n",
      "Validated batch 82 batch loss 0.368163973\n",
      "Validated batch 83 batch loss 0.326847762\n",
      "Validated batch 84 batch loss 0.343717843\n",
      "Validated batch 85 batch loss 0.323340416\n",
      "Validated batch 86 batch loss 0.342349082\n",
      "Validated batch 87 batch loss 0.295767874\n",
      "Validated batch 88 batch loss 0.325683475\n",
      "Validated batch 89 batch loss 0.306343347\n",
      "Validated batch 90 batch loss 0.314571321\n",
      "Validated batch 91 batch loss 0.331979364\n",
      "Validated batch 92 batch loss 0.323487878\n",
      "Validated batch 93 batch loss 0.335375309\n",
      "Validated batch 94 batch loss 0.323578358\n",
      "Validated batch 95 batch loss 0.314939141\n",
      "Validated batch 96 batch loss 0.290212691\n",
      "Validated batch 97 batch loss 0.307836503\n",
      "Validated batch 98 batch loss 0.364613444\n",
      "Validated batch 99 batch loss 0.306956649\n",
      "Validated batch 100 batch loss 0.319867\n",
      "Validated batch 101 batch loss 0.318698734\n",
      "Validated batch 102 batch loss 0.310230464\n",
      "Validated batch 103 batch loss 0.318799049\n",
      "Validated batch 104 batch loss 0.328345597\n",
      "Validated batch 105 batch loss 0.314071238\n",
      "Validated batch 106 batch loss 0.322313637\n",
      "Validated batch 107 batch loss 0.346484\n",
      "Validated batch 108 batch loss 0.357480109\n",
      "Validated batch 109 batch loss 0.304712564\n",
      "Validated batch 110 batch loss 0.349371612\n",
      "Validated batch 111 batch loss 0.289631605\n",
      "Validated batch 112 batch loss 0.316055208\n",
      "Validated batch 113 batch loss 0.308334827\n",
      "Validated batch 114 batch loss 0.321639657\n",
      "Validated batch 115 batch loss 0.36920467\n",
      "Validated batch 116 batch loss 0.303679109\n",
      "Validated batch 117 batch loss 0.309808403\n",
      "Validated batch 118 batch loss 0.330966324\n",
      "Validated batch 119 batch loss 0.299164981\n",
      "Validated batch 120 batch loss 0.329541147\n",
      "Validated batch 121 batch loss 0.37056455\n",
      "Validated batch 122 batch loss 0.287759542\n",
      "Validated batch 123 batch loss 0.329367071\n",
      "Validated batch 124 batch loss 0.313669473\n",
      "Validated batch 125 batch loss 0.338272452\n",
      "Validated batch 126 batch loss 0.346826345\n",
      "Validated batch 127 batch loss 0.306991458\n",
      "Validated batch 128 batch loss 0.269419909\n",
      "Validated batch 129 batch loss 0.324224919\n",
      "Validated batch 130 batch loss 0.306160063\n",
      "Validated batch 131 batch loss 0.327996\n",
      "Validated batch 132 batch loss 0.344953626\n",
      "Validated batch 133 batch loss 0.301320761\n",
      "Validated batch 134 batch loss 0.332945049\n",
      "Validated batch 135 batch loss 0.359932661\n",
      "Validated batch 136 batch loss 0.330318719\n",
      "Validated batch 137 batch loss 0.33799988\n",
      "Validated batch 138 batch loss 0.308339238\n",
      "Validated batch 139 batch loss 0.320711076\n",
      "Validated batch 140 batch loss 0.295781404\n",
      "Validated batch 141 batch loss 0.333257735\n",
      "Validated batch 142 batch loss 0.322353542\n",
      "Validated batch 143 batch loss 0.312753886\n",
      "Validated batch 144 batch loss 0.338214457\n",
      "Validated batch 145 batch loss 0.31799075\n",
      "Validated batch 146 batch loss 0.340590209\n",
      "Validated batch 147 batch loss 0.350882411\n",
      "Validated batch 148 batch loss 0.291091919\n",
      "Validated batch 149 batch loss 0.351069629\n",
      "Validated batch 150 batch loss 0.335627913\n",
      "Validated batch 151 batch loss 0.296132922\n",
      "Validated batch 152 batch loss 0.340560973\n",
      "Validated batch 153 batch loss 0.332785815\n",
      "Validated batch 154 batch loss 0.313181639\n",
      "Validated batch 155 batch loss 0.362734735\n",
      "Validated batch 156 batch loss 0.321905375\n",
      "Validated batch 157 batch loss 0.34629488\n",
      "Validated batch 158 batch loss 0.309875697\n",
      "Validated batch 159 batch loss 0.331778616\n",
      "Validated batch 160 batch loss 0.348553419\n",
      "Validated batch 161 batch loss 0.318160057\n",
      "Validated batch 162 batch loss 0.325784206\n",
      "Validated batch 163 batch loss 0.29963702\n",
      "Validated batch 164 batch loss 0.321518809\n",
      "Validated batch 165 batch loss 0.320698291\n",
      "Validated batch 166 batch loss 0.306310505\n",
      "Validated batch 167 batch loss 0.328044415\n",
      "Validated batch 168 batch loss 0.321394444\n",
      "Validated batch 169 batch loss 0.336274475\n",
      "Validated batch 170 batch loss 0.338341326\n",
      "Validated batch 171 batch loss 0.339753538\n",
      "Validated batch 172 batch loss 0.326034039\n",
      "Validated batch 173 batch loss 0.36327064\n",
      "Validated batch 174 batch loss 0.333293974\n",
      "Validated batch 175 batch loss 0.354435503\n",
      "Validated batch 176 batch loss 0.332532197\n",
      "Validated batch 177 batch loss 0.36275\n",
      "Validated batch 178 batch loss 0.350786448\n",
      "Validated batch 179 batch loss 0.314825356\n",
      "Validated batch 180 batch loss 0.313638836\n",
      "Validated batch 181 batch loss 0.34187448\n",
      "Validated batch 182 batch loss 0.353026927\n",
      "Validated batch 183 batch loss 0.309341341\n",
      "Validated batch 184 batch loss 0.332546294\n",
      "Validated batch 185 batch loss 0.327105224\n",
      "Epoch 1 val loss 0.32837021350860596\n",
      "Model /aiffel/aiffel/mpii/models2/model-epoch-1-loss-0.3284.h5 saved.\n",
      "Start epoch 2 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.315525591 epoch total loss 0.315525591\n",
      "Trained batch 2 batch loss 0.331083328 epoch total loss 0.323304474\n",
      "Trained batch 3 batch loss 0.343290359 epoch total loss 0.329966426\n",
      "Trained batch 4 batch loss 0.355907351 epoch total loss 0.33645165\n",
      "Trained batch 5 batch loss 0.347327322 epoch total loss 0.338626802\n",
      "Trained batch 6 batch loss 0.336385339 epoch total loss 0.33825323\n",
      "Trained batch 7 batch loss 0.348299861 epoch total loss 0.33968845\n",
      "Trained batch 8 batch loss 0.326489389 epoch total loss 0.338038564\n",
      "Trained batch 9 batch loss 0.29145968 epoch total loss 0.332863122\n",
      "Trained batch 10 batch loss 0.315566897 epoch total loss 0.331133515\n",
      "Trained batch 11 batch loss 0.310257822 epoch total loss 0.329235733\n",
      "Trained batch 12 batch loss 0.333502859 epoch total loss 0.329591304\n",
      "Trained batch 13 batch loss 0.324731588 epoch total loss 0.329217464\n",
      "Trained batch 14 batch loss 0.319415808 epoch total loss 0.328517377\n",
      "Trained batch 15 batch loss 0.29484117 epoch total loss 0.326272309\n",
      "Trained batch 16 batch loss 0.290603697 epoch total loss 0.324043\n",
      "Trained batch 17 batch loss 0.275720447 epoch total loss 0.32120052\n",
      "Trained batch 18 batch loss 0.278997809 epoch total loss 0.318855911\n",
      "Trained batch 19 batch loss 0.303039253 epoch total loss 0.318023443\n",
      "Trained batch 20 batch loss 0.276042491 epoch total loss 0.315924406\n",
      "Trained batch 21 batch loss 0.297837228 epoch total loss 0.315063119\n",
      "Trained batch 22 batch loss 0.3375251 epoch total loss 0.316084117\n",
      "Trained batch 23 batch loss 0.33530727 epoch total loss 0.316919893\n",
      "Trained batch 24 batch loss 0.307899773 epoch total loss 0.316544056\n",
      "Trained batch 25 batch loss 0.27124247 epoch total loss 0.314732\n",
      "Trained batch 26 batch loss 0.283863664 epoch total loss 0.31354475\n",
      "Trained batch 27 batch loss 0.306495726 epoch total loss 0.313283682\n",
      "Trained batch 28 batch loss 0.314848602 epoch total loss 0.313339561\n",
      "Trained batch 29 batch loss 0.309882581 epoch total loss 0.313220352\n",
      "Trained batch 30 batch loss 0.29446426 epoch total loss 0.312595159\n",
      "Trained batch 31 batch loss 0.324490815 epoch total loss 0.312978864\n",
      "Trained batch 32 batch loss 0.301362634 epoch total loss 0.312615871\n",
      "Trained batch 33 batch loss 0.324348837 epoch total loss 0.312971413\n",
      "Trained batch 34 batch loss 0.319181859 epoch total loss 0.313154042\n",
      "Trained batch 35 batch loss 0.347746283 epoch total loss 0.314142376\n",
      "Trained batch 36 batch loss 0.366674274 epoch total loss 0.315601617\n",
      "Trained batch 37 batch loss 0.38715452 epoch total loss 0.31753549\n",
      "Trained batch 38 batch loss 0.33532235 epoch total loss 0.318003565\n",
      "Trained batch 39 batch loss 0.279943 epoch total loss 0.317027658\n",
      "Trained batch 40 batch loss 0.342552394 epoch total loss 0.317665756\n",
      "Trained batch 41 batch loss 0.361912757 epoch total loss 0.318744957\n",
      "Trained batch 42 batch loss 0.337635666 epoch total loss 0.319194734\n",
      "Trained batch 43 batch loss 0.335770905 epoch total loss 0.319580227\n",
      "Trained batch 44 batch loss 0.317689836 epoch total loss 0.319537282\n",
      "Trained batch 45 batch loss 0.330484331 epoch total loss 0.319780529\n",
      "Trained batch 46 batch loss 0.309873134 epoch total loss 0.319565177\n",
      "Trained batch 47 batch loss 0.318521321 epoch total loss 0.319542974\n",
      "Trained batch 48 batch loss 0.336679399 epoch total loss 0.319899976\n",
      "Trained batch 49 batch loss 0.318027705 epoch total loss 0.31986177\n",
      "Trained batch 50 batch loss 0.330213219 epoch total loss 0.320068777\n",
      "Trained batch 51 batch loss 0.297178209 epoch total loss 0.319619954\n",
      "Trained batch 52 batch loss 0.316193283 epoch total loss 0.319554031\n",
      "Trained batch 53 batch loss 0.303156972 epoch total loss 0.319244683\n",
      "Trained batch 54 batch loss 0.296746045 epoch total loss 0.318828017\n",
      "Trained batch 55 batch loss 0.303182304 epoch total loss 0.318543553\n",
      "Trained batch 56 batch loss 0.321862757 epoch total loss 0.31860283\n",
      "Trained batch 57 batch loss 0.346534789 epoch total loss 0.31909287\n",
      "Trained batch 58 batch loss 0.368535161 epoch total loss 0.319945335\n",
      "Trained batch 59 batch loss 0.363564283 epoch total loss 0.320684642\n",
      "Trained batch 60 batch loss 0.33349967 epoch total loss 0.320898205\n",
      "Trained batch 61 batch loss 0.291015446 epoch total loss 0.320408344\n",
      "Trained batch 62 batch loss 0.274013191 epoch total loss 0.319660038\n",
      "Trained batch 63 batch loss 0.270421147 epoch total loss 0.318878472\n",
      "Trained batch 64 batch loss 0.243383393 epoch total loss 0.317698866\n",
      "Trained batch 65 batch loss 0.268642157 epoch total loss 0.316944152\n",
      "Trained batch 66 batch loss 0.283270031 epoch total loss 0.316433936\n",
      "Trained batch 67 batch loss 0.343729138 epoch total loss 0.316841334\n",
      "Trained batch 68 batch loss 0.339749306 epoch total loss 0.31717819\n",
      "Trained batch 69 batch loss 0.315683842 epoch total loss 0.317156523\n",
      "Trained batch 70 batch loss 0.276838303 epoch total loss 0.316580564\n",
      "Trained batch 71 batch loss 0.28319025 epoch total loss 0.316110253\n",
      "Trained batch 72 batch loss 0.307465196 epoch total loss 0.31599018\n",
      "Trained batch 73 batch loss 0.323304892 epoch total loss 0.316090375\n",
      "Trained batch 74 batch loss 0.323803604 epoch total loss 0.316194624\n",
      "Trained batch 75 batch loss 0.321247876 epoch total loss 0.316261977\n",
      "Trained batch 76 batch loss 0.320070833 epoch total loss 0.316312075\n",
      "Trained batch 77 batch loss 0.304006249 epoch total loss 0.316152275\n",
      "Trained batch 78 batch loss 0.308944046 epoch total loss 0.316059858\n",
      "Trained batch 79 batch loss 0.317109734 epoch total loss 0.316073149\n",
      "Trained batch 80 batch loss 0.319896281 epoch total loss 0.316120952\n",
      "Trained batch 81 batch loss 0.331971943 epoch total loss 0.316316664\n",
      "Trained batch 82 batch loss 0.366754591 epoch total loss 0.316931754\n",
      "Trained batch 83 batch loss 0.299857825 epoch total loss 0.316726029\n",
      "Trained batch 84 batch loss 0.278240442 epoch total loss 0.316267878\n",
      "Trained batch 85 batch loss 0.291873574 epoch total loss 0.315980881\n",
      "Trained batch 86 batch loss 0.307681888 epoch total loss 0.315884382\n",
      "Trained batch 87 batch loss 0.288179338 epoch total loss 0.315565944\n",
      "Trained batch 88 batch loss 0.259313136 epoch total loss 0.314926714\n",
      "Trained batch 89 batch loss 0.295819581 epoch total loss 0.314712018\n",
      "Trained batch 90 batch loss 0.314553916 epoch total loss 0.314710289\n",
      "Trained batch 91 batch loss 0.319681913 epoch total loss 0.314764917\n",
      "Trained batch 92 batch loss 0.336555302 epoch total loss 0.315001756\n",
      "Trained batch 93 batch loss 0.336942971 epoch total loss 0.315237671\n",
      "Trained batch 94 batch loss 0.32980293 epoch total loss 0.315392643\n",
      "Trained batch 95 batch loss 0.303477705 epoch total loss 0.315267235\n",
      "Trained batch 96 batch loss 0.351408541 epoch total loss 0.315643698\n",
      "Trained batch 97 batch loss 0.359741569 epoch total loss 0.316098303\n",
      "Trained batch 98 batch loss 0.317078 epoch total loss 0.316108286\n",
      "Trained batch 99 batch loss 0.308844596 epoch total loss 0.316034943\n",
      "Trained batch 100 batch loss 0.287613422 epoch total loss 0.315750718\n",
      "Trained batch 101 batch loss 0.269000679 epoch total loss 0.315287858\n",
      "Trained batch 102 batch loss 0.273968756 epoch total loss 0.314882755\n",
      "Trained batch 103 batch loss 0.262726158 epoch total loss 0.314376384\n",
      "Trained batch 104 batch loss 0.306410581 epoch total loss 0.314299792\n",
      "Trained batch 105 batch loss 0.30046615 epoch total loss 0.314168036\n",
      "Trained batch 106 batch loss 0.330430448 epoch total loss 0.314321458\n",
      "Trained batch 107 batch loss 0.340214878 epoch total loss 0.314563423\n",
      "Trained batch 108 batch loss 0.294405431 epoch total loss 0.314376801\n",
      "Trained batch 109 batch loss 0.287828386 epoch total loss 0.314133227\n",
      "Trained batch 110 batch loss 0.281353742 epoch total loss 0.313835204\n",
      "Trained batch 111 batch loss 0.299920827 epoch total loss 0.313709855\n",
      "Trained batch 112 batch loss 0.325998366 epoch total loss 0.313819587\n",
      "Trained batch 113 batch loss 0.320454538 epoch total loss 0.313878298\n",
      "Trained batch 114 batch loss 0.33612445 epoch total loss 0.314073443\n",
      "Trained batch 115 batch loss 0.299585521 epoch total loss 0.313947469\n",
      "Trained batch 116 batch loss 0.304003149 epoch total loss 0.313861758\n",
      "Trained batch 117 batch loss 0.309330761 epoch total loss 0.313823\n",
      "Trained batch 118 batch loss 0.31935215 epoch total loss 0.313869864\n",
      "Trained batch 119 batch loss 0.299775451 epoch total loss 0.3137514\n",
      "Trained batch 120 batch loss 0.274689108 epoch total loss 0.313425899\n",
      "Trained batch 121 batch loss 0.308100224 epoch total loss 0.313381881\n",
      "Trained batch 122 batch loss 0.31051439 epoch total loss 0.313358366\n",
      "Trained batch 123 batch loss 0.322011709 epoch total loss 0.3134287\n",
      "Trained batch 124 batch loss 0.332288563 epoch total loss 0.313580781\n",
      "Trained batch 125 batch loss 0.314729571 epoch total loss 0.31358996\n",
      "Trained batch 126 batch loss 0.294717133 epoch total loss 0.313440174\n",
      "Trained batch 127 batch loss 0.27478084 epoch total loss 0.313135773\n",
      "Trained batch 128 batch loss 0.260020226 epoch total loss 0.312720805\n",
      "Trained batch 129 batch loss 0.290951 epoch total loss 0.312552035\n",
      "Trained batch 130 batch loss 0.273315847 epoch total loss 0.312250227\n",
      "Trained batch 131 batch loss 0.292951018 epoch total loss 0.312102884\n",
      "Trained batch 132 batch loss 0.317923188 epoch total loss 0.312147\n",
      "Trained batch 133 batch loss 0.322948933 epoch total loss 0.312228203\n",
      "Trained batch 134 batch loss 0.340593338 epoch total loss 0.312439889\n",
      "Trained batch 135 batch loss 0.35914433 epoch total loss 0.312785834\n",
      "Trained batch 136 batch loss 0.366847456 epoch total loss 0.313183367\n",
      "Trained batch 137 batch loss 0.3782821 epoch total loss 0.313658535\n",
      "Trained batch 138 batch loss 0.289344341 epoch total loss 0.313482344\n",
      "Trained batch 139 batch loss 0.306102335 epoch total loss 0.313429236\n",
      "Trained batch 140 batch loss 0.296731621 epoch total loss 0.313309968\n",
      "Trained batch 141 batch loss 0.303051621 epoch total loss 0.31323722\n",
      "Trained batch 142 batch loss 0.303773403 epoch total loss 0.313170552\n",
      "Trained batch 143 batch loss 0.293434352 epoch total loss 0.313032538\n",
      "Trained batch 144 batch loss 0.288515866 epoch total loss 0.312862277\n",
      "Trained batch 145 batch loss 0.301286787 epoch total loss 0.312782466\n",
      "Trained batch 146 batch loss 0.274909079 epoch total loss 0.312523067\n",
      "Trained batch 147 batch loss 0.269395709 epoch total loss 0.312229663\n",
      "Trained batch 148 batch loss 0.31043607 epoch total loss 0.312217563\n",
      "Trained batch 149 batch loss 0.330440313 epoch total loss 0.312339872\n",
      "Trained batch 150 batch loss 0.269056559 epoch total loss 0.312051326\n",
      "Trained batch 151 batch loss 0.285878032 epoch total loss 0.311877966\n",
      "Trained batch 152 batch loss 0.293063134 epoch total loss 0.311754197\n",
      "Trained batch 153 batch loss 0.318222225 epoch total loss 0.311796486\n",
      "Trained batch 154 batch loss 0.358331293 epoch total loss 0.312098652\n",
      "Trained batch 155 batch loss 0.311181366 epoch total loss 0.312092721\n",
      "Trained batch 156 batch loss 0.354440361 epoch total loss 0.312364161\n",
      "Trained batch 157 batch loss 0.369935364 epoch total loss 0.312730849\n",
      "Trained batch 158 batch loss 0.382060379 epoch total loss 0.313169658\n",
      "Trained batch 159 batch loss 0.318269759 epoch total loss 0.313201725\n",
      "Trained batch 160 batch loss 0.310239255 epoch total loss 0.313183218\n",
      "Trained batch 161 batch loss 0.263807595 epoch total loss 0.312876552\n",
      "Trained batch 162 batch loss 0.269984126 epoch total loss 0.312611789\n",
      "Trained batch 163 batch loss 0.284265637 epoch total loss 0.312437892\n",
      "Trained batch 164 batch loss 0.27780208 epoch total loss 0.312226683\n",
      "Trained batch 165 batch loss 0.258982 epoch total loss 0.311904\n",
      "Trained batch 166 batch loss 0.242075711 epoch total loss 0.311483353\n",
      "Trained batch 167 batch loss 0.273267657 epoch total loss 0.311254501\n",
      "Trained batch 168 batch loss 0.289178669 epoch total loss 0.311123103\n",
      "Trained batch 169 batch loss 0.294829488 epoch total loss 0.311026692\n",
      "Trained batch 170 batch loss 0.337979555 epoch total loss 0.311185241\n",
      "Trained batch 171 batch loss 0.320720583 epoch total loss 0.311241\n",
      "Trained batch 172 batch loss 0.347551137 epoch total loss 0.311452091\n",
      "Trained batch 173 batch loss 0.335695207 epoch total loss 0.311592221\n",
      "Trained batch 174 batch loss 0.355601639 epoch total loss 0.311845154\n",
      "Trained batch 175 batch loss 0.385773242 epoch total loss 0.312267601\n",
      "Trained batch 176 batch loss 0.338562548 epoch total loss 0.312417\n",
      "Trained batch 177 batch loss 0.31888032 epoch total loss 0.312453508\n",
      "Trained batch 178 batch loss 0.312549949 epoch total loss 0.312454045\n",
      "Trained batch 179 batch loss 0.300762683 epoch total loss 0.312388748\n",
      "Trained batch 180 batch loss 0.310155541 epoch total loss 0.31237632\n",
      "Trained batch 181 batch loss 0.333446413 epoch total loss 0.312492728\n",
      "Trained batch 182 batch loss 0.326546192 epoch total loss 0.312569946\n",
      "Trained batch 183 batch loss 0.334441483 epoch total loss 0.312689453\n",
      "Trained batch 184 batch loss 0.348676324 epoch total loss 0.312885046\n",
      "Trained batch 185 batch loss 0.378266215 epoch total loss 0.313238442\n",
      "Trained batch 186 batch loss 0.323524326 epoch total loss 0.313293755\n",
      "Trained batch 187 batch loss 0.323889405 epoch total loss 0.313350409\n",
      "Trained batch 188 batch loss 0.300080299 epoch total loss 0.313279808\n",
      "Trained batch 189 batch loss 0.305033624 epoch total loss 0.313236207\n",
      "Trained batch 190 batch loss 0.316297799 epoch total loss 0.31325233\n",
      "Trained batch 191 batch loss 0.322833 epoch total loss 0.313302487\n",
      "Trained batch 192 batch loss 0.29930076 epoch total loss 0.313229561\n",
      "Trained batch 193 batch loss 0.304546595 epoch total loss 0.313184559\n",
      "Trained batch 194 batch loss 0.280849248 epoch total loss 0.313017905\n",
      "Trained batch 195 batch loss 0.292426854 epoch total loss 0.312912315\n",
      "Trained batch 196 batch loss 0.329654694 epoch total loss 0.312997729\n",
      "Trained batch 197 batch loss 0.310283154 epoch total loss 0.31298393\n",
      "Trained batch 198 batch loss 0.31723243 epoch total loss 0.313005418\n",
      "Trained batch 199 batch loss 0.331292272 epoch total loss 0.313097298\n",
      "Trained batch 200 batch loss 0.279490292 epoch total loss 0.312929273\n",
      "Trained batch 201 batch loss 0.308697164 epoch total loss 0.312908202\n",
      "Trained batch 202 batch loss 0.275869608 epoch total loss 0.312724859\n",
      "Trained batch 203 batch loss 0.291370332 epoch total loss 0.312619656\n",
      "Trained batch 204 batch loss 0.283275545 epoch total loss 0.31247583\n",
      "Trained batch 205 batch loss 0.250219494 epoch total loss 0.312172145\n",
      "Trained batch 206 batch loss 0.273314 epoch total loss 0.311983496\n",
      "Trained batch 207 batch loss 0.291935265 epoch total loss 0.311886668\n",
      "Trained batch 208 batch loss 0.279465199 epoch total loss 0.311730802\n",
      "Trained batch 209 batch loss 0.282363713 epoch total loss 0.311590284\n",
      "Trained batch 210 batch loss 0.286597788 epoch total loss 0.311471254\n",
      "Trained batch 211 batch loss 0.305679262 epoch total loss 0.311443806\n",
      "Trained batch 212 batch loss 0.293593466 epoch total loss 0.311359614\n",
      "Trained batch 213 batch loss 0.295360863 epoch total loss 0.311284512\n",
      "Trained batch 214 batch loss 0.342739433 epoch total loss 0.311431527\n",
      "Trained batch 215 batch loss 0.315791845 epoch total loss 0.311451793\n",
      "Trained batch 216 batch loss 0.32979086 epoch total loss 0.31153667\n",
      "Trained batch 217 batch loss 0.296798378 epoch total loss 0.31146878\n",
      "Trained batch 218 batch loss 0.312299848 epoch total loss 0.311472595\n",
      "Trained batch 219 batch loss 0.312373728 epoch total loss 0.311476678\n",
      "Trained batch 220 batch loss 0.318964332 epoch total loss 0.311510712\n",
      "Trained batch 221 batch loss 0.351288587 epoch total loss 0.311690688\n",
      "Trained batch 222 batch loss 0.329686314 epoch total loss 0.31177178\n",
      "Trained batch 223 batch loss 0.307154536 epoch total loss 0.311751068\n",
      "Trained batch 224 batch loss 0.334887624 epoch total loss 0.311854333\n",
      "Trained batch 225 batch loss 0.335569263 epoch total loss 0.311959743\n",
      "Trained batch 226 batch loss 0.321040154 epoch total loss 0.311999917\n",
      "Trained batch 227 batch loss 0.352545023 epoch total loss 0.312178522\n",
      "Trained batch 228 batch loss 0.335549682 epoch total loss 0.312281\n",
      "Trained batch 229 batch loss 0.325586021 epoch total loss 0.312339127\n",
      "Trained batch 230 batch loss 0.340856612 epoch total loss 0.312463105\n",
      "Trained batch 231 batch loss 0.315836489 epoch total loss 0.312477708\n",
      "Trained batch 232 batch loss 0.319232523 epoch total loss 0.312506795\n",
      "Trained batch 233 batch loss 0.322411388 epoch total loss 0.312549323\n",
      "Trained batch 234 batch loss 0.292187572 epoch total loss 0.3124623\n",
      "Trained batch 235 batch loss 0.31640929 epoch total loss 0.312479079\n",
      "Trained batch 236 batch loss 0.322329193 epoch total loss 0.312520832\n",
      "Trained batch 237 batch loss 0.300752789 epoch total loss 0.312471151\n",
      "Trained batch 238 batch loss 0.291602463 epoch total loss 0.312383473\n",
      "Trained batch 239 batch loss 0.28789562 epoch total loss 0.312281\n",
      "Trained batch 240 batch loss 0.307950854 epoch total loss 0.312262982\n",
      "Trained batch 241 batch loss 0.322111517 epoch total loss 0.312303841\n",
      "Trained batch 242 batch loss 0.303355932 epoch total loss 0.312266856\n",
      "Trained batch 243 batch loss 0.287385076 epoch total loss 0.312164456\n",
      "Trained batch 244 batch loss 0.282763571 epoch total loss 0.312043965\n",
      "Trained batch 245 batch loss 0.268825501 epoch total loss 0.311867535\n",
      "Trained batch 246 batch loss 0.287152082 epoch total loss 0.311767071\n",
      "Trained batch 247 batch loss 0.292243481 epoch total loss 0.311688036\n",
      "Trained batch 248 batch loss 0.272574425 epoch total loss 0.311530322\n",
      "Trained batch 249 batch loss 0.304379404 epoch total loss 0.311501622\n",
      "Trained batch 250 batch loss 0.313220114 epoch total loss 0.311508477\n",
      "Trained batch 251 batch loss 0.29435879 epoch total loss 0.31144014\n",
      "Trained batch 252 batch loss 0.330525726 epoch total loss 0.311515898\n",
      "Trained batch 253 batch loss 0.325043976 epoch total loss 0.311569363\n",
      "Trained batch 254 batch loss 0.310202181 epoch total loss 0.311564\n",
      "Trained batch 255 batch loss 0.362490326 epoch total loss 0.311763674\n",
      "Trained batch 256 batch loss 0.326762974 epoch total loss 0.311822265\n",
      "Trained batch 257 batch loss 0.317128927 epoch total loss 0.311842918\n",
      "Trained batch 258 batch loss 0.295301 epoch total loss 0.311778814\n",
      "Trained batch 259 batch loss 0.306691349 epoch total loss 0.311759174\n",
      "Trained batch 260 batch loss 0.306465179 epoch total loss 0.311738819\n",
      "Trained batch 261 batch loss 0.320788056 epoch total loss 0.311773479\n",
      "Trained batch 262 batch loss 0.311134338 epoch total loss 0.311771035\n",
      "Trained batch 263 batch loss 0.299946815 epoch total loss 0.311726093\n",
      "Trained batch 264 batch loss 0.330547601 epoch total loss 0.31179741\n",
      "Trained batch 265 batch loss 0.313437879 epoch total loss 0.311803609\n",
      "Trained batch 266 batch loss 0.320167899 epoch total loss 0.311835051\n",
      "Trained batch 267 batch loss 0.306629539 epoch total loss 0.31181556\n",
      "Trained batch 268 batch loss 0.293313324 epoch total loss 0.311746508\n",
      "Trained batch 269 batch loss 0.298500985 epoch total loss 0.311697274\n",
      "Trained batch 270 batch loss 0.290957272 epoch total loss 0.311620444\n",
      "Trained batch 271 batch loss 0.293516636 epoch total loss 0.311553657\n",
      "Trained batch 272 batch loss 0.337053686 epoch total loss 0.311647385\n",
      "Trained batch 273 batch loss 0.303655595 epoch total loss 0.311618119\n",
      "Trained batch 274 batch loss 0.32186994 epoch total loss 0.311655521\n",
      "Trained batch 275 batch loss 0.306547612 epoch total loss 0.311636955\n",
      "Trained batch 276 batch loss 0.336557657 epoch total loss 0.311727256\n",
      "Trained batch 277 batch loss 0.301896513 epoch total loss 0.311691761\n",
      "Trained batch 278 batch loss 0.257020891 epoch total loss 0.311495095\n",
      "Trained batch 279 batch loss 0.292668641 epoch total loss 0.311427623\n",
      "Trained batch 280 batch loss 0.330593973 epoch total loss 0.311496079\n",
      "Trained batch 281 batch loss 0.333032966 epoch total loss 0.311572731\n",
      "Trained batch 282 batch loss 0.333114833 epoch total loss 0.311649114\n",
      "Trained batch 283 batch loss 0.331656843 epoch total loss 0.311719805\n",
      "Trained batch 284 batch loss 0.323933184 epoch total loss 0.31176281\n",
      "Trained batch 285 batch loss 0.300230682 epoch total loss 0.311722368\n",
      "Trained batch 286 batch loss 0.335709453 epoch total loss 0.311806232\n",
      "Trained batch 287 batch loss 0.293501407 epoch total loss 0.311742455\n",
      "Trained batch 288 batch loss 0.282109916 epoch total loss 0.311639577\n",
      "Trained batch 289 batch loss 0.306579441 epoch total loss 0.311622053\n",
      "Trained batch 290 batch loss 0.301450223 epoch total loss 0.311587\n",
      "Trained batch 291 batch loss 0.313570827 epoch total loss 0.311593801\n",
      "Trained batch 292 batch loss 0.300708979 epoch total loss 0.311556548\n",
      "Trained batch 293 batch loss 0.341751337 epoch total loss 0.311659604\n",
      "Trained batch 294 batch loss 0.301507115 epoch total loss 0.311625063\n",
      "Trained batch 295 batch loss 0.307688624 epoch total loss 0.311611712\n",
      "Trained batch 296 batch loss 0.304044694 epoch total loss 0.311586142\n",
      "Trained batch 297 batch loss 0.325423658 epoch total loss 0.311632752\n",
      "Trained batch 298 batch loss 0.312682271 epoch total loss 0.311636269\n",
      "Trained batch 299 batch loss 0.309348673 epoch total loss 0.31162861\n",
      "Trained batch 300 batch loss 0.319631755 epoch total loss 0.311655313\n",
      "Trained batch 301 batch loss 0.284402579 epoch total loss 0.311564744\n",
      "Trained batch 302 batch loss 0.313841581 epoch total loss 0.311572284\n",
      "Trained batch 303 batch loss 0.299371779 epoch total loss 0.311532021\n",
      "Trained batch 304 batch loss 0.304868668 epoch total loss 0.311510116\n",
      "Trained batch 305 batch loss 0.3161394 epoch total loss 0.311525285\n",
      "Trained batch 306 batch loss 0.336566329 epoch total loss 0.311607122\n",
      "Trained batch 307 batch loss 0.341636896 epoch total loss 0.311704934\n",
      "Trained batch 308 batch loss 0.311287 epoch total loss 0.311703563\n",
      "Trained batch 309 batch loss 0.291388839 epoch total loss 0.311637819\n",
      "Trained batch 310 batch loss 0.269743979 epoch total loss 0.311502695\n",
      "Trained batch 311 batch loss 0.324020267 epoch total loss 0.311542928\n",
      "Trained batch 312 batch loss 0.323548436 epoch total loss 0.311581403\n",
      "Trained batch 313 batch loss 0.341572344 epoch total loss 0.311677247\n",
      "Trained batch 314 batch loss 0.314302325 epoch total loss 0.311685592\n",
      "Trained batch 315 batch loss 0.337028593 epoch total loss 0.311766058\n",
      "Trained batch 316 batch loss 0.324531227 epoch total loss 0.31180644\n",
      "Trained batch 317 batch loss 0.323046207 epoch total loss 0.311841905\n",
      "Trained batch 318 batch loss 0.342549324 epoch total loss 0.311938465\n",
      "Trained batch 319 batch loss 0.310925245 epoch total loss 0.311935306\n",
      "Trained batch 320 batch loss 0.325480074 epoch total loss 0.311977625\n",
      "Trained batch 321 batch loss 0.343825191 epoch total loss 0.312076837\n",
      "Trained batch 322 batch loss 0.318530738 epoch total loss 0.312096864\n",
      "Trained batch 323 batch loss 0.351872206 epoch total loss 0.312220037\n",
      "Trained batch 324 batch loss 0.320371866 epoch total loss 0.31224519\n",
      "Trained batch 325 batch loss 0.336484253 epoch total loss 0.312319785\n",
      "Trained batch 326 batch loss 0.306586146 epoch total loss 0.312302202\n",
      "Trained batch 327 batch loss 0.272909164 epoch total loss 0.312181741\n",
      "Trained batch 328 batch loss 0.346792966 epoch total loss 0.312287271\n",
      "Trained batch 329 batch loss 0.315635532 epoch total loss 0.312297434\n",
      "Trained batch 330 batch loss 0.320911825 epoch total loss 0.31232354\n",
      "Trained batch 331 batch loss 0.312784046 epoch total loss 0.312324941\n",
      "Trained batch 332 batch loss 0.304920614 epoch total loss 0.312302649\n",
      "Trained batch 333 batch loss 0.322745234 epoch total loss 0.312334\n",
      "Trained batch 334 batch loss 0.316692263 epoch total loss 0.312347054\n",
      "Trained batch 335 batch loss 0.290342391 epoch total loss 0.31228137\n",
      "Trained batch 336 batch loss 0.246250764 epoch total loss 0.312084854\n",
      "Trained batch 337 batch loss 0.283845276 epoch total loss 0.31200105\n",
      "Trained batch 338 batch loss 0.299257964 epoch total loss 0.31196335\n",
      "Trained batch 339 batch loss 0.293832958 epoch total loss 0.311909854\n",
      "Trained batch 340 batch loss 0.285762638 epoch total loss 0.311832935\n",
      "Trained batch 341 batch loss 0.308321089 epoch total loss 0.311822653\n",
      "Trained batch 342 batch loss 0.311599284 epoch total loss 0.311822\n",
      "Trained batch 343 batch loss 0.321459174 epoch total loss 0.311850071\n",
      "Trained batch 344 batch loss 0.318528116 epoch total loss 0.311869502\n",
      "Trained batch 345 batch loss 0.354995936 epoch total loss 0.311994493\n",
      "Trained batch 346 batch loss 0.349082679 epoch total loss 0.312101692\n",
      "Trained batch 347 batch loss 0.366667449 epoch total loss 0.312258929\n",
      "Trained batch 348 batch loss 0.356085628 epoch total loss 0.312384874\n",
      "Trained batch 349 batch loss 0.329473227 epoch total loss 0.312433839\n",
      "Trained batch 350 batch loss 0.326578319 epoch total loss 0.312474251\n",
      "Trained batch 351 batch loss 0.286209524 epoch total loss 0.312399417\n",
      "Trained batch 352 batch loss 0.312232226 epoch total loss 0.31239894\n",
      "Trained batch 353 batch loss 0.332577676 epoch total loss 0.312456131\n",
      "Trained batch 354 batch loss 0.287358791 epoch total loss 0.312385231\n",
      "Trained batch 355 batch loss 0.275064707 epoch total loss 0.312280089\n",
      "Trained batch 356 batch loss 0.256302416 epoch total loss 0.312122852\n",
      "Trained batch 357 batch loss 0.283680081 epoch total loss 0.31204319\n",
      "Trained batch 358 batch loss 0.300366133 epoch total loss 0.312010586\n",
      "Trained batch 359 batch loss 0.269504607 epoch total loss 0.311892211\n",
      "Trained batch 360 batch loss 0.268153757 epoch total loss 0.311770707\n",
      "Trained batch 361 batch loss 0.310080171 epoch total loss 0.311766028\n",
      "Trained batch 362 batch loss 0.321200937 epoch total loss 0.311792076\n",
      "Trained batch 363 batch loss 0.317228734 epoch total loss 0.311807036\n",
      "Trained batch 364 batch loss 0.301164687 epoch total loss 0.3117778\n",
      "Trained batch 365 batch loss 0.281791449 epoch total loss 0.311695665\n",
      "Trained batch 366 batch loss 0.345495373 epoch total loss 0.311788\n",
      "Trained batch 367 batch loss 0.325507 epoch total loss 0.311825395\n",
      "Trained batch 368 batch loss 0.303581178 epoch total loss 0.311802983\n",
      "Trained batch 369 batch loss 0.299452573 epoch total loss 0.311769515\n",
      "Trained batch 370 batch loss 0.296256185 epoch total loss 0.311727583\n",
      "Trained batch 371 batch loss 0.293973 epoch total loss 0.311679751\n",
      "Trained batch 372 batch loss 0.283893138 epoch total loss 0.311605036\n",
      "Trained batch 373 batch loss 0.290406138 epoch total loss 0.311548203\n",
      "Trained batch 374 batch loss 0.287007809 epoch total loss 0.311482608\n",
      "Trained batch 375 batch loss 0.266689301 epoch total loss 0.311363161\n",
      "Trained batch 376 batch loss 0.297791809 epoch total loss 0.31132707\n",
      "Trained batch 377 batch loss 0.300872266 epoch total loss 0.311299324\n",
      "Trained batch 378 batch loss 0.296396971 epoch total loss 0.311259896\n",
      "Trained batch 379 batch loss 0.271848 epoch total loss 0.311155915\n",
      "Trained batch 380 batch loss 0.280921459 epoch total loss 0.311076343\n",
      "Trained batch 381 batch loss 0.297042936 epoch total loss 0.311039507\n",
      "Trained batch 382 batch loss 0.329742789 epoch total loss 0.311088473\n",
      "Trained batch 383 batch loss 0.325506896 epoch total loss 0.311126143\n",
      "Trained batch 384 batch loss 0.344220877 epoch total loss 0.311212331\n",
      "Trained batch 385 batch loss 0.304987162 epoch total loss 0.311196148\n",
      "Trained batch 386 batch loss 0.334944606 epoch total loss 0.31125766\n",
      "Trained batch 387 batch loss 0.335147828 epoch total loss 0.311319381\n",
      "Trained batch 388 batch loss 0.351378381 epoch total loss 0.311422646\n",
      "Trained batch 389 batch loss 0.30459 epoch total loss 0.311405063\n",
      "Trained batch 390 batch loss 0.316019416 epoch total loss 0.311416894\n",
      "Trained batch 391 batch loss 0.318018198 epoch total loss 0.311433792\n",
      "Trained batch 392 batch loss 0.352834135 epoch total loss 0.311539412\n",
      "Trained batch 393 batch loss 0.339304864 epoch total loss 0.311610043\n",
      "Trained batch 394 batch loss 0.324304938 epoch total loss 0.311642259\n",
      "Trained batch 395 batch loss 0.304427207 epoch total loss 0.311624\n",
      "Trained batch 396 batch loss 0.330511808 epoch total loss 0.311671704\n",
      "Trained batch 397 batch loss 0.299935967 epoch total loss 0.31164214\n",
      "Trained batch 398 batch loss 0.303562105 epoch total loss 0.311621815\n",
      "Trained batch 399 batch loss 0.311086833 epoch total loss 0.311620474\n",
      "Trained batch 400 batch loss 0.341439098 epoch total loss 0.311695\n",
      "Trained batch 401 batch loss 0.305761307 epoch total loss 0.311680228\n",
      "Trained batch 402 batch loss 0.304536164 epoch total loss 0.311662465\n",
      "Trained batch 403 batch loss 0.328472763 epoch total loss 0.311704189\n",
      "Trained batch 404 batch loss 0.304093122 epoch total loss 0.311685324\n",
      "Trained batch 405 batch loss 0.282972 epoch total loss 0.311614454\n",
      "Trained batch 406 batch loss 0.318195403 epoch total loss 0.311630666\n",
      "Trained batch 407 batch loss 0.304910153 epoch total loss 0.311614156\n",
      "Trained batch 408 batch loss 0.276879072 epoch total loss 0.311529\n",
      "Trained batch 409 batch loss 0.279922664 epoch total loss 0.311451733\n",
      "Trained batch 410 batch loss 0.295124114 epoch total loss 0.311411917\n",
      "Trained batch 411 batch loss 0.294360042 epoch total loss 0.311370432\n",
      "Trained batch 412 batch loss 0.328297198 epoch total loss 0.31141153\n",
      "Trained batch 413 batch loss 0.312459022 epoch total loss 0.311414033\n",
      "Trained batch 414 batch loss 0.290145814 epoch total loss 0.311362654\n",
      "Trained batch 415 batch loss 0.303970963 epoch total loss 0.311344862\n",
      "Trained batch 416 batch loss 0.306932658 epoch total loss 0.311334252\n",
      "Trained batch 417 batch loss 0.314317346 epoch total loss 0.311341405\n",
      "Trained batch 418 batch loss 0.297259957 epoch total loss 0.311307698\n",
      "Trained batch 419 batch loss 0.294886619 epoch total loss 0.311268508\n",
      "Trained batch 420 batch loss 0.280834079 epoch total loss 0.311196059\n",
      "Trained batch 421 batch loss 0.305549324 epoch total loss 0.311182648\n",
      "Trained batch 422 batch loss 0.327593595 epoch total loss 0.31122151\n",
      "Trained batch 423 batch loss 0.2931889 epoch total loss 0.311178863\n",
      "Trained batch 424 batch loss 0.284008116 epoch total loss 0.311114788\n",
      "Trained batch 425 batch loss 0.291802734 epoch total loss 0.311069369\n",
      "Trained batch 426 batch loss 0.311871558 epoch total loss 0.311071247\n",
      "Trained batch 427 batch loss 0.301281869 epoch total loss 0.311048329\n",
      "Trained batch 428 batch loss 0.312572241 epoch total loss 0.311051905\n",
      "Trained batch 429 batch loss 0.329793751 epoch total loss 0.311095595\n",
      "Trained batch 430 batch loss 0.292409062 epoch total loss 0.311052114\n",
      "Trained batch 431 batch loss 0.279050291 epoch total loss 0.310977876\n",
      "Trained batch 432 batch loss 0.28757304 epoch total loss 0.310923696\n",
      "Trained batch 433 batch loss 0.287001938 epoch total loss 0.310868442\n",
      "Trained batch 434 batch loss 0.26975894 epoch total loss 0.31077373\n",
      "Trained batch 435 batch loss 0.31760186 epoch total loss 0.310789406\n",
      "Trained batch 436 batch loss 0.344817787 epoch total loss 0.310867459\n",
      "Trained batch 437 batch loss 0.36057198 epoch total loss 0.310981184\n",
      "Trained batch 438 batch loss 0.34765029 epoch total loss 0.311064899\n",
      "Trained batch 439 batch loss 0.327277 epoch total loss 0.311101824\n",
      "Trained batch 440 batch loss 0.318011492 epoch total loss 0.31111753\n",
      "Trained batch 441 batch loss 0.299190283 epoch total loss 0.311090469\n",
      "Trained batch 442 batch loss 0.317548752 epoch total loss 0.311105102\n",
      "Trained batch 443 batch loss 0.340389431 epoch total loss 0.311171204\n",
      "Trained batch 444 batch loss 0.29691124 epoch total loss 0.311139077\n",
      "Trained batch 445 batch loss 0.307445973 epoch total loss 0.311130792\n",
      "Trained batch 446 batch loss 0.319740504 epoch total loss 0.311150104\n",
      "Trained batch 447 batch loss 0.28656891 epoch total loss 0.311095119\n",
      "Trained batch 448 batch loss 0.303719282 epoch total loss 0.311078697\n",
      "Trained batch 449 batch loss 0.280973226 epoch total loss 0.311011642\n",
      "Trained batch 450 batch loss 0.258900315 epoch total loss 0.31089583\n",
      "Trained batch 451 batch loss 0.278720289 epoch total loss 0.310824484\n",
      "Trained batch 452 batch loss 0.309043735 epoch total loss 0.31082052\n",
      "Trained batch 453 batch loss 0.325848073 epoch total loss 0.31085369\n",
      "Trained batch 454 batch loss 0.357870281 epoch total loss 0.310957253\n",
      "Trained batch 455 batch loss 0.325479269 epoch total loss 0.310989171\n",
      "Trained batch 456 batch loss 0.324232161 epoch total loss 0.311018229\n",
      "Trained batch 457 batch loss 0.327107847 epoch total loss 0.311053425\n",
      "Trained batch 458 batch loss 0.284774125 epoch total loss 0.310996056\n",
      "Trained batch 459 batch loss 0.328510225 epoch total loss 0.311034203\n",
      "Trained batch 460 batch loss 0.332579911 epoch total loss 0.311081022\n",
      "Trained batch 461 batch loss 0.26792 epoch total loss 0.310987383\n",
      "Trained batch 462 batch loss 0.308309078 epoch total loss 0.310981572\n",
      "Trained batch 463 batch loss 0.364546627 epoch total loss 0.311097264\n",
      "Trained batch 464 batch loss 0.345309228 epoch total loss 0.311171\n",
      "Trained batch 465 batch loss 0.29362911 epoch total loss 0.311133265\n",
      "Trained batch 466 batch loss 0.282159537 epoch total loss 0.311071098\n",
      "Trained batch 467 batch loss 0.289832026 epoch total loss 0.31102562\n",
      "Trained batch 468 batch loss 0.278552175 epoch total loss 0.31095621\n",
      "Trained batch 469 batch loss 0.288878381 epoch total loss 0.310909152\n",
      "Trained batch 470 batch loss 0.265683 epoch total loss 0.31081292\n",
      "Trained batch 471 batch loss 0.275780171 epoch total loss 0.310738564\n",
      "Trained batch 472 batch loss 0.300037384 epoch total loss 0.310715884\n",
      "Trained batch 473 batch loss 0.302316964 epoch total loss 0.310698152\n",
      "Trained batch 474 batch loss 0.326414824 epoch total loss 0.310731292\n",
      "Trained batch 475 batch loss 0.332671791 epoch total loss 0.310777485\n",
      "Trained batch 476 batch loss 0.307446718 epoch total loss 0.310770512\n",
      "Trained batch 477 batch loss 0.301358074 epoch total loss 0.310750782\n",
      "Trained batch 478 batch loss 0.313395023 epoch total loss 0.310756326\n",
      "Trained batch 479 batch loss 0.297797501 epoch total loss 0.310729235\n",
      "Trained batch 480 batch loss 0.312573552 epoch total loss 0.31073311\n",
      "Trained batch 481 batch loss 0.319084823 epoch total loss 0.310750484\n",
      "Trained batch 482 batch loss 0.340248734 epoch total loss 0.310811698\n",
      "Trained batch 483 batch loss 0.336344659 epoch total loss 0.310864568\n",
      "Trained batch 484 batch loss 0.330423474 epoch total loss 0.31090498\n",
      "Trained batch 485 batch loss 0.312460423 epoch total loss 0.310908169\n",
      "Trained batch 486 batch loss 0.297141433 epoch total loss 0.310879827\n",
      "Trained batch 487 batch loss 0.310598403 epoch total loss 0.31087926\n",
      "Trained batch 488 batch loss 0.312491298 epoch total loss 0.310882539\n",
      "Trained batch 489 batch loss 0.333272129 epoch total loss 0.310928315\n",
      "Trained batch 490 batch loss 0.369664699 epoch total loss 0.31104818\n",
      "Trained batch 491 batch loss 0.369008929 epoch total loss 0.311166197\n",
      "Trained batch 492 batch loss 0.31152156 epoch total loss 0.311166942\n",
      "Trained batch 493 batch loss 0.304297149 epoch total loss 0.311153\n",
      "Trained batch 494 batch loss 0.339336395 epoch total loss 0.311210036\n",
      "Trained batch 495 batch loss 0.346475661 epoch total loss 0.311281294\n",
      "Trained batch 496 batch loss 0.340331793 epoch total loss 0.311339885\n",
      "Trained batch 497 batch loss 0.31769681 epoch total loss 0.31135267\n",
      "Trained batch 498 batch loss 0.297159731 epoch total loss 0.311324179\n",
      "Trained batch 499 batch loss 0.31217289 epoch total loss 0.311325908\n",
      "Trained batch 500 batch loss 0.305286467 epoch total loss 0.311313808\n",
      "Trained batch 501 batch loss 0.296080947 epoch total loss 0.31128341\n",
      "Trained batch 502 batch loss 0.339346141 epoch total loss 0.311339289\n",
      "Trained batch 503 batch loss 0.306541502 epoch total loss 0.311329782\n",
      "Trained batch 504 batch loss 0.301766634 epoch total loss 0.311310828\n",
      "Trained batch 505 batch loss 0.315700859 epoch total loss 0.3113195\n",
      "Trained batch 506 batch loss 0.321874082 epoch total loss 0.311340362\n",
      "Trained batch 507 batch loss 0.307983071 epoch total loss 0.311333746\n",
      "Trained batch 508 batch loss 0.28966397 epoch total loss 0.311291069\n",
      "Trained batch 509 batch loss 0.302835733 epoch total loss 0.311274469\n",
      "Trained batch 510 batch loss 0.327943861 epoch total loss 0.311307162\n",
      "Trained batch 511 batch loss 0.310119659 epoch total loss 0.311304837\n",
      "Trained batch 512 batch loss 0.323547363 epoch total loss 0.311328739\n",
      "Trained batch 513 batch loss 0.338114917 epoch total loss 0.311380953\n",
      "Trained batch 514 batch loss 0.327447087 epoch total loss 0.311412245\n",
      "Trained batch 515 batch loss 0.325702 epoch total loss 0.311439961\n",
      "Trained batch 516 batch loss 0.294018567 epoch total loss 0.311406225\n",
      "Trained batch 517 batch loss 0.299983799 epoch total loss 0.311384141\n",
      "Trained batch 518 batch loss 0.280250669 epoch total loss 0.31132403\n",
      "Trained batch 519 batch loss 0.28766048 epoch total loss 0.311278433\n",
      "Trained batch 520 batch loss 0.300908089 epoch total loss 0.311258495\n",
      "Trained batch 521 batch loss 0.29436788 epoch total loss 0.31122607\n",
      "Trained batch 522 batch loss 0.311611414 epoch total loss 0.311226815\n",
      "Trained batch 523 batch loss 0.309526026 epoch total loss 0.311223567\n",
      "Trained batch 524 batch loss 0.32358107 epoch total loss 0.31124714\n",
      "Trained batch 525 batch loss 0.304939032 epoch total loss 0.31123513\n",
      "Trained batch 526 batch loss 0.319384038 epoch total loss 0.311250597\n",
      "Trained batch 527 batch loss 0.334876567 epoch total loss 0.31129542\n",
      "Trained batch 528 batch loss 0.358331352 epoch total loss 0.311384529\n",
      "Trained batch 529 batch loss 0.351459682 epoch total loss 0.311460257\n",
      "Trained batch 530 batch loss 0.359198183 epoch total loss 0.311550319\n",
      "Trained batch 531 batch loss 0.329464078 epoch total loss 0.311584085\n",
      "Trained batch 532 batch loss 0.325864583 epoch total loss 0.311610907\n",
      "Trained batch 533 batch loss 0.301838279 epoch total loss 0.311592579\n",
      "Trained batch 534 batch loss 0.328330904 epoch total loss 0.311623901\n",
      "Trained batch 535 batch loss 0.331838936 epoch total loss 0.31166169\n",
      "Trained batch 536 batch loss 0.30563128 epoch total loss 0.311650425\n",
      "Trained batch 537 batch loss 0.293542504 epoch total loss 0.311616719\n",
      "Trained batch 538 batch loss 0.300146759 epoch total loss 0.31159538\n",
      "Trained batch 539 batch loss 0.289173126 epoch total loss 0.311553776\n",
      "Trained batch 540 batch loss 0.299454212 epoch total loss 0.311531365\n",
      "Trained batch 541 batch loss 0.303091675 epoch total loss 0.311515778\n",
      "Trained batch 542 batch loss 0.299991965 epoch total loss 0.311494499\n",
      "Trained batch 543 batch loss 0.31412068 epoch total loss 0.311499327\n",
      "Trained batch 544 batch loss 0.311437428 epoch total loss 0.311499208\n",
      "Trained batch 545 batch loss 0.331819773 epoch total loss 0.311536491\n",
      "Trained batch 546 batch loss 0.322261155 epoch total loss 0.311556131\n",
      "Trained batch 547 batch loss 0.359460145 epoch total loss 0.31164372\n",
      "Trained batch 548 batch loss 0.311878532 epoch total loss 0.311644137\n",
      "Trained batch 549 batch loss 0.284683079 epoch total loss 0.311595023\n",
      "Trained batch 550 batch loss 0.281397849 epoch total loss 0.311540127\n",
      "Trained batch 551 batch loss 0.285696447 epoch total loss 0.311493218\n",
      "Trained batch 552 batch loss 0.316273749 epoch total loss 0.31150189\n",
      "Trained batch 553 batch loss 0.31615752 epoch total loss 0.311510295\n",
      "Trained batch 554 batch loss 0.287449449 epoch total loss 0.311466873\n",
      "Trained batch 555 batch loss 0.298029363 epoch total loss 0.311442673\n",
      "Trained batch 556 batch loss 0.289837837 epoch total loss 0.311403811\n",
      "Trained batch 557 batch loss 0.334539026 epoch total loss 0.311445326\n",
      "Trained batch 558 batch loss 0.335801065 epoch total loss 0.311489\n",
      "Trained batch 559 batch loss 0.311211586 epoch total loss 0.311488509\n",
      "Trained batch 560 batch loss 0.312264383 epoch total loss 0.31148991\n",
      "Trained batch 561 batch loss 0.264823 epoch total loss 0.311406702\n",
      "Trained batch 562 batch loss 0.244382769 epoch total loss 0.311287433\n",
      "Trained batch 563 batch loss 0.260753512 epoch total loss 0.311197698\n",
      "Trained batch 564 batch loss 0.290047526 epoch total loss 0.311160207\n",
      "Trained batch 565 batch loss 0.28488043 epoch total loss 0.311113685\n",
      "Trained batch 566 batch loss 0.300353706 epoch total loss 0.311094671\n",
      "Trained batch 567 batch loss 0.316838354 epoch total loss 0.311104804\n",
      "Trained batch 568 batch loss 0.300821841 epoch total loss 0.311086714\n",
      "Trained batch 569 batch loss 0.272054136 epoch total loss 0.311018109\n",
      "Trained batch 570 batch loss 0.302499175 epoch total loss 0.311003178\n",
      "Trained batch 571 batch loss 0.310064763 epoch total loss 0.311001509\n",
      "Trained batch 572 batch loss 0.279662669 epoch total loss 0.310946733\n",
      "Trained batch 573 batch loss 0.310287416 epoch total loss 0.31094557\n",
      "Trained batch 574 batch loss 0.301058173 epoch total loss 0.310928345\n",
      "Trained batch 575 batch loss 0.288689554 epoch total loss 0.310889691\n",
      "Trained batch 576 batch loss 0.27173844 epoch total loss 0.310821712\n",
      "Trained batch 577 batch loss 0.274393708 epoch total loss 0.310758591\n",
      "Trained batch 578 batch loss 0.321558356 epoch total loss 0.310777277\n",
      "Trained batch 579 batch loss 0.295279562 epoch total loss 0.310750514\n",
      "Trained batch 580 batch loss 0.301182 epoch total loss 0.310734\n",
      "Trained batch 581 batch loss 0.317347765 epoch total loss 0.310745388\n",
      "Trained batch 582 batch loss 0.307897151 epoch total loss 0.310740501\n",
      "Trained batch 583 batch loss 0.320170909 epoch total loss 0.310756683\n",
      "Trained batch 584 batch loss 0.333314538 epoch total loss 0.310795307\n",
      "Trained batch 585 batch loss 0.326501966 epoch total loss 0.310822159\n",
      "Trained batch 586 batch loss 0.295512676 epoch total loss 0.310796052\n",
      "Trained batch 587 batch loss 0.274123877 epoch total loss 0.310733557\n",
      "Trained batch 588 batch loss 0.272560835 epoch total loss 0.310668647\n",
      "Trained batch 589 batch loss 0.288895279 epoch total loss 0.310631692\n",
      "Trained batch 590 batch loss 0.301736534 epoch total loss 0.310616612\n",
      "Trained batch 591 batch loss 0.301624984 epoch total loss 0.310601413\n",
      "Trained batch 592 batch loss 0.332383335 epoch total loss 0.310638189\n",
      "Trained batch 593 batch loss 0.345736384 epoch total loss 0.310697377\n",
      "Trained batch 594 batch loss 0.343793482 epoch total loss 0.310753107\n",
      "Trained batch 595 batch loss 0.303597569 epoch total loss 0.310741097\n",
      "Trained batch 596 batch loss 0.305023 epoch total loss 0.3107315\n",
      "Trained batch 597 batch loss 0.301124454 epoch total loss 0.310715377\n",
      "Trained batch 598 batch loss 0.317924798 epoch total loss 0.310727447\n",
      "Trained batch 599 batch loss 0.32782647 epoch total loss 0.310756\n",
      "Trained batch 600 batch loss 0.327877641 epoch total loss 0.310784519\n",
      "Trained batch 601 batch loss 0.310752332 epoch total loss 0.310784459\n",
      "Trained batch 602 batch loss 0.307919443 epoch total loss 0.310779721\n",
      "Trained batch 603 batch loss 0.328707278 epoch total loss 0.310809433\n",
      "Trained batch 604 batch loss 0.326596797 epoch total loss 0.31083557\n",
      "Trained batch 605 batch loss 0.314673841 epoch total loss 0.310841918\n",
      "Trained batch 606 batch loss 0.327458769 epoch total loss 0.310869336\n",
      "Trained batch 607 batch loss 0.32848224 epoch total loss 0.310898334\n",
      "Trained batch 608 batch loss 0.302418351 epoch total loss 0.310884386\n",
      "Trained batch 609 batch loss 0.317482829 epoch total loss 0.310895234\n",
      "Trained batch 610 batch loss 0.303629577 epoch total loss 0.310883313\n",
      "Trained batch 611 batch loss 0.33343631 epoch total loss 0.310920238\n",
      "Trained batch 612 batch loss 0.33049643 epoch total loss 0.310952216\n",
      "Trained batch 613 batch loss 0.31786114 epoch total loss 0.310963482\n",
      "Trained batch 614 batch loss 0.284903944 epoch total loss 0.310921\n",
      "Trained batch 615 batch loss 0.325279415 epoch total loss 0.310944378\n",
      "Trained batch 616 batch loss 0.303964049 epoch total loss 0.310933053\n",
      "Trained batch 617 batch loss 0.296013772 epoch total loss 0.310908884\n",
      "Trained batch 618 batch loss 0.295137525 epoch total loss 0.310883373\n",
      "Trained batch 619 batch loss 0.313731939 epoch total loss 0.310887963\n",
      "Trained batch 620 batch loss 0.319007248 epoch total loss 0.310901046\n",
      "Trained batch 621 batch loss 0.289857 epoch total loss 0.310867161\n",
      "Trained batch 622 batch loss 0.290494323 epoch total loss 0.310834408\n",
      "Trained batch 623 batch loss 0.258517116 epoch total loss 0.310750425\n",
      "Trained batch 624 batch loss 0.283070266 epoch total loss 0.310706079\n",
      "Trained batch 625 batch loss 0.273663223 epoch total loss 0.310646802\n",
      "Trained batch 626 batch loss 0.279913336 epoch total loss 0.310597688\n",
      "Trained batch 627 batch loss 0.260273814 epoch total loss 0.31051743\n",
      "Trained batch 628 batch loss 0.267575324 epoch total loss 0.310449064\n",
      "Trained batch 629 batch loss 0.274927437 epoch total loss 0.310392588\n",
      "Trained batch 630 batch loss 0.286891222 epoch total loss 0.310355306\n",
      "Trained batch 631 batch loss 0.276304275 epoch total loss 0.310301334\n",
      "Trained batch 632 batch loss 0.278081417 epoch total loss 0.310250342\n",
      "Trained batch 633 batch loss 0.309261769 epoch total loss 0.310248792\n",
      "Trained batch 634 batch loss 0.338668585 epoch total loss 0.310293615\n",
      "Trained batch 635 batch loss 0.332816422 epoch total loss 0.31032908\n",
      "Trained batch 636 batch loss 0.313915461 epoch total loss 0.310334712\n",
      "Trained batch 637 batch loss 0.316295445 epoch total loss 0.31034407\n",
      "Trained batch 638 batch loss 0.321193337 epoch total loss 0.310361087\n",
      "Trained batch 639 batch loss 0.359309077 epoch total loss 0.310437709\n",
      "Trained batch 640 batch loss 0.317465156 epoch total loss 0.310448676\n",
      "Trained batch 641 batch loss 0.286010861 epoch total loss 0.310410559\n",
      "Trained batch 642 batch loss 0.308669358 epoch total loss 0.310407847\n",
      "Trained batch 643 batch loss 0.300856978 epoch total loss 0.310392976\n",
      "Trained batch 644 batch loss 0.27471894 epoch total loss 0.310337573\n",
      "Trained batch 645 batch loss 0.291501373 epoch total loss 0.310308397\n",
      "Trained batch 646 batch loss 0.293939888 epoch total loss 0.310283065\n",
      "Trained batch 647 batch loss 0.299702406 epoch total loss 0.310266703\n",
      "Trained batch 648 batch loss 0.29724887 epoch total loss 0.310246617\n",
      "Trained batch 649 batch loss 0.276460081 epoch total loss 0.310194552\n",
      "Trained batch 650 batch loss 0.293627143 epoch total loss 0.310169071\n",
      "Trained batch 651 batch loss 0.27748698 epoch total loss 0.310118854\n",
      "Trained batch 652 batch loss 0.245023429 epoch total loss 0.310019016\n",
      "Trained batch 653 batch loss 0.344275147 epoch total loss 0.310071468\n",
      "Trained batch 654 batch loss 0.348735362 epoch total loss 0.310130596\n",
      "Trained batch 655 batch loss 0.336245686 epoch total loss 0.310170472\n",
      "Trained batch 656 batch loss 0.330913305 epoch total loss 0.310202092\n",
      "Trained batch 657 batch loss 0.329214394 epoch total loss 0.31023103\n",
      "Trained batch 658 batch loss 0.308983386 epoch total loss 0.310229123\n",
      "Trained batch 659 batch loss 0.295773834 epoch total loss 0.310207188\n",
      "Trained batch 660 batch loss 0.282914281 epoch total loss 0.310165852\n",
      "Trained batch 661 batch loss 0.313457668 epoch total loss 0.310170829\n",
      "Trained batch 662 batch loss 0.294877738 epoch total loss 0.310147732\n",
      "Trained batch 663 batch loss 0.304865271 epoch total loss 0.310139775\n",
      "Trained batch 664 batch loss 0.327545285 epoch total loss 0.310165972\n",
      "Trained batch 665 batch loss 0.315115869 epoch total loss 0.310173422\n",
      "Trained batch 666 batch loss 0.334489167 epoch total loss 0.31020993\n",
      "Trained batch 667 batch loss 0.335733533 epoch total loss 0.310248196\n",
      "Trained batch 668 batch loss 0.33303526 epoch total loss 0.31028232\n",
      "Trained batch 669 batch loss 0.336939126 epoch total loss 0.310322165\n",
      "Trained batch 670 batch loss 0.337960839 epoch total loss 0.310363442\n",
      "Trained batch 671 batch loss 0.316677392 epoch total loss 0.310372829\n",
      "Trained batch 672 batch loss 0.347032219 epoch total loss 0.310427397\n",
      "Trained batch 673 batch loss 0.376339197 epoch total loss 0.310525328\n",
      "Trained batch 674 batch loss 0.341139644 epoch total loss 0.310570747\n",
      "Trained batch 675 batch loss 0.304762959 epoch total loss 0.310562164\n",
      "Trained batch 676 batch loss 0.351897031 epoch total loss 0.310623318\n",
      "Trained batch 677 batch loss 0.345025122 epoch total loss 0.310674131\n",
      "Trained batch 678 batch loss 0.323618323 epoch total loss 0.310693234\n",
      "Trained batch 679 batch loss 0.311715782 epoch total loss 0.310694754\n",
      "Trained batch 680 batch loss 0.298852801 epoch total loss 0.31067735\n",
      "Trained batch 681 batch loss 0.295740038 epoch total loss 0.310655415\n",
      "Trained batch 682 batch loss 0.3236368 epoch total loss 0.310674459\n",
      "Trained batch 683 batch loss 0.320875466 epoch total loss 0.31068939\n",
      "Trained batch 684 batch loss 0.31037423 epoch total loss 0.310688943\n",
      "Trained batch 685 batch loss 0.330903 epoch total loss 0.310718447\n",
      "Trained batch 686 batch loss 0.333610177 epoch total loss 0.310751796\n",
      "Trained batch 687 batch loss 0.32648471 epoch total loss 0.310774714\n",
      "Trained batch 688 batch loss 0.306644 epoch total loss 0.310768694\n",
      "Trained batch 689 batch loss 0.278716683 epoch total loss 0.310722172\n",
      "Trained batch 690 batch loss 0.27276054 epoch total loss 0.310667187\n",
      "Trained batch 691 batch loss 0.307920158 epoch total loss 0.310663193\n",
      "Trained batch 692 batch loss 0.33198753 epoch total loss 0.310694\n",
      "Trained batch 693 batch loss 0.298440218 epoch total loss 0.310676336\n",
      "Trained batch 694 batch loss 0.317396045 epoch total loss 0.310686022\n",
      "Trained batch 695 batch loss 0.268776983 epoch total loss 0.310625732\n",
      "Trained batch 696 batch loss 0.326089 epoch total loss 0.310647964\n",
      "Trained batch 697 batch loss 0.304207772 epoch total loss 0.310638726\n",
      "Trained batch 698 batch loss 0.32149452 epoch total loss 0.310654283\n",
      "Trained batch 699 batch loss 0.324856579 epoch total loss 0.310674608\n",
      "Trained batch 700 batch loss 0.291549116 epoch total loss 0.310647279\n",
      "Trained batch 701 batch loss 0.288888037 epoch total loss 0.310616255\n",
      "Trained batch 702 batch loss 0.281062365 epoch total loss 0.310574144\n",
      "Trained batch 703 batch loss 0.275269598 epoch total loss 0.310523927\n",
      "Trained batch 704 batch loss 0.262681127 epoch total loss 0.310455978\n",
      "Trained batch 705 batch loss 0.280453235 epoch total loss 0.31041342\n",
      "Trained batch 706 batch loss 0.295578331 epoch total loss 0.31039241\n",
      "Trained batch 707 batch loss 0.294723839 epoch total loss 0.310370237\n",
      "Trained batch 708 batch loss 0.273896664 epoch total loss 0.310318738\n",
      "Trained batch 709 batch loss 0.293513536 epoch total loss 0.310295016\n",
      "Trained batch 710 batch loss 0.297010213 epoch total loss 0.31027633\n",
      "Trained batch 711 batch loss 0.26466164 epoch total loss 0.310212165\n",
      "Trained batch 712 batch loss 0.291632622 epoch total loss 0.310186058\n",
      "Trained batch 713 batch loss 0.329568624 epoch total loss 0.310213268\n",
      "Trained batch 714 batch loss 0.304807156 epoch total loss 0.310205698\n",
      "Trained batch 715 batch loss 0.303437978 epoch total loss 0.310196221\n",
      "Trained batch 716 batch loss 0.292275786 epoch total loss 0.310171217\n",
      "Trained batch 717 batch loss 0.324354231 epoch total loss 0.310190976\n",
      "Trained batch 718 batch loss 0.301970124 epoch total loss 0.310179532\n",
      "Trained batch 719 batch loss 0.284339041 epoch total loss 0.31014359\n",
      "Trained batch 720 batch loss 0.262055933 epoch total loss 0.310076803\n",
      "Trained batch 721 batch loss 0.298009157 epoch total loss 0.310060054\n",
      "Trained batch 722 batch loss 0.289473355 epoch total loss 0.310031533\n",
      "Trained batch 723 batch loss 0.339099556 epoch total loss 0.310071737\n",
      "Trained batch 724 batch loss 0.308243245 epoch total loss 0.310069203\n",
      "Trained batch 725 batch loss 0.305237144 epoch total loss 0.310062557\n",
      "Trained batch 726 batch loss 0.275073618 epoch total loss 0.310014337\n",
      "Trained batch 727 batch loss 0.306988984 epoch total loss 0.310010195\n",
      "Trained batch 728 batch loss 0.301673412 epoch total loss 0.309998721\n",
      "Trained batch 729 batch loss 0.312511 epoch total loss 0.310002178\n",
      "Trained batch 730 batch loss 0.302289188 epoch total loss 0.309991628\n",
      "Trained batch 731 batch loss 0.324310243 epoch total loss 0.310011208\n",
      "Trained batch 732 batch loss 0.279676497 epoch total loss 0.309969783\n",
      "Trained batch 733 batch loss 0.306424558 epoch total loss 0.309964925\n",
      "Trained batch 734 batch loss 0.273178309 epoch total loss 0.309914827\n",
      "Trained batch 735 batch loss 0.307850391 epoch total loss 0.309912\n",
      "Trained batch 736 batch loss 0.301799774 epoch total loss 0.309901\n",
      "Trained batch 737 batch loss 0.319773 epoch total loss 0.30991438\n",
      "Trained batch 738 batch loss 0.311276734 epoch total loss 0.309916228\n",
      "Trained batch 739 batch loss 0.319577962 epoch total loss 0.309929311\n",
      "Trained batch 740 batch loss 0.291251808 epoch total loss 0.309904069\n",
      "Trained batch 741 batch loss 0.26673615 epoch total loss 0.309845805\n",
      "Trained batch 742 batch loss 0.272426844 epoch total loss 0.30979538\n",
      "Trained batch 743 batch loss 0.282351762 epoch total loss 0.309758455\n",
      "Trained batch 744 batch loss 0.288832307 epoch total loss 0.309730321\n",
      "Trained batch 745 batch loss 0.304878086 epoch total loss 0.309723794\n",
      "Trained batch 746 batch loss 0.268226 epoch total loss 0.309668154\n",
      "Trained batch 747 batch loss 0.326217711 epoch total loss 0.309690326\n",
      "Trained batch 748 batch loss 0.325009257 epoch total loss 0.309710801\n",
      "Trained batch 749 batch loss 0.306195945 epoch total loss 0.309706122\n",
      "Trained batch 750 batch loss 0.34447217 epoch total loss 0.309752464\n",
      "Trained batch 751 batch loss 0.28112 epoch total loss 0.309714317\n",
      "Trained batch 752 batch loss 0.273958027 epoch total loss 0.309666783\n",
      "Trained batch 753 batch loss 0.288579941 epoch total loss 0.309638768\n",
      "Trained batch 754 batch loss 0.305203706 epoch total loss 0.309632897\n",
      "Trained batch 755 batch loss 0.336988896 epoch total loss 0.309669107\n",
      "Trained batch 756 batch loss 0.33086127 epoch total loss 0.309697151\n",
      "Trained batch 757 batch loss 0.321843475 epoch total loss 0.309713185\n",
      "Trained batch 758 batch loss 0.300249338 epoch total loss 0.309700698\n",
      "Trained batch 759 batch loss 0.291156709 epoch total loss 0.30967626\n",
      "Trained batch 760 batch loss 0.316936284 epoch total loss 0.309685826\n",
      "Trained batch 761 batch loss 0.308755606 epoch total loss 0.309684604\n",
      "Trained batch 762 batch loss 0.342200637 epoch total loss 0.309727252\n",
      "Trained batch 763 batch loss 0.31588766 epoch total loss 0.309735328\n",
      "Trained batch 764 batch loss 0.327978045 epoch total loss 0.3097592\n",
      "Trained batch 765 batch loss 0.354761243 epoch total loss 0.309818029\n",
      "Trained batch 766 batch loss 0.29240495 epoch total loss 0.30979532\n",
      "Trained batch 767 batch loss 0.334849209 epoch total loss 0.309827983\n",
      "Trained batch 768 batch loss 0.348116696 epoch total loss 0.309877843\n",
      "Trained batch 769 batch loss 0.337837934 epoch total loss 0.309914201\n",
      "Trained batch 770 batch loss 0.303979158 epoch total loss 0.309906512\n",
      "Trained batch 771 batch loss 0.301376969 epoch total loss 0.309895426\n",
      "Trained batch 772 batch loss 0.307498634 epoch total loss 0.309892327\n",
      "Trained batch 773 batch loss 0.298473179 epoch total loss 0.309877574\n",
      "Trained batch 774 batch loss 0.310447812 epoch total loss 0.30987832\n",
      "Trained batch 775 batch loss 0.304984748 epoch total loss 0.309871972\n",
      "Trained batch 776 batch loss 0.29640612 epoch total loss 0.309854627\n",
      "Trained batch 777 batch loss 0.297389448 epoch total loss 0.309838593\n",
      "Trained batch 778 batch loss 0.3000184 epoch total loss 0.309825957\n",
      "Trained batch 779 batch loss 0.302235186 epoch total loss 0.309816211\n",
      "Trained batch 780 batch loss 0.30478844 epoch total loss 0.309809774\n",
      "Trained batch 781 batch loss 0.305007428 epoch total loss 0.309803635\n",
      "Trained batch 782 batch loss 0.282790542 epoch total loss 0.309769094\n",
      "Trained batch 783 batch loss 0.279916942 epoch total loss 0.309730977\n",
      "Trained batch 784 batch loss 0.287334919 epoch total loss 0.309702396\n",
      "Trained batch 785 batch loss 0.285071224 epoch total loss 0.309671\n",
      "Trained batch 786 batch loss 0.29510802 epoch total loss 0.309652478\n",
      "Trained batch 787 batch loss 0.32065028 epoch total loss 0.309666455\n",
      "Trained batch 788 batch loss 0.325780451 epoch total loss 0.309686899\n",
      "Trained batch 789 batch loss 0.324054509 epoch total loss 0.309705108\n",
      "Trained batch 790 batch loss 0.311293781 epoch total loss 0.309707135\n",
      "Trained batch 791 batch loss 0.295518398 epoch total loss 0.309689194\n",
      "Trained batch 792 batch loss 0.319654226 epoch total loss 0.309701771\n",
      "Trained batch 793 batch loss 0.249822915 epoch total loss 0.309626251\n",
      "Trained batch 794 batch loss 0.292350531 epoch total loss 0.309604496\n",
      "Trained batch 795 batch loss 0.288573444 epoch total loss 0.309578031\n",
      "Trained batch 796 batch loss 0.316976935 epoch total loss 0.30958733\n",
      "Trained batch 797 batch loss 0.327852279 epoch total loss 0.309610218\n",
      "Trained batch 798 batch loss 0.319206595 epoch total loss 0.309622258\n",
      "Trained batch 799 batch loss 0.293418109 epoch total loss 0.309601963\n",
      "Trained batch 800 batch loss 0.2981188 epoch total loss 0.309587628\n",
      "Trained batch 801 batch loss 0.302695811 epoch total loss 0.309579\n",
      "Trained batch 802 batch loss 0.256698459 epoch total loss 0.309513092\n",
      "Trained batch 803 batch loss 0.287862211 epoch total loss 0.309486121\n",
      "Trained batch 804 batch loss 0.309757531 epoch total loss 0.309486449\n",
      "Trained batch 805 batch loss 0.331459612 epoch total loss 0.309513748\n",
      "Trained batch 806 batch loss 0.321997941 epoch total loss 0.309529245\n",
      "Trained batch 807 batch loss 0.334693611 epoch total loss 0.309560418\n",
      "Trained batch 808 batch loss 0.317719519 epoch total loss 0.309570491\n",
      "Trained batch 809 batch loss 0.332759976 epoch total loss 0.309599161\n",
      "Trained batch 810 batch loss 0.302843064 epoch total loss 0.309590816\n",
      "Trained batch 811 batch loss 0.304463059 epoch total loss 0.309584498\n",
      "Trained batch 812 batch loss 0.304189771 epoch total loss 0.309577852\n",
      "Trained batch 813 batch loss 0.295428097 epoch total loss 0.309560448\n",
      "Trained batch 814 batch loss 0.305927485 epoch total loss 0.309555978\n",
      "Trained batch 815 batch loss 0.312071204 epoch total loss 0.309559047\n",
      "Trained batch 816 batch loss 0.283159226 epoch total loss 0.309526712\n",
      "Trained batch 817 batch loss 0.290372342 epoch total loss 0.309503257\n",
      "Trained batch 818 batch loss 0.271435589 epoch total loss 0.309456736\n",
      "Trained batch 819 batch loss 0.279386818 epoch total loss 0.309420019\n",
      "Trained batch 820 batch loss 0.305945039 epoch total loss 0.309415758\n",
      "Trained batch 821 batch loss 0.317303896 epoch total loss 0.309425384\n",
      "Trained batch 822 batch loss 0.303362191 epoch total loss 0.309418\n",
      "Trained batch 823 batch loss 0.323996902 epoch total loss 0.309435695\n",
      "Trained batch 824 batch loss 0.292521358 epoch total loss 0.309415191\n",
      "Trained batch 825 batch loss 0.302686214 epoch total loss 0.309407026\n",
      "Trained batch 826 batch loss 0.285975933 epoch total loss 0.309378684\n",
      "Trained batch 827 batch loss 0.294867337 epoch total loss 0.30936113\n",
      "Trained batch 828 batch loss 0.284738332 epoch total loss 0.309331357\n",
      "Trained batch 829 batch loss 0.275291085 epoch total loss 0.30929032\n",
      "Trained batch 830 batch loss 0.289546877 epoch total loss 0.309266537\n",
      "Trained batch 831 batch loss 0.322135776 epoch total loss 0.309282035\n",
      "Trained batch 832 batch loss 0.306536287 epoch total loss 0.309278756\n",
      "Trained batch 833 batch loss 0.317686409 epoch total loss 0.30928883\n",
      "Trained batch 834 batch loss 0.286276191 epoch total loss 0.309261262\n",
      "Trained batch 835 batch loss 0.307263255 epoch total loss 0.309258848\n",
      "Trained batch 836 batch loss 0.286000252 epoch total loss 0.309231043\n",
      "Trained batch 837 batch loss 0.318739921 epoch total loss 0.309242398\n",
      "Trained batch 838 batch loss 0.295733035 epoch total loss 0.309226274\n",
      "Trained batch 839 batch loss 0.315204918 epoch total loss 0.309233427\n",
      "Trained batch 840 batch loss 0.304248333 epoch total loss 0.309227496\n",
      "Trained batch 841 batch loss 0.335888416 epoch total loss 0.309259176\n",
      "Trained batch 842 batch loss 0.305400223 epoch total loss 0.309254587\n",
      "Trained batch 843 batch loss 0.296521127 epoch total loss 0.309239477\n",
      "Trained batch 844 batch loss 0.279740125 epoch total loss 0.309204549\n",
      "Trained batch 845 batch loss 0.321214736 epoch total loss 0.309218764\n",
      "Trained batch 846 batch loss 0.306420684 epoch total loss 0.309215456\n",
      "Trained batch 847 batch loss 0.301081836 epoch total loss 0.30920586\n",
      "Trained batch 848 batch loss 0.327475876 epoch total loss 0.309227407\n",
      "Trained batch 849 batch loss 0.331243545 epoch total loss 0.309253335\n",
      "Trained batch 850 batch loss 0.322482914 epoch total loss 0.309268892\n",
      "Trained batch 851 batch loss 0.322139293 epoch total loss 0.309284031\n",
      "Trained batch 852 batch loss 0.325701833 epoch total loss 0.309303313\n",
      "Trained batch 853 batch loss 0.329926729 epoch total loss 0.309327483\n",
      "Trained batch 854 batch loss 0.308962315 epoch total loss 0.309327066\n",
      "Trained batch 855 batch loss 0.31582737 epoch total loss 0.309334666\n",
      "Trained batch 856 batch loss 0.302404165 epoch total loss 0.309326559\n",
      "Trained batch 857 batch loss 0.327497661 epoch total loss 0.309347749\n",
      "Trained batch 858 batch loss 0.325996429 epoch total loss 0.30936715\n",
      "Trained batch 859 batch loss 0.331358373 epoch total loss 0.30939275\n",
      "Trained batch 860 batch loss 0.313552648 epoch total loss 0.309397578\n",
      "Trained batch 861 batch loss 0.316475928 epoch total loss 0.309405774\n",
      "Trained batch 862 batch loss 0.273447275 epoch total loss 0.309364051\n",
      "Trained batch 863 batch loss 0.276345462 epoch total loss 0.309325784\n",
      "Trained batch 864 batch loss 0.282588512 epoch total loss 0.30929485\n",
      "Trained batch 865 batch loss 0.288008034 epoch total loss 0.309270203\n",
      "Trained batch 866 batch loss 0.324914396 epoch total loss 0.309288293\n",
      "Trained batch 867 batch loss 0.311915815 epoch total loss 0.309291333\n",
      "Trained batch 868 batch loss 0.310033023 epoch total loss 0.309292167\n",
      "Trained batch 869 batch loss 0.312714845 epoch total loss 0.309296101\n",
      "Trained batch 870 batch loss 0.332854331 epoch total loss 0.309323192\n",
      "Trained batch 871 batch loss 0.311658353 epoch total loss 0.309325844\n",
      "Trained batch 872 batch loss 0.309473902 epoch total loss 0.309326023\n",
      "Trained batch 873 batch loss 0.317152917 epoch total loss 0.309335\n",
      "Trained batch 874 batch loss 0.318863302 epoch total loss 0.309345901\n",
      "Trained batch 875 batch loss 0.308319539 epoch total loss 0.309344739\n",
      "Trained batch 876 batch loss 0.320465773 epoch total loss 0.309357435\n",
      "Trained batch 877 batch loss 0.356450826 epoch total loss 0.309411108\n",
      "Trained batch 878 batch loss 0.298636049 epoch total loss 0.30939886\n",
      "Trained batch 879 batch loss 0.294197142 epoch total loss 0.309381545\n",
      "Trained batch 880 batch loss 0.333426535 epoch total loss 0.309408873\n",
      "Trained batch 881 batch loss 0.296177208 epoch total loss 0.309393853\n",
      "Trained batch 882 batch loss 0.341593325 epoch total loss 0.309430361\n",
      "Trained batch 883 batch loss 0.301765025 epoch total loss 0.309421659\n",
      "Trained batch 884 batch loss 0.301052034 epoch total loss 0.309412211\n",
      "Trained batch 885 batch loss 0.324289531 epoch total loss 0.309429\n",
      "Trained batch 886 batch loss 0.302157402 epoch total loss 0.309420794\n",
      "Trained batch 887 batch loss 0.325939834 epoch total loss 0.309439391\n",
      "Trained batch 888 batch loss 0.322933227 epoch total loss 0.30945459\n",
      "Trained batch 889 batch loss 0.307815462 epoch total loss 0.309452742\n",
      "Trained batch 890 batch loss 0.348700404 epoch total loss 0.30949682\n",
      "Trained batch 891 batch loss 0.323610187 epoch total loss 0.309512675\n",
      "Trained batch 892 batch loss 0.286898166 epoch total loss 0.309487313\n",
      "Trained batch 893 batch loss 0.255277365 epoch total loss 0.309426606\n",
      "Trained batch 894 batch loss 0.299118757 epoch total loss 0.309415102\n",
      "Trained batch 895 batch loss 0.315444142 epoch total loss 0.309421808\n",
      "Trained batch 896 batch loss 0.325494707 epoch total loss 0.309439749\n",
      "Trained batch 897 batch loss 0.327314854 epoch total loss 0.309459686\n",
      "Trained batch 898 batch loss 0.313500881 epoch total loss 0.309464186\n",
      "Trained batch 899 batch loss 0.306189835 epoch total loss 0.309460521\n",
      "Trained batch 900 batch loss 0.326921016 epoch total loss 0.309479952\n",
      "Trained batch 901 batch loss 0.323186755 epoch total loss 0.309495151\n",
      "Trained batch 902 batch loss 0.302493304 epoch total loss 0.309487373\n",
      "Trained batch 903 batch loss 0.293216318 epoch total loss 0.309469372\n",
      "Trained batch 904 batch loss 0.300741464 epoch total loss 0.309459716\n",
      "Trained batch 905 batch loss 0.307951331 epoch total loss 0.309458047\n",
      "Trained batch 906 batch loss 0.311082423 epoch total loss 0.309459865\n",
      "Trained batch 907 batch loss 0.306077123 epoch total loss 0.30945614\n",
      "Trained batch 908 batch loss 0.315920293 epoch total loss 0.309463263\n",
      "Trained batch 909 batch loss 0.309967846 epoch total loss 0.309463829\n",
      "Trained batch 910 batch loss 0.309762776 epoch total loss 0.309464127\n",
      "Trained batch 911 batch loss 0.339044333 epoch total loss 0.309496611\n",
      "Trained batch 912 batch loss 0.338235021 epoch total loss 0.309528112\n",
      "Trained batch 913 batch loss 0.333919764 epoch total loss 0.309554845\n",
      "Trained batch 914 batch loss 0.304256141 epoch total loss 0.309549034\n",
      "Trained batch 915 batch loss 0.286477596 epoch total loss 0.309523821\n",
      "Trained batch 916 batch loss 0.284922689 epoch total loss 0.309496939\n",
      "Trained batch 917 batch loss 0.29143548 epoch total loss 0.30947727\n",
      "Trained batch 918 batch loss 0.293756872 epoch total loss 0.309460133\n",
      "Trained batch 919 batch loss 0.328343421 epoch total loss 0.309480697\n",
      "Trained batch 920 batch loss 0.302572906 epoch total loss 0.309473187\n",
      "Trained batch 921 batch loss 0.313203335 epoch total loss 0.30947724\n",
      "Trained batch 922 batch loss 0.313656896 epoch total loss 0.30948177\n",
      "Trained batch 923 batch loss 0.295679092 epoch total loss 0.309466809\n",
      "Trained batch 924 batch loss 0.294056088 epoch total loss 0.30945015\n",
      "Trained batch 925 batch loss 0.296382606 epoch total loss 0.309436023\n",
      "Trained batch 926 batch loss 0.271911204 epoch total loss 0.309395522\n",
      "Trained batch 927 batch loss 0.313916981 epoch total loss 0.30940038\n",
      "Trained batch 928 batch loss 0.319695443 epoch total loss 0.309411466\n",
      "Trained batch 929 batch loss 0.302108169 epoch total loss 0.309403598\n",
      "Trained batch 930 batch loss 0.289350122 epoch total loss 0.309382021\n",
      "Trained batch 931 batch loss 0.294828892 epoch total loss 0.309366405\n",
      "Trained batch 932 batch loss 0.277751446 epoch total loss 0.30933246\n",
      "Trained batch 933 batch loss 0.278746963 epoch total loss 0.309299678\n",
      "Trained batch 934 batch loss 0.2868267 epoch total loss 0.309275627\n",
      "Trained batch 935 batch loss 0.29157728 epoch total loss 0.309256673\n",
      "Trained batch 936 batch loss 0.315845072 epoch total loss 0.309263736\n",
      "Trained batch 937 batch loss 0.307030022 epoch total loss 0.309261352\n",
      "Trained batch 938 batch loss 0.310467273 epoch total loss 0.309262633\n",
      "Trained batch 939 batch loss 0.287846863 epoch total loss 0.309239805\n",
      "Trained batch 940 batch loss 0.282269329 epoch total loss 0.309211105\n",
      "Trained batch 941 batch loss 0.329820246 epoch total loss 0.30923304\n",
      "Trained batch 942 batch loss 0.315123171 epoch total loss 0.309239298\n",
      "Trained batch 943 batch loss 0.32589677 epoch total loss 0.309256941\n",
      "Trained batch 944 batch loss 0.304682314 epoch total loss 0.309252113\n",
      "Trained batch 945 batch loss 0.26871106 epoch total loss 0.309209198\n",
      "Trained batch 946 batch loss 0.301204979 epoch total loss 0.309200734\n",
      "Trained batch 947 batch loss 0.312676936 epoch total loss 0.309204429\n",
      "Trained batch 948 batch loss 0.316048 epoch total loss 0.309211642\n",
      "Trained batch 949 batch loss 0.319171131 epoch total loss 0.309222132\n",
      "Trained batch 950 batch loss 0.344567716 epoch total loss 0.309259355\n",
      "Trained batch 951 batch loss 0.341339737 epoch total loss 0.309293091\n",
      "Trained batch 952 batch loss 0.334987283 epoch total loss 0.309320092\n",
      "Trained batch 953 batch loss 0.310103774 epoch total loss 0.309320897\n",
      "Trained batch 954 batch loss 0.296277791 epoch total loss 0.309307188\n",
      "Trained batch 955 batch loss 0.29939574 epoch total loss 0.309296846\n",
      "Trained batch 956 batch loss 0.287587374 epoch total loss 0.309274137\n",
      "Trained batch 957 batch loss 0.285939366 epoch total loss 0.309249759\n",
      "Trained batch 958 batch loss 0.288430959 epoch total loss 0.309228033\n",
      "Trained batch 959 batch loss 0.295962751 epoch total loss 0.309214175\n",
      "Trained batch 960 batch loss 0.300896525 epoch total loss 0.309205532\n",
      "Trained batch 961 batch loss 0.30886969 epoch total loss 0.309205174\n",
      "Trained batch 962 batch loss 0.28084749 epoch total loss 0.3091757\n",
      "Trained batch 963 batch loss 0.287283152 epoch total loss 0.309153\n",
      "Trained batch 964 batch loss 0.24774003 epoch total loss 0.309089273\n",
      "Trained batch 965 batch loss 0.258593082 epoch total loss 0.30903697\n",
      "Trained batch 966 batch loss 0.308958054 epoch total loss 0.309036881\n",
      "Trained batch 967 batch loss 0.306274533 epoch total loss 0.30903402\n",
      "Trained batch 968 batch loss 0.302998364 epoch total loss 0.309027791\n",
      "Trained batch 969 batch loss 0.27226311 epoch total loss 0.308989882\n",
      "Trained batch 970 batch loss 0.299546957 epoch total loss 0.308980167\n",
      "Trained batch 971 batch loss 0.274791896 epoch total loss 0.308944941\n",
      "Trained batch 972 batch loss 0.272593647 epoch total loss 0.308907539\n",
      "Trained batch 973 batch loss 0.300642818 epoch total loss 0.308899015\n",
      "Trained batch 974 batch loss 0.315580159 epoch total loss 0.30890587\n",
      "Trained batch 975 batch loss 0.31144467 epoch total loss 0.308908463\n",
      "Trained batch 976 batch loss 0.290138245 epoch total loss 0.30888924\n",
      "Trained batch 977 batch loss 0.285424739 epoch total loss 0.308865219\n",
      "Trained batch 978 batch loss 0.290857643 epoch total loss 0.308846802\n",
      "Trained batch 979 batch loss 0.267139167 epoch total loss 0.308804214\n",
      "Trained batch 980 batch loss 0.286009401 epoch total loss 0.308780968\n",
      "Trained batch 981 batch loss 0.330229789 epoch total loss 0.308802843\n",
      "Trained batch 982 batch loss 0.322496623 epoch total loss 0.308816791\n",
      "Trained batch 983 batch loss 0.31251508 epoch total loss 0.308820546\n",
      "Trained batch 984 batch loss 0.326574266 epoch total loss 0.308838576\n",
      "Trained batch 985 batch loss 0.317462862 epoch total loss 0.308847338\n",
      "Trained batch 986 batch loss 0.323160738 epoch total loss 0.308861852\n",
      "Trained batch 987 batch loss 0.326684356 epoch total loss 0.308879912\n",
      "Trained batch 988 batch loss 0.306755096 epoch total loss 0.308877766\n",
      "Trained batch 989 batch loss 0.276325613 epoch total loss 0.308844864\n",
      "Trained batch 990 batch loss 0.279181719 epoch total loss 0.308814883\n",
      "Trained batch 991 batch loss 0.311158419 epoch total loss 0.308817267\n",
      "Trained batch 992 batch loss 0.321169078 epoch total loss 0.308829695\n",
      "Trained batch 993 batch loss 0.329257488 epoch total loss 0.308850288\n",
      "Trained batch 994 batch loss 0.334157556 epoch total loss 0.30887574\n",
      "Trained batch 995 batch loss 0.297552466 epoch total loss 0.308864355\n",
      "Trained batch 996 batch loss 0.28778103 epoch total loss 0.308843195\n",
      "Trained batch 997 batch loss 0.295751303 epoch total loss 0.308830053\n",
      "Trained batch 998 batch loss 0.313308299 epoch total loss 0.308834523\n",
      "Trained batch 999 batch loss 0.334210575 epoch total loss 0.308859915\n",
      "Trained batch 1000 batch loss 0.297280282 epoch total loss 0.308848321\n",
      "Trained batch 1001 batch loss 0.311508328 epoch total loss 0.308851\n",
      "Trained batch 1002 batch loss 0.301579952 epoch total loss 0.308843732\n",
      "Trained batch 1003 batch loss 0.315499932 epoch total loss 0.308850378\n",
      "Trained batch 1004 batch loss 0.313747287 epoch total loss 0.308855236\n",
      "Trained batch 1005 batch loss 0.331348449 epoch total loss 0.308877647\n",
      "Trained batch 1006 batch loss 0.318947405 epoch total loss 0.308887631\n",
      "Trained batch 1007 batch loss 0.275094777 epoch total loss 0.308854073\n",
      "Trained batch 1008 batch loss 0.318579674 epoch total loss 0.308863729\n",
      "Trained batch 1009 batch loss 0.314984232 epoch total loss 0.308869779\n",
      "Trained batch 1010 batch loss 0.301199555 epoch total loss 0.30886218\n",
      "Trained batch 1011 batch loss 0.297129452 epoch total loss 0.308850557\n",
      "Trained batch 1012 batch loss 0.29305312 epoch total loss 0.30883497\n",
      "Trained batch 1013 batch loss 0.299661785 epoch total loss 0.30882591\n",
      "Trained batch 1014 batch loss 0.364350319 epoch total loss 0.308880657\n",
      "Trained batch 1015 batch loss 0.328731775 epoch total loss 0.308900207\n",
      "Trained batch 1016 batch loss 0.312701553 epoch total loss 0.308903962\n",
      "Trained batch 1017 batch loss 0.327213675 epoch total loss 0.308921963\n",
      "Trained batch 1018 batch loss 0.356808424 epoch total loss 0.308969021\n",
      "Trained batch 1019 batch loss 0.2929793 epoch total loss 0.308953315\n",
      "Trained batch 1020 batch loss 0.301229984 epoch total loss 0.308945745\n",
      "Trained batch 1021 batch loss 0.314475119 epoch total loss 0.308951169\n",
      "Trained batch 1022 batch loss 0.305445075 epoch total loss 0.308947742\n",
      "Trained batch 1023 batch loss 0.286444068 epoch total loss 0.308925748\n",
      "Trained batch 1024 batch loss 0.27510193 epoch total loss 0.308892727\n",
      "Trained batch 1025 batch loss 0.272189349 epoch total loss 0.308856905\n",
      "Trained batch 1026 batch loss 0.293195307 epoch total loss 0.308841646\n",
      "Trained batch 1027 batch loss 0.314101 epoch total loss 0.308846742\n",
      "Trained batch 1028 batch loss 0.333537519 epoch total loss 0.308870763\n",
      "Trained batch 1029 batch loss 0.354291 epoch total loss 0.30891487\n",
      "Trained batch 1030 batch loss 0.333322436 epoch total loss 0.308938563\n",
      "Trained batch 1031 batch loss 0.329926819 epoch total loss 0.308958918\n",
      "Trained batch 1032 batch loss 0.316922486 epoch total loss 0.308966637\n",
      "Trained batch 1033 batch loss 0.281095445 epoch total loss 0.308939666\n",
      "Trained batch 1034 batch loss 0.305349648 epoch total loss 0.308936208\n",
      "Trained batch 1035 batch loss 0.303215116 epoch total loss 0.308930695\n",
      "Trained batch 1036 batch loss 0.307760596 epoch total loss 0.308929563\n",
      "Trained batch 1037 batch loss 0.298558474 epoch total loss 0.308919549\n",
      "Trained batch 1038 batch loss 0.322926581 epoch total loss 0.308933049\n",
      "Trained batch 1039 batch loss 0.310489 epoch total loss 0.30893454\n",
      "Trained batch 1040 batch loss 0.297686666 epoch total loss 0.308923751\n",
      "Trained batch 1041 batch loss 0.313276231 epoch total loss 0.308927923\n",
      "Trained batch 1042 batch loss 0.297712505 epoch total loss 0.308917135\n",
      "Trained batch 1043 batch loss 0.276762903 epoch total loss 0.308886319\n",
      "Trained batch 1044 batch loss 0.282028288 epoch total loss 0.3088606\n",
      "Trained batch 1045 batch loss 0.302523345 epoch total loss 0.30885455\n",
      "Trained batch 1046 batch loss 0.28904289 epoch total loss 0.308835596\n",
      "Trained batch 1047 batch loss 0.345902324 epoch total loss 0.308871\n",
      "Trained batch 1048 batch loss 0.341457903 epoch total loss 0.308902115\n",
      "Trained batch 1049 batch loss 0.332445383 epoch total loss 0.308924556\n",
      "Trained batch 1050 batch loss 0.332178503 epoch total loss 0.308946699\n",
      "Trained batch 1051 batch loss 0.325629592 epoch total loss 0.308962584\n",
      "Trained batch 1052 batch loss 0.308896422 epoch total loss 0.308962524\n",
      "Trained batch 1053 batch loss 0.322217077 epoch total loss 0.308975101\n",
      "Trained batch 1054 batch loss 0.314352661 epoch total loss 0.308980197\n",
      "Trained batch 1055 batch loss 0.308735162 epoch total loss 0.30898\n",
      "Trained batch 1056 batch loss 0.288494378 epoch total loss 0.308960557\n",
      "Trained batch 1057 batch loss 0.332905769 epoch total loss 0.308983237\n",
      "Trained batch 1058 batch loss 0.307206303 epoch total loss 0.308981568\n",
      "Trained batch 1059 batch loss 0.303690463 epoch total loss 0.308976561\n",
      "Trained batch 1060 batch loss 0.300145388 epoch total loss 0.308968216\n",
      "Trained batch 1061 batch loss 0.276702017 epoch total loss 0.308937818\n",
      "Trained batch 1062 batch loss 0.2924878 epoch total loss 0.308922321\n",
      "Trained batch 1063 batch loss 0.30697152 epoch total loss 0.308920473\n",
      "Trained batch 1064 batch loss 0.333664954 epoch total loss 0.308943748\n",
      "Trained batch 1065 batch loss 0.311213 epoch total loss 0.308945894\n",
      "Trained batch 1066 batch loss 0.323302686 epoch total loss 0.308959365\n",
      "Trained batch 1067 batch loss 0.309480876 epoch total loss 0.308959842\n",
      "Trained batch 1068 batch loss 0.34355092 epoch total loss 0.308992207\n",
      "Trained batch 1069 batch loss 0.275338054 epoch total loss 0.308960736\n",
      "Trained batch 1070 batch loss 0.297704905 epoch total loss 0.308950216\n",
      "Trained batch 1071 batch loss 0.291107357 epoch total loss 0.308933556\n",
      "Trained batch 1072 batch loss 0.268608421 epoch total loss 0.308895946\n",
      "Trained batch 1073 batch loss 0.253195018 epoch total loss 0.30884403\n",
      "Trained batch 1074 batch loss 0.262339383 epoch total loss 0.308800727\n",
      "Trained batch 1075 batch loss 0.272431195 epoch total loss 0.308766901\n",
      "Trained batch 1076 batch loss 0.245665386 epoch total loss 0.308708251\n",
      "Trained batch 1077 batch loss 0.249219984 epoch total loss 0.308653\n",
      "Trained batch 1078 batch loss 0.229804382 epoch total loss 0.308579862\n",
      "Trained batch 1079 batch loss 0.25508979 epoch total loss 0.308530271\n",
      "Trained batch 1080 batch loss 0.290968806 epoch total loss 0.308514\n",
      "Trained batch 1081 batch loss 0.300918281 epoch total loss 0.308506966\n",
      "Trained batch 1082 batch loss 0.282990903 epoch total loss 0.308483392\n",
      "Trained batch 1083 batch loss 0.301114351 epoch total loss 0.308476597\n",
      "Trained batch 1084 batch loss 0.326969028 epoch total loss 0.308493644\n",
      "Trained batch 1085 batch loss 0.293402225 epoch total loss 0.308479726\n",
      "Trained batch 1086 batch loss 0.320765853 epoch total loss 0.308491051\n",
      "Trained batch 1087 batch loss 0.292185336 epoch total loss 0.308476031\n",
      "Trained batch 1088 batch loss 0.276090026 epoch total loss 0.308446258\n",
      "Trained batch 1089 batch loss 0.267233849 epoch total loss 0.308408439\n",
      "Trained batch 1090 batch loss 0.304514319 epoch total loss 0.308404863\n",
      "Trained batch 1091 batch loss 0.358419597 epoch total loss 0.308450699\n",
      "Trained batch 1092 batch loss 0.307342649 epoch total loss 0.308449686\n",
      "Trained batch 1093 batch loss 0.317142367 epoch total loss 0.308457643\n",
      "Trained batch 1094 batch loss 0.294410378 epoch total loss 0.308444798\n",
      "Trained batch 1095 batch loss 0.325853646 epoch total loss 0.308460712\n",
      "Trained batch 1096 batch loss 0.2842803 epoch total loss 0.308438629\n",
      "Trained batch 1097 batch loss 0.295552611 epoch total loss 0.308426887\n",
      "Trained batch 1098 batch loss 0.283669531 epoch total loss 0.308404326\n",
      "Trained batch 1099 batch loss 0.310233504 epoch total loss 0.308406\n",
      "Trained batch 1100 batch loss 0.318040431 epoch total loss 0.308414787\n",
      "Trained batch 1101 batch loss 0.30003202 epoch total loss 0.308407158\n",
      "Trained batch 1102 batch loss 0.3106803 epoch total loss 0.308409214\n",
      "Trained batch 1103 batch loss 0.305321425 epoch total loss 0.308406413\n",
      "Trained batch 1104 batch loss 0.28088057 epoch total loss 0.308381468\n",
      "Trained batch 1105 batch loss 0.282235056 epoch total loss 0.308357805\n",
      "Trained batch 1106 batch loss 0.296803504 epoch total loss 0.308347374\n",
      "Trained batch 1107 batch loss 0.303150117 epoch total loss 0.308342695\n",
      "Trained batch 1108 batch loss 0.276956648 epoch total loss 0.308314353\n",
      "Trained batch 1109 batch loss 0.24884972 epoch total loss 0.308260739\n",
      "Trained batch 1110 batch loss 0.278558642 epoch total loss 0.308233976\n",
      "Trained batch 1111 batch loss 0.29980588 epoch total loss 0.308226377\n",
      "Trained batch 1112 batch loss 0.299666047 epoch total loss 0.308218688\n",
      "Trained batch 1113 batch loss 0.303032696 epoch total loss 0.308214\n",
      "Trained batch 1114 batch loss 0.314494401 epoch total loss 0.308219641\n",
      "Trained batch 1115 batch loss 0.328371882 epoch total loss 0.308237731\n",
      "Trained batch 1116 batch loss 0.314546347 epoch total loss 0.308243364\n",
      "Trained batch 1117 batch loss 0.279949665 epoch total loss 0.308218032\n",
      "Trained batch 1118 batch loss 0.292238861 epoch total loss 0.308203727\n",
      "Trained batch 1119 batch loss 0.29694435 epoch total loss 0.308193654\n",
      "Trained batch 1120 batch loss 0.310421407 epoch total loss 0.308195651\n",
      "Trained batch 1121 batch loss 0.27699545 epoch total loss 0.308167845\n",
      "Trained batch 1122 batch loss 0.224330053 epoch total loss 0.308093131\n",
      "Trained batch 1123 batch loss 0.258206546 epoch total loss 0.308048695\n",
      "Trained batch 1124 batch loss 0.307841361 epoch total loss 0.308048517\n",
      "Trained batch 1125 batch loss 0.329240233 epoch total loss 0.308067352\n",
      "Trained batch 1126 batch loss 0.357776761 epoch total loss 0.308111519\n",
      "Trained batch 1127 batch loss 0.350964963 epoch total loss 0.308149517\n",
      "Trained batch 1128 batch loss 0.346553355 epoch total loss 0.308183581\n",
      "Trained batch 1129 batch loss 0.299492031 epoch total loss 0.308175892\n",
      "Trained batch 1130 batch loss 0.325673312 epoch total loss 0.308191389\n",
      "Trained batch 1131 batch loss 0.317325 epoch total loss 0.308199435\n",
      "Trained batch 1132 batch loss 0.307030201 epoch total loss 0.308198422\n",
      "Trained batch 1133 batch loss 0.327879727 epoch total loss 0.308215797\n",
      "Trained batch 1134 batch loss 0.370537817 epoch total loss 0.308270752\n",
      "Trained batch 1135 batch loss 0.289443731 epoch total loss 0.308254153\n",
      "Trained batch 1136 batch loss 0.314957112 epoch total loss 0.308260083\n",
      "Trained batch 1137 batch loss 0.306897461 epoch total loss 0.308258861\n",
      "Trained batch 1138 batch loss 0.295521885 epoch total loss 0.308247685\n",
      "Trained batch 1139 batch loss 0.321187377 epoch total loss 0.30825904\n",
      "Trained batch 1140 batch loss 0.328636736 epoch total loss 0.308276922\n",
      "Trained batch 1141 batch loss 0.315462142 epoch total loss 0.30828324\n",
      "Trained batch 1142 batch loss 0.344652772 epoch total loss 0.308315068\n",
      "Trained batch 1143 batch loss 0.345712721 epoch total loss 0.308347791\n",
      "Trained batch 1144 batch loss 0.359926462 epoch total loss 0.308392882\n",
      "Trained batch 1145 batch loss 0.348496228 epoch total loss 0.30842793\n",
      "Trained batch 1146 batch loss 0.33920753 epoch total loss 0.308454782\n",
      "Trained batch 1147 batch loss 0.337529451 epoch total loss 0.308480114\n",
      "Trained batch 1148 batch loss 0.329440653 epoch total loss 0.308498383\n",
      "Trained batch 1149 batch loss 0.316113 epoch total loss 0.308505\n",
      "Trained batch 1150 batch loss 0.32371974 epoch total loss 0.308518231\n",
      "Trained batch 1151 batch loss 0.318040967 epoch total loss 0.308526516\n",
      "Trained batch 1152 batch loss 0.341729194 epoch total loss 0.308555335\n",
      "Trained batch 1153 batch loss 0.317368627 epoch total loss 0.308563\n",
      "Trained batch 1154 batch loss 0.307306 epoch total loss 0.308561921\n",
      "Trained batch 1155 batch loss 0.336144805 epoch total loss 0.308585793\n",
      "Trained batch 1156 batch loss 0.305697739 epoch total loss 0.308583289\n",
      "Trained batch 1157 batch loss 0.301135838 epoch total loss 0.308576882\n",
      "Trained batch 1158 batch loss 0.302156 epoch total loss 0.308571309\n",
      "Trained batch 1159 batch loss 0.311337233 epoch total loss 0.308573723\n",
      "Trained batch 1160 batch loss 0.36211 epoch total loss 0.308619887\n",
      "Trained batch 1161 batch loss 0.331884 epoch total loss 0.308639914\n",
      "Trained batch 1162 batch loss 0.301980317 epoch total loss 0.308634162\n",
      "Trained batch 1163 batch loss 0.309053093 epoch total loss 0.30863452\n",
      "Trained batch 1164 batch loss 0.321369231 epoch total loss 0.308645487\n",
      "Trained batch 1165 batch loss 0.311423749 epoch total loss 0.308647871\n",
      "Trained batch 1166 batch loss 0.340102255 epoch total loss 0.308674842\n",
      "Trained batch 1167 batch loss 0.337108642 epoch total loss 0.308699191\n",
      "Trained batch 1168 batch loss 0.320213795 epoch total loss 0.308709055\n",
      "Trained batch 1169 batch loss 0.300515443 epoch total loss 0.308702022\n",
      "Trained batch 1170 batch loss 0.28437975 epoch total loss 0.30868125\n",
      "Trained batch 1171 batch loss 0.249521047 epoch total loss 0.308630735\n",
      "Trained batch 1172 batch loss 0.244715169 epoch total loss 0.308576196\n",
      "Trained batch 1173 batch loss 0.252803773 epoch total loss 0.308528662\n",
      "Trained batch 1174 batch loss 0.264529169 epoch total loss 0.30849117\n",
      "Trained batch 1175 batch loss 0.26984483 epoch total loss 0.308458269\n",
      "Trained batch 1176 batch loss 0.289124906 epoch total loss 0.308441848\n",
      "Trained batch 1177 batch loss 0.277739763 epoch total loss 0.308415741\n",
      "Trained batch 1178 batch loss 0.27392152 epoch total loss 0.308386475\n",
      "Trained batch 1179 batch loss 0.29240489 epoch total loss 0.308372945\n",
      "Trained batch 1180 batch loss 0.315782696 epoch total loss 0.308379233\n",
      "Trained batch 1181 batch loss 0.310646892 epoch total loss 0.30838114\n",
      "Trained batch 1182 batch loss 0.281712 epoch total loss 0.30835858\n",
      "Trained batch 1183 batch loss 0.270902723 epoch total loss 0.3083269\n",
      "Trained batch 1184 batch loss 0.284694284 epoch total loss 0.308306962\n",
      "Trained batch 1185 batch loss 0.280351579 epoch total loss 0.308283359\n",
      "Trained batch 1186 batch loss 0.303276926 epoch total loss 0.308279157\n",
      "Trained batch 1187 batch loss 0.33947885 epoch total loss 0.308305442\n",
      "Trained batch 1188 batch loss 0.332777888 epoch total loss 0.308326036\n",
      "Trained batch 1189 batch loss 0.315033436 epoch total loss 0.308331668\n",
      "Trained batch 1190 batch loss 0.327036381 epoch total loss 0.308347374\n",
      "Trained batch 1191 batch loss 0.305987746 epoch total loss 0.308345407\n",
      "Trained batch 1192 batch loss 0.305278778 epoch total loss 0.308342814\n",
      "Trained batch 1193 batch loss 0.287877828 epoch total loss 0.308325678\n",
      "Trained batch 1194 batch loss 0.283885 epoch total loss 0.308305174\n",
      "Trained batch 1195 batch loss 0.283517212 epoch total loss 0.308284432\n",
      "Trained batch 1196 batch loss 0.289659232 epoch total loss 0.308268875\n",
      "Trained batch 1197 batch loss 0.319983542 epoch total loss 0.30827865\n",
      "Trained batch 1198 batch loss 0.282131612 epoch total loss 0.308256835\n",
      "Trained batch 1199 batch loss 0.316570252 epoch total loss 0.308263749\n",
      "Trained batch 1200 batch loss 0.293235749 epoch total loss 0.308251232\n",
      "Trained batch 1201 batch loss 0.297058523 epoch total loss 0.308241934\n",
      "Trained batch 1202 batch loss 0.290215492 epoch total loss 0.308226943\n",
      "Trained batch 1203 batch loss 0.295563072 epoch total loss 0.308216393\n",
      "Trained batch 1204 batch loss 0.292419851 epoch total loss 0.30820328\n",
      "Trained batch 1205 batch loss 0.305941284 epoch total loss 0.308201402\n",
      "Trained batch 1206 batch loss 0.323106855 epoch total loss 0.30821377\n",
      "Trained batch 1207 batch loss 0.329178363 epoch total loss 0.308231145\n",
      "Trained batch 1208 batch loss 0.317100644 epoch total loss 0.308238506\n",
      "Trained batch 1209 batch loss 0.308585972 epoch total loss 0.308238804\n",
      "Trained batch 1210 batch loss 0.308241129 epoch total loss 0.308238775\n",
      "Trained batch 1211 batch loss 0.298229426 epoch total loss 0.308230519\n",
      "Trained batch 1212 batch loss 0.310797602 epoch total loss 0.308232635\n",
      "Trained batch 1213 batch loss 0.302069306 epoch total loss 0.308227539\n",
      "Trained batch 1214 batch loss 0.318475604 epoch total loss 0.308235973\n",
      "Trained batch 1215 batch loss 0.289795786 epoch total loss 0.308220804\n",
      "Trained batch 1216 batch loss 0.291576117 epoch total loss 0.308207124\n",
      "Trained batch 1217 batch loss 0.301787615 epoch total loss 0.308201849\n",
      "Trained batch 1218 batch loss 0.279701442 epoch total loss 0.308178425\n",
      "Trained batch 1219 batch loss 0.285815269 epoch total loss 0.308160096\n",
      "Trained batch 1220 batch loss 0.327096075 epoch total loss 0.308175623\n",
      "Trained batch 1221 batch loss 0.291003346 epoch total loss 0.308161557\n",
      "Trained batch 1222 batch loss 0.297834963 epoch total loss 0.308153093\n",
      "Trained batch 1223 batch loss 0.304113299 epoch total loss 0.308149785\n",
      "Trained batch 1224 batch loss 0.307106793 epoch total loss 0.308148921\n",
      "Trained batch 1225 batch loss 0.341440499 epoch total loss 0.3081761\n",
      "Trained batch 1226 batch loss 0.324700177 epoch total loss 0.308189571\n",
      "Trained batch 1227 batch loss 0.338672549 epoch total loss 0.308214426\n",
      "Trained batch 1228 batch loss 0.337138265 epoch total loss 0.30823797\n",
      "Trained batch 1229 batch loss 0.307578683 epoch total loss 0.308237433\n",
      "Trained batch 1230 batch loss 0.309110731 epoch total loss 0.308238149\n",
      "Trained batch 1231 batch loss 0.285856545 epoch total loss 0.308219969\n",
      "Trained batch 1232 batch loss 0.288550198 epoch total loss 0.308204\n",
      "Trained batch 1233 batch loss 0.281262964 epoch total loss 0.30818215\n",
      "Trained batch 1234 batch loss 0.268898547 epoch total loss 0.308150291\n",
      "Trained batch 1235 batch loss 0.304406375 epoch total loss 0.308147281\n",
      "Trained batch 1236 batch loss 0.281709045 epoch total loss 0.308125883\n",
      "Trained batch 1237 batch loss 0.310429722 epoch total loss 0.308127761\n",
      "Trained batch 1238 batch loss 0.312723488 epoch total loss 0.308131456\n",
      "Trained batch 1239 batch loss 0.317835689 epoch total loss 0.308139294\n",
      "Trained batch 1240 batch loss 0.289413691 epoch total loss 0.308124185\n",
      "Trained batch 1241 batch loss 0.291798353 epoch total loss 0.308111042\n",
      "Trained batch 1242 batch loss 0.294840693 epoch total loss 0.308100373\n",
      "Trained batch 1243 batch loss 0.271628588 epoch total loss 0.308071017\n",
      "Trained batch 1244 batch loss 0.282717735 epoch total loss 0.308050632\n",
      "Trained batch 1245 batch loss 0.297778457 epoch total loss 0.308042407\n",
      "Trained batch 1246 batch loss 0.300306559 epoch total loss 0.308036178\n",
      "Trained batch 1247 batch loss 0.298921615 epoch total loss 0.308028877\n",
      "Trained batch 1248 batch loss 0.285089761 epoch total loss 0.308010489\n",
      "Trained batch 1249 batch loss 0.291499853 epoch total loss 0.307997286\n",
      "Trained batch 1250 batch loss 0.284172028 epoch total loss 0.307978213\n",
      "Trained batch 1251 batch loss 0.31544441 epoch total loss 0.307984173\n",
      "Trained batch 1252 batch loss 0.276750416 epoch total loss 0.307959229\n",
      "Trained batch 1253 batch loss 0.29002744 epoch total loss 0.307944953\n",
      "Trained batch 1254 batch loss 0.279825538 epoch total loss 0.307922512\n",
      "Trained batch 1255 batch loss 0.287334204 epoch total loss 0.307906091\n",
      "Trained batch 1256 batch loss 0.323415 epoch total loss 0.307918459\n",
      "Trained batch 1257 batch loss 0.302871764 epoch total loss 0.307914436\n",
      "Trained batch 1258 batch loss 0.320563525 epoch total loss 0.307924509\n",
      "Trained batch 1259 batch loss 0.316677272 epoch total loss 0.307931453\n",
      "Trained batch 1260 batch loss 0.28281489 epoch total loss 0.307911515\n",
      "Trained batch 1261 batch loss 0.31513688 epoch total loss 0.307917237\n",
      "Trained batch 1262 batch loss 0.29034242 epoch total loss 0.30790332\n",
      "Trained batch 1263 batch loss 0.298540056 epoch total loss 0.307895899\n",
      "Trained batch 1264 batch loss 0.292406708 epoch total loss 0.30788365\n",
      "Trained batch 1265 batch loss 0.283410102 epoch total loss 0.307864308\n",
      "Trained batch 1266 batch loss 0.282615453 epoch total loss 0.307844371\n",
      "Trained batch 1267 batch loss 0.348103017 epoch total loss 0.30787617\n",
      "Trained batch 1268 batch loss 0.290166199 epoch total loss 0.307862192\n",
      "Trained batch 1269 batch loss 0.337876618 epoch total loss 0.307885855\n",
      "Trained batch 1270 batch loss 0.328474492 epoch total loss 0.307902068\n",
      "Trained batch 1271 batch loss 0.314039379 epoch total loss 0.307906866\n",
      "Trained batch 1272 batch loss 0.30881232 epoch total loss 0.307907581\n",
      "Trained batch 1273 batch loss 0.320542485 epoch total loss 0.307917535\n",
      "Trained batch 1274 batch loss 0.306132019 epoch total loss 0.307916105\n",
      "Trained batch 1275 batch loss 0.335547119 epoch total loss 0.307937771\n",
      "Trained batch 1276 batch loss 0.317982405 epoch total loss 0.307945669\n",
      "Trained batch 1277 batch loss 0.301374376 epoch total loss 0.307940513\n",
      "Trained batch 1278 batch loss 0.264739066 epoch total loss 0.307906687\n",
      "Trained batch 1279 batch loss 0.277577609 epoch total loss 0.307883\n",
      "Trained batch 1280 batch loss 0.295848072 epoch total loss 0.307873577\n",
      "Trained batch 1281 batch loss 0.305933982 epoch total loss 0.307872087\n",
      "Trained batch 1282 batch loss 0.282094479 epoch total loss 0.30785197\n",
      "Trained batch 1283 batch loss 0.231551677 epoch total loss 0.307792485\n",
      "Trained batch 1284 batch loss 0.250033766 epoch total loss 0.307747513\n",
      "Trained batch 1285 batch loss 0.304509073 epoch total loss 0.30774498\n",
      "Trained batch 1286 batch loss 0.289910883 epoch total loss 0.307731122\n",
      "Trained batch 1287 batch loss 0.314829469 epoch total loss 0.307736635\n",
      "Trained batch 1288 batch loss 0.312888354 epoch total loss 0.307740629\n",
      "Trained batch 1289 batch loss 0.305995464 epoch total loss 0.307739288\n",
      "Trained batch 1290 batch loss 0.284524679 epoch total loss 0.307721287\n",
      "Trained batch 1291 batch loss 0.279972225 epoch total loss 0.30769977\n",
      "Trained batch 1292 batch loss 0.297235072 epoch total loss 0.307691693\n",
      "Trained batch 1293 batch loss 0.304872721 epoch total loss 0.307689518\n",
      "Trained batch 1294 batch loss 0.31356889 epoch total loss 0.307694048\n",
      "Trained batch 1295 batch loss 0.309540153 epoch total loss 0.307695478\n",
      "Trained batch 1296 batch loss 0.349499792 epoch total loss 0.307727724\n",
      "Trained batch 1297 batch loss 0.31212768 epoch total loss 0.307731122\n",
      "Trained batch 1298 batch loss 0.309218407 epoch total loss 0.307732254\n",
      "Trained batch 1299 batch loss 0.318746865 epoch total loss 0.307740748\n",
      "Trained batch 1300 batch loss 0.278141201 epoch total loss 0.307717979\n",
      "Trained batch 1301 batch loss 0.272071183 epoch total loss 0.307690561\n",
      "Trained batch 1302 batch loss 0.300942659 epoch total loss 0.307685375\n",
      "Trained batch 1303 batch loss 0.301112354 epoch total loss 0.307680339\n",
      "Trained batch 1304 batch loss 0.280229539 epoch total loss 0.307659298\n",
      "Trained batch 1305 batch loss 0.313108563 epoch total loss 0.307663471\n",
      "Trained batch 1306 batch loss 0.285602599 epoch total loss 0.307646573\n",
      "Trained batch 1307 batch loss 0.263115495 epoch total loss 0.307612509\n",
      "Trained batch 1308 batch loss 0.264735 epoch total loss 0.307579726\n",
      "Trained batch 1309 batch loss 0.285895199 epoch total loss 0.307563156\n",
      "Trained batch 1310 batch loss 0.283744574 epoch total loss 0.307545\n",
      "Trained batch 1311 batch loss 0.26261133 epoch total loss 0.307510704\n",
      "Trained batch 1312 batch loss 0.271979272 epoch total loss 0.307483613\n",
      "Trained batch 1313 batch loss 0.268225104 epoch total loss 0.307453722\n",
      "Trained batch 1314 batch loss 0.262995303 epoch total loss 0.307419896\n",
      "Trained batch 1315 batch loss 0.381821036 epoch total loss 0.307476491\n",
      "Trained batch 1316 batch loss 0.293889642 epoch total loss 0.307466149\n",
      "Trained batch 1317 batch loss 0.287077278 epoch total loss 0.307450682\n",
      "Trained batch 1318 batch loss 0.288679779 epoch total loss 0.307436407\n",
      "Trained batch 1319 batch loss 0.284501612 epoch total loss 0.307419032\n",
      "Trained batch 1320 batch loss 0.30144307 epoch total loss 0.307414532\n",
      "Trained batch 1321 batch loss 0.293559313 epoch total loss 0.307404041\n",
      "Trained batch 1322 batch loss 0.321434855 epoch total loss 0.307414651\n",
      "Trained batch 1323 batch loss 0.303019643 epoch total loss 0.307411313\n",
      "Trained batch 1324 batch loss 0.283738017 epoch total loss 0.307393432\n",
      "Trained batch 1325 batch loss 0.35019365 epoch total loss 0.307425737\n",
      "Trained batch 1326 batch loss 0.359257579 epoch total loss 0.307464838\n",
      "Trained batch 1327 batch loss 0.304103553 epoch total loss 0.307462305\n",
      "Trained batch 1328 batch loss 0.334474444 epoch total loss 0.30748263\n",
      "Trained batch 1329 batch loss 0.287150323 epoch total loss 0.307467341\n",
      "Trained batch 1330 batch loss 0.313434362 epoch total loss 0.307471842\n",
      "Trained batch 1331 batch loss 0.274809301 epoch total loss 0.307447284\n",
      "Trained batch 1332 batch loss 0.303066075 epoch total loss 0.307444\n",
      "Trained batch 1333 batch loss 0.305524856 epoch total loss 0.307442546\n",
      "Trained batch 1334 batch loss 0.291644275 epoch total loss 0.307430714\n",
      "Trained batch 1335 batch loss 0.293569177 epoch total loss 0.307420343\n",
      "Trained batch 1336 batch loss 0.263329893 epoch total loss 0.307387352\n",
      "Trained batch 1337 batch loss 0.249075502 epoch total loss 0.307343751\n",
      "Trained batch 1338 batch loss 0.269437224 epoch total loss 0.307315409\n",
      "Trained batch 1339 batch loss 0.338555455 epoch total loss 0.307338744\n",
      "Trained batch 1340 batch loss 0.385145485 epoch total loss 0.307396799\n",
      "Trained batch 1341 batch loss 0.363739729 epoch total loss 0.307438821\n",
      "Trained batch 1342 batch loss 0.339405924 epoch total loss 0.307462633\n",
      "Trained batch 1343 batch loss 0.323889554 epoch total loss 0.307474881\n",
      "Trained batch 1344 batch loss 0.345696807 epoch total loss 0.307503313\n",
      "Trained batch 1345 batch loss 0.267636627 epoch total loss 0.307473689\n",
      "Trained batch 1346 batch loss 0.257057697 epoch total loss 0.307436228\n",
      "Trained batch 1347 batch loss 0.264674813 epoch total loss 0.307404459\n",
      "Trained batch 1348 batch loss 0.28910476 epoch total loss 0.307390898\n",
      "Trained batch 1349 batch loss 0.344688892 epoch total loss 0.307418555\n",
      "Trained batch 1350 batch loss 0.375566602 epoch total loss 0.30746904\n",
      "Trained batch 1351 batch loss 0.297131866 epoch total loss 0.307461381\n",
      "Trained batch 1352 batch loss 0.31559974 epoch total loss 0.307467401\n",
      "Trained batch 1353 batch loss 0.317624897 epoch total loss 0.307474911\n",
      "Trained batch 1354 batch loss 0.309683591 epoch total loss 0.30747655\n",
      "Trained batch 1355 batch loss 0.313574404 epoch total loss 0.30748105\n",
      "Trained batch 1356 batch loss 0.313064933 epoch total loss 0.307485163\n",
      "Trained batch 1357 batch loss 0.30019486 epoch total loss 0.307479799\n",
      "Trained batch 1358 batch loss 0.326295853 epoch total loss 0.307493657\n",
      "Trained batch 1359 batch loss 0.323143721 epoch total loss 0.30750519\n",
      "Trained batch 1360 batch loss 0.299456418 epoch total loss 0.30749926\n",
      "Trained batch 1361 batch loss 0.298143804 epoch total loss 0.307492405\n",
      "Trained batch 1362 batch loss 0.276128083 epoch total loss 0.307469368\n",
      "Trained batch 1363 batch loss 0.300812632 epoch total loss 0.30746448\n",
      "Trained batch 1364 batch loss 0.298484236 epoch total loss 0.307457924\n",
      "Trained batch 1365 batch loss 0.283555627 epoch total loss 0.3074404\n",
      "Trained batch 1366 batch loss 0.255921245 epoch total loss 0.3074027\n",
      "Trained batch 1367 batch loss 0.32363373 epoch total loss 0.307414562\n",
      "Trained batch 1368 batch loss 0.291340649 epoch total loss 0.307402819\n",
      "Trained batch 1369 batch loss 0.303027 epoch total loss 0.307399631\n",
      "Trained batch 1370 batch loss 0.291201651 epoch total loss 0.307387829\n",
      "Trained batch 1371 batch loss 0.295313716 epoch total loss 0.307379\n",
      "Trained batch 1372 batch loss 0.286041945 epoch total loss 0.307363451\n",
      "Trained batch 1373 batch loss 0.307577282 epoch total loss 0.307363629\n",
      "Trained batch 1374 batch loss 0.316788346 epoch total loss 0.307370484\n",
      "Trained batch 1375 batch loss 0.300997972 epoch total loss 0.307365865\n",
      "Trained batch 1376 batch loss 0.355428 epoch total loss 0.307400793\n",
      "Trained batch 1377 batch loss 0.309439391 epoch total loss 0.307402283\n",
      "Trained batch 1378 batch loss 0.325683087 epoch total loss 0.307415545\n",
      "Trained batch 1379 batch loss 0.315090775 epoch total loss 0.307421118\n",
      "Trained batch 1380 batch loss 0.302137882 epoch total loss 0.307417274\n",
      "Trained batch 1381 batch loss 0.297628045 epoch total loss 0.307410181\n",
      "Trained batch 1382 batch loss 0.310052752 epoch total loss 0.307412118\n",
      "Trained batch 1383 batch loss 0.302520722 epoch total loss 0.307408571\n",
      "Trained batch 1384 batch loss 0.299977928 epoch total loss 0.307403207\n",
      "Trained batch 1385 batch loss 0.302283496 epoch total loss 0.307399511\n",
      "Trained batch 1386 batch loss 0.317283958 epoch total loss 0.307406634\n",
      "Trained batch 1387 batch loss 0.29164356 epoch total loss 0.307395279\n",
      "Trained batch 1388 batch loss 0.313175797 epoch total loss 0.307399452\n",
      "Epoch 2 train loss 0.3073994517326355\n",
      "Validated batch 1 batch loss 0.317097604\n",
      "Validated batch 2 batch loss 0.285598874\n",
      "Validated batch 3 batch loss 0.308410347\n",
      "Validated batch 4 batch loss 0.297088385\n",
      "Validated batch 5 batch loss 0.31346643\n",
      "Validated batch 6 batch loss 0.316277\n",
      "Validated batch 7 batch loss 0.309461743\n",
      "Validated batch 8 batch loss 0.344366\n",
      "Validated batch 9 batch loss 0.328768343\n",
      "Validated batch 10 batch loss 0.300909609\n",
      "Validated batch 11 batch loss 0.32034263\n",
      "Validated batch 12 batch loss 0.331089735\n",
      "Validated batch 13 batch loss 0.318531036\n",
      "Validated batch 14 batch loss 0.323559225\n",
      "Validated batch 15 batch loss 0.313120276\n",
      "Validated batch 16 batch loss 0.328244567\n",
      "Validated batch 17 batch loss 0.310739517\n",
      "Validated batch 18 batch loss 0.275267035\n",
      "Validated batch 19 batch loss 0.303400457\n",
      "Validated batch 20 batch loss 0.333006173\n",
      "Validated batch 21 batch loss 0.313425\n",
      "Validated batch 22 batch loss 0.317451119\n",
      "Validated batch 23 batch loss 0.304050177\n",
      "Validated batch 24 batch loss 0.30374378\n",
      "Validated batch 25 batch loss 0.321854532\n",
      "Validated batch 26 batch loss 0.300681829\n",
      "Validated batch 27 batch loss 0.307017833\n",
      "Validated batch 28 batch loss 0.314805239\n",
      "Validated batch 29 batch loss 0.31453225\n",
      "Validated batch 30 batch loss 0.332286209\n",
      "Validated batch 31 batch loss 0.32217443\n",
      "Validated batch 32 batch loss 0.329313278\n",
      "Validated batch 33 batch loss 0.302154213\n",
      "Validated batch 34 batch loss 0.342790455\n",
      "Validated batch 35 batch loss 0.310752928\n",
      "Validated batch 36 batch loss 0.306329787\n",
      "Validated batch 37 batch loss 0.335114539\n",
      "Validated batch 38 batch loss 0.331105381\n",
      "Validated batch 39 batch loss 0.304323763\n",
      "Validated batch 40 batch loss 0.351478845\n",
      "Validated batch 41 batch loss 0.266081035\n",
      "Validated batch 42 batch loss 0.328602463\n",
      "Validated batch 43 batch loss 0.273371607\n",
      "Validated batch 44 batch loss 0.300468832\n",
      "Validated batch 45 batch loss 0.330750316\n",
      "Validated batch 46 batch loss 0.296683848\n",
      "Validated batch 47 batch loss 0.312381685\n",
      "Validated batch 48 batch loss 0.28733778\n",
      "Validated batch 49 batch loss 0.295057207\n",
      "Validated batch 50 batch loss 0.283422649\n",
      "Validated batch 51 batch loss 0.306071192\n",
      "Validated batch 52 batch loss 0.319925696\n",
      "Validated batch 53 batch loss 0.313162088\n",
      "Validated batch 54 batch loss 0.295644373\n",
      "Validated batch 55 batch loss 0.306499243\n",
      "Validated batch 56 batch loss 0.311178714\n",
      "Validated batch 57 batch loss 0.301490128\n",
      "Validated batch 58 batch loss 0.328674436\n",
      "Validated batch 59 batch loss 0.2937392\n",
      "Validated batch 60 batch loss 0.299309731\n",
      "Validated batch 61 batch loss 0.316582561\n",
      "Validated batch 62 batch loss 0.301980346\n",
      "Validated batch 63 batch loss 0.338540018\n",
      "Validated batch 64 batch loss 0.317125648\n",
      "Validated batch 65 batch loss 0.282433033\n",
      "Validated batch 66 batch loss 0.330061018\n",
      "Validated batch 67 batch loss 0.304639339\n",
      "Validated batch 68 batch loss 0.306940287\n",
      "Validated batch 69 batch loss 0.315897375\n",
      "Validated batch 70 batch loss 0.346551895\n",
      "Validated batch 71 batch loss 0.323687822\n",
      "Validated batch 72 batch loss 0.309292704\n",
      "Validated batch 73 batch loss 0.314284742\n",
      "Validated batch 74 batch loss 0.290165603\n",
      "Validated batch 75 batch loss 0.331936479\n",
      "Validated batch 76 batch loss 0.31152004\n",
      "Validated batch 77 batch loss 0.280524135\n",
      "Validated batch 78 batch loss 0.298208416\n",
      "Validated batch 79 batch loss 0.313195199\n",
      "Validated batch 80 batch loss 0.317668974\n",
      "Validated batch 81 batch loss 0.331910223\n",
      "Validated batch 82 batch loss 0.304216921\n",
      "Validated batch 83 batch loss 0.293513775\n",
      "Validated batch 84 batch loss 0.299319297\n",
      "Validated batch 85 batch loss 0.32650739\n",
      "Validated batch 86 batch loss 0.318541795\n",
      "Validated batch 87 batch loss 0.308261037\n",
      "Validated batch 88 batch loss 0.324234366\n",
      "Validated batch 89 batch loss 0.379802585\n",
      "Validated batch 90 batch loss 0.336513668\n",
      "Validated batch 91 batch loss 0.313441366\n",
      "Validated batch 92 batch loss 0.290425718\n",
      "Validated batch 93 batch loss 0.300119251\n",
      "Validated batch 94 batch loss 0.329022676\n",
      "Validated batch 95 batch loss 0.297931463\n",
      "Validated batch 96 batch loss 0.296923637\n",
      "Validated batch 97 batch loss 0.311916679\n",
      "Validated batch 98 batch loss 0.299494624\n",
      "Validated batch 99 batch loss 0.294660658\n",
      "Validated batch 100 batch loss 0.304021865\n",
      "Validated batch 101 batch loss 0.287178159\n",
      "Validated batch 102 batch loss 0.329066753\n",
      "Validated batch 103 batch loss 0.296700716\n",
      "Validated batch 104 batch loss 0.278463066\n",
      "Validated batch 105 batch loss 0.296020269\n",
      "Validated batch 106 batch loss 0.328038692\n",
      "Validated batch 107 batch loss 0.329232812\n",
      "Validated batch 108 batch loss 0.348201722\n",
      "Validated batch 109 batch loss 0.30354\n",
      "Validated batch 110 batch loss 0.338087738\n",
      "Validated batch 111 batch loss 0.309813231\n",
      "Validated batch 112 batch loss 0.31844008\n",
      "Validated batch 113 batch loss 0.313485593\n",
      "Validated batch 114 batch loss 0.253703892\n",
      "Validated batch 115 batch loss 0.314592332\n",
      "Validated batch 116 batch loss 0.32500726\n",
      "Validated batch 117 batch loss 0.326152593\n",
      "Validated batch 118 batch loss 0.317985833\n",
      "Validated batch 119 batch loss 0.317566633\n",
      "Validated batch 120 batch loss 0.318155825\n",
      "Validated batch 121 batch loss 0.35284248\n",
      "Validated batch 122 batch loss 0.314417779\n",
      "Validated batch 123 batch loss 0.336030215\n",
      "Validated batch 124 batch loss 0.3125709\n",
      "Validated batch 125 batch loss 0.322595775\n",
      "Validated batch 126 batch loss 0.317667156\n",
      "Validated batch 127 batch loss 0.299093962\n",
      "Validated batch 128 batch loss 0.326151729\n",
      "Validated batch 129 batch loss 0.325516701\n",
      "Validated batch 130 batch loss 0.334989637\n",
      "Validated batch 131 batch loss 0.313423693\n",
      "Validated batch 132 batch loss 0.325325161\n",
      "Validated batch 133 batch loss 0.291543514\n",
      "Validated batch 134 batch loss 0.298495859\n",
      "Validated batch 135 batch loss 0.326071978\n",
      "Validated batch 136 batch loss 0.293032289\n",
      "Validated batch 137 batch loss 0.325102568\n",
      "Validated batch 138 batch loss 0.314232975\n",
      "Validated batch 139 batch loss 0.311895609\n",
      "Validated batch 140 batch loss 0.300056815\n",
      "Validated batch 141 batch loss 0.312800437\n",
      "Validated batch 142 batch loss 0.312951952\n",
      "Validated batch 143 batch loss 0.319800615\n",
      "Validated batch 144 batch loss 0.356872559\n",
      "Validated batch 145 batch loss 0.298104346\n",
      "Validated batch 146 batch loss 0.323600918\n",
      "Validated batch 147 batch loss 0.301581323\n",
      "Validated batch 148 batch loss 0.324427456\n",
      "Validated batch 149 batch loss 0.31850791\n",
      "Validated batch 150 batch loss 0.300443023\n",
      "Validated batch 151 batch loss 0.250669628\n",
      "Validated batch 152 batch loss 0.312733859\n",
      "Validated batch 153 batch loss 0.305070966\n",
      "Validated batch 154 batch loss 0.316255897\n",
      "Validated batch 155 batch loss 0.323442161\n",
      "Validated batch 156 batch loss 0.29016158\n",
      "Validated batch 157 batch loss 0.313290745\n",
      "Validated batch 158 batch loss 0.349699914\n",
      "Validated batch 159 batch loss 0.327816427\n",
      "Validated batch 160 batch loss 0.315444022\n",
      "Validated batch 161 batch loss 0.283786565\n",
      "Validated batch 162 batch loss 0.298703074\n",
      "Validated batch 163 batch loss 0.3079606\n",
      "Validated batch 164 batch loss 0.313818842\n",
      "Validated batch 165 batch loss 0.269760609\n",
      "Validated batch 166 batch loss 0.29777959\n",
      "Validated batch 167 batch loss 0.333685905\n",
      "Validated batch 168 batch loss 0.278936744\n",
      "Validated batch 169 batch loss 0.285508633\n",
      "Validated batch 170 batch loss 0.288822114\n",
      "Validated batch 171 batch loss 0.310968757\n",
      "Validated batch 172 batch loss 0.293105662\n",
      "Validated batch 173 batch loss 0.320401579\n",
      "Validated batch 174 batch loss 0.271474183\n",
      "Validated batch 175 batch loss 0.313841373\n",
      "Validated batch 176 batch loss 0.332995832\n",
      "Validated batch 177 batch loss 0.348927706\n",
      "Validated batch 178 batch loss 0.304903686\n",
      "Validated batch 179 batch loss 0.335391939\n",
      "Validated batch 180 batch loss 0.276272923\n",
      "Validated batch 181 batch loss 0.283456683\n",
      "Validated batch 182 batch loss 0.311503112\n",
      "Validated batch 183 batch loss 0.302967608\n",
      "Validated batch 184 batch loss 0.328823388\n",
      "Validated batch 185 batch loss 0.349571764\n",
      "Epoch 2 val loss 0.31196510791778564\n",
      "Model /aiffel/aiffel/mpii/models2/model-epoch-2-loss-0.3120.h5 saved.\n",
      "Start epoch 3 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.315878659 epoch total loss 0.315878659\n",
      "Trained batch 2 batch loss 0.323815674 epoch total loss 0.319847167\n",
      "Trained batch 3 batch loss 0.31348 epoch total loss 0.317724794\n",
      "Trained batch 4 batch loss 0.314086705 epoch total loss 0.316815257\n",
      "Trained batch 5 batch loss 0.317715198 epoch total loss 0.316995233\n",
      "Trained batch 6 batch loss 0.308829933 epoch total loss 0.31563434\n",
      "Trained batch 7 batch loss 0.308956504 epoch total loss 0.314680368\n",
      "Trained batch 8 batch loss 0.27837044 epoch total loss 0.310141623\n",
      "Trained batch 9 batch loss 0.294658691 epoch total loss 0.308421284\n",
      "Trained batch 10 batch loss 0.325855374 epoch total loss 0.31016469\n",
      "Trained batch 11 batch loss 0.337627888 epoch total loss 0.31266135\n",
      "Trained batch 12 batch loss 0.299639255 epoch total loss 0.311576158\n",
      "Trained batch 13 batch loss 0.300697833 epoch total loss 0.310739368\n",
      "Trained batch 14 batch loss 0.313205302 epoch total loss 0.3109155\n",
      "Trained batch 15 batch loss 0.27391234 epoch total loss 0.308448642\n",
      "Trained batch 16 batch loss 0.324767381 epoch total loss 0.309468567\n",
      "Trained batch 17 batch loss 0.333606 epoch total loss 0.31088841\n",
      "Trained batch 18 batch loss 0.331443399 epoch total loss 0.312030345\n",
      "Trained batch 19 batch loss 0.293942362 epoch total loss 0.31107834\n",
      "Trained batch 20 batch loss 0.27442944 epoch total loss 0.309245884\n",
      "Trained batch 21 batch loss 0.249161571 epoch total loss 0.306384742\n",
      "Trained batch 22 batch loss 0.27749002 epoch total loss 0.305071354\n",
      "Trained batch 23 batch loss 0.276056796 epoch total loss 0.303809851\n",
      "Trained batch 24 batch loss 0.279351145 epoch total loss 0.302790731\n",
      "Trained batch 25 batch loss 0.31072408 epoch total loss 0.303108096\n",
      "Trained batch 26 batch loss 0.321662664 epoch total loss 0.303821713\n",
      "Trained batch 27 batch loss 0.277571112 epoch total loss 0.302849442\n",
      "Trained batch 28 batch loss 0.301351488 epoch total loss 0.302795947\n",
      "Trained batch 29 batch loss 0.282755375 epoch total loss 0.30210489\n",
      "Trained batch 30 batch loss 0.265877932 epoch total loss 0.3008973\n",
      "Trained batch 31 batch loss 0.285295784 epoch total loss 0.300394028\n",
      "Trained batch 32 batch loss 0.298090398 epoch total loss 0.300322026\n",
      "Trained batch 33 batch loss 0.300061 epoch total loss 0.300314128\n",
      "Trained batch 34 batch loss 0.28904736 epoch total loss 0.299982756\n",
      "Trained batch 35 batch loss 0.2553657 epoch total loss 0.298707962\n",
      "Trained batch 36 batch loss 0.30761072 epoch total loss 0.298955262\n",
      "Trained batch 37 batch loss 0.352182508 epoch total loss 0.30039382\n",
      "Trained batch 38 batch loss 0.277541786 epoch total loss 0.299792469\n",
      "Trained batch 39 batch loss 0.309768379 epoch total loss 0.300048262\n",
      "Trained batch 40 batch loss 0.247669742 epoch total loss 0.298738807\n",
      "Trained batch 41 batch loss 0.244074985 epoch total loss 0.297405541\n",
      "Trained batch 42 batch loss 0.206434414 epoch total loss 0.295239568\n",
      "Trained batch 43 batch loss 0.24985157 epoch total loss 0.294184029\n",
      "Trained batch 44 batch loss 0.302206755 epoch total loss 0.29436636\n",
      "Trained batch 45 batch loss 0.294961125 epoch total loss 0.294379562\n",
      "Trained batch 46 batch loss 0.262577832 epoch total loss 0.293688238\n",
      "Trained batch 47 batch loss 0.263407856 epoch total loss 0.293043971\n",
      "Trained batch 48 batch loss 0.24479264 epoch total loss 0.292038739\n",
      "Trained batch 49 batch loss 0.317388594 epoch total loss 0.292556077\n",
      "Trained batch 50 batch loss 0.348962367 epoch total loss 0.293684214\n",
      "Trained batch 51 batch loss 0.296616167 epoch total loss 0.293741703\n",
      "Trained batch 52 batch loss 0.281921893 epoch total loss 0.293514431\n",
      "Trained batch 53 batch loss 0.297104061 epoch total loss 0.293582141\n",
      "Trained batch 54 batch loss 0.29367736 epoch total loss 0.2935839\n",
      "Trained batch 55 batch loss 0.275877804 epoch total loss 0.293261975\n",
      "Trained batch 56 batch loss 0.266913891 epoch total loss 0.292791456\n",
      "Trained batch 57 batch loss 0.293109 epoch total loss 0.292797059\n",
      "Trained batch 58 batch loss 0.306682855 epoch total loss 0.293036461\n",
      "Trained batch 59 batch loss 0.289397717 epoch total loss 0.2929748\n",
      "Trained batch 60 batch loss 0.299907476 epoch total loss 0.293090343\n",
      "Trained batch 61 batch loss 0.304904938 epoch total loss 0.293284029\n",
      "Trained batch 62 batch loss 0.265346169 epoch total loss 0.292833418\n",
      "Trained batch 63 batch loss 0.262223929 epoch total loss 0.29234755\n",
      "Trained batch 64 batch loss 0.291870624 epoch total loss 0.2923401\n",
      "Trained batch 65 batch loss 0.301305234 epoch total loss 0.292478025\n",
      "Trained batch 66 batch loss 0.29915902 epoch total loss 0.292579234\n",
      "Trained batch 67 batch loss 0.287557 epoch total loss 0.292504311\n",
      "Trained batch 68 batch loss 0.299114287 epoch total loss 0.292601496\n",
      "Trained batch 69 batch loss 0.27091825 epoch total loss 0.29228726\n",
      "Trained batch 70 batch loss 0.2529217 epoch total loss 0.29172489\n",
      "Trained batch 71 batch loss 0.293512523 epoch total loss 0.291750073\n",
      "Trained batch 72 batch loss 0.299674362 epoch total loss 0.291860133\n",
      "Trained batch 73 batch loss 0.30137226 epoch total loss 0.291990429\n",
      "Trained batch 74 batch loss 0.309986234 epoch total loss 0.292233616\n",
      "Trained batch 75 batch loss 0.291142553 epoch total loss 0.292219073\n",
      "Trained batch 76 batch loss 0.269601405 epoch total loss 0.291921496\n",
      "Trained batch 77 batch loss 0.298498482 epoch total loss 0.29200691\n",
      "Trained batch 78 batch loss 0.30956772 epoch total loss 0.292232037\n",
      "Trained batch 79 batch loss 0.308569342 epoch total loss 0.292438835\n",
      "Trained batch 80 batch loss 0.299776435 epoch total loss 0.292530566\n",
      "Trained batch 81 batch loss 0.286437333 epoch total loss 0.292455345\n",
      "Trained batch 82 batch loss 0.270038784 epoch total loss 0.292181969\n",
      "Trained batch 83 batch loss 0.278305471 epoch total loss 0.292014778\n",
      "Trained batch 84 batch loss 0.30245012 epoch total loss 0.292139\n",
      "Trained batch 85 batch loss 0.293714166 epoch total loss 0.292157531\n",
      "Trained batch 86 batch loss 0.288776338 epoch total loss 0.292118222\n",
      "Trained batch 87 batch loss 0.292915106 epoch total loss 0.292127401\n",
      "Trained batch 88 batch loss 0.266763568 epoch total loss 0.291839153\n",
      "Trained batch 89 batch loss 0.299366146 epoch total loss 0.291923732\n",
      "Trained batch 90 batch loss 0.291883916 epoch total loss 0.291923285\n",
      "Trained batch 91 batch loss 0.265770078 epoch total loss 0.291635901\n",
      "Trained batch 92 batch loss 0.299463034 epoch total loss 0.291720957\n",
      "Trained batch 93 batch loss 0.268016696 epoch total loss 0.291466087\n",
      "Trained batch 94 batch loss 0.308591813 epoch total loss 0.291648269\n",
      "Trained batch 95 batch loss 0.269545794 epoch total loss 0.291415632\n",
      "Trained batch 96 batch loss 0.288115233 epoch total loss 0.29138124\n",
      "Trained batch 97 batch loss 0.300787449 epoch total loss 0.291478217\n",
      "Trained batch 98 batch loss 0.304201543 epoch total loss 0.291608036\n",
      "Trained batch 99 batch loss 0.279361308 epoch total loss 0.291484326\n",
      "Trained batch 100 batch loss 0.288648695 epoch total loss 0.291455984\n",
      "Trained batch 101 batch loss 0.275979102 epoch total loss 0.291302741\n",
      "Trained batch 102 batch loss 0.275400758 epoch total loss 0.291146845\n",
      "Trained batch 103 batch loss 0.337279886 epoch total loss 0.291594744\n",
      "Trained batch 104 batch loss 0.30685243 epoch total loss 0.291741431\n",
      "Trained batch 105 batch loss 0.270614892 epoch total loss 0.291540235\n",
      "Trained batch 106 batch loss 0.296802491 epoch total loss 0.291589886\n",
      "Trained batch 107 batch loss 0.270118326 epoch total loss 0.291389227\n",
      "Trained batch 108 batch loss 0.284898371 epoch total loss 0.291329116\n",
      "Trained batch 109 batch loss 0.306184232 epoch total loss 0.291465402\n",
      "Trained batch 110 batch loss 0.31570372 epoch total loss 0.29168576\n",
      "Trained batch 111 batch loss 0.305842847 epoch total loss 0.291813314\n",
      "Trained batch 112 batch loss 0.290990561 epoch total loss 0.291805953\n",
      "Trained batch 113 batch loss 0.327148676 epoch total loss 0.292118728\n",
      "Trained batch 114 batch loss 0.294237375 epoch total loss 0.292137325\n",
      "Trained batch 115 batch loss 0.291605085 epoch total loss 0.292132705\n",
      "Trained batch 116 batch loss 0.289052457 epoch total loss 0.292106122\n",
      "Trained batch 117 batch loss 0.268941313 epoch total loss 0.291908145\n",
      "Trained batch 118 batch loss 0.277759701 epoch total loss 0.29178822\n",
      "Trained batch 119 batch loss 0.279673666 epoch total loss 0.291686445\n",
      "Trained batch 120 batch loss 0.292674839 epoch total loss 0.291694671\n",
      "Trained batch 121 batch loss 0.310111761 epoch total loss 0.291846871\n",
      "Trained batch 122 batch loss 0.330359876 epoch total loss 0.292162567\n",
      "Trained batch 123 batch loss 0.328314632 epoch total loss 0.292456508\n",
      "Trained batch 124 batch loss 0.342857301 epoch total loss 0.292862952\n",
      "Trained batch 125 batch loss 0.331729442 epoch total loss 0.293173879\n",
      "Trained batch 126 batch loss 0.307943612 epoch total loss 0.293291122\n",
      "Trained batch 127 batch loss 0.258282065 epoch total loss 0.29301545\n",
      "Trained batch 128 batch loss 0.234010771 epoch total loss 0.292554498\n",
      "Trained batch 129 batch loss 0.244615823 epoch total loss 0.292182893\n",
      "Trained batch 130 batch loss 0.264089584 epoch total loss 0.291966766\n",
      "Trained batch 131 batch loss 0.291442811 epoch total loss 0.291962773\n",
      "Trained batch 132 batch loss 0.304325908 epoch total loss 0.292056441\n",
      "Trained batch 133 batch loss 0.294391632 epoch total loss 0.292074\n",
      "Trained batch 134 batch loss 0.261489958 epoch total loss 0.291845739\n",
      "Trained batch 135 batch loss 0.245575324 epoch total loss 0.291503\n",
      "Trained batch 136 batch loss 0.274858 epoch total loss 0.291380614\n",
      "Trained batch 137 batch loss 0.29394269 epoch total loss 0.2913993\n",
      "Trained batch 138 batch loss 0.311015964 epoch total loss 0.291541457\n",
      "Trained batch 139 batch loss 0.315924406 epoch total loss 0.291716874\n",
      "Trained batch 140 batch loss 0.313533068 epoch total loss 0.29187271\n",
      "Trained batch 141 batch loss 0.307974637 epoch total loss 0.291986912\n",
      "Trained batch 142 batch loss 0.316801906 epoch total loss 0.292161673\n",
      "Trained batch 143 batch loss 0.309501857 epoch total loss 0.292282939\n",
      "Trained batch 144 batch loss 0.270571649 epoch total loss 0.292132169\n",
      "Trained batch 145 batch loss 0.277850568 epoch total loss 0.292033672\n",
      "Trained batch 146 batch loss 0.306752264 epoch total loss 0.292134494\n",
      "Trained batch 147 batch loss 0.301858604 epoch total loss 0.292200625\n",
      "Trained batch 148 batch loss 0.289124727 epoch total loss 0.292179823\n",
      "Trained batch 149 batch loss 0.301224828 epoch total loss 0.29224053\n",
      "Trained batch 150 batch loss 0.292840958 epoch total loss 0.292244524\n",
      "Trained batch 151 batch loss 0.280267954 epoch total loss 0.29216522\n",
      "Trained batch 152 batch loss 0.27766636 epoch total loss 0.292069823\n",
      "Trained batch 153 batch loss 0.228557348 epoch total loss 0.291654736\n",
      "Trained batch 154 batch loss 0.309759676 epoch total loss 0.291772306\n",
      "Trained batch 155 batch loss 0.297765523 epoch total loss 0.29181096\n",
      "Trained batch 156 batch loss 0.329716712 epoch total loss 0.292053938\n",
      "Trained batch 157 batch loss 0.313164949 epoch total loss 0.292188376\n",
      "Trained batch 158 batch loss 0.308138251 epoch total loss 0.292289346\n",
      "Trained batch 159 batch loss 0.277923137 epoch total loss 0.292199\n",
      "Trained batch 160 batch loss 0.274881661 epoch total loss 0.292090774\n",
      "Trained batch 161 batch loss 0.276491076 epoch total loss 0.291993856\n",
      "Trained batch 162 batch loss 0.294706523 epoch total loss 0.292010635\n",
      "Trained batch 163 batch loss 0.277186185 epoch total loss 0.291919678\n",
      "Trained batch 164 batch loss 0.293065965 epoch total loss 0.291926652\n",
      "Trained batch 165 batch loss 0.308267802 epoch total loss 0.292025715\n",
      "Trained batch 166 batch loss 0.330459267 epoch total loss 0.292257249\n",
      "Trained batch 167 batch loss 0.316216022 epoch total loss 0.292400688\n",
      "Trained batch 168 batch loss 0.317332208 epoch total loss 0.292549103\n",
      "Trained batch 169 batch loss 0.324609667 epoch total loss 0.292738795\n",
      "Trained batch 170 batch loss 0.331139296 epoch total loss 0.292964697\n",
      "Trained batch 171 batch loss 0.318096757 epoch total loss 0.293111652\n",
      "Trained batch 172 batch loss 0.347300768 epoch total loss 0.293426722\n",
      "Trained batch 173 batch loss 0.320964 epoch total loss 0.293585896\n",
      "Trained batch 174 batch loss 0.312132865 epoch total loss 0.293692499\n",
      "Trained batch 175 batch loss 0.285632968 epoch total loss 0.293646425\n",
      "Trained batch 176 batch loss 0.310119 epoch total loss 0.293740034\n",
      "Trained batch 177 batch loss 0.307388216 epoch total loss 0.293817133\n",
      "Trained batch 178 batch loss 0.314654142 epoch total loss 0.293934226\n",
      "Trained batch 179 batch loss 0.322012752 epoch total loss 0.294091076\n",
      "Trained batch 180 batch loss 0.283139735 epoch total loss 0.294030219\n",
      "Trained batch 181 batch loss 0.284759313 epoch total loss 0.293979019\n",
      "Trained batch 182 batch loss 0.25595808 epoch total loss 0.293770105\n",
      "Trained batch 183 batch loss 0.273552746 epoch total loss 0.293659627\n",
      "Trained batch 184 batch loss 0.272786528 epoch total loss 0.29354617\n",
      "Trained batch 185 batch loss 0.282525927 epoch total loss 0.293486595\n",
      "Trained batch 186 batch loss 0.285763234 epoch total loss 0.293445081\n",
      "Trained batch 187 batch loss 0.292951465 epoch total loss 0.293442428\n",
      "Trained batch 188 batch loss 0.284134328 epoch total loss 0.293392926\n",
      "Trained batch 189 batch loss 0.297465086 epoch total loss 0.293414474\n",
      "Trained batch 190 batch loss 0.273649216 epoch total loss 0.293310434\n",
      "Trained batch 191 batch loss 0.276910037 epoch total loss 0.293224543\n",
      "Trained batch 192 batch loss 0.300430924 epoch total loss 0.293262094\n",
      "Trained batch 193 batch loss 0.298859209 epoch total loss 0.293291092\n",
      "Trained batch 194 batch loss 0.304360569 epoch total loss 0.293348134\n",
      "Trained batch 195 batch loss 0.287653029 epoch total loss 0.293318927\n",
      "Trained batch 196 batch loss 0.30709213 epoch total loss 0.293389201\n",
      "Trained batch 197 batch loss 0.294796884 epoch total loss 0.293396354\n",
      "Trained batch 198 batch loss 0.249842107 epoch total loss 0.293176383\n",
      "Trained batch 199 batch loss 0.239835754 epoch total loss 0.292908341\n",
      "Trained batch 200 batch loss 0.240826428 epoch total loss 0.292647928\n",
      "Trained batch 201 batch loss 0.27714628 epoch total loss 0.2925708\n",
      "Trained batch 202 batch loss 0.293542832 epoch total loss 0.292575598\n",
      "Trained batch 203 batch loss 0.328396082 epoch total loss 0.292752057\n",
      "Trained batch 204 batch loss 0.297848105 epoch total loss 0.292777032\n",
      "Trained batch 205 batch loss 0.26385957 epoch total loss 0.292635977\n",
      "Trained batch 206 batch loss 0.277536213 epoch total loss 0.292562664\n",
      "Trained batch 207 batch loss 0.301775485 epoch total loss 0.292607188\n",
      "Trained batch 208 batch loss 0.290713161 epoch total loss 0.292598069\n",
      "Trained batch 209 batch loss 0.292062759 epoch total loss 0.292595536\n",
      "Trained batch 210 batch loss 0.302154809 epoch total loss 0.292641044\n",
      "Trained batch 211 batch loss 0.296732068 epoch total loss 0.292660445\n",
      "Trained batch 212 batch loss 0.33550486 epoch total loss 0.292862564\n",
      "Trained batch 213 batch loss 0.312376589 epoch total loss 0.292954177\n",
      "Trained batch 214 batch loss 0.303431273 epoch total loss 0.293003142\n",
      "Trained batch 215 batch loss 0.283771336 epoch total loss 0.292960197\n",
      "Trained batch 216 batch loss 0.252144456 epoch total loss 0.29277122\n",
      "Trained batch 217 batch loss 0.32776463 epoch total loss 0.29293251\n",
      "Trained batch 218 batch loss 0.336170197 epoch total loss 0.293130845\n",
      "Trained batch 219 batch loss 0.323750973 epoch total loss 0.293270648\n",
      "Trained batch 220 batch loss 0.307873905 epoch total loss 0.293337047\n",
      "Trained batch 221 batch loss 0.303996801 epoch total loss 0.293385267\n",
      "Trained batch 222 batch loss 0.344419 epoch total loss 0.293615162\n",
      "Trained batch 223 batch loss 0.327532858 epoch total loss 0.293767244\n",
      "Trained batch 224 batch loss 0.284662873 epoch total loss 0.293726593\n",
      "Trained batch 225 batch loss 0.313371181 epoch total loss 0.293813884\n",
      "Trained batch 226 batch loss 0.294580579 epoch total loss 0.293817282\n",
      "Trained batch 227 batch loss 0.326426595 epoch total loss 0.293960899\n",
      "Trained batch 228 batch loss 0.288574755 epoch total loss 0.293937296\n",
      "Trained batch 229 batch loss 0.311105251 epoch total loss 0.294012249\n",
      "Trained batch 230 batch loss 0.313714504 epoch total loss 0.2940979\n",
      "Trained batch 231 batch loss 0.299156189 epoch total loss 0.294119805\n",
      "Trained batch 232 batch loss 0.314621598 epoch total loss 0.294208169\n",
      "Trained batch 233 batch loss 0.289755195 epoch total loss 0.294189066\n",
      "Trained batch 234 batch loss 0.272393554 epoch total loss 0.294095904\n",
      "Trained batch 235 batch loss 0.24607718 epoch total loss 0.293891579\n",
      "Trained batch 236 batch loss 0.297769785 epoch total loss 0.293908\n",
      "Trained batch 237 batch loss 0.30447188 epoch total loss 0.293952584\n",
      "Trained batch 238 batch loss 0.299790055 epoch total loss 0.293977112\n",
      "Trained batch 239 batch loss 0.284852505 epoch total loss 0.293938935\n",
      "Trained batch 240 batch loss 0.274577588 epoch total loss 0.29385823\n",
      "Trained batch 241 batch loss 0.305970401 epoch total loss 0.293908507\n",
      "Trained batch 242 batch loss 0.318912387 epoch total loss 0.294011801\n",
      "Trained batch 243 batch loss 0.321306765 epoch total loss 0.294124126\n",
      "Trained batch 244 batch loss 0.308433682 epoch total loss 0.294182748\n",
      "Trained batch 245 batch loss 0.308101684 epoch total loss 0.294239581\n",
      "Trained batch 246 batch loss 0.330865264 epoch total loss 0.294388473\n",
      "Trained batch 247 batch loss 0.28902182 epoch total loss 0.294366747\n",
      "Trained batch 248 batch loss 0.31048 epoch total loss 0.294431716\n",
      "Trained batch 249 batch loss 0.318610311 epoch total loss 0.294528812\n",
      "Trained batch 250 batch loss 0.330985308 epoch total loss 0.294674665\n",
      "Trained batch 251 batch loss 0.311283588 epoch total loss 0.294740826\n",
      "Trained batch 252 batch loss 0.320911378 epoch total loss 0.294844687\n",
      "Trained batch 253 batch loss 0.29992041 epoch total loss 0.294864744\n",
      "Trained batch 254 batch loss 0.276278526 epoch total loss 0.294791549\n",
      "Trained batch 255 batch loss 0.328077644 epoch total loss 0.294922084\n",
      "Trained batch 256 batch loss 0.287647694 epoch total loss 0.294893682\n",
      "Trained batch 257 batch loss 0.307956755 epoch total loss 0.294944525\n",
      "Trained batch 258 batch loss 0.293971598 epoch total loss 0.29494074\n",
      "Trained batch 259 batch loss 0.274305165 epoch total loss 0.294861078\n",
      "Trained batch 260 batch loss 0.265984923 epoch total loss 0.29475\n",
      "Trained batch 261 batch loss 0.274000049 epoch total loss 0.294670522\n",
      "Trained batch 262 batch loss 0.324959904 epoch total loss 0.294786125\n",
      "Trained batch 263 batch loss 0.297218 epoch total loss 0.294795364\n",
      "Trained batch 264 batch loss 0.296253026 epoch total loss 0.294800878\n",
      "Trained batch 265 batch loss 0.306076 epoch total loss 0.294843435\n",
      "Trained batch 266 batch loss 0.315362751 epoch total loss 0.294920564\n",
      "Trained batch 267 batch loss 0.291918129 epoch total loss 0.294909298\n",
      "Trained batch 268 batch loss 0.280008554 epoch total loss 0.294853687\n",
      "Trained batch 269 batch loss 0.348431081 epoch total loss 0.295052886\n",
      "Trained batch 270 batch loss 0.333237588 epoch total loss 0.295194298\n",
      "Trained batch 271 batch loss 0.27683109 epoch total loss 0.295126557\n",
      "Trained batch 272 batch loss 0.30515787 epoch total loss 0.295163423\n",
      "Trained batch 273 batch loss 0.313392401 epoch total loss 0.29523021\n",
      "Trained batch 274 batch loss 0.28096962 epoch total loss 0.295178145\n",
      "Trained batch 275 batch loss 0.305084616 epoch total loss 0.295214176\n",
      "Trained batch 276 batch loss 0.297429413 epoch total loss 0.295222223\n",
      "Trained batch 277 batch loss 0.306833446 epoch total loss 0.295264125\n",
      "Trained batch 278 batch loss 0.281584144 epoch total loss 0.295214921\n",
      "Trained batch 279 batch loss 0.309272081 epoch total loss 0.295265317\n",
      "Trained batch 280 batch loss 0.322676122 epoch total loss 0.295363218\n",
      "Trained batch 281 batch loss 0.285709023 epoch total loss 0.295328826\n",
      "Trained batch 282 batch loss 0.327180386 epoch total loss 0.295441777\n",
      "Trained batch 283 batch loss 0.294857591 epoch total loss 0.29543972\n",
      "Trained batch 284 batch loss 0.298057944 epoch total loss 0.295448959\n",
      "Trained batch 285 batch loss 0.316379935 epoch total loss 0.295522392\n",
      "Trained batch 286 batch loss 0.273487926 epoch total loss 0.295445383\n",
      "Trained batch 287 batch loss 0.304596275 epoch total loss 0.295477241\n",
      "Trained batch 288 batch loss 0.302471 epoch total loss 0.29550153\n",
      "Trained batch 289 batch loss 0.284155637 epoch total loss 0.295462281\n",
      "Trained batch 290 batch loss 0.269660264 epoch total loss 0.295373291\n",
      "Trained batch 291 batch loss 0.250238538 epoch total loss 0.295218199\n",
      "Trained batch 292 batch loss 0.280662239 epoch total loss 0.29516834\n",
      "Trained batch 293 batch loss 0.272868365 epoch total loss 0.295092225\n",
      "Trained batch 294 batch loss 0.241886497 epoch total loss 0.294911265\n",
      "Trained batch 295 batch loss 0.269813776 epoch total loss 0.29482618\n",
      "Trained batch 296 batch loss 0.287600338 epoch total loss 0.294801772\n",
      "Trained batch 297 batch loss 0.289236426 epoch total loss 0.294783026\n",
      "Trained batch 298 batch loss 0.292577505 epoch total loss 0.294775635\n",
      "Trained batch 299 batch loss 0.287530661 epoch total loss 0.294751406\n",
      "Trained batch 300 batch loss 0.286195755 epoch total loss 0.294722885\n",
      "Trained batch 301 batch loss 0.315358341 epoch total loss 0.29479143\n",
      "Trained batch 302 batch loss 0.312985539 epoch total loss 0.294851691\n",
      "Trained batch 303 batch loss 0.315293908 epoch total loss 0.294919163\n",
      "Trained batch 304 batch loss 0.285691172 epoch total loss 0.294888794\n",
      "Trained batch 305 batch loss 0.285643518 epoch total loss 0.294858485\n",
      "Trained batch 306 batch loss 0.280874878 epoch total loss 0.294812799\n",
      "Trained batch 307 batch loss 0.255942971 epoch total loss 0.294686198\n",
      "Trained batch 308 batch loss 0.278997183 epoch total loss 0.294635266\n",
      "Trained batch 309 batch loss 0.325540721 epoch total loss 0.294735253\n",
      "Trained batch 310 batch loss 0.340022206 epoch total loss 0.294881344\n",
      "Trained batch 311 batch loss 0.345039904 epoch total loss 0.295042634\n",
      "Trained batch 312 batch loss 0.306820273 epoch total loss 0.295080394\n",
      "Trained batch 313 batch loss 0.317366838 epoch total loss 0.295151591\n",
      "Trained batch 314 batch loss 0.316441923 epoch total loss 0.295219392\n",
      "Trained batch 315 batch loss 0.303884208 epoch total loss 0.295246899\n",
      "Trained batch 316 batch loss 0.292459726 epoch total loss 0.295238078\n",
      "Trained batch 317 batch loss 0.296285927 epoch total loss 0.295241386\n",
      "Trained batch 318 batch loss 0.275266856 epoch total loss 0.295178592\n",
      "Trained batch 319 batch loss 0.297815442 epoch total loss 0.295186847\n",
      "Trained batch 320 batch loss 0.289721608 epoch total loss 0.295169771\n",
      "Trained batch 321 batch loss 0.297109097 epoch total loss 0.295175821\n",
      "Trained batch 322 batch loss 0.279828638 epoch total loss 0.295128167\n",
      "Trained batch 323 batch loss 0.27532348 epoch total loss 0.295066833\n",
      "Trained batch 324 batch loss 0.281300217 epoch total loss 0.295024365\n",
      "Trained batch 325 batch loss 0.272359133 epoch total loss 0.294954628\n",
      "Trained batch 326 batch loss 0.250424325 epoch total loss 0.294818044\n",
      "Trained batch 327 batch loss 0.249517 epoch total loss 0.294679493\n",
      "Trained batch 328 batch loss 0.280076504 epoch total loss 0.294634968\n",
      "Trained batch 329 batch loss 0.269978642 epoch total loss 0.294560045\n",
      "Trained batch 330 batch loss 0.305548757 epoch total loss 0.294593334\n",
      "Trained batch 331 batch loss 0.25997597 epoch total loss 0.294488788\n",
      "Trained batch 332 batch loss 0.25427568 epoch total loss 0.294367641\n",
      "Trained batch 333 batch loss 0.267410755 epoch total loss 0.294286698\n",
      "Trained batch 334 batch loss 0.294544041 epoch total loss 0.294287443\n",
      "Trained batch 335 batch loss 0.307041734 epoch total loss 0.294325531\n",
      "Trained batch 336 batch loss 0.261763573 epoch total loss 0.294228613\n",
      "Trained batch 337 batch loss 0.288263768 epoch total loss 0.294210911\n",
      "Trained batch 338 batch loss 0.255155861 epoch total loss 0.294095367\n",
      "Trained batch 339 batch loss 0.282691777 epoch total loss 0.29406172\n",
      "Trained batch 340 batch loss 0.280448377 epoch total loss 0.294021696\n",
      "Trained batch 341 batch loss 0.308463067 epoch total loss 0.294064045\n",
      "Trained batch 342 batch loss 0.338073075 epoch total loss 0.294192731\n",
      "Trained batch 343 batch loss 0.332073778 epoch total loss 0.294303179\n",
      "Trained batch 344 batch loss 0.317935824 epoch total loss 0.294371873\n",
      "Trained batch 345 batch loss 0.279582202 epoch total loss 0.294329\n",
      "Trained batch 346 batch loss 0.250398189 epoch total loss 0.29420203\n",
      "Trained batch 347 batch loss 0.298182666 epoch total loss 0.294213474\n",
      "Trained batch 348 batch loss 0.28391391 epoch total loss 0.29418388\n",
      "Trained batch 349 batch loss 0.271036476 epoch total loss 0.29411754\n",
      "Trained batch 350 batch loss 0.288147032 epoch total loss 0.294100493\n",
      "Trained batch 351 batch loss 0.291000038 epoch total loss 0.294091672\n",
      "Trained batch 352 batch loss 0.30449602 epoch total loss 0.294121236\n",
      "Trained batch 353 batch loss 0.328669757 epoch total loss 0.294219077\n",
      "Trained batch 354 batch loss 0.298405975 epoch total loss 0.294230908\n",
      "Trained batch 355 batch loss 0.303870559 epoch total loss 0.294258088\n",
      "Trained batch 356 batch loss 0.325057328 epoch total loss 0.294344604\n",
      "Trained batch 357 batch loss 0.318425864 epoch total loss 0.294412047\n",
      "Trained batch 358 batch loss 0.326904327 epoch total loss 0.294502825\n",
      "Trained batch 359 batch loss 0.277146667 epoch total loss 0.294454455\n",
      "Trained batch 360 batch loss 0.277386606 epoch total loss 0.29440707\n",
      "Trained batch 361 batch loss 0.2804856 epoch total loss 0.294368505\n",
      "Trained batch 362 batch loss 0.308399975 epoch total loss 0.294407278\n",
      "Trained batch 363 batch loss 0.309257567 epoch total loss 0.294448167\n",
      "Trained batch 364 batch loss 0.31317535 epoch total loss 0.294499636\n",
      "Trained batch 365 batch loss 0.339957654 epoch total loss 0.29462418\n",
      "Trained batch 366 batch loss 0.320146441 epoch total loss 0.294693917\n",
      "Trained batch 367 batch loss 0.268590361 epoch total loss 0.294622779\n",
      "Trained batch 368 batch loss 0.298507482 epoch total loss 0.294633359\n",
      "Trained batch 369 batch loss 0.324385166 epoch total loss 0.294713974\n",
      "Trained batch 370 batch loss 0.307448268 epoch total loss 0.294748396\n",
      "Trained batch 371 batch loss 0.318819821 epoch total loss 0.294813275\n",
      "Trained batch 372 batch loss 0.323800236 epoch total loss 0.294891179\n",
      "Trained batch 373 batch loss 0.280332744 epoch total loss 0.294852167\n",
      "Trained batch 374 batch loss 0.282263607 epoch total loss 0.294818521\n",
      "Trained batch 375 batch loss 0.257757574 epoch total loss 0.294719696\n",
      "Trained batch 376 batch loss 0.318560779 epoch total loss 0.294783086\n",
      "Trained batch 377 batch loss 0.303170562 epoch total loss 0.294805318\n",
      "Trained batch 378 batch loss 0.290934026 epoch total loss 0.294795096\n",
      "Trained batch 379 batch loss 0.287328899 epoch total loss 0.294775397\n",
      "Trained batch 380 batch loss 0.316479713 epoch total loss 0.294832498\n",
      "Trained batch 381 batch loss 0.323522061 epoch total loss 0.294907808\n",
      "Trained batch 382 batch loss 0.260880053 epoch total loss 0.294818729\n",
      "Trained batch 383 batch loss 0.285550624 epoch total loss 0.294794559\n",
      "Trained batch 384 batch loss 0.327710927 epoch total loss 0.294880271\n",
      "Trained batch 385 batch loss 0.295429796 epoch total loss 0.294881701\n",
      "Trained batch 386 batch loss 0.307462871 epoch total loss 0.294914305\n",
      "Trained batch 387 batch loss 0.301006049 epoch total loss 0.294930041\n",
      "Trained batch 388 batch loss 0.272770196 epoch total loss 0.29487294\n",
      "Trained batch 389 batch loss 0.304757237 epoch total loss 0.294898331\n",
      "Trained batch 390 batch loss 0.278615355 epoch total loss 0.294856608\n",
      "Trained batch 391 batch loss 0.254832596 epoch total loss 0.294754237\n",
      "Trained batch 392 batch loss 0.232872322 epoch total loss 0.294596374\n",
      "Trained batch 393 batch loss 0.247808009 epoch total loss 0.294477314\n",
      "Trained batch 394 batch loss 0.313927531 epoch total loss 0.294526666\n",
      "Trained batch 395 batch loss 0.324211657 epoch total loss 0.294601828\n",
      "Trained batch 396 batch loss 0.334287226 epoch total loss 0.294702053\n",
      "Trained batch 397 batch loss 0.296738327 epoch total loss 0.294707179\n",
      "Trained batch 398 batch loss 0.278058082 epoch total loss 0.294665337\n",
      "Trained batch 399 batch loss 0.309124 epoch total loss 0.294701606\n",
      "Trained batch 400 batch loss 0.308567 epoch total loss 0.294736266\n",
      "Trained batch 401 batch loss 0.310684949 epoch total loss 0.294776022\n",
      "Trained batch 402 batch loss 0.292842776 epoch total loss 0.294771194\n",
      "Trained batch 403 batch loss 0.298978567 epoch total loss 0.294781655\n",
      "Trained batch 404 batch loss 0.319437087 epoch total loss 0.29484266\n",
      "Trained batch 405 batch loss 0.276040405 epoch total loss 0.294796258\n",
      "Trained batch 406 batch loss 0.299639404 epoch total loss 0.294808179\n",
      "Trained batch 407 batch loss 0.285274029 epoch total loss 0.294784725\n",
      "Trained batch 408 batch loss 0.272151351 epoch total loss 0.294729263\n",
      "Trained batch 409 batch loss 0.269675314 epoch total loss 0.294668\n",
      "Trained batch 410 batch loss 0.31037277 epoch total loss 0.294706285\n",
      "Trained batch 411 batch loss 0.271120131 epoch total loss 0.294648916\n",
      "Trained batch 412 batch loss 0.269340396 epoch total loss 0.294587463\n",
      "Trained batch 413 batch loss 0.277199566 epoch total loss 0.294545382\n",
      "Trained batch 414 batch loss 0.294781029 epoch total loss 0.294545949\n",
      "Trained batch 415 batch loss 0.334737927 epoch total loss 0.294642806\n",
      "Trained batch 416 batch loss 0.296801567 epoch total loss 0.294648\n",
      "Trained batch 417 batch loss 0.325713038 epoch total loss 0.294722497\n",
      "Trained batch 418 batch loss 0.362082273 epoch total loss 0.294883639\n",
      "Trained batch 419 batch loss 0.271097422 epoch total loss 0.294826865\n",
      "Trained batch 420 batch loss 0.327153534 epoch total loss 0.294903845\n",
      "Trained batch 421 batch loss 0.33084029 epoch total loss 0.294989198\n",
      "Trained batch 422 batch loss 0.31219852 epoch total loss 0.295029968\n",
      "Trained batch 423 batch loss 0.311117589 epoch total loss 0.295068\n",
      "Trained batch 424 batch loss 0.280556858 epoch total loss 0.295033783\n",
      "Trained batch 425 batch loss 0.263117462 epoch total loss 0.294958681\n",
      "Trained batch 426 batch loss 0.318697095 epoch total loss 0.295014381\n",
      "Trained batch 427 batch loss 0.294342637 epoch total loss 0.295012832\n",
      "Trained batch 428 batch loss 0.292230934 epoch total loss 0.295006305\n",
      "Trained batch 429 batch loss 0.29087469 epoch total loss 0.294996679\n",
      "Trained batch 430 batch loss 0.283663 epoch total loss 0.294970334\n",
      "Trained batch 431 batch loss 0.304909 epoch total loss 0.294993401\n",
      "Trained batch 432 batch loss 0.291027516 epoch total loss 0.294984221\n",
      "Trained batch 433 batch loss 0.280583352 epoch total loss 0.294950962\n",
      "Trained batch 434 batch loss 0.303032935 epoch total loss 0.294969589\n",
      "Trained batch 435 batch loss 0.325671315 epoch total loss 0.29504016\n",
      "Trained batch 436 batch loss 0.308873832 epoch total loss 0.29507187\n",
      "Trained batch 437 batch loss 0.277142555 epoch total loss 0.295030862\n",
      "Trained batch 438 batch loss 0.291215956 epoch total loss 0.29502213\n",
      "Trained batch 439 batch loss 0.280463338 epoch total loss 0.29498896\n",
      "Trained batch 440 batch loss 0.280724019 epoch total loss 0.294956565\n",
      "Trained batch 441 batch loss 0.272860616 epoch total loss 0.294906437\n",
      "Trained batch 442 batch loss 0.293206602 epoch total loss 0.294902623\n",
      "Trained batch 443 batch loss 0.293654084 epoch total loss 0.294899791\n",
      "Trained batch 444 batch loss 0.29430306 epoch total loss 0.29489845\n",
      "Trained batch 445 batch loss 0.30289638 epoch total loss 0.294916421\n",
      "Trained batch 446 batch loss 0.292670459 epoch total loss 0.294911385\n",
      "Trained batch 447 batch loss 0.339869201 epoch total loss 0.295011967\n",
      "Trained batch 448 batch loss 0.3534863 epoch total loss 0.295142472\n",
      "Trained batch 449 batch loss 0.369472712 epoch total loss 0.295308024\n",
      "Trained batch 450 batch loss 0.313197553 epoch total loss 0.29534781\n",
      "Trained batch 451 batch loss 0.263979763 epoch total loss 0.295278251\n",
      "Trained batch 452 batch loss 0.329030603 epoch total loss 0.295352906\n",
      "Trained batch 453 batch loss 0.304226339 epoch total loss 0.295372486\n",
      "Trained batch 454 batch loss 0.34215948 epoch total loss 0.295475572\n",
      "Trained batch 455 batch loss 0.325515568 epoch total loss 0.295541584\n",
      "Trained batch 456 batch loss 0.311792612 epoch total loss 0.295577228\n",
      "Trained batch 457 batch loss 0.321054041 epoch total loss 0.295633\n",
      "Trained batch 458 batch loss 0.286939681 epoch total loss 0.295614\n",
      "Trained batch 459 batch loss 0.300177276 epoch total loss 0.295623958\n",
      "Trained batch 460 batch loss 0.304437786 epoch total loss 0.295643121\n",
      "Trained batch 461 batch loss 0.31392768 epoch total loss 0.295682788\n",
      "Trained batch 462 batch loss 0.304016799 epoch total loss 0.295700818\n",
      "Trained batch 463 batch loss 0.349495947 epoch total loss 0.295817047\n",
      "Trained batch 464 batch loss 0.289702773 epoch total loss 0.295803845\n",
      "Trained batch 465 batch loss 0.278385401 epoch total loss 0.295766383\n",
      "Trained batch 466 batch loss 0.306845605 epoch total loss 0.295790166\n",
      "Trained batch 467 batch loss 0.299170554 epoch total loss 0.295797378\n",
      "Trained batch 468 batch loss 0.301489085 epoch total loss 0.295809537\n",
      "Trained batch 469 batch loss 0.289051503 epoch total loss 0.295795113\n",
      "Trained batch 470 batch loss 0.29770273 epoch total loss 0.295799166\n",
      "Trained batch 471 batch loss 0.312832177 epoch total loss 0.295835316\n",
      "Trained batch 472 batch loss 0.312219888 epoch total loss 0.295870066\n",
      "Trained batch 473 batch loss 0.31824249 epoch total loss 0.295917332\n",
      "Trained batch 474 batch loss 0.320191592 epoch total loss 0.295968562\n",
      "Trained batch 475 batch loss 0.302845329 epoch total loss 0.295983016\n",
      "Trained batch 476 batch loss 0.315233111 epoch total loss 0.296023458\n",
      "Trained batch 477 batch loss 0.287696213 epoch total loss 0.296006\n",
      "Trained batch 478 batch loss 0.284390837 epoch total loss 0.295981705\n",
      "Trained batch 479 batch loss 0.312784523 epoch total loss 0.296016783\n",
      "Trained batch 480 batch loss 0.313560545 epoch total loss 0.29605335\n",
      "Trained batch 481 batch loss 0.325168222 epoch total loss 0.296113878\n",
      "Trained batch 482 batch loss 0.3216694 epoch total loss 0.296166897\n",
      "Trained batch 483 batch loss 0.36682114 epoch total loss 0.296313167\n",
      "Trained batch 484 batch loss 0.348910362 epoch total loss 0.296421826\n",
      "Trained batch 485 batch loss 0.286548674 epoch total loss 0.296401471\n",
      "Trained batch 486 batch loss 0.24180983 epoch total loss 0.296289146\n",
      "Trained batch 487 batch loss 0.238906741 epoch total loss 0.296171308\n",
      "Trained batch 488 batch loss 0.280625284 epoch total loss 0.296139449\n",
      "Trained batch 489 batch loss 0.27566579 epoch total loss 0.296097577\n",
      "Trained batch 490 batch loss 0.21501933 epoch total loss 0.295932144\n",
      "Trained batch 491 batch loss 0.22912474 epoch total loss 0.295796067\n",
      "Trained batch 492 batch loss 0.239597976 epoch total loss 0.295681834\n",
      "Trained batch 493 batch loss 0.259374559 epoch total loss 0.295608193\n",
      "Trained batch 494 batch loss 0.282683492 epoch total loss 0.295582026\n",
      "Trained batch 495 batch loss 0.293440551 epoch total loss 0.295577705\n",
      "Trained batch 496 batch loss 0.290593 epoch total loss 0.295567632\n",
      "Trained batch 497 batch loss 0.29931581 epoch total loss 0.295575172\n",
      "Trained batch 498 batch loss 0.323727816 epoch total loss 0.295631707\n",
      "Trained batch 499 batch loss 0.294298172 epoch total loss 0.295629025\n",
      "Trained batch 500 batch loss 0.279200166 epoch total loss 0.295596182\n",
      "Trained batch 501 batch loss 0.338594943 epoch total loss 0.295682\n",
      "Trained batch 502 batch loss 0.337806404 epoch total loss 0.295765907\n",
      "Trained batch 503 batch loss 0.285740048 epoch total loss 0.295745969\n",
      "Trained batch 504 batch loss 0.247168168 epoch total loss 0.295649588\n",
      "Trained batch 505 batch loss 0.273295194 epoch total loss 0.295605332\n",
      "Trained batch 506 batch loss 0.28161341 epoch total loss 0.295577675\n",
      "Trained batch 507 batch loss 0.329484075 epoch total loss 0.295644552\n",
      "Trained batch 508 batch loss 0.309365034 epoch total loss 0.295671582\n",
      "Trained batch 509 batch loss 0.303879887 epoch total loss 0.295687705\n",
      "Trained batch 510 batch loss 0.300883472 epoch total loss 0.295697898\n",
      "Trained batch 511 batch loss 0.300807357 epoch total loss 0.295707911\n",
      "Trained batch 512 batch loss 0.281362355 epoch total loss 0.295679867\n",
      "Trained batch 513 batch loss 0.29667142 epoch total loss 0.295681804\n",
      "Trained batch 514 batch loss 0.28579706 epoch total loss 0.295662582\n",
      "Trained batch 515 batch loss 0.358317882 epoch total loss 0.295784235\n",
      "Trained batch 516 batch loss 0.300827563 epoch total loss 0.295794\n",
      "Trained batch 517 batch loss 0.262649804 epoch total loss 0.295729905\n",
      "Trained batch 518 batch loss 0.269995183 epoch total loss 0.295680225\n",
      "Trained batch 519 batch loss 0.283970475 epoch total loss 0.295657635\n",
      "Trained batch 520 batch loss 0.303923488 epoch total loss 0.295673549\n",
      "Trained batch 521 batch loss 0.284796864 epoch total loss 0.295652658\n",
      "Trained batch 522 batch loss 0.306178838 epoch total loss 0.295672834\n",
      "Trained batch 523 batch loss 0.317564636 epoch total loss 0.295714676\n",
      "Trained batch 524 batch loss 0.326402724 epoch total loss 0.295773238\n",
      "Trained batch 525 batch loss 0.334083945 epoch total loss 0.295846224\n",
      "Trained batch 526 batch loss 0.334582508 epoch total loss 0.295919865\n",
      "Trained batch 527 batch loss 0.327024579 epoch total loss 0.295978904\n",
      "Trained batch 528 batch loss 0.31944108 epoch total loss 0.296023339\n",
      "Trained batch 529 batch loss 0.280280292 epoch total loss 0.295993567\n",
      "Trained batch 530 batch loss 0.262925088 epoch total loss 0.29593116\n",
      "Trained batch 531 batch loss 0.284781724 epoch total loss 0.29591015\n",
      "Trained batch 532 batch loss 0.312185585 epoch total loss 0.295940757\n",
      "Trained batch 533 batch loss 0.308700234 epoch total loss 0.295964688\n",
      "Trained batch 534 batch loss 0.312451929 epoch total loss 0.295995563\n",
      "Trained batch 535 batch loss 0.28071776 epoch total loss 0.295967\n",
      "Trained batch 536 batch loss 0.271845579 epoch total loss 0.295922\n",
      "Trained batch 537 batch loss 0.258932501 epoch total loss 0.295853108\n",
      "Trained batch 538 batch loss 0.267971605 epoch total loss 0.295801312\n",
      "Trained batch 539 batch loss 0.269735724 epoch total loss 0.295752913\n",
      "Trained batch 540 batch loss 0.26688379 epoch total loss 0.295699447\n",
      "Trained batch 541 batch loss 0.261861384 epoch total loss 0.295636892\n",
      "Trained batch 542 batch loss 0.290878147 epoch total loss 0.295628101\n",
      "Trained batch 543 batch loss 0.296250015 epoch total loss 0.295629263\n",
      "Trained batch 544 batch loss 0.285902441 epoch total loss 0.295611382\n",
      "Trained batch 545 batch loss 0.304420948 epoch total loss 0.295627564\n",
      "Trained batch 546 batch loss 0.295571119 epoch total loss 0.295627475\n",
      "Trained batch 547 batch loss 0.310958862 epoch total loss 0.295655489\n",
      "Trained batch 548 batch loss 0.297579467 epoch total loss 0.295659\n",
      "Trained batch 549 batch loss 0.310296386 epoch total loss 0.295685679\n",
      "Trained batch 550 batch loss 0.348793626 epoch total loss 0.295782238\n",
      "Trained batch 551 batch loss 0.284870028 epoch total loss 0.29576245\n",
      "Trained batch 552 batch loss 0.244222522 epoch total loss 0.295669049\n",
      "Trained batch 553 batch loss 0.256687731 epoch total loss 0.295598567\n",
      "Trained batch 554 batch loss 0.284044981 epoch total loss 0.295577705\n",
      "Trained batch 555 batch loss 0.263833106 epoch total loss 0.295520514\n",
      "Trained batch 556 batch loss 0.288408399 epoch total loss 0.295507729\n",
      "Trained batch 557 batch loss 0.27055186 epoch total loss 0.295462906\n",
      "Trained batch 558 batch loss 0.305738181 epoch total loss 0.295481324\n",
      "Trained batch 559 batch loss 0.316926628 epoch total loss 0.29551971\n",
      "Trained batch 560 batch loss 0.315807968 epoch total loss 0.295555919\n",
      "Trained batch 561 batch loss 0.30095315 epoch total loss 0.295565546\n",
      "Trained batch 562 batch loss 0.324260533 epoch total loss 0.295616597\n",
      "Trained batch 563 batch loss 0.347590297 epoch total loss 0.295708925\n",
      "Trained batch 564 batch loss 0.369184017 epoch total loss 0.29583922\n",
      "Trained batch 565 batch loss 0.307133287 epoch total loss 0.295859188\n",
      "Trained batch 566 batch loss 0.307894289 epoch total loss 0.295880467\n",
      "Trained batch 567 batch loss 0.294101566 epoch total loss 0.295877308\n",
      "Trained batch 568 batch loss 0.323065728 epoch total loss 0.29592517\n",
      "Trained batch 569 batch loss 0.28097865 epoch total loss 0.295898885\n",
      "Trained batch 570 batch loss 0.294528306 epoch total loss 0.295896471\n",
      "Trained batch 571 batch loss 0.29282558 epoch total loss 0.295891106\n",
      "Trained batch 572 batch loss 0.32070896 epoch total loss 0.295934498\n",
      "Trained batch 573 batch loss 0.304322124 epoch total loss 0.295949131\n",
      "Trained batch 574 batch loss 0.301844776 epoch total loss 0.295959413\n",
      "Trained batch 575 batch loss 0.285328329 epoch total loss 0.295940936\n",
      "Trained batch 576 batch loss 0.290057719 epoch total loss 0.295930713\n",
      "Trained batch 577 batch loss 0.309693515 epoch total loss 0.295954555\n",
      "Trained batch 578 batch loss 0.286841959 epoch total loss 0.29593879\n",
      "Trained batch 579 batch loss 0.276801884 epoch total loss 0.295905709\n",
      "Trained batch 580 batch loss 0.240453109 epoch total loss 0.295810103\n",
      "Trained batch 581 batch loss 0.261125565 epoch total loss 0.29575038\n",
      "Trained batch 582 batch loss 0.276643813 epoch total loss 0.295717567\n",
      "Trained batch 583 batch loss 0.287246555 epoch total loss 0.295703024\n",
      "Trained batch 584 batch loss 0.256241679 epoch total loss 0.295635462\n",
      "Trained batch 585 batch loss 0.258575112 epoch total loss 0.295572102\n",
      "Trained batch 586 batch loss 0.253037095 epoch total loss 0.295499533\n",
      "Trained batch 587 batch loss 0.285658866 epoch total loss 0.295482755\n",
      "Trained batch 588 batch loss 0.31860435 epoch total loss 0.295522094\n",
      "Trained batch 589 batch loss 0.30211997 epoch total loss 0.295533299\n",
      "Trained batch 590 batch loss 0.329446942 epoch total loss 0.295590788\n",
      "Trained batch 591 batch loss 0.314112693 epoch total loss 0.29562214\n",
      "Trained batch 592 batch loss 0.267742485 epoch total loss 0.295575052\n",
      "Trained batch 593 batch loss 0.317183226 epoch total loss 0.295611471\n",
      "Trained batch 594 batch loss 0.272917718 epoch total loss 0.295573264\n",
      "Trained batch 595 batch loss 0.285366416 epoch total loss 0.295556128\n",
      "Trained batch 596 batch loss 0.30859 epoch total loss 0.295578\n",
      "Trained batch 597 batch loss 0.250350952 epoch total loss 0.295502245\n",
      "Trained batch 598 batch loss 0.270273179 epoch total loss 0.295460075\n",
      "Trained batch 599 batch loss 0.260241359 epoch total loss 0.295401275\n",
      "Trained batch 600 batch loss 0.25744009 epoch total loss 0.295338\n",
      "Trained batch 601 batch loss 0.284160584 epoch total loss 0.295319408\n",
      "Trained batch 602 batch loss 0.402578056 epoch total loss 0.295497566\n",
      "Trained batch 603 batch loss 0.340375304 epoch total loss 0.295572\n",
      "Trained batch 604 batch loss 0.316595733 epoch total loss 0.295606792\n",
      "Trained batch 605 batch loss 0.338037372 epoch total loss 0.295676947\n",
      "Trained batch 606 batch loss 0.341834694 epoch total loss 0.295753092\n",
      "Trained batch 607 batch loss 0.297226608 epoch total loss 0.295755535\n",
      "Trained batch 608 batch loss 0.313394964 epoch total loss 0.295784563\n",
      "Trained batch 609 batch loss 0.282850981 epoch total loss 0.295763314\n",
      "Trained batch 610 batch loss 0.30331248 epoch total loss 0.295775682\n",
      "Trained batch 611 batch loss 0.320008337 epoch total loss 0.295815349\n",
      "Trained batch 612 batch loss 0.296595365 epoch total loss 0.29581663\n",
      "Trained batch 613 batch loss 0.295810401 epoch total loss 0.29581663\n",
      "Trained batch 614 batch loss 0.262612194 epoch total loss 0.295762539\n",
      "Trained batch 615 batch loss 0.296743482 epoch total loss 0.295764148\n",
      "Trained batch 616 batch loss 0.297037 epoch total loss 0.295766205\n",
      "Trained batch 617 batch loss 0.32968697 epoch total loss 0.29582119\n",
      "Trained batch 618 batch loss 0.285188764 epoch total loss 0.295803964\n",
      "Trained batch 619 batch loss 0.270316839 epoch total loss 0.295762777\n",
      "Trained batch 620 batch loss 0.284374416 epoch total loss 0.295744419\n",
      "Trained batch 621 batch loss 0.293548524 epoch total loss 0.295740873\n",
      "Trained batch 622 batch loss 0.301220715 epoch total loss 0.295749694\n",
      "Trained batch 623 batch loss 0.313056 epoch total loss 0.29577747\n",
      "Trained batch 624 batch loss 0.30705905 epoch total loss 0.29579553\n",
      "Trained batch 625 batch loss 0.288633078 epoch total loss 0.295784086\n",
      "Trained batch 626 batch loss 0.27227816 epoch total loss 0.295746535\n",
      "Trained batch 627 batch loss 0.27052778 epoch total loss 0.295706302\n",
      "Trained batch 628 batch loss 0.267894924 epoch total loss 0.295662016\n",
      "Trained batch 629 batch loss 0.261878401 epoch total loss 0.295608312\n",
      "Trained batch 630 batch loss 0.315066159 epoch total loss 0.295639187\n",
      "Trained batch 631 batch loss 0.289837658 epoch total loss 0.29563\n",
      "Trained batch 632 batch loss 0.294529468 epoch total loss 0.29562825\n",
      "Trained batch 633 batch loss 0.288130045 epoch total loss 0.295616388\n",
      "Trained batch 634 batch loss 0.299146146 epoch total loss 0.295621961\n",
      "Trained batch 635 batch loss 0.276082247 epoch total loss 0.295591205\n",
      "Trained batch 636 batch loss 0.275537908 epoch total loss 0.295559675\n",
      "Trained batch 637 batch loss 0.279697031 epoch total loss 0.29553476\n",
      "Trained batch 638 batch loss 0.284498602 epoch total loss 0.295517474\n",
      "Trained batch 639 batch loss 0.275609 epoch total loss 0.295486301\n",
      "Trained batch 640 batch loss 0.258506894 epoch total loss 0.295428544\n",
      "Trained batch 641 batch loss 0.301281095 epoch total loss 0.295437664\n",
      "Trained batch 642 batch loss 0.270261 epoch total loss 0.295398474\n",
      "Trained batch 643 batch loss 0.283989489 epoch total loss 0.295380741\n",
      "Trained batch 644 batch loss 0.292429745 epoch total loss 0.295376152\n",
      "Trained batch 645 batch loss 0.281923801 epoch total loss 0.29535529\n",
      "Trained batch 646 batch loss 0.263938248 epoch total loss 0.295306653\n",
      "Trained batch 647 batch loss 0.274676055 epoch total loss 0.295274764\n",
      "Trained batch 648 batch loss 0.293373555 epoch total loss 0.295271844\n",
      "Trained batch 649 batch loss 0.303891659 epoch total loss 0.295285136\n",
      "Trained batch 650 batch loss 0.317548841 epoch total loss 0.295319378\n",
      "Trained batch 651 batch loss 0.275317043 epoch total loss 0.295288652\n",
      "Trained batch 652 batch loss 0.243412584 epoch total loss 0.29520908\n",
      "Trained batch 653 batch loss 0.268320292 epoch total loss 0.295167923\n",
      "Trained batch 654 batch loss 0.26003769 epoch total loss 0.295114189\n",
      "Trained batch 655 batch loss 0.314953804 epoch total loss 0.295144498\n",
      "Trained batch 656 batch loss 0.289247692 epoch total loss 0.295135498\n",
      "Trained batch 657 batch loss 0.279134899 epoch total loss 0.29511115\n",
      "Trained batch 658 batch loss 0.301099092 epoch total loss 0.295120239\n",
      "Trained batch 659 batch loss 0.3261123 epoch total loss 0.295167267\n",
      "Trained batch 660 batch loss 0.28391093 epoch total loss 0.295150191\n",
      "Trained batch 661 batch loss 0.322818905 epoch total loss 0.295192063\n",
      "Trained batch 662 batch loss 0.27780515 epoch total loss 0.295165777\n",
      "Trained batch 663 batch loss 0.295235634 epoch total loss 0.295165896\n",
      "Trained batch 664 batch loss 0.313690424 epoch total loss 0.295193791\n",
      "Trained batch 665 batch loss 0.325225621 epoch total loss 0.295238972\n",
      "Trained batch 666 batch loss 0.295517445 epoch total loss 0.295239389\n",
      "Trained batch 667 batch loss 0.285463095 epoch total loss 0.295224726\n",
      "Trained batch 668 batch loss 0.308582187 epoch total loss 0.295244694\n",
      "Trained batch 669 batch loss 0.337307215 epoch total loss 0.295307577\n",
      "Trained batch 670 batch loss 0.321684271 epoch total loss 0.295346946\n",
      "Trained batch 671 batch loss 0.284487486 epoch total loss 0.295330763\n",
      "Trained batch 672 batch loss 0.284981847 epoch total loss 0.295315385\n",
      "Trained batch 673 batch loss 0.285964966 epoch total loss 0.295301497\n",
      "Trained batch 674 batch loss 0.291921228 epoch total loss 0.29529646\n",
      "Trained batch 675 batch loss 0.268832505 epoch total loss 0.295257241\n",
      "Trained batch 676 batch loss 0.264822602 epoch total loss 0.295212209\n",
      "Trained batch 677 batch loss 0.292287618 epoch total loss 0.295207888\n",
      "Trained batch 678 batch loss 0.282348871 epoch total loss 0.295188934\n",
      "Trained batch 679 batch loss 0.279199839 epoch total loss 0.29516539\n",
      "Trained batch 680 batch loss 0.303522378 epoch total loss 0.295177698\n",
      "Trained batch 681 batch loss 0.272459298 epoch total loss 0.29514432\n",
      "Trained batch 682 batch loss 0.221818015 epoch total loss 0.295036823\n",
      "Trained batch 683 batch loss 0.26787129 epoch total loss 0.294997036\n",
      "Trained batch 684 batch loss 0.285290897 epoch total loss 0.294982851\n",
      "Trained batch 685 batch loss 0.296141505 epoch total loss 0.294984549\n",
      "Trained batch 686 batch loss 0.30367884 epoch total loss 0.294997215\n",
      "Trained batch 687 batch loss 0.287335813 epoch total loss 0.294986069\n",
      "Trained batch 688 batch loss 0.276361793 epoch total loss 0.294959\n",
      "Trained batch 689 batch loss 0.263714343 epoch total loss 0.29491365\n",
      "Trained batch 690 batch loss 0.268145293 epoch total loss 0.294874847\n",
      "Trained batch 691 batch loss 0.270455241 epoch total loss 0.294839531\n",
      "Trained batch 692 batch loss 0.28105858 epoch total loss 0.294819593\n",
      "Trained batch 693 batch loss 0.269377619 epoch total loss 0.294782907\n",
      "Trained batch 694 batch loss 0.298127383 epoch total loss 0.294787705\n",
      "Trained batch 695 batch loss 0.257886618 epoch total loss 0.294734627\n",
      "Trained batch 696 batch loss 0.268458277 epoch total loss 0.294696867\n",
      "Trained batch 697 batch loss 0.276517212 epoch total loss 0.29467079\n",
      "Trained batch 698 batch loss 0.271464109 epoch total loss 0.294637561\n",
      "Trained batch 699 batch loss 0.286697417 epoch total loss 0.294626206\n",
      "Trained batch 700 batch loss 0.307891458 epoch total loss 0.29464516\n",
      "Trained batch 701 batch loss 0.308405757 epoch total loss 0.29466477\n",
      "Trained batch 702 batch loss 0.251800448 epoch total loss 0.294603735\n",
      "Trained batch 703 batch loss 0.263781369 epoch total loss 0.294559866\n",
      "Trained batch 704 batch loss 0.252441823 epoch total loss 0.294500053\n",
      "Trained batch 705 batch loss 0.320906878 epoch total loss 0.294537514\n",
      "Trained batch 706 batch loss 0.272299528 epoch total loss 0.294505984\n",
      "Trained batch 707 batch loss 0.332163095 epoch total loss 0.29455927\n",
      "Trained batch 708 batch loss 0.304790258 epoch total loss 0.294573724\n",
      "Trained batch 709 batch loss 0.307397157 epoch total loss 0.294591814\n",
      "Trained batch 710 batch loss 0.314928681 epoch total loss 0.294620454\n",
      "Trained batch 711 batch loss 0.289686501 epoch total loss 0.29461351\n",
      "Trained batch 712 batch loss 0.278258473 epoch total loss 0.294590563\n",
      "Trained batch 713 batch loss 0.282811284 epoch total loss 0.294574022\n",
      "Trained batch 714 batch loss 0.291925281 epoch total loss 0.294570327\n",
      "Trained batch 715 batch loss 0.299363375 epoch total loss 0.294577032\n",
      "Trained batch 716 batch loss 0.309162587 epoch total loss 0.294597387\n",
      "Trained batch 717 batch loss 0.321246833 epoch total loss 0.294634551\n",
      "Trained batch 718 batch loss 0.302622855 epoch total loss 0.294645697\n",
      "Trained batch 719 batch loss 0.233516842 epoch total loss 0.294560671\n",
      "Trained batch 720 batch loss 0.254559785 epoch total loss 0.294505119\n",
      "Trained batch 721 batch loss 0.258012205 epoch total loss 0.294454515\n",
      "Trained batch 722 batch loss 0.277010649 epoch total loss 0.294430345\n",
      "Trained batch 723 batch loss 0.262291402 epoch total loss 0.29438591\n",
      "Trained batch 724 batch loss 0.281178057 epoch total loss 0.294367641\n",
      "Trained batch 725 batch loss 0.278254479 epoch total loss 0.294345438\n",
      "Trained batch 726 batch loss 0.285820305 epoch total loss 0.294333696\n",
      "Trained batch 727 batch loss 0.352648944 epoch total loss 0.294413894\n",
      "Trained batch 728 batch loss 0.31003195 epoch total loss 0.294435352\n",
      "Trained batch 729 batch loss 0.312734485 epoch total loss 0.294460446\n",
      "Trained batch 730 batch loss 0.263239294 epoch total loss 0.294417679\n",
      "Trained batch 731 batch loss 0.28741923 epoch total loss 0.294408113\n",
      "Trained batch 732 batch loss 0.280678391 epoch total loss 0.294389367\n",
      "Trained batch 733 batch loss 0.312032342 epoch total loss 0.294413418\n",
      "Trained batch 734 batch loss 0.322774291 epoch total loss 0.294452041\n",
      "Trained batch 735 batch loss 0.295289546 epoch total loss 0.294453204\n",
      "Trained batch 736 batch loss 0.292558193 epoch total loss 0.294450611\n",
      "Trained batch 737 batch loss 0.287381172 epoch total loss 0.294441\n",
      "Trained batch 738 batch loss 0.31729722 epoch total loss 0.294471979\n",
      "Trained batch 739 batch loss 0.287557423 epoch total loss 0.294462621\n",
      "Trained batch 740 batch loss 0.300234079 epoch total loss 0.294470429\n",
      "Trained batch 741 batch loss 0.295332551 epoch total loss 0.294471592\n",
      "Trained batch 742 batch loss 0.300353587 epoch total loss 0.294479519\n",
      "Trained batch 743 batch loss 0.293993413 epoch total loss 0.294478863\n",
      "Trained batch 744 batch loss 0.291394949 epoch total loss 0.294474721\n",
      "Trained batch 745 batch loss 0.306411684 epoch total loss 0.294490725\n",
      "Trained batch 746 batch loss 0.306102246 epoch total loss 0.294506311\n",
      "Trained batch 747 batch loss 0.323671103 epoch total loss 0.294545352\n",
      "Trained batch 748 batch loss 0.319109321 epoch total loss 0.294578195\n",
      "Trained batch 749 batch loss 0.312517941 epoch total loss 0.294602126\n",
      "Trained batch 750 batch loss 0.280537486 epoch total loss 0.29458338\n",
      "Trained batch 751 batch loss 0.289980173 epoch total loss 0.294577241\n",
      "Trained batch 752 batch loss 0.279837668 epoch total loss 0.294557631\n",
      "Trained batch 753 batch loss 0.297346532 epoch total loss 0.294561327\n",
      "Trained batch 754 batch loss 0.294205248 epoch total loss 0.294560879\n",
      "Trained batch 755 batch loss 0.293019205 epoch total loss 0.294558823\n",
      "Trained batch 756 batch loss 0.310279757 epoch total loss 0.294579595\n",
      "Trained batch 757 batch loss 0.280161113 epoch total loss 0.294560552\n",
      "Trained batch 758 batch loss 0.29129535 epoch total loss 0.29455626\n",
      "Trained batch 759 batch loss 0.309764266 epoch total loss 0.294576287\n",
      "Trained batch 760 batch loss 0.261646032 epoch total loss 0.294532955\n",
      "Trained batch 761 batch loss 0.307965666 epoch total loss 0.294550598\n",
      "Trained batch 762 batch loss 0.327014029 epoch total loss 0.294593215\n",
      "Trained batch 763 batch loss 0.316729516 epoch total loss 0.294622213\n",
      "Trained batch 764 batch loss 0.282774568 epoch total loss 0.294606715\n",
      "Trained batch 765 batch loss 0.321594507 epoch total loss 0.294642\n",
      "Trained batch 766 batch loss 0.315560102 epoch total loss 0.2946693\n",
      "Trained batch 767 batch loss 0.299358368 epoch total loss 0.29467544\n",
      "Trained batch 768 batch loss 0.305603713 epoch total loss 0.294689655\n",
      "Trained batch 769 batch loss 0.295218259 epoch total loss 0.294690341\n",
      "Trained batch 770 batch loss 0.30175826 epoch total loss 0.29469952\n",
      "Trained batch 771 batch loss 0.309764802 epoch total loss 0.29471907\n",
      "Trained batch 772 batch loss 0.332594186 epoch total loss 0.294768125\n",
      "Trained batch 773 batch loss 0.323750108 epoch total loss 0.294805616\n",
      "Trained batch 774 batch loss 0.292407691 epoch total loss 0.294802517\n",
      "Trained batch 775 batch loss 0.258871078 epoch total loss 0.294756144\n",
      "Trained batch 776 batch loss 0.259593815 epoch total loss 0.294710815\n",
      "Trained batch 777 batch loss 0.299760789 epoch total loss 0.294717312\n",
      "Trained batch 778 batch loss 0.272031128 epoch total loss 0.294688165\n",
      "Trained batch 779 batch loss 0.298065901 epoch total loss 0.294692516\n",
      "Trained batch 780 batch loss 0.317606598 epoch total loss 0.294721901\n",
      "Trained batch 781 batch loss 0.303895384 epoch total loss 0.294733644\n",
      "Trained batch 782 batch loss 0.303053588 epoch total loss 0.294744283\n",
      "Trained batch 783 batch loss 0.297168851 epoch total loss 0.294747353\n",
      "Trained batch 784 batch loss 0.32230404 epoch total loss 0.294782519\n",
      "Trained batch 785 batch loss 0.295067251 epoch total loss 0.294782907\n",
      "Trained batch 786 batch loss 0.263748676 epoch total loss 0.294743419\n",
      "Trained batch 787 batch loss 0.294356048 epoch total loss 0.294742912\n",
      "Trained batch 788 batch loss 0.345973969 epoch total loss 0.294807941\n",
      "Trained batch 789 batch loss 0.308895499 epoch total loss 0.294825792\n",
      "Trained batch 790 batch loss 0.295778602 epoch total loss 0.294827\n",
      "Trained batch 791 batch loss 0.273684353 epoch total loss 0.294800282\n",
      "Trained batch 792 batch loss 0.274529368 epoch total loss 0.294774681\n",
      "Trained batch 793 batch loss 0.289216042 epoch total loss 0.294767678\n",
      "Trained batch 794 batch loss 0.258025259 epoch total loss 0.294721395\n",
      "Trained batch 795 batch loss 0.241393894 epoch total loss 0.29465431\n",
      "Trained batch 796 batch loss 0.26971069 epoch total loss 0.294623\n",
      "Trained batch 797 batch loss 0.281467915 epoch total loss 0.294606477\n",
      "Trained batch 798 batch loss 0.280780107 epoch total loss 0.294589132\n",
      "Trained batch 799 batch loss 0.312246501 epoch total loss 0.294611245\n",
      "Trained batch 800 batch loss 0.305847228 epoch total loss 0.294625282\n",
      "Trained batch 801 batch loss 0.313037276 epoch total loss 0.29464826\n",
      "Trained batch 802 batch loss 0.291422695 epoch total loss 0.294644237\n",
      "Trained batch 803 batch loss 0.302881777 epoch total loss 0.294654518\n",
      "Trained batch 804 batch loss 0.291257113 epoch total loss 0.294650286\n",
      "Trained batch 805 batch loss 0.291257858 epoch total loss 0.294646084\n",
      "Trained batch 806 batch loss 0.300955445 epoch total loss 0.294653893\n",
      "Trained batch 807 batch loss 0.313502312 epoch total loss 0.294677258\n",
      "Trained batch 808 batch loss 0.348703384 epoch total loss 0.294744134\n",
      "Trained batch 809 batch loss 0.331344485 epoch total loss 0.294789374\n",
      "Trained batch 810 batch loss 0.284692854 epoch total loss 0.294776917\n",
      "Trained batch 811 batch loss 0.287137747 epoch total loss 0.294767499\n",
      "Trained batch 812 batch loss 0.287529349 epoch total loss 0.294758588\n",
      "Trained batch 813 batch loss 0.330503523 epoch total loss 0.294802576\n",
      "Trained batch 814 batch loss 0.301179171 epoch total loss 0.294810385\n",
      "Trained batch 815 batch loss 0.345652789 epoch total loss 0.294872791\n",
      "Trained batch 816 batch loss 0.360927045 epoch total loss 0.294953734\n",
      "Trained batch 817 batch loss 0.298705578 epoch total loss 0.294958323\n",
      "Trained batch 818 batch loss 0.317797124 epoch total loss 0.294986248\n",
      "Trained batch 819 batch loss 0.299831957 epoch total loss 0.294992179\n",
      "Trained batch 820 batch loss 0.308250338 epoch total loss 0.295008332\n",
      "Trained batch 821 batch loss 0.312680393 epoch total loss 0.295029849\n",
      "Trained batch 822 batch loss 0.317618072 epoch total loss 0.295057327\n",
      "Trained batch 823 batch loss 0.282784 epoch total loss 0.295042425\n",
      "Trained batch 824 batch loss 0.264708757 epoch total loss 0.29500562\n",
      "Trained batch 825 batch loss 0.291388094 epoch total loss 0.295001209\n",
      "Trained batch 826 batch loss 0.318452299 epoch total loss 0.29502961\n",
      "Trained batch 827 batch loss 0.296900183 epoch total loss 0.295031875\n",
      "Trained batch 828 batch loss 0.288208932 epoch total loss 0.29502365\n",
      "Trained batch 829 batch loss 0.294376671 epoch total loss 0.295022845\n",
      "Trained batch 830 batch loss 0.274486691 epoch total loss 0.294998109\n",
      "Trained batch 831 batch loss 0.318780661 epoch total loss 0.295026749\n",
      "Trained batch 832 batch loss 0.275307536 epoch total loss 0.295003057\n",
      "Trained batch 833 batch loss 0.30253005 epoch total loss 0.295012087\n",
      "Trained batch 834 batch loss 0.326171875 epoch total loss 0.295049459\n",
      "Trained batch 835 batch loss 0.318021655 epoch total loss 0.295076966\n",
      "Trained batch 836 batch loss 0.323901296 epoch total loss 0.295111448\n",
      "Trained batch 837 batch loss 0.32651788 epoch total loss 0.295148969\n",
      "Trained batch 838 batch loss 0.32024917 epoch total loss 0.29517892\n",
      "Trained batch 839 batch loss 0.312360287 epoch total loss 0.295199394\n",
      "Trained batch 840 batch loss 0.287277132 epoch total loss 0.295189977\n",
      "Trained batch 841 batch loss 0.282715291 epoch total loss 0.295175135\n",
      "Trained batch 842 batch loss 0.275817 epoch total loss 0.295152158\n",
      "Trained batch 843 batch loss 0.262675643 epoch total loss 0.295113623\n",
      "Trained batch 844 batch loss 0.284168422 epoch total loss 0.295100659\n",
      "Trained batch 845 batch loss 0.303061277 epoch total loss 0.295110077\n",
      "Trained batch 846 batch loss 0.284728169 epoch total loss 0.295097798\n",
      "Trained batch 847 batch loss 0.294219762 epoch total loss 0.295096755\n",
      "Trained batch 848 batch loss 0.29824847 epoch total loss 0.29510048\n",
      "Trained batch 849 batch loss 0.308770567 epoch total loss 0.295116603\n",
      "Trained batch 850 batch loss 0.306716502 epoch total loss 0.295130253\n",
      "Trained batch 851 batch loss 0.264804602 epoch total loss 0.295094609\n",
      "Trained batch 852 batch loss 0.246116236 epoch total loss 0.295037091\n",
      "Trained batch 853 batch loss 0.271121889 epoch total loss 0.295009077\n",
      "Trained batch 854 batch loss 0.303163379 epoch total loss 0.295018613\n",
      "Trained batch 855 batch loss 0.345612854 epoch total loss 0.295077771\n",
      "Trained batch 856 batch loss 0.309369296 epoch total loss 0.29509449\n",
      "Trained batch 857 batch loss 0.339354634 epoch total loss 0.295146137\n",
      "Trained batch 858 batch loss 0.301179141 epoch total loss 0.295153171\n",
      "Trained batch 859 batch loss 0.319489062 epoch total loss 0.295181483\n",
      "Trained batch 860 batch loss 0.327213258 epoch total loss 0.295218736\n",
      "Trained batch 861 batch loss 0.307993233 epoch total loss 0.295233577\n",
      "Trained batch 862 batch loss 0.316874415 epoch total loss 0.295258671\n",
      "Trained batch 863 batch loss 0.304189652 epoch total loss 0.295269\n",
      "Trained batch 864 batch loss 0.334892184 epoch total loss 0.295314878\n",
      "Trained batch 865 batch loss 0.320913434 epoch total loss 0.295344472\n",
      "Trained batch 866 batch loss 0.289784431 epoch total loss 0.295338035\n",
      "Trained batch 867 batch loss 0.3114779 epoch total loss 0.295356661\n",
      "Trained batch 868 batch loss 0.286955774 epoch total loss 0.295346975\n",
      "Trained batch 869 batch loss 0.305322707 epoch total loss 0.295358449\n",
      "Trained batch 870 batch loss 0.31161502 epoch total loss 0.295377135\n",
      "Trained batch 871 batch loss 0.282201052 epoch total loss 0.295362025\n",
      "Trained batch 872 batch loss 0.285423577 epoch total loss 0.295350611\n",
      "Trained batch 873 batch loss 0.281950384 epoch total loss 0.295335293\n",
      "Trained batch 874 batch loss 0.284713507 epoch total loss 0.295323104\n",
      "Trained batch 875 batch loss 0.28946656 epoch total loss 0.295316398\n",
      "Trained batch 876 batch loss 0.278059751 epoch total loss 0.295296699\n",
      "Trained batch 877 batch loss 0.320799053 epoch total loss 0.295325786\n",
      "Trained batch 878 batch loss 0.3113105 epoch total loss 0.295343965\n",
      "Trained batch 879 batch loss 0.330735445 epoch total loss 0.295384258\n",
      "Trained batch 880 batch loss 0.324272662 epoch total loss 0.2954171\n",
      "Trained batch 881 batch loss 0.304606289 epoch total loss 0.295427501\n",
      "Trained batch 882 batch loss 0.306021214 epoch total loss 0.295439541\n",
      "Trained batch 883 batch loss 0.312878519 epoch total loss 0.29545927\n",
      "Trained batch 884 batch loss 0.30428803 epoch total loss 0.295469254\n",
      "Trained batch 885 batch loss 0.296600908 epoch total loss 0.295470536\n",
      "Trained batch 886 batch loss 0.270578653 epoch total loss 0.295442432\n",
      "Trained batch 887 batch loss 0.274222314 epoch total loss 0.295418531\n",
      "Trained batch 888 batch loss 0.269068807 epoch total loss 0.295388848\n",
      "Trained batch 889 batch loss 0.292351663 epoch total loss 0.29538545\n",
      "Trained batch 890 batch loss 0.335811555 epoch total loss 0.295430869\n",
      "Trained batch 891 batch loss 0.275805295 epoch total loss 0.295408845\n",
      "Trained batch 892 batch loss 0.309169412 epoch total loss 0.295424283\n",
      "Trained batch 893 batch loss 0.284617335 epoch total loss 0.295412183\n",
      "Trained batch 894 batch loss 0.269168288 epoch total loss 0.295382828\n",
      "Trained batch 895 batch loss 0.28068468 epoch total loss 0.295366377\n",
      "Trained batch 896 batch loss 0.264516 epoch total loss 0.295331955\n",
      "Trained batch 897 batch loss 0.322393835 epoch total loss 0.295362115\n",
      "Trained batch 898 batch loss 0.305120289 epoch total loss 0.295372963\n",
      "Trained batch 899 batch loss 0.28718245 epoch total loss 0.295363843\n",
      "Trained batch 900 batch loss 0.2841281 epoch total loss 0.295351356\n",
      "Trained batch 901 batch loss 0.294559449 epoch total loss 0.295350462\n",
      "Trained batch 902 batch loss 0.277775407 epoch total loss 0.295331\n",
      "Trained batch 903 batch loss 0.299652576 epoch total loss 0.29533577\n",
      "Trained batch 904 batch loss 0.266600549 epoch total loss 0.295304\n",
      "Trained batch 905 batch loss 0.289903641 epoch total loss 0.29529804\n",
      "Trained batch 906 batch loss 0.272857338 epoch total loss 0.295273274\n",
      "Trained batch 907 batch loss 0.284939319 epoch total loss 0.29526189\n",
      "Trained batch 908 batch loss 0.316363454 epoch total loss 0.295285136\n",
      "Trained batch 909 batch loss 0.286215127 epoch total loss 0.295275152\n",
      "Trained batch 910 batch loss 0.267328918 epoch total loss 0.295244455\n",
      "Trained batch 911 batch loss 0.267414778 epoch total loss 0.295213908\n",
      "Trained batch 912 batch loss 0.297047585 epoch total loss 0.295215935\n",
      "Trained batch 913 batch loss 0.285333365 epoch total loss 0.295205116\n",
      "Trained batch 914 batch loss 0.328198373 epoch total loss 0.295241207\n",
      "Trained batch 915 batch loss 0.287954152 epoch total loss 0.29523325\n",
      "Trained batch 916 batch loss 0.303805292 epoch total loss 0.295242608\n",
      "Trained batch 917 batch loss 0.302503228 epoch total loss 0.295250505\n",
      "Trained batch 918 batch loss 0.287483573 epoch total loss 0.295242041\n",
      "Trained batch 919 batch loss 0.288055 epoch total loss 0.295234233\n",
      "Trained batch 920 batch loss 0.276129961 epoch total loss 0.295213461\n",
      "Trained batch 921 batch loss 0.284894466 epoch total loss 0.295202225\n",
      "Trained batch 922 batch loss 0.306324333 epoch total loss 0.295214295\n",
      "Trained batch 923 batch loss 0.31088686 epoch total loss 0.295231283\n",
      "Trained batch 924 batch loss 0.313786626 epoch total loss 0.295251369\n",
      "Trained batch 925 batch loss 0.293009698 epoch total loss 0.295248926\n",
      "Trained batch 926 batch loss 0.294230849 epoch total loss 0.295247823\n",
      "Trained batch 927 batch loss 0.299246043 epoch total loss 0.295252144\n",
      "Trained batch 928 batch loss 0.266610175 epoch total loss 0.295221269\n",
      "Trained batch 929 batch loss 0.273110032 epoch total loss 0.295197457\n",
      "Trained batch 930 batch loss 0.31584543 epoch total loss 0.29521966\n",
      "Trained batch 931 batch loss 0.300066561 epoch total loss 0.295224875\n",
      "Trained batch 932 batch loss 0.315145224 epoch total loss 0.295246273\n",
      "Trained batch 933 batch loss 0.33530432 epoch total loss 0.295289189\n",
      "Trained batch 934 batch loss 0.357064396 epoch total loss 0.29535532\n",
      "Trained batch 935 batch loss 0.326157957 epoch total loss 0.295388281\n",
      "Trained batch 936 batch loss 0.305202395 epoch total loss 0.295398772\n",
      "Trained batch 937 batch loss 0.302402109 epoch total loss 0.295406252\n",
      "Trained batch 938 batch loss 0.287359864 epoch total loss 0.295397669\n",
      "Trained batch 939 batch loss 0.287259489 epoch total loss 0.295389\n",
      "Trained batch 940 batch loss 0.291373134 epoch total loss 0.295384735\n",
      "Trained batch 941 batch loss 0.303248525 epoch total loss 0.295393109\n",
      "Trained batch 942 batch loss 0.325875193 epoch total loss 0.295425445\n",
      "Trained batch 943 batch loss 0.322373927 epoch total loss 0.295454025\n",
      "Trained batch 944 batch loss 0.345323682 epoch total loss 0.295506895\n",
      "Trained batch 945 batch loss 0.343337834 epoch total loss 0.295557469\n",
      "Trained batch 946 batch loss 0.309684038 epoch total loss 0.29557243\n",
      "Trained batch 947 batch loss 0.281197906 epoch total loss 0.295557231\n",
      "Trained batch 948 batch loss 0.294989556 epoch total loss 0.295556635\n",
      "Trained batch 949 batch loss 0.32562691 epoch total loss 0.295588315\n",
      "Trained batch 950 batch loss 0.290386617 epoch total loss 0.295582831\n",
      "Trained batch 951 batch loss 0.287700385 epoch total loss 0.295574516\n",
      "Trained batch 952 batch loss 0.282759249 epoch total loss 0.295561045\n",
      "Trained batch 953 batch loss 0.296052754 epoch total loss 0.295561552\n",
      "Trained batch 954 batch loss 0.284444481 epoch total loss 0.295549929\n",
      "Trained batch 955 batch loss 0.314843953 epoch total loss 0.295570135\n",
      "Trained batch 956 batch loss 0.301506221 epoch total loss 0.295576334\n",
      "Trained batch 957 batch loss 0.291982681 epoch total loss 0.295572609\n",
      "Trained batch 958 batch loss 0.311555654 epoch total loss 0.295589268\n",
      "Trained batch 959 batch loss 0.306789696 epoch total loss 0.295600951\n",
      "Trained batch 960 batch loss 0.320249856 epoch total loss 0.29562664\n",
      "Trained batch 961 batch loss 0.304449379 epoch total loss 0.295635819\n",
      "Trained batch 962 batch loss 0.306307822 epoch total loss 0.295646906\n",
      "Trained batch 963 batch loss 0.287237763 epoch total loss 0.295638174\n",
      "Trained batch 964 batch loss 0.288659245 epoch total loss 0.295630932\n",
      "Trained batch 965 batch loss 0.286726981 epoch total loss 0.295621693\n",
      "Trained batch 966 batch loss 0.287444651 epoch total loss 0.295613229\n",
      "Trained batch 967 batch loss 0.275627226 epoch total loss 0.295592576\n",
      "Trained batch 968 batch loss 0.265532434 epoch total loss 0.295561522\n",
      "Trained batch 969 batch loss 0.245697245 epoch total loss 0.295510054\n",
      "Trained batch 970 batch loss 0.266426206 epoch total loss 0.295480072\n",
      "Trained batch 971 batch loss 0.272806823 epoch total loss 0.295456707\n",
      "Trained batch 972 batch loss 0.30910939 epoch total loss 0.295470744\n",
      "Trained batch 973 batch loss 0.303929806 epoch total loss 0.295479447\n",
      "Trained batch 974 batch loss 0.280569911 epoch total loss 0.295464128\n",
      "Trained batch 975 batch loss 0.311061949 epoch total loss 0.295480132\n",
      "Trained batch 976 batch loss 0.296077758 epoch total loss 0.295480758\n",
      "Trained batch 977 batch loss 0.312631607 epoch total loss 0.295498312\n",
      "Trained batch 978 batch loss 0.285614312 epoch total loss 0.295488209\n",
      "Trained batch 979 batch loss 0.30110243 epoch total loss 0.29549396\n",
      "Trained batch 980 batch loss 0.2819556 epoch total loss 0.295480132\n",
      "Trained batch 981 batch loss 0.27552104 epoch total loss 0.295459777\n",
      "Trained batch 982 batch loss 0.261608958 epoch total loss 0.295425296\n",
      "Trained batch 983 batch loss 0.261482835 epoch total loss 0.295390755\n",
      "Trained batch 984 batch loss 0.250372738 epoch total loss 0.295345\n",
      "Trained batch 985 batch loss 0.27722314 epoch total loss 0.295326591\n",
      "Trained batch 986 batch loss 0.2719163 epoch total loss 0.295302838\n",
      "Trained batch 987 batch loss 0.242687553 epoch total loss 0.295249522\n",
      "Trained batch 988 batch loss 0.267657042 epoch total loss 0.295221627\n",
      "Trained batch 989 batch loss 0.284803361 epoch total loss 0.295211077\n",
      "Trained batch 990 batch loss 0.299705744 epoch total loss 0.295215607\n",
      "Trained batch 991 batch loss 0.290953815 epoch total loss 0.295211315\n",
      "Trained batch 992 batch loss 0.297386974 epoch total loss 0.295213521\n",
      "Trained batch 993 batch loss 0.277106524 epoch total loss 0.295195282\n",
      "Trained batch 994 batch loss 0.305228233 epoch total loss 0.295205384\n",
      "Trained batch 995 batch loss 0.291641146 epoch total loss 0.295201778\n",
      "Trained batch 996 batch loss 0.310222596 epoch total loss 0.295216858\n",
      "Trained batch 997 batch loss 0.29261 epoch total loss 0.295214236\n",
      "Trained batch 998 batch loss 0.279300183 epoch total loss 0.295198262\n",
      "Trained batch 999 batch loss 0.278052121 epoch total loss 0.295181096\n",
      "Trained batch 1000 batch loss 0.261396945 epoch total loss 0.2951473\n",
      "Trained batch 1001 batch loss 0.318962693 epoch total loss 0.295171112\n",
      "Trained batch 1002 batch loss 0.294774234 epoch total loss 0.295170695\n",
      "Trained batch 1003 batch loss 0.303855926 epoch total loss 0.295179367\n",
      "Trained batch 1004 batch loss 0.305868864 epoch total loss 0.295190036\n",
      "Trained batch 1005 batch loss 0.322062224 epoch total loss 0.295216769\n",
      "Trained batch 1006 batch loss 0.330133557 epoch total loss 0.295251459\n",
      "Trained batch 1007 batch loss 0.335530847 epoch total loss 0.295291483\n",
      "Trained batch 1008 batch loss 0.325756609 epoch total loss 0.295321703\n",
      "Trained batch 1009 batch loss 0.286126316 epoch total loss 0.295312583\n",
      "Trained batch 1010 batch loss 0.312772334 epoch total loss 0.295329869\n",
      "Trained batch 1011 batch loss 0.324305475 epoch total loss 0.295358539\n",
      "Trained batch 1012 batch loss 0.320040792 epoch total loss 0.295382917\n",
      "Trained batch 1013 batch loss 0.283343554 epoch total loss 0.295371056\n",
      "Trained batch 1014 batch loss 0.276064038 epoch total loss 0.295352\n",
      "Trained batch 1015 batch loss 0.284733742 epoch total loss 0.295341551\n",
      "Trained batch 1016 batch loss 0.267435253 epoch total loss 0.295314074\n",
      "Trained batch 1017 batch loss 0.285688162 epoch total loss 0.295304596\n",
      "Trained batch 1018 batch loss 0.271968514 epoch total loss 0.295281678\n",
      "Trained batch 1019 batch loss 0.277320564 epoch total loss 0.295264035\n",
      "Trained batch 1020 batch loss 0.294914126 epoch total loss 0.295263708\n",
      "Trained batch 1021 batch loss 0.275234312 epoch total loss 0.295244098\n",
      "Trained batch 1022 batch loss 0.25407365 epoch total loss 0.295203775\n",
      "Trained batch 1023 batch loss 0.268479198 epoch total loss 0.295177668\n",
      "Trained batch 1024 batch loss 0.276921779 epoch total loss 0.295159847\n",
      "Trained batch 1025 batch loss 0.258828342 epoch total loss 0.295124382\n",
      "Trained batch 1026 batch loss 0.271728814 epoch total loss 0.295101583\n",
      "Trained batch 1027 batch loss 0.267862797 epoch total loss 0.295075059\n",
      "Trained batch 1028 batch loss 0.282615036 epoch total loss 0.295062959\n",
      "Trained batch 1029 batch loss 0.252254397 epoch total loss 0.295021355\n",
      "Trained batch 1030 batch loss 0.281322122 epoch total loss 0.295008034\n",
      "Trained batch 1031 batch loss 0.26125595 epoch total loss 0.294975311\n",
      "Trained batch 1032 batch loss 0.276486456 epoch total loss 0.294957399\n",
      "Trained batch 1033 batch loss 0.323763072 epoch total loss 0.294985265\n",
      "Trained batch 1034 batch loss 0.340565801 epoch total loss 0.295029372\n",
      "Trained batch 1035 batch loss 0.300679296 epoch total loss 0.295034826\n",
      "Trained batch 1036 batch loss 0.305987269 epoch total loss 0.295045406\n",
      "Trained batch 1037 batch loss 0.331164539 epoch total loss 0.295080274\n",
      "Trained batch 1038 batch loss 0.297362268 epoch total loss 0.29508245\n",
      "Trained batch 1039 batch loss 0.33468 epoch total loss 0.295120567\n",
      "Trained batch 1040 batch loss 0.27578482 epoch total loss 0.295102\n",
      "Trained batch 1041 batch loss 0.300481617 epoch total loss 0.295107156\n",
      "Trained batch 1042 batch loss 0.32931 epoch total loss 0.295139968\n",
      "Trained batch 1043 batch loss 0.310922861 epoch total loss 0.295155108\n",
      "Trained batch 1044 batch loss 0.268436581 epoch total loss 0.295129508\n",
      "Trained batch 1045 batch loss 0.262171388 epoch total loss 0.295097977\n",
      "Trained batch 1046 batch loss 0.29532063 epoch total loss 0.295098186\n",
      "Trained batch 1047 batch loss 0.34016633 epoch total loss 0.29514125\n",
      "Trained batch 1048 batch loss 0.331852674 epoch total loss 0.295176268\n",
      "Trained batch 1049 batch loss 0.325503826 epoch total loss 0.295205176\n",
      "Trained batch 1050 batch loss 0.314417243 epoch total loss 0.295223475\n",
      "Trained batch 1051 batch loss 0.311356276 epoch total loss 0.295238853\n",
      "Trained batch 1052 batch loss 0.28511858 epoch total loss 0.295229226\n",
      "Trained batch 1053 batch loss 0.300487787 epoch total loss 0.295234203\n",
      "Trained batch 1054 batch loss 0.296389967 epoch total loss 0.295235306\n",
      "Trained batch 1055 batch loss 0.293824852 epoch total loss 0.295233965\n",
      "Trained batch 1056 batch loss 0.292529881 epoch total loss 0.295231402\n",
      "Trained batch 1057 batch loss 0.296428382 epoch total loss 0.295232534\n",
      "Trained batch 1058 batch loss 0.29970932 epoch total loss 0.295236766\n",
      "Trained batch 1059 batch loss 0.2922782 epoch total loss 0.295233965\n",
      "Trained batch 1060 batch loss 0.31139195 epoch total loss 0.295249224\n",
      "Trained batch 1061 batch loss 0.305411667 epoch total loss 0.29525882\n",
      "Trained batch 1062 batch loss 0.322024912 epoch total loss 0.295284\n",
      "Trained batch 1063 batch loss 0.324686587 epoch total loss 0.29531166\n",
      "Trained batch 1064 batch loss 0.29237318 epoch total loss 0.295308888\n",
      "Trained batch 1065 batch loss 0.318678379 epoch total loss 0.295330822\n",
      "Trained batch 1066 batch loss 0.301041901 epoch total loss 0.295336187\n",
      "Trained batch 1067 batch loss 0.304587662 epoch total loss 0.295344859\n",
      "Trained batch 1068 batch loss 0.298743516 epoch total loss 0.295348048\n",
      "Trained batch 1069 batch loss 0.281872809 epoch total loss 0.295335412\n",
      "Trained batch 1070 batch loss 0.27486971 epoch total loss 0.295316279\n",
      "Trained batch 1071 batch loss 0.278712422 epoch total loss 0.295300782\n",
      "Trained batch 1072 batch loss 0.287048221 epoch total loss 0.295293093\n",
      "Trained batch 1073 batch loss 0.286788255 epoch total loss 0.295285165\n",
      "Trained batch 1074 batch loss 0.305113554 epoch total loss 0.295294315\n",
      "Trained batch 1075 batch loss 0.324325472 epoch total loss 0.295321286\n",
      "Trained batch 1076 batch loss 0.297142386 epoch total loss 0.295323\n",
      "Trained batch 1077 batch loss 0.298830241 epoch total loss 0.295326263\n",
      "Trained batch 1078 batch loss 0.305224627 epoch total loss 0.295335442\n",
      "Trained batch 1079 batch loss 0.337824821 epoch total loss 0.29537484\n",
      "Trained batch 1080 batch loss 0.276855916 epoch total loss 0.295357674\n",
      "Trained batch 1081 batch loss 0.271194607 epoch total loss 0.295335352\n",
      "Trained batch 1082 batch loss 0.279132843 epoch total loss 0.295320392\n",
      "Trained batch 1083 batch loss 0.255501091 epoch total loss 0.295283616\n",
      "Trained batch 1084 batch loss 0.286498427 epoch total loss 0.295275509\n",
      "Trained batch 1085 batch loss 0.326240659 epoch total loss 0.29530403\n",
      "Trained batch 1086 batch loss 0.288630456 epoch total loss 0.295297891\n",
      "Trained batch 1087 batch loss 0.269625336 epoch total loss 0.295274287\n",
      "Trained batch 1088 batch loss 0.309835762 epoch total loss 0.295287669\n",
      "Trained batch 1089 batch loss 0.281767905 epoch total loss 0.295275241\n",
      "Trained batch 1090 batch loss 0.296905726 epoch total loss 0.295276761\n",
      "Trained batch 1091 batch loss 0.294129759 epoch total loss 0.295275688\n",
      "Trained batch 1092 batch loss 0.305299371 epoch total loss 0.295284867\n",
      "Trained batch 1093 batch loss 0.297734767 epoch total loss 0.295287102\n",
      "Trained batch 1094 batch loss 0.308833778 epoch total loss 0.2952995\n",
      "Trained batch 1095 batch loss 0.320817798 epoch total loss 0.295322806\n",
      "Trained batch 1096 batch loss 0.285221785 epoch total loss 0.295313597\n",
      "Trained batch 1097 batch loss 0.296328396 epoch total loss 0.295314521\n",
      "Trained batch 1098 batch loss 0.277380288 epoch total loss 0.295298189\n",
      "Trained batch 1099 batch loss 0.270940751 epoch total loss 0.295276016\n",
      "Trained batch 1100 batch loss 0.263649642 epoch total loss 0.295247257\n",
      "Trained batch 1101 batch loss 0.294034153 epoch total loss 0.295246154\n",
      "Trained batch 1102 batch loss 0.274847597 epoch total loss 0.295227647\n",
      "Trained batch 1103 batch loss 0.273715377 epoch total loss 0.295208126\n",
      "Trained batch 1104 batch loss 0.25951457 epoch total loss 0.295175791\n",
      "Trained batch 1105 batch loss 0.281844765 epoch total loss 0.295163721\n",
      "Trained batch 1106 batch loss 0.303788 epoch total loss 0.295171529\n",
      "Trained batch 1107 batch loss 0.322114766 epoch total loss 0.295195878\n",
      "Trained batch 1108 batch loss 0.310886383 epoch total loss 0.295210034\n",
      "Trained batch 1109 batch loss 0.318674356 epoch total loss 0.295231193\n",
      "Trained batch 1110 batch loss 0.301962912 epoch total loss 0.295237243\n",
      "Trained batch 1111 batch loss 0.293667 epoch total loss 0.295235842\n",
      "Trained batch 1112 batch loss 0.274429739 epoch total loss 0.295217156\n",
      "Trained batch 1113 batch loss 0.315109611 epoch total loss 0.295235038\n",
      "Trained batch 1114 batch loss 0.268673092 epoch total loss 0.295211196\n",
      "Trained batch 1115 batch loss 0.315573603 epoch total loss 0.295229465\n",
      "Trained batch 1116 batch loss 0.32381916 epoch total loss 0.295255095\n",
      "Trained batch 1117 batch loss 0.287760258 epoch total loss 0.295248359\n",
      "Trained batch 1118 batch loss 0.284579396 epoch total loss 0.295238823\n",
      "Trained batch 1119 batch loss 0.307160378 epoch total loss 0.295249462\n",
      "Trained batch 1120 batch loss 0.260830343 epoch total loss 0.295218736\n",
      "Trained batch 1121 batch loss 0.294861615 epoch total loss 0.295218408\n",
      "Trained batch 1122 batch loss 0.27151531 epoch total loss 0.295197308\n",
      "Trained batch 1123 batch loss 0.277298331 epoch total loss 0.295181364\n",
      "Trained batch 1124 batch loss 0.262944788 epoch total loss 0.295152694\n",
      "Trained batch 1125 batch loss 0.278534472 epoch total loss 0.295137912\n",
      "Trained batch 1126 batch loss 0.256447464 epoch total loss 0.29510355\n",
      "Trained batch 1127 batch loss 0.313388407 epoch total loss 0.295119762\n",
      "Trained batch 1128 batch loss 0.324487805 epoch total loss 0.29514581\n",
      "Trained batch 1129 batch loss 0.322112501 epoch total loss 0.295169681\n",
      "Trained batch 1130 batch loss 0.322175264 epoch total loss 0.295193583\n",
      "Trained batch 1131 batch loss 0.308280647 epoch total loss 0.295205176\n",
      "Trained batch 1132 batch loss 0.31593141 epoch total loss 0.295223475\n",
      "Trained batch 1133 batch loss 0.310726374 epoch total loss 0.295237154\n",
      "Trained batch 1134 batch loss 0.287362248 epoch total loss 0.29523021\n",
      "Trained batch 1135 batch loss 0.278217494 epoch total loss 0.295215219\n",
      "Trained batch 1136 batch loss 0.261466712 epoch total loss 0.295185506\n",
      "Trained batch 1137 batch loss 0.263777256 epoch total loss 0.29515788\n",
      "Trained batch 1138 batch loss 0.267365307 epoch total loss 0.295133471\n",
      "Trained batch 1139 batch loss 0.253988266 epoch total loss 0.295097351\n",
      "Trained batch 1140 batch loss 0.244262308 epoch total loss 0.295052767\n",
      "Trained batch 1141 batch loss 0.235164747 epoch total loss 0.295000255\n",
      "Trained batch 1142 batch loss 0.2362414 epoch total loss 0.294948816\n",
      "Trained batch 1143 batch loss 0.214737728 epoch total loss 0.294878662\n",
      "Trained batch 1144 batch loss 0.250977695 epoch total loss 0.294840276\n",
      "Trained batch 1145 batch loss 0.240898848 epoch total loss 0.294793159\n",
      "Trained batch 1146 batch loss 0.287897378 epoch total loss 0.294787169\n",
      "Trained batch 1147 batch loss 0.281013459 epoch total loss 0.294775128\n",
      "Trained batch 1148 batch loss 0.273139954 epoch total loss 0.294756293\n",
      "Trained batch 1149 batch loss 0.29752022 epoch total loss 0.294758677\n",
      "Trained batch 1150 batch loss 0.288894117 epoch total loss 0.294753581\n",
      "Trained batch 1151 batch loss 0.344254673 epoch total loss 0.294796586\n",
      "Trained batch 1152 batch loss 0.34251231 epoch total loss 0.294838\n",
      "Trained batch 1153 batch loss 0.317312241 epoch total loss 0.294857502\n",
      "Trained batch 1154 batch loss 0.321879238 epoch total loss 0.294880897\n",
      "Trained batch 1155 batch loss 0.32728821 epoch total loss 0.294908971\n",
      "Trained batch 1156 batch loss 0.292872339 epoch total loss 0.294907212\n",
      "Trained batch 1157 batch loss 0.301893711 epoch total loss 0.294913262\n",
      "Trained batch 1158 batch loss 0.3092466 epoch total loss 0.29492563\n",
      "Trained batch 1159 batch loss 0.32114777 epoch total loss 0.29494822\n",
      "Trained batch 1160 batch loss 0.2896896 epoch total loss 0.29494372\n",
      "Trained batch 1161 batch loss 0.315838456 epoch total loss 0.294961691\n",
      "Trained batch 1162 batch loss 0.280220807 epoch total loss 0.294949\n",
      "Trained batch 1163 batch loss 0.28773272 epoch total loss 0.294942796\n",
      "Trained batch 1164 batch loss 0.29082486 epoch total loss 0.29493925\n",
      "Trained batch 1165 batch loss 0.249779642 epoch total loss 0.294900507\n",
      "Trained batch 1166 batch loss 0.246878743 epoch total loss 0.29485932\n",
      "Trained batch 1167 batch loss 0.268485487 epoch total loss 0.29483673\n",
      "Trained batch 1168 batch loss 0.319184303 epoch total loss 0.294857562\n",
      "Trained batch 1169 batch loss 0.316893607 epoch total loss 0.294876426\n",
      "Trained batch 1170 batch loss 0.330483764 epoch total loss 0.294906855\n",
      "Trained batch 1171 batch loss 0.314295292 epoch total loss 0.294923425\n",
      "Trained batch 1172 batch loss 0.290651858 epoch total loss 0.294919759\n",
      "Trained batch 1173 batch loss 0.294930696 epoch total loss 0.294919759\n",
      "Trained batch 1174 batch loss 0.264005631 epoch total loss 0.294893444\n",
      "Trained batch 1175 batch loss 0.252279729 epoch total loss 0.294857174\n",
      "Trained batch 1176 batch loss 0.272738814 epoch total loss 0.294838369\n",
      "Trained batch 1177 batch loss 0.302050114 epoch total loss 0.294844508\n",
      "Trained batch 1178 batch loss 0.30892846 epoch total loss 0.294856459\n",
      "Trained batch 1179 batch loss 0.285447478 epoch total loss 0.294848502\n",
      "Trained batch 1180 batch loss 0.323253602 epoch total loss 0.294872552\n",
      "Trained batch 1181 batch loss 0.296781182 epoch total loss 0.294874161\n",
      "Trained batch 1182 batch loss 0.292044222 epoch total loss 0.294871777\n",
      "Trained batch 1183 batch loss 0.304022461 epoch total loss 0.294879526\n",
      "Trained batch 1184 batch loss 0.28370291 epoch total loss 0.294870079\n",
      "Trained batch 1185 batch loss 0.3075158 epoch total loss 0.294880748\n",
      "Trained batch 1186 batch loss 0.258925557 epoch total loss 0.294850409\n",
      "Trained batch 1187 batch loss 0.237697214 epoch total loss 0.294802278\n",
      "Trained batch 1188 batch loss 0.246342167 epoch total loss 0.294761479\n",
      "Trained batch 1189 batch loss 0.294949114 epoch total loss 0.294761628\n",
      "Trained batch 1190 batch loss 0.314360797 epoch total loss 0.294778109\n",
      "Trained batch 1191 batch loss 0.31428045 epoch total loss 0.29479447\n",
      "Trained batch 1192 batch loss 0.338253856 epoch total loss 0.294830948\n",
      "Trained batch 1193 batch loss 0.300527364 epoch total loss 0.294835716\n",
      "Trained batch 1194 batch loss 0.292391092 epoch total loss 0.29483366\n",
      "Trained batch 1195 batch loss 0.31475088 epoch total loss 0.294850349\n",
      "Trained batch 1196 batch loss 0.297424853 epoch total loss 0.294852495\n",
      "Trained batch 1197 batch loss 0.326793194 epoch total loss 0.294879168\n",
      "Trained batch 1198 batch loss 0.335796714 epoch total loss 0.294913322\n",
      "Trained batch 1199 batch loss 0.35321188 epoch total loss 0.294961929\n",
      "Trained batch 1200 batch loss 0.330029339 epoch total loss 0.294991136\n",
      "Trained batch 1201 batch loss 0.292463213 epoch total loss 0.29498902\n",
      "Trained batch 1202 batch loss 0.28467533 epoch total loss 0.294980437\n",
      "Trained batch 1203 batch loss 0.284297109 epoch total loss 0.294971585\n",
      "Trained batch 1204 batch loss 0.27801922 epoch total loss 0.294957489\n",
      "Trained batch 1205 batch loss 0.254937708 epoch total loss 0.294924289\n",
      "Trained batch 1206 batch loss 0.28465265 epoch total loss 0.294915766\n",
      "Trained batch 1207 batch loss 0.264642894 epoch total loss 0.294890672\n",
      "Trained batch 1208 batch loss 0.258112192 epoch total loss 0.294860244\n",
      "Trained batch 1209 batch loss 0.249243826 epoch total loss 0.294822484\n",
      "Trained batch 1210 batch loss 0.253466845 epoch total loss 0.294788331\n",
      "Trained batch 1211 batch loss 0.274323583 epoch total loss 0.294771433\n",
      "Trained batch 1212 batch loss 0.282061964 epoch total loss 0.294760942\n",
      "Trained batch 1213 batch loss 0.280793548 epoch total loss 0.294749439\n",
      "Trained batch 1214 batch loss 0.262796223 epoch total loss 0.294723123\n",
      "Trained batch 1215 batch loss 0.261896312 epoch total loss 0.294696093\n",
      "Trained batch 1216 batch loss 0.279035389 epoch total loss 0.294683218\n",
      "Trained batch 1217 batch loss 0.271942943 epoch total loss 0.294664532\n",
      "Trained batch 1218 batch loss 0.274103791 epoch total loss 0.294647634\n",
      "Trained batch 1219 batch loss 0.254893184 epoch total loss 0.29461503\n",
      "Trained batch 1220 batch loss 0.278137296 epoch total loss 0.29460153\n",
      "Trained batch 1221 batch loss 0.334018171 epoch total loss 0.294633806\n",
      "Trained batch 1222 batch loss 0.308620691 epoch total loss 0.29464525\n",
      "Trained batch 1223 batch loss 0.326543301 epoch total loss 0.294671327\n",
      "Trained batch 1224 batch loss 0.311675459 epoch total loss 0.294685215\n",
      "Trained batch 1225 batch loss 0.297059417 epoch total loss 0.294687152\n",
      "Trained batch 1226 batch loss 0.265342414 epoch total loss 0.294663221\n",
      "Trained batch 1227 batch loss 0.261118293 epoch total loss 0.294635862\n",
      "Trained batch 1228 batch loss 0.276677191 epoch total loss 0.294621259\n",
      "Trained batch 1229 batch loss 0.292882353 epoch total loss 0.294619828\n",
      "Trained batch 1230 batch loss 0.322017342 epoch total loss 0.294642121\n",
      "Trained batch 1231 batch loss 0.320843637 epoch total loss 0.29466337\n",
      "Trained batch 1232 batch loss 0.2989721 epoch total loss 0.294666886\n",
      "Trained batch 1233 batch loss 0.28261134 epoch total loss 0.294657111\n",
      "Trained batch 1234 batch loss 0.302533686 epoch total loss 0.294663489\n",
      "Trained batch 1235 batch loss 0.300948381 epoch total loss 0.294668555\n",
      "Trained batch 1236 batch loss 0.233995065 epoch total loss 0.294619501\n",
      "Trained batch 1237 batch loss 0.240579069 epoch total loss 0.294575781\n",
      "Trained batch 1238 batch loss 0.249230623 epoch total loss 0.294539183\n",
      "Trained batch 1239 batch loss 0.31470409 epoch total loss 0.294555455\n",
      "Trained batch 1240 batch loss 0.309053242 epoch total loss 0.294567138\n",
      "Trained batch 1241 batch loss 0.321171016 epoch total loss 0.294588566\n",
      "Trained batch 1242 batch loss 0.314466536 epoch total loss 0.29460457\n",
      "Trained batch 1243 batch loss 0.329612374 epoch total loss 0.294632733\n",
      "Trained batch 1244 batch loss 0.327213854 epoch total loss 0.294658929\n",
      "Trained batch 1245 batch loss 0.287544876 epoch total loss 0.294653207\n",
      "Trained batch 1246 batch loss 0.33967644 epoch total loss 0.294689357\n",
      "Trained batch 1247 batch loss 0.329382926 epoch total loss 0.294717163\n",
      "Trained batch 1248 batch loss 0.304361 epoch total loss 0.294724882\n",
      "Trained batch 1249 batch loss 0.271084189 epoch total loss 0.294705957\n",
      "Trained batch 1250 batch loss 0.266602457 epoch total loss 0.294683486\n",
      "Trained batch 1251 batch loss 0.264388114 epoch total loss 0.294659257\n",
      "Trained batch 1252 batch loss 0.251957506 epoch total loss 0.294625133\n",
      "Trained batch 1253 batch loss 0.280497074 epoch total loss 0.294613838\n",
      "Trained batch 1254 batch loss 0.300402433 epoch total loss 0.294618487\n",
      "Trained batch 1255 batch loss 0.286797106 epoch total loss 0.294612259\n",
      "Trained batch 1256 batch loss 0.32075572 epoch total loss 0.29463309\n",
      "Trained batch 1257 batch loss 0.305533499 epoch total loss 0.294641763\n",
      "Trained batch 1258 batch loss 0.327778757 epoch total loss 0.294668108\n",
      "Trained batch 1259 batch loss 0.286566257 epoch total loss 0.294661671\n",
      "Trained batch 1260 batch loss 0.328873724 epoch total loss 0.294688821\n",
      "Trained batch 1261 batch loss 0.304240286 epoch total loss 0.294696391\n",
      "Trained batch 1262 batch loss 0.318022698 epoch total loss 0.294714868\n",
      "Trained batch 1263 batch loss 0.350445449 epoch total loss 0.294759\n",
      "Trained batch 1264 batch loss 0.331084818 epoch total loss 0.294787735\n",
      "Trained batch 1265 batch loss 0.29601568 epoch total loss 0.294788718\n",
      "Trained batch 1266 batch loss 0.289849401 epoch total loss 0.294784814\n",
      "Trained batch 1267 batch loss 0.286267191 epoch total loss 0.294778079\n",
      "Trained batch 1268 batch loss 0.306974083 epoch total loss 0.294787705\n",
      "Trained batch 1269 batch loss 0.288948178 epoch total loss 0.294783086\n",
      "Trained batch 1270 batch loss 0.339857489 epoch total loss 0.29481858\n",
      "Trained batch 1271 batch loss 0.291687846 epoch total loss 0.294816107\n",
      "Trained batch 1272 batch loss 0.31797123 epoch total loss 0.294834316\n",
      "Trained batch 1273 batch loss 0.325419962 epoch total loss 0.294858336\n",
      "Trained batch 1274 batch loss 0.347093672 epoch total loss 0.294899344\n",
      "Trained batch 1275 batch loss 0.344100088 epoch total loss 0.294937909\n",
      "Trained batch 1276 batch loss 0.322864562 epoch total loss 0.294959813\n",
      "Trained batch 1277 batch loss 0.334854454 epoch total loss 0.294991046\n",
      "Trained batch 1278 batch loss 0.319440365 epoch total loss 0.295010179\n",
      "Trained batch 1279 batch loss 0.324036658 epoch total loss 0.295032889\n",
      "Trained batch 1280 batch loss 0.297028273 epoch total loss 0.295034438\n",
      "Trained batch 1281 batch loss 0.311876923 epoch total loss 0.295047581\n",
      "Trained batch 1282 batch loss 0.267372102 epoch total loss 0.295026\n",
      "Trained batch 1283 batch loss 0.287061125 epoch total loss 0.295019776\n",
      "Trained batch 1284 batch loss 0.267722607 epoch total loss 0.294998527\n",
      "Trained batch 1285 batch loss 0.262245893 epoch total loss 0.294973016\n",
      "Trained batch 1286 batch loss 0.27328831 epoch total loss 0.294956177\n",
      "Trained batch 1287 batch loss 0.257515848 epoch total loss 0.294927061\n",
      "Trained batch 1288 batch loss 0.265829474 epoch total loss 0.29490447\n",
      "Trained batch 1289 batch loss 0.29412514 epoch total loss 0.294903874\n",
      "Trained batch 1290 batch loss 0.269583493 epoch total loss 0.294884264\n",
      "Trained batch 1291 batch loss 0.281398803 epoch total loss 0.294873804\n",
      "Trained batch 1292 batch loss 0.285693735 epoch total loss 0.294866711\n",
      "Trained batch 1293 batch loss 0.31385085 epoch total loss 0.294881403\n",
      "Trained batch 1294 batch loss 0.289555818 epoch total loss 0.294877291\n",
      "Trained batch 1295 batch loss 0.310152948 epoch total loss 0.294889063\n",
      "Trained batch 1296 batch loss 0.327308267 epoch total loss 0.294914067\n",
      "Trained batch 1297 batch loss 0.294914663 epoch total loss 0.294914097\n",
      "Trained batch 1298 batch loss 0.303589135 epoch total loss 0.294920772\n",
      "Trained batch 1299 batch loss 0.285276473 epoch total loss 0.294913352\n",
      "Trained batch 1300 batch loss 0.28767 epoch total loss 0.294907779\n",
      "Trained batch 1301 batch loss 0.26572451 epoch total loss 0.294885337\n",
      "Trained batch 1302 batch loss 0.257359356 epoch total loss 0.294856519\n",
      "Trained batch 1303 batch loss 0.257806271 epoch total loss 0.294828087\n",
      "Trained batch 1304 batch loss 0.301164061 epoch total loss 0.294832945\n",
      "Trained batch 1305 batch loss 0.293774098 epoch total loss 0.29483211\n",
      "Trained batch 1306 batch loss 0.289934397 epoch total loss 0.294828385\n",
      "Trained batch 1307 batch loss 0.305477321 epoch total loss 0.294836521\n",
      "Trained batch 1308 batch loss 0.29828313 epoch total loss 0.294839174\n",
      "Trained batch 1309 batch loss 0.258937687 epoch total loss 0.294811755\n",
      "Trained batch 1310 batch loss 0.299245209 epoch total loss 0.294815123\n",
      "Trained batch 1311 batch loss 0.300310344 epoch total loss 0.294819325\n",
      "Trained batch 1312 batch loss 0.263768703 epoch total loss 0.294795662\n",
      "Trained batch 1313 batch loss 0.265684038 epoch total loss 0.294773489\n",
      "Trained batch 1314 batch loss 0.276983559 epoch total loss 0.294759959\n",
      "Trained batch 1315 batch loss 0.28495127 epoch total loss 0.294752479\n",
      "Trained batch 1316 batch loss 0.289585859 epoch total loss 0.294748545\n",
      "Trained batch 1317 batch loss 0.309414089 epoch total loss 0.294759691\n",
      "Trained batch 1318 batch loss 0.282550097 epoch total loss 0.294750452\n",
      "Trained batch 1319 batch loss 0.252790183 epoch total loss 0.294718623\n",
      "Trained batch 1320 batch loss 0.239926592 epoch total loss 0.294677109\n",
      "Trained batch 1321 batch loss 0.228982195 epoch total loss 0.294627368\n",
      "Trained batch 1322 batch loss 0.230885938 epoch total loss 0.294579178\n",
      "Trained batch 1323 batch loss 0.273577541 epoch total loss 0.294563293\n",
      "Trained batch 1324 batch loss 0.269493103 epoch total loss 0.294544369\n",
      "Trained batch 1325 batch loss 0.270140499 epoch total loss 0.294525951\n",
      "Trained batch 1326 batch loss 0.27406913 epoch total loss 0.294510543\n",
      "Trained batch 1327 batch loss 0.290453374 epoch total loss 0.294507474\n",
      "Trained batch 1328 batch loss 0.281442106 epoch total loss 0.294497639\n",
      "Trained batch 1329 batch loss 0.279884309 epoch total loss 0.294486642\n",
      "Trained batch 1330 batch loss 0.291958839 epoch total loss 0.294484735\n",
      "Trained batch 1331 batch loss 0.325252473 epoch total loss 0.294507861\n",
      "Trained batch 1332 batch loss 0.297201604 epoch total loss 0.294509888\n",
      "Trained batch 1333 batch loss 0.304112643 epoch total loss 0.2945171\n",
      "Trained batch 1334 batch loss 0.27471146 epoch total loss 0.294502258\n",
      "Trained batch 1335 batch loss 0.28042385 epoch total loss 0.294491708\n",
      "Trained batch 1336 batch loss 0.27850914 epoch total loss 0.294479728\n",
      "Trained batch 1337 batch loss 0.32272622 epoch total loss 0.294500858\n",
      "Trained batch 1338 batch loss 0.291947931 epoch total loss 0.29449895\n",
      "Trained batch 1339 batch loss 0.287054569 epoch total loss 0.294493407\n",
      "Trained batch 1340 batch loss 0.331092417 epoch total loss 0.294520706\n",
      "Trained batch 1341 batch loss 0.325394869 epoch total loss 0.294543743\n",
      "Trained batch 1342 batch loss 0.306937546 epoch total loss 0.294552982\n",
      "Trained batch 1343 batch loss 0.315303266 epoch total loss 0.294568449\n",
      "Trained batch 1344 batch loss 0.292438298 epoch total loss 0.29456687\n",
      "Trained batch 1345 batch loss 0.280206323 epoch total loss 0.294556201\n",
      "Trained batch 1346 batch loss 0.277369857 epoch total loss 0.294543415\n",
      "Trained batch 1347 batch loss 0.291103 epoch total loss 0.294540882\n",
      "Trained batch 1348 batch loss 0.277978897 epoch total loss 0.294528574\n",
      "Trained batch 1349 batch loss 0.268062651 epoch total loss 0.294508964\n",
      "Trained batch 1350 batch loss 0.290717691 epoch total loss 0.294506162\n",
      "Trained batch 1351 batch loss 0.274082869 epoch total loss 0.294491023\n",
      "Trained batch 1352 batch loss 0.257248223 epoch total loss 0.294463515\n",
      "Trained batch 1353 batch loss 0.287536919 epoch total loss 0.294458389\n",
      "Trained batch 1354 batch loss 0.265432596 epoch total loss 0.294436961\n",
      "Trained batch 1355 batch loss 0.270187229 epoch total loss 0.29441905\n",
      "Trained batch 1356 batch loss 0.25884524 epoch total loss 0.294392824\n",
      "Trained batch 1357 batch loss 0.237410888 epoch total loss 0.294350803\n",
      "Trained batch 1358 batch loss 0.283657312 epoch total loss 0.294342935\n",
      "Trained batch 1359 batch loss 0.288116813 epoch total loss 0.294338346\n",
      "Trained batch 1360 batch loss 0.295397162 epoch total loss 0.29433915\n",
      "Trained batch 1361 batch loss 0.293166608 epoch total loss 0.294338286\n",
      "Trained batch 1362 batch loss 0.302270293 epoch total loss 0.294344097\n",
      "Trained batch 1363 batch loss 0.322468698 epoch total loss 0.29436475\n",
      "Trained batch 1364 batch loss 0.313467562 epoch total loss 0.294378757\n",
      "Trained batch 1365 batch loss 0.32414639 epoch total loss 0.294400573\n",
      "Trained batch 1366 batch loss 0.290767759 epoch total loss 0.29439792\n",
      "Trained batch 1367 batch loss 0.314205557 epoch total loss 0.294412404\n",
      "Trained batch 1368 batch loss 0.282466829 epoch total loss 0.294403672\n",
      "Trained batch 1369 batch loss 0.284295589 epoch total loss 0.294396311\n",
      "Trained batch 1370 batch loss 0.31812188 epoch total loss 0.294413626\n",
      "Trained batch 1371 batch loss 0.282138079 epoch total loss 0.294404656\n",
      "Trained batch 1372 batch loss 0.27079457 epoch total loss 0.29438743\n",
      "Trained batch 1373 batch loss 0.270675182 epoch total loss 0.294370145\n",
      "Trained batch 1374 batch loss 0.292559832 epoch total loss 0.294368863\n",
      "Trained batch 1375 batch loss 0.257719517 epoch total loss 0.29434219\n",
      "Trained batch 1376 batch loss 0.237768337 epoch total loss 0.294301063\n",
      "Trained batch 1377 batch loss 0.235565305 epoch total loss 0.294258416\n",
      "Trained batch 1378 batch loss 0.297563404 epoch total loss 0.29426083\n",
      "Trained batch 1379 batch loss 0.2663261 epoch total loss 0.294240564\n",
      "Trained batch 1380 batch loss 0.279851615 epoch total loss 0.294230133\n",
      "Trained batch 1381 batch loss 0.256325901 epoch total loss 0.294202685\n",
      "Trained batch 1382 batch loss 0.249671608 epoch total loss 0.294170469\n",
      "Trained batch 1383 batch loss 0.280004054 epoch total loss 0.294160217\n",
      "Trained batch 1384 batch loss 0.314581 epoch total loss 0.294174969\n",
      "Trained batch 1385 batch loss 0.316616833 epoch total loss 0.294191182\n",
      "Trained batch 1386 batch loss 0.291200936 epoch total loss 0.294189\n",
      "Trained batch 1387 batch loss 0.325872958 epoch total loss 0.294211864\n",
      "Trained batch 1388 batch loss 0.311343372 epoch total loss 0.294224203\n",
      "Epoch 3 train loss 0.29422420263290405\n",
      "Validated batch 1 batch loss 0.294462115\n",
      "Validated batch 2 batch loss 0.273473948\n",
      "Validated batch 3 batch loss 0.287851721\n",
      "Validated batch 4 batch loss 0.289783061\n",
      "Validated batch 5 batch loss 0.296751857\n",
      "Validated batch 6 batch loss 0.308242708\n",
      "Validated batch 7 batch loss 0.294686466\n",
      "Validated batch 8 batch loss 0.312052637\n",
      "Validated batch 9 batch loss 0.291929513\n",
      "Validated batch 10 batch loss 0.303804219\n",
      "Validated batch 11 batch loss 0.299606562\n",
      "Validated batch 12 batch loss 0.304524809\n",
      "Validated batch 13 batch loss 0.30818\n",
      "Validated batch 14 batch loss 0.300383836\n",
      "Validated batch 15 batch loss 0.29454422\n",
      "Validated batch 16 batch loss 0.297671467\n",
      "Validated batch 17 batch loss 0.335442811\n",
      "Validated batch 18 batch loss 0.307539672\n",
      "Validated batch 19 batch loss 0.271782726\n",
      "Validated batch 20 batch loss 0.329173893\n",
      "Validated batch 21 batch loss 0.297849476\n",
      "Validated batch 22 batch loss 0.287088156\n",
      "Validated batch 23 batch loss 0.303967\n",
      "Validated batch 24 batch loss 0.324806\n",
      "Validated batch 25 batch loss 0.30965811\n",
      "Validated batch 26 batch loss 0.286103368\n",
      "Validated batch 27 batch loss 0.293130487\n",
      "Validated batch 28 batch loss 0.276448101\n",
      "Validated batch 29 batch loss 0.300900161\n",
      "Validated batch 30 batch loss 0.316178441\n",
      "Validated batch 31 batch loss 0.269109815\n",
      "Validated batch 32 batch loss 0.298297763\n",
      "Validated batch 33 batch loss 0.292331308\n",
      "Validated batch 34 batch loss 0.317564726\n",
      "Validated batch 35 batch loss 0.3042\n",
      "Validated batch 36 batch loss 0.300884128\n",
      "Validated batch 37 batch loss 0.285014391\n",
      "Validated batch 38 batch loss 0.284072757\n",
      "Validated batch 39 batch loss 0.302740484\n",
      "Validated batch 40 batch loss 0.301979125\n",
      "Validated batch 41 batch loss 0.310525835\n",
      "Validated batch 42 batch loss 0.310616314\n",
      "Validated batch 43 batch loss 0.366897941\n",
      "Validated batch 44 batch loss 0.308043718\n",
      "Validated batch 45 batch loss 0.300400555\n",
      "Validated batch 46 batch loss 0.271782815\n",
      "Validated batch 47 batch loss 0.262851387\n",
      "Validated batch 48 batch loss 0.293369889\n",
      "Validated batch 49 batch loss 0.308634102\n",
      "Validated batch 50 batch loss 0.279835194\n",
      "Validated batch 51 batch loss 0.309403896\n",
      "Validated batch 52 batch loss 0.339438915\n",
      "Validated batch 53 batch loss 0.250602752\n",
      "Validated batch 54 batch loss 0.301460117\n",
      "Validated batch 55 batch loss 0.289522529\n",
      "Validated batch 56 batch loss 0.318747044\n",
      "Validated batch 57 batch loss 0.30318439\n",
      "Validated batch 58 batch loss 0.254990757\n",
      "Validated batch 59 batch loss 0.261184096\n",
      "Validated batch 60 batch loss 0.283964872\n",
      "Validated batch 61 batch loss 0.290578485\n",
      "Validated batch 62 batch loss 0.285448849\n",
      "Validated batch 63 batch loss 0.298563927\n",
      "Validated batch 64 batch loss 0.261035204\n",
      "Validated batch 65 batch loss 0.300720483\n",
      "Validated batch 66 batch loss 0.328392386\n",
      "Validated batch 67 batch loss 0.314849138\n",
      "Validated batch 68 batch loss 0.302924156\n",
      "Validated batch 69 batch loss 0.272094935\n",
      "Validated batch 70 batch loss 0.282592714\n",
      "Validated batch 71 batch loss 0.290071815\n",
      "Validated batch 72 batch loss 0.294106215\n",
      "Validated batch 73 batch loss 0.268347293\n",
      "Validated batch 74 batch loss 0.298621863\n",
      "Validated batch 75 batch loss 0.33417204\n",
      "Validated batch 76 batch loss 0.288993686\n",
      "Validated batch 77 batch loss 0.265596896\n",
      "Validated batch 78 batch loss 0.279168129\n",
      "Validated batch 79 batch loss 0.295485884\n",
      "Validated batch 80 batch loss 0.266458422\n",
      "Validated batch 81 batch loss 0.30798462\n",
      "Validated batch 82 batch loss 0.285520613\n",
      "Validated batch 83 batch loss 0.293241948\n",
      "Validated batch 84 batch loss 0.31800133\n",
      "Validated batch 85 batch loss 0.325128317\n",
      "Validated batch 86 batch loss 0.287577838\n",
      "Validated batch 87 batch loss 0.319956779\n",
      "Validated batch 88 batch loss 0.260408372\n",
      "Validated batch 89 batch loss 0.282692462\n",
      "Validated batch 90 batch loss 0.27686\n",
      "Validated batch 91 batch loss 0.296592414\n",
      "Validated batch 92 batch loss 0.35072431\n",
      "Validated batch 93 batch loss 0.296473801\n",
      "Validated batch 94 batch loss 0.275308281\n",
      "Validated batch 95 batch loss 0.287947804\n",
      "Validated batch 96 batch loss 0.277312636\n",
      "Validated batch 97 batch loss 0.283271104\n",
      "Validated batch 98 batch loss 0.320697069\n",
      "Validated batch 99 batch loss 0.297980964\n",
      "Validated batch 100 batch loss 0.31238991\n",
      "Validated batch 101 batch loss 0.31955868\n",
      "Validated batch 102 batch loss 0.309020638\n",
      "Validated batch 103 batch loss 0.310255826\n",
      "Validated batch 104 batch loss 0.347432554\n",
      "Validated batch 105 batch loss 0.311666906\n",
      "Validated batch 106 batch loss 0.319089025\n",
      "Validated batch 107 batch loss 0.31392616\n",
      "Validated batch 108 batch loss 0.339695722\n",
      "Validated batch 109 batch loss 0.33038491\n",
      "Validated batch 110 batch loss 0.284992576\n",
      "Validated batch 111 batch loss 0.311782479\n",
      "Validated batch 112 batch loss 0.331086934\n",
      "Validated batch 113 batch loss 0.319814295\n",
      "Validated batch 114 batch loss 0.296050459\n",
      "Validated batch 115 batch loss 0.299907565\n",
      "Validated batch 116 batch loss 0.314429522\n",
      "Validated batch 117 batch loss 0.30990833\n",
      "Validated batch 118 batch loss 0.283572346\n",
      "Validated batch 119 batch loss 0.300345093\n",
      "Validated batch 120 batch loss 0.296908826\n",
      "Validated batch 121 batch loss 0.299308747\n",
      "Validated batch 122 batch loss 0.317263842\n",
      "Validated batch 123 batch loss 0.292911589\n",
      "Validated batch 124 batch loss 0.287093133\n",
      "Validated batch 125 batch loss 0.33245495\n",
      "Validated batch 126 batch loss 0.281119585\n",
      "Validated batch 127 batch loss 0.278181255\n",
      "Validated batch 128 batch loss 0.289290428\n",
      "Validated batch 129 batch loss 0.339824885\n",
      "Validated batch 130 batch loss 0.336295784\n",
      "Validated batch 131 batch loss 0.336325586\n",
      "Validated batch 132 batch loss 0.298386514\n",
      "Validated batch 133 batch loss 0.337071538\n",
      "Validated batch 134 batch loss 0.298010051\n",
      "Validated batch 135 batch loss 0.327714622\n",
      "Validated batch 136 batch loss 0.311947256\n",
      "Validated batch 137 batch loss 0.247287735\n",
      "Validated batch 138 batch loss 0.299471945\n",
      "Validated batch 139 batch loss 0.307760268\n",
      "Validated batch 140 batch loss 0.314986527\n",
      "Validated batch 141 batch loss 0.301292837\n",
      "Validated batch 142 batch loss 0.274308532\n",
      "Validated batch 143 batch loss 0.311802417\n",
      "Validated batch 144 batch loss 0.315459669\n",
      "Validated batch 145 batch loss 0.328669518\n",
      "Validated batch 146 batch loss 0.325952202\n",
      "Validated batch 147 batch loss 0.319337159\n",
      "Validated batch 148 batch loss 0.292767346\n",
      "Validated batch 149 batch loss 0.303512722\n",
      "Validated batch 150 batch loss 0.311270177\n",
      "Validated batch 151 batch loss 0.308912218\n",
      "Validated batch 152 batch loss 0.321733296\n",
      "Validated batch 153 batch loss 0.335254401\n",
      "Validated batch 154 batch loss 0.313080847\n",
      "Validated batch 155 batch loss 0.339422762\n",
      "Validated batch 156 batch loss 0.297517419\n",
      "Validated batch 157 batch loss 0.301146626\n",
      "Validated batch 158 batch loss 0.29598856\n",
      "Validated batch 159 batch loss 0.271315575\n",
      "Validated batch 160 batch loss 0.319231212\n",
      "Validated batch 161 batch loss 0.304629773\n",
      "Validated batch 162 batch loss 0.305800229\n",
      "Validated batch 163 batch loss 0.299681723\n",
      "Validated batch 164 batch loss 0.304441482\n",
      "Validated batch 165 batch loss 0.29256013\n",
      "Validated batch 166 batch loss 0.314424425\n",
      "Validated batch 167 batch loss 0.348035187\n",
      "Validated batch 168 batch loss 0.297136813\n",
      "Validated batch 169 batch loss 0.305359\n",
      "Validated batch 170 batch loss 0.282899737\n",
      "Validated batch 171 batch loss 0.318658322\n",
      "Validated batch 172 batch loss 0.309487402\n",
      "Validated batch 173 batch loss 0.292693526\n",
      "Validated batch 174 batch loss 0.30641064\n",
      "Validated batch 175 batch loss 0.322902918\n",
      "Validated batch 176 batch loss 0.308149099\n",
      "Validated batch 177 batch loss 0.318165272\n",
      "Validated batch 178 batch loss 0.307963222\n",
      "Validated batch 179 batch loss 0.289074\n",
      "Validated batch 180 batch loss 0.289449275\n",
      "Validated batch 181 batch loss 0.305871606\n",
      "Validated batch 182 batch loss 0.283908427\n",
      "Validated batch 183 batch loss 0.289294\n",
      "Validated batch 184 batch loss 0.298943818\n",
      "Validated batch 185 batch loss 0.348540336\n",
      "Epoch 3 val loss 0.3019943833351135\n",
      "Model /aiffel/aiffel/mpii/models2/model-epoch-3-loss-0.3020.h5 saved.\n",
      "Start epoch 4 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.26235646 epoch total loss 0.26235646\n",
      "Trained batch 2 batch loss 0.250231922 epoch total loss 0.256294191\n",
      "Trained batch 3 batch loss 0.284995973 epoch total loss 0.265861452\n",
      "Trained batch 4 batch loss 0.270536721 epoch total loss 0.267030269\n",
      "Trained batch 5 batch loss 0.250814706 epoch total loss 0.26378715\n",
      "Trained batch 6 batch loss 0.252515227 epoch total loss 0.261908501\n",
      "Trained batch 7 batch loss 0.256629914 epoch total loss 0.261154413\n",
      "Trained batch 8 batch loss 0.250457108 epoch total loss 0.259817243\n",
      "Trained batch 9 batch loss 0.233687475 epoch total loss 0.25691393\n",
      "Trained batch 10 batch loss 0.205642462 epoch total loss 0.251786768\n",
      "Trained batch 11 batch loss 0.232228041 epoch total loss 0.250008702\n",
      "Trained batch 12 batch loss 0.255865872 epoch total loss 0.250496805\n",
      "Trained batch 13 batch loss 0.236590162 epoch total loss 0.249427065\n",
      "Trained batch 14 batch loss 0.225903884 epoch total loss 0.24774684\n",
      "Trained batch 15 batch loss 0.245160729 epoch total loss 0.247574434\n",
      "Trained batch 16 batch loss 0.238723263 epoch total loss 0.247021243\n",
      "Trained batch 17 batch loss 0.265057743 epoch total loss 0.248082221\n",
      "Trained batch 18 batch loss 0.284553945 epoch total loss 0.250108421\n",
      "Trained batch 19 batch loss 0.284528553 epoch total loss 0.25192\n",
      "Trained batch 20 batch loss 0.28364265 epoch total loss 0.253506154\n",
      "Trained batch 21 batch loss 0.263418764 epoch total loss 0.253978193\n",
      "Trained batch 22 batch loss 0.297345608 epoch total loss 0.255949438\n",
      "Trained batch 23 batch loss 0.304316789 epoch total loss 0.258052379\n",
      "Trained batch 24 batch loss 0.313748389 epoch total loss 0.260373026\n",
      "Trained batch 25 batch loss 0.306806177 epoch total loss 0.262230366\n",
      "Trained batch 26 batch loss 0.302951694 epoch total loss 0.263796568\n",
      "Trained batch 27 batch loss 0.334569514 epoch total loss 0.266417772\n",
      "Trained batch 28 batch loss 0.300462157 epoch total loss 0.267633647\n",
      "Trained batch 29 batch loss 0.311006337 epoch total loss 0.269129276\n",
      "Trained batch 30 batch loss 0.325339377 epoch total loss 0.271002948\n",
      "Trained batch 31 batch loss 0.311050892 epoch total loss 0.272294819\n",
      "Trained batch 32 batch loss 0.288833886 epoch total loss 0.272811651\n",
      "Trained batch 33 batch loss 0.308200032 epoch total loss 0.273884028\n",
      "Trained batch 34 batch loss 0.262088805 epoch total loss 0.273537099\n",
      "Trained batch 35 batch loss 0.289004683 epoch total loss 0.273979038\n",
      "Trained batch 36 batch loss 0.288203537 epoch total loss 0.274374127\n",
      "Trained batch 37 batch loss 0.296119362 epoch total loss 0.274961859\n",
      "Trained batch 38 batch loss 0.300688654 epoch total loss 0.275638878\n",
      "Trained batch 39 batch loss 0.271664917 epoch total loss 0.275536984\n",
      "Trained batch 40 batch loss 0.302982688 epoch total loss 0.276223123\n",
      "Trained batch 41 batch loss 0.283902824 epoch total loss 0.276410431\n",
      "Trained batch 42 batch loss 0.263927579 epoch total loss 0.276113212\n",
      "Trained batch 43 batch loss 0.292541087 epoch total loss 0.276495278\n",
      "Trained batch 44 batch loss 0.279033124 epoch total loss 0.276552945\n",
      "Trained batch 45 batch loss 0.281475 epoch total loss 0.27666232\n",
      "Trained batch 46 batch loss 0.302657157 epoch total loss 0.277227432\n",
      "Trained batch 47 batch loss 0.304304063 epoch total loss 0.27780351\n",
      "Trained batch 48 batch loss 0.260468572 epoch total loss 0.277442366\n",
      "Trained batch 49 batch loss 0.301739663 epoch total loss 0.277938247\n",
      "Trained batch 50 batch loss 0.259196043 epoch total loss 0.277563393\n",
      "Trained batch 51 batch loss 0.287335336 epoch total loss 0.277755022\n",
      "Trained batch 52 batch loss 0.291882396 epoch total loss 0.2780267\n",
      "Trained batch 53 batch loss 0.289485186 epoch total loss 0.278242886\n",
      "Trained batch 54 batch loss 0.293528736 epoch total loss 0.278525949\n",
      "Trained batch 55 batch loss 0.266943127 epoch total loss 0.278315365\n",
      "Trained batch 56 batch loss 0.292237312 epoch total loss 0.278563946\n",
      "Trained batch 57 batch loss 0.291013867 epoch total loss 0.278782368\n",
      "Trained batch 58 batch loss 0.29319337 epoch total loss 0.27903083\n",
      "Trained batch 59 batch loss 0.277622879 epoch total loss 0.279006958\n",
      "Trained batch 60 batch loss 0.287696451 epoch total loss 0.279151797\n",
      "Trained batch 61 batch loss 0.284115106 epoch total loss 0.279233158\n",
      "Trained batch 62 batch loss 0.308725655 epoch total loss 0.279708833\n",
      "Trained batch 63 batch loss 0.255125046 epoch total loss 0.279318601\n",
      "Trained batch 64 batch loss 0.289040476 epoch total loss 0.279470503\n",
      "Trained batch 65 batch loss 0.306621522 epoch total loss 0.279888213\n",
      "Trained batch 66 batch loss 0.324236453 epoch total loss 0.280560136\n",
      "Trained batch 67 batch loss 0.297311813 epoch total loss 0.280810177\n",
      "Trained batch 68 batch loss 0.273608446 epoch total loss 0.28070426\n",
      "Trained batch 69 batch loss 0.247338802 epoch total loss 0.280220717\n",
      "Trained batch 70 batch loss 0.300894618 epoch total loss 0.280516058\n",
      "Trained batch 71 batch loss 0.299255 epoch total loss 0.28078\n",
      "Trained batch 72 batch loss 0.318162918 epoch total loss 0.281299204\n",
      "Trained batch 73 batch loss 0.317076713 epoch total loss 0.281789303\n",
      "Trained batch 74 batch loss 0.271705866 epoch total loss 0.281653047\n",
      "Trained batch 75 batch loss 0.305379242 epoch total loss 0.281969398\n",
      "Trained batch 76 batch loss 0.2692689 epoch total loss 0.281802267\n",
      "Trained batch 77 batch loss 0.289796203 epoch total loss 0.281906098\n",
      "Trained batch 78 batch loss 0.280026853 epoch total loss 0.281882018\n",
      "Trained batch 79 batch loss 0.285499573 epoch total loss 0.281927794\n",
      "Trained batch 80 batch loss 0.278027445 epoch total loss 0.281879038\n",
      "Trained batch 81 batch loss 0.292903751 epoch total loss 0.282015145\n",
      "Trained batch 82 batch loss 0.299811482 epoch total loss 0.282232195\n",
      "Trained batch 83 batch loss 0.295434 epoch total loss 0.28239125\n",
      "Trained batch 84 batch loss 0.296625882 epoch total loss 0.282560676\n",
      "Trained batch 85 batch loss 0.308931947 epoch total loss 0.282870919\n",
      "Trained batch 86 batch loss 0.307109773 epoch total loss 0.283152789\n",
      "Trained batch 87 batch loss 0.314628035 epoch total loss 0.283514559\n",
      "Trained batch 88 batch loss 0.333540142 epoch total loss 0.284083039\n",
      "Trained batch 89 batch loss 0.3269099 epoch total loss 0.284564257\n",
      "Trained batch 90 batch loss 0.302202791 epoch total loss 0.284760207\n",
      "Trained batch 91 batch loss 0.303728431 epoch total loss 0.284968644\n",
      "Trained batch 92 batch loss 0.297674149 epoch total loss 0.285106748\n",
      "Trained batch 93 batch loss 0.294691324 epoch total loss 0.285209835\n",
      "Trained batch 94 batch loss 0.264410436 epoch total loss 0.284988552\n",
      "Trained batch 95 batch loss 0.287264198 epoch total loss 0.285012484\n",
      "Trained batch 96 batch loss 0.322785109 epoch total loss 0.285405964\n",
      "Trained batch 97 batch loss 0.285767853 epoch total loss 0.285409689\n",
      "Trained batch 98 batch loss 0.277714491 epoch total loss 0.28533116\n",
      "Trained batch 99 batch loss 0.294476748 epoch total loss 0.285423547\n",
      "Trained batch 100 batch loss 0.273686349 epoch total loss 0.285306156\n",
      "Trained batch 101 batch loss 0.256574422 epoch total loss 0.285021693\n",
      "Trained batch 102 batch loss 0.258352339 epoch total loss 0.284760237\n",
      "Trained batch 103 batch loss 0.298567951 epoch total loss 0.284894288\n",
      "Trained batch 104 batch loss 0.275952339 epoch total loss 0.284808308\n",
      "Trained batch 105 batch loss 0.241595581 epoch total loss 0.284396768\n",
      "Trained batch 106 batch loss 0.257936686 epoch total loss 0.284147143\n",
      "Trained batch 107 batch loss 0.2651622 epoch total loss 0.2839697\n",
      "Trained batch 108 batch loss 0.303853929 epoch total loss 0.284153819\n",
      "Trained batch 109 batch loss 0.274196148 epoch total loss 0.284062475\n",
      "Trained batch 110 batch loss 0.284191608 epoch total loss 0.284063637\n",
      "Trained batch 111 batch loss 0.290564924 epoch total loss 0.284122199\n",
      "Trained batch 112 batch loss 0.325751156 epoch total loss 0.284493893\n",
      "Trained batch 113 batch loss 0.335056514 epoch total loss 0.284941345\n",
      "Trained batch 114 batch loss 0.324403822 epoch total loss 0.285287529\n",
      "Trained batch 115 batch loss 0.333390415 epoch total loss 0.285705805\n",
      "Trained batch 116 batch loss 0.29548502 epoch total loss 0.285790116\n",
      "Trained batch 117 batch loss 0.296171278 epoch total loss 0.285878867\n",
      "Trained batch 118 batch loss 0.249904588 epoch total loss 0.285574\n",
      "Trained batch 119 batch loss 0.276710927 epoch total loss 0.285499513\n",
      "Trained batch 120 batch loss 0.302508891 epoch total loss 0.285641253\n",
      "Trained batch 121 batch loss 0.312002808 epoch total loss 0.285859138\n",
      "Trained batch 122 batch loss 0.287849307 epoch total loss 0.28587544\n",
      "Trained batch 123 batch loss 0.291301608 epoch total loss 0.285919547\n",
      "Trained batch 124 batch loss 0.252153 epoch total loss 0.285647243\n",
      "Trained batch 125 batch loss 0.257515281 epoch total loss 0.285422176\n",
      "Trained batch 126 batch loss 0.242786482 epoch total loss 0.285083801\n",
      "Trained batch 127 batch loss 0.274250031 epoch total loss 0.284998506\n",
      "Trained batch 128 batch loss 0.265738726 epoch total loss 0.284848034\n",
      "Trained batch 129 batch loss 0.269705415 epoch total loss 0.284730673\n",
      "Trained batch 130 batch loss 0.251911789 epoch total loss 0.284478188\n",
      "Trained batch 131 batch loss 0.218964964 epoch total loss 0.283978105\n",
      "Trained batch 132 batch loss 0.249108091 epoch total loss 0.283713907\n",
      "Trained batch 133 batch loss 0.293029815 epoch total loss 0.283783972\n",
      "Trained batch 134 batch loss 0.302579969 epoch total loss 0.283924252\n",
      "Trained batch 135 batch loss 0.310832858 epoch total loss 0.28412357\n",
      "Trained batch 136 batch loss 0.289816141 epoch total loss 0.284165442\n",
      "Trained batch 137 batch loss 0.342633903 epoch total loss 0.284592211\n",
      "Trained batch 138 batch loss 0.283363312 epoch total loss 0.2845833\n",
      "Trained batch 139 batch loss 0.287320524 epoch total loss 0.28460297\n",
      "Trained batch 140 batch loss 0.297441065 epoch total loss 0.284694672\n",
      "Trained batch 141 batch loss 0.313979298 epoch total loss 0.284902364\n",
      "Trained batch 142 batch loss 0.285222054 epoch total loss 0.284904629\n",
      "Trained batch 143 batch loss 0.266194075 epoch total loss 0.284773767\n",
      "Trained batch 144 batch loss 0.26828298 epoch total loss 0.284659266\n",
      "Trained batch 145 batch loss 0.216306716 epoch total loss 0.284187883\n",
      "Trained batch 146 batch loss 0.260838926 epoch total loss 0.284027934\n",
      "Trained batch 147 batch loss 0.284862876 epoch total loss 0.284033626\n",
      "Trained batch 148 batch loss 0.275508165 epoch total loss 0.283976018\n",
      "Trained batch 149 batch loss 0.280604124 epoch total loss 0.283953398\n",
      "Trained batch 150 batch loss 0.298836291 epoch total loss 0.28405261\n",
      "Trained batch 151 batch loss 0.315116912 epoch total loss 0.284258336\n",
      "Trained batch 152 batch loss 0.268758833 epoch total loss 0.284156382\n",
      "Trained batch 153 batch loss 0.252021223 epoch total loss 0.283946335\n",
      "Trained batch 154 batch loss 0.286581844 epoch total loss 0.283963472\n",
      "Trained batch 155 batch loss 0.272587091 epoch total loss 0.283890069\n",
      "Trained batch 156 batch loss 0.276424885 epoch total loss 0.283842206\n",
      "Trained batch 157 batch loss 0.292603195 epoch total loss 0.283898\n",
      "Trained batch 158 batch loss 0.279786289 epoch total loss 0.283871979\n",
      "Trained batch 159 batch loss 0.268296331 epoch total loss 0.283774018\n",
      "Trained batch 160 batch loss 0.285671502 epoch total loss 0.28378588\n",
      "Trained batch 161 batch loss 0.271731883 epoch total loss 0.283711\n",
      "Trained batch 162 batch loss 0.307067513 epoch total loss 0.28385517\n",
      "Trained batch 163 batch loss 0.254882187 epoch total loss 0.283677429\n",
      "Trained batch 164 batch loss 0.278195232 epoch total loss 0.283644\n",
      "Trained batch 165 batch loss 0.260374814 epoch total loss 0.283503\n",
      "Trained batch 166 batch loss 0.277890503 epoch total loss 0.28346917\n",
      "Trained batch 167 batch loss 0.272472352 epoch total loss 0.283403307\n",
      "Trained batch 168 batch loss 0.293087751 epoch total loss 0.283460945\n",
      "Trained batch 169 batch loss 0.330322802 epoch total loss 0.283738256\n",
      "Trained batch 170 batch loss 0.298581779 epoch total loss 0.283825547\n",
      "Trained batch 171 batch loss 0.300101817 epoch total loss 0.283920735\n",
      "Trained batch 172 batch loss 0.29560703 epoch total loss 0.283988684\n",
      "Trained batch 173 batch loss 0.272183955 epoch total loss 0.283920437\n",
      "Trained batch 174 batch loss 0.254416764 epoch total loss 0.283750892\n",
      "Trained batch 175 batch loss 0.314270586 epoch total loss 0.283925265\n",
      "Trained batch 176 batch loss 0.329435229 epoch total loss 0.28418386\n",
      "Trained batch 177 batch loss 0.322718769 epoch total loss 0.284401566\n",
      "Trained batch 178 batch loss 0.347070903 epoch total loss 0.28475365\n",
      "Trained batch 179 batch loss 0.308683395 epoch total loss 0.284887344\n",
      "Trained batch 180 batch loss 0.309759587 epoch total loss 0.285025537\n",
      "Trained batch 181 batch loss 0.301411062 epoch total loss 0.285116047\n",
      "Trained batch 182 batch loss 0.313063741 epoch total loss 0.285269618\n",
      "Trained batch 183 batch loss 0.286682 epoch total loss 0.285277337\n",
      "Trained batch 184 batch loss 0.311524868 epoch total loss 0.285419971\n",
      "Trained batch 185 batch loss 0.289954513 epoch total loss 0.285444498\n",
      "Trained batch 186 batch loss 0.265096068 epoch total loss 0.285335094\n",
      "Trained batch 187 batch loss 0.288900584 epoch total loss 0.285354167\n",
      "Trained batch 188 batch loss 0.268419266 epoch total loss 0.285264075\n",
      "Trained batch 189 batch loss 0.25221011 epoch total loss 0.285089195\n",
      "Trained batch 190 batch loss 0.233470008 epoch total loss 0.284817517\n",
      "Trained batch 191 batch loss 0.268538743 epoch total loss 0.284732282\n",
      "Trained batch 192 batch loss 0.313139558 epoch total loss 0.284880251\n",
      "Trained batch 193 batch loss 0.302197397 epoch total loss 0.284969956\n",
      "Trained batch 194 batch loss 0.32019344 epoch total loss 0.285151541\n",
      "Trained batch 195 batch loss 0.316307753 epoch total loss 0.285311311\n",
      "Trained batch 196 batch loss 0.280183941 epoch total loss 0.285285145\n",
      "Trained batch 197 batch loss 0.311890781 epoch total loss 0.285420209\n",
      "Trained batch 198 batch loss 0.318032742 epoch total loss 0.285584897\n",
      "Trained batch 199 batch loss 0.295147359 epoch total loss 0.285632938\n",
      "Trained batch 200 batch loss 0.301974982 epoch total loss 0.285714656\n",
      "Trained batch 201 batch loss 0.312826574 epoch total loss 0.285849571\n",
      "Trained batch 202 batch loss 0.29973793 epoch total loss 0.285918325\n",
      "Trained batch 203 batch loss 0.304722488 epoch total loss 0.286010951\n",
      "Trained batch 204 batch loss 0.285064429 epoch total loss 0.286006302\n",
      "Trained batch 205 batch loss 0.31603536 epoch total loss 0.28615281\n",
      "Trained batch 206 batch loss 0.30631423 epoch total loss 0.286250651\n",
      "Trained batch 207 batch loss 0.291644633 epoch total loss 0.286276728\n",
      "Trained batch 208 batch loss 0.300011575 epoch total loss 0.28634274\n",
      "Trained batch 209 batch loss 0.303800583 epoch total loss 0.286426276\n",
      "Trained batch 210 batch loss 0.305355161 epoch total loss 0.286516398\n",
      "Trained batch 211 batch loss 0.253361404 epoch total loss 0.28635928\n",
      "Trained batch 212 batch loss 0.305695921 epoch total loss 0.286450475\n",
      "Trained batch 213 batch loss 0.321216136 epoch total loss 0.286613703\n",
      "Trained batch 214 batch loss 0.27451849 epoch total loss 0.286557168\n",
      "Trained batch 215 batch loss 0.279565096 epoch total loss 0.286524653\n",
      "Trained batch 216 batch loss 0.272703439 epoch total loss 0.286460668\n",
      "Trained batch 217 batch loss 0.259966433 epoch total loss 0.286338568\n",
      "Trained batch 218 batch loss 0.301097751 epoch total loss 0.286406279\n",
      "Trained batch 219 batch loss 0.283450782 epoch total loss 0.286392778\n",
      "Trained batch 220 batch loss 0.243543193 epoch total loss 0.28619802\n",
      "Trained batch 221 batch loss 0.23016274 epoch total loss 0.285944462\n",
      "Trained batch 222 batch loss 0.283170938 epoch total loss 0.285931975\n",
      "Trained batch 223 batch loss 0.240104079 epoch total loss 0.285726458\n",
      "Trained batch 224 batch loss 0.281214923 epoch total loss 0.285706341\n",
      "Trained batch 225 batch loss 0.271442145 epoch total loss 0.285642952\n",
      "Trained batch 226 batch loss 0.259819537 epoch total loss 0.28552866\n",
      "Trained batch 227 batch loss 0.314563155 epoch total loss 0.285656571\n",
      "Trained batch 228 batch loss 0.308976769 epoch total loss 0.285758853\n",
      "Trained batch 229 batch loss 0.2951805 epoch total loss 0.28579998\n",
      "Trained batch 230 batch loss 0.305538416 epoch total loss 0.285885811\n",
      "Trained batch 231 batch loss 0.265668482 epoch total loss 0.285798311\n",
      "Trained batch 232 batch loss 0.255678296 epoch total loss 0.285668463\n",
      "Trained batch 233 batch loss 0.288056731 epoch total loss 0.285678715\n",
      "Trained batch 234 batch loss 0.300822288 epoch total loss 0.285743415\n",
      "Trained batch 235 batch loss 0.303032577 epoch total loss 0.285817\n",
      "Trained batch 236 batch loss 0.303279847 epoch total loss 0.285890967\n",
      "Trained batch 237 batch loss 0.288219333 epoch total loss 0.285900772\n",
      "Trained batch 238 batch loss 0.269082129 epoch total loss 0.28583011\n",
      "Trained batch 239 batch loss 0.30119738 epoch total loss 0.285894424\n",
      "Trained batch 240 batch loss 0.286945492 epoch total loss 0.285898805\n",
      "Trained batch 241 batch loss 0.292557538 epoch total loss 0.285926431\n",
      "Trained batch 242 batch loss 0.295419246 epoch total loss 0.285965651\n",
      "Trained batch 243 batch loss 0.322632104 epoch total loss 0.28611654\n",
      "Trained batch 244 batch loss 0.292344332 epoch total loss 0.286142081\n",
      "Trained batch 245 batch loss 0.304689169 epoch total loss 0.286217749\n",
      "Trained batch 246 batch loss 0.285114825 epoch total loss 0.286213279\n",
      "Trained batch 247 batch loss 0.294917285 epoch total loss 0.286248505\n",
      "Trained batch 248 batch loss 0.280768305 epoch total loss 0.286226422\n",
      "Trained batch 249 batch loss 0.279899895 epoch total loss 0.28620103\n",
      "Trained batch 250 batch loss 0.291490555 epoch total loss 0.28622216\n",
      "Trained batch 251 batch loss 0.307407826 epoch total loss 0.28630659\n",
      "Trained batch 252 batch loss 0.294494241 epoch total loss 0.286339074\n",
      "Trained batch 253 batch loss 0.25493753 epoch total loss 0.286214948\n",
      "Trained batch 254 batch loss 0.245210871 epoch total loss 0.286053509\n",
      "Trained batch 255 batch loss 0.23439005 epoch total loss 0.285850912\n",
      "Trained batch 256 batch loss 0.274767041 epoch total loss 0.28580761\n",
      "Trained batch 257 batch loss 0.275159299 epoch total loss 0.285766184\n",
      "Trained batch 258 batch loss 0.256081581 epoch total loss 0.285651118\n",
      "Trained batch 259 batch loss 0.228722468 epoch total loss 0.285431325\n",
      "Trained batch 260 batch loss 0.262720615 epoch total loss 0.285343975\n",
      "Trained batch 261 batch loss 0.285944611 epoch total loss 0.28534624\n",
      "Trained batch 262 batch loss 0.286834061 epoch total loss 0.285351932\n",
      "Trained batch 263 batch loss 0.275041 epoch total loss 0.285312712\n",
      "Trained batch 264 batch loss 0.262428403 epoch total loss 0.285226047\n",
      "Trained batch 265 batch loss 0.276319921 epoch total loss 0.28519243\n",
      "Trained batch 266 batch loss 0.2885952 epoch total loss 0.285205245\n",
      "Trained batch 267 batch loss 0.29856354 epoch total loss 0.285255253\n",
      "Trained batch 268 batch loss 0.276907682 epoch total loss 0.28522411\n",
      "Trained batch 269 batch loss 0.289871156 epoch total loss 0.285241395\n",
      "Trained batch 270 batch loss 0.297788858 epoch total loss 0.285287857\n",
      "Trained batch 271 batch loss 0.316306859 epoch total loss 0.285402328\n",
      "Trained batch 272 batch loss 0.300860614 epoch total loss 0.285459161\n",
      "Trained batch 273 batch loss 0.318949163 epoch total loss 0.285581827\n",
      "Trained batch 274 batch loss 0.320195079 epoch total loss 0.285708159\n",
      "Trained batch 275 batch loss 0.286507338 epoch total loss 0.28571105\n",
      "Trained batch 276 batch loss 0.294956923 epoch total loss 0.285744578\n",
      "Trained batch 277 batch loss 0.273487657 epoch total loss 0.285700321\n",
      "Trained batch 278 batch loss 0.288967729 epoch total loss 0.285712093\n",
      "Trained batch 279 batch loss 0.246520594 epoch total loss 0.285571635\n",
      "Trained batch 280 batch loss 0.27252996 epoch total loss 0.285525054\n",
      "Trained batch 281 batch loss 0.278917938 epoch total loss 0.28550154\n",
      "Trained batch 282 batch loss 0.28373152 epoch total loss 0.285495251\n",
      "Trained batch 283 batch loss 0.284274459 epoch total loss 0.28549093\n",
      "Trained batch 284 batch loss 0.29659462 epoch total loss 0.28553\n",
      "Trained batch 285 batch loss 0.310660273 epoch total loss 0.285618186\n",
      "Trained batch 286 batch loss 0.304115385 epoch total loss 0.285682857\n",
      "Trained batch 287 batch loss 0.340662092 epoch total loss 0.285874426\n",
      "Trained batch 288 batch loss 0.329442471 epoch total loss 0.286025703\n",
      "Trained batch 289 batch loss 0.298009217 epoch total loss 0.286067188\n",
      "Trained batch 290 batch loss 0.288639188 epoch total loss 0.286076069\n",
      "Trained batch 291 batch loss 0.243367791 epoch total loss 0.285929322\n",
      "Trained batch 292 batch loss 0.229079932 epoch total loss 0.285734624\n",
      "Trained batch 293 batch loss 0.259623319 epoch total loss 0.285645485\n",
      "Trained batch 294 batch loss 0.285535157 epoch total loss 0.285645127\n",
      "Trained batch 295 batch loss 0.219006181 epoch total loss 0.285419255\n",
      "Trained batch 296 batch loss 0.23315677 epoch total loss 0.285242677\n",
      "Trained batch 297 batch loss 0.241215214 epoch total loss 0.28509444\n",
      "Trained batch 298 batch loss 0.22936365 epoch total loss 0.28490743\n",
      "Trained batch 299 batch loss 0.269859731 epoch total loss 0.284857094\n",
      "Trained batch 300 batch loss 0.279502034 epoch total loss 0.284839243\n",
      "Trained batch 301 batch loss 0.279910684 epoch total loss 0.284822851\n",
      "Trained batch 302 batch loss 0.278558165 epoch total loss 0.284802109\n",
      "Trained batch 303 batch loss 0.303965807 epoch total loss 0.28486535\n",
      "Trained batch 304 batch loss 0.31693086 epoch total loss 0.28497085\n",
      "Trained batch 305 batch loss 0.290668845 epoch total loss 0.284989536\n",
      "Trained batch 306 batch loss 0.30864 epoch total loss 0.285066813\n",
      "Trained batch 307 batch loss 0.274764478 epoch total loss 0.285033256\n",
      "Trained batch 308 batch loss 0.267432272 epoch total loss 0.284976125\n",
      "Trained batch 309 batch loss 0.272908419 epoch total loss 0.284937084\n",
      "Trained batch 310 batch loss 0.247377977 epoch total loss 0.284815907\n",
      "Trained batch 311 batch loss 0.276726693 epoch total loss 0.28478989\n",
      "Trained batch 312 batch loss 0.258602887 epoch total loss 0.284705967\n",
      "Trained batch 313 batch loss 0.270659089 epoch total loss 0.284661084\n",
      "Trained batch 314 batch loss 0.246623889 epoch total loss 0.284539938\n",
      "Trained batch 315 batch loss 0.266032666 epoch total loss 0.284481168\n",
      "Trained batch 316 batch loss 0.28448084 epoch total loss 0.284481168\n",
      "Trained batch 317 batch loss 0.269869268 epoch total loss 0.284435064\n",
      "Trained batch 318 batch loss 0.30578959 epoch total loss 0.284502208\n",
      "Trained batch 319 batch loss 0.282911658 epoch total loss 0.284497231\n",
      "Trained batch 320 batch loss 0.279370487 epoch total loss 0.284481227\n",
      "Trained batch 321 batch loss 0.2876167 epoch total loss 0.284490973\n",
      "Trained batch 322 batch loss 0.272065043 epoch total loss 0.284452379\n",
      "Trained batch 323 batch loss 0.269711196 epoch total loss 0.284406751\n",
      "Trained batch 324 batch loss 0.310616195 epoch total loss 0.284487635\n",
      "Trained batch 325 batch loss 0.291127682 epoch total loss 0.284508079\n",
      "Trained batch 326 batch loss 0.316312164 epoch total loss 0.284605652\n",
      "Trained batch 327 batch loss 0.288148791 epoch total loss 0.28461647\n",
      "Trained batch 328 batch loss 0.316504449 epoch total loss 0.284713686\n",
      "Trained batch 329 batch loss 0.295489609 epoch total loss 0.284746438\n",
      "Trained batch 330 batch loss 0.256945223 epoch total loss 0.284662187\n",
      "Trained batch 331 batch loss 0.260103405 epoch total loss 0.284587979\n",
      "Trained batch 332 batch loss 0.275736332 epoch total loss 0.284561306\n",
      "Trained batch 333 batch loss 0.286333323 epoch total loss 0.284566641\n",
      "Trained batch 334 batch loss 0.292750657 epoch total loss 0.284591138\n",
      "Trained batch 335 batch loss 0.300679207 epoch total loss 0.28463915\n",
      "Trained batch 336 batch loss 0.287062883 epoch total loss 0.284646362\n",
      "Trained batch 337 batch loss 0.262306094 epoch total loss 0.284580082\n",
      "Trained batch 338 batch loss 0.286000937 epoch total loss 0.284584284\n",
      "Trained batch 339 batch loss 0.293670952 epoch total loss 0.284611106\n",
      "Trained batch 340 batch loss 0.259150594 epoch total loss 0.284536213\n",
      "Trained batch 341 batch loss 0.28016606 epoch total loss 0.284523398\n",
      "Trained batch 342 batch loss 0.28786695 epoch total loss 0.284533173\n",
      "Trained batch 343 batch loss 0.288719893 epoch total loss 0.284545362\n",
      "Trained batch 344 batch loss 0.282414198 epoch total loss 0.284539193\n",
      "Trained batch 345 batch loss 0.266281694 epoch total loss 0.284486264\n",
      "Trained batch 346 batch loss 0.251221269 epoch total loss 0.284390122\n",
      "Trained batch 347 batch loss 0.241200268 epoch total loss 0.284265667\n",
      "Trained batch 348 batch loss 0.210313946 epoch total loss 0.284053147\n",
      "Trained batch 349 batch loss 0.278109908 epoch total loss 0.2840361\n",
      "Trained batch 350 batch loss 0.295503557 epoch total loss 0.284068853\n",
      "Trained batch 351 batch loss 0.302515596 epoch total loss 0.284121424\n",
      "Trained batch 352 batch loss 0.305852562 epoch total loss 0.284183145\n",
      "Trained batch 353 batch loss 0.326732844 epoch total loss 0.284303695\n",
      "Trained batch 354 batch loss 0.287748516 epoch total loss 0.28431344\n",
      "Trained batch 355 batch loss 0.274095565 epoch total loss 0.284284651\n",
      "Trained batch 356 batch loss 0.257036567 epoch total loss 0.284208119\n",
      "Trained batch 357 batch loss 0.274532378 epoch total loss 0.284181\n",
      "Trained batch 358 batch loss 0.287166238 epoch total loss 0.284189343\n",
      "Trained batch 359 batch loss 0.258511484 epoch total loss 0.284117818\n",
      "Trained batch 360 batch loss 0.327517152 epoch total loss 0.284238368\n",
      "Trained batch 361 batch loss 0.297912806 epoch total loss 0.284276247\n",
      "Trained batch 362 batch loss 0.295971692 epoch total loss 0.284308553\n",
      "Trained batch 363 batch loss 0.307639062 epoch total loss 0.284372836\n",
      "Trained batch 364 batch loss 0.347216129 epoch total loss 0.284545481\n",
      "Trained batch 365 batch loss 0.319012791 epoch total loss 0.284639925\n",
      "Trained batch 366 batch loss 0.320685983 epoch total loss 0.284738392\n",
      "Trained batch 367 batch loss 0.326069802 epoch total loss 0.284851044\n",
      "Trained batch 368 batch loss 0.32245928 epoch total loss 0.284953207\n",
      "Trained batch 369 batch loss 0.287685186 epoch total loss 0.284960628\n",
      "Trained batch 370 batch loss 0.284958899 epoch total loss 0.284960598\n",
      "Trained batch 371 batch loss 0.324649036 epoch total loss 0.285067588\n",
      "Trained batch 372 batch loss 0.348479211 epoch total loss 0.285238028\n",
      "Trained batch 373 batch loss 0.318701267 epoch total loss 0.285327762\n",
      "Trained batch 374 batch loss 0.30196172 epoch total loss 0.285372227\n",
      "Trained batch 375 batch loss 0.284959376 epoch total loss 0.285371125\n",
      "Trained batch 376 batch loss 0.294100821 epoch total loss 0.285394341\n",
      "Trained batch 377 batch loss 0.225594074 epoch total loss 0.285235733\n",
      "Trained batch 378 batch loss 0.319674402 epoch total loss 0.285326809\n",
      "Trained batch 379 batch loss 0.298946947 epoch total loss 0.28536278\n",
      "Trained batch 380 batch loss 0.243410066 epoch total loss 0.285252362\n",
      "Trained batch 381 batch loss 0.243773431 epoch total loss 0.285143495\n",
      "Trained batch 382 batch loss 0.265744448 epoch total loss 0.285092711\n",
      "Trained batch 383 batch loss 0.237527177 epoch total loss 0.284968525\n",
      "Trained batch 384 batch loss 0.271667719 epoch total loss 0.284933895\n",
      "Trained batch 385 batch loss 0.337458 epoch total loss 0.2850703\n",
      "Trained batch 386 batch loss 0.347856909 epoch total loss 0.285232961\n",
      "Trained batch 387 batch loss 0.327478647 epoch total loss 0.285342127\n",
      "Trained batch 388 batch loss 0.316596836 epoch total loss 0.285422683\n",
      "Trained batch 389 batch loss 0.31453377 epoch total loss 0.285497516\n",
      "Trained batch 390 batch loss 0.321080267 epoch total loss 0.285588771\n",
      "Trained batch 391 batch loss 0.317127645 epoch total loss 0.285669416\n",
      "Trained batch 392 batch loss 0.311512768 epoch total loss 0.285735369\n",
      "Trained batch 393 batch loss 0.291576415 epoch total loss 0.28575024\n",
      "Trained batch 394 batch loss 0.281848907 epoch total loss 0.285740346\n",
      "Trained batch 395 batch loss 0.325600654 epoch total loss 0.285841256\n",
      "Trained batch 396 batch loss 0.339307606 epoch total loss 0.285976261\n",
      "Trained batch 397 batch loss 0.312010735 epoch total loss 0.286041856\n",
      "Trained batch 398 batch loss 0.283945382 epoch total loss 0.286036581\n",
      "Trained batch 399 batch loss 0.293416381 epoch total loss 0.286055088\n",
      "Trained batch 400 batch loss 0.281473726 epoch total loss 0.286043614\n",
      "Trained batch 401 batch loss 0.299984783 epoch total loss 0.286078393\n",
      "Trained batch 402 batch loss 0.301138371 epoch total loss 0.286115855\n",
      "Trained batch 403 batch loss 0.321816295 epoch total loss 0.286204457\n",
      "Trained batch 404 batch loss 0.356525064 epoch total loss 0.286378503\n",
      "Trained batch 405 batch loss 0.286420733 epoch total loss 0.286378622\n",
      "Trained batch 406 batch loss 0.301330686 epoch total loss 0.286415428\n",
      "Trained batch 407 batch loss 0.27970776 epoch total loss 0.286398947\n",
      "Trained batch 408 batch loss 0.299828589 epoch total loss 0.286431879\n",
      "Trained batch 409 batch loss 0.306978405 epoch total loss 0.286482096\n",
      "Trained batch 410 batch loss 0.314573705 epoch total loss 0.286550611\n",
      "Trained batch 411 batch loss 0.282994896 epoch total loss 0.286541969\n",
      "Trained batch 412 batch loss 0.304792702 epoch total loss 0.286586285\n",
      "Trained batch 413 batch loss 0.280817956 epoch total loss 0.286572307\n",
      "Trained batch 414 batch loss 0.284785867 epoch total loss 0.286568\n",
      "Trained batch 415 batch loss 0.318336397 epoch total loss 0.286644548\n",
      "Trained batch 416 batch loss 0.318686962 epoch total loss 0.286721557\n",
      "Trained batch 417 batch loss 0.304687917 epoch total loss 0.286764652\n",
      "Trained batch 418 batch loss 0.297762603 epoch total loss 0.286790937\n",
      "Trained batch 419 batch loss 0.27788955 epoch total loss 0.286769718\n",
      "Trained batch 420 batch loss 0.266900867 epoch total loss 0.286722392\n",
      "Trained batch 421 batch loss 0.24348706 epoch total loss 0.286619693\n",
      "Trained batch 422 batch loss 0.248525888 epoch total loss 0.286529422\n",
      "Trained batch 423 batch loss 0.252115339 epoch total loss 0.286448061\n",
      "Trained batch 424 batch loss 0.239621729 epoch total loss 0.286337644\n",
      "Trained batch 425 batch loss 0.245517552 epoch total loss 0.286241591\n",
      "Trained batch 426 batch loss 0.215372682 epoch total loss 0.286075205\n",
      "Trained batch 427 batch loss 0.223607659 epoch total loss 0.285928935\n",
      "Trained batch 428 batch loss 0.222509578 epoch total loss 0.285780758\n",
      "Trained batch 429 batch loss 0.264307439 epoch total loss 0.28573069\n",
      "Trained batch 430 batch loss 0.26085791 epoch total loss 0.285672843\n",
      "Trained batch 431 batch loss 0.26705268 epoch total loss 0.28562963\n",
      "Trained batch 432 batch loss 0.300986439 epoch total loss 0.285665184\n",
      "Trained batch 433 batch loss 0.263541937 epoch total loss 0.285614103\n",
      "Trained batch 434 batch loss 0.256399572 epoch total loss 0.28554678\n",
      "Trained batch 435 batch loss 0.259840101 epoch total loss 0.285487711\n",
      "Trained batch 436 batch loss 0.2658813 epoch total loss 0.28544274\n",
      "Trained batch 437 batch loss 0.243725479 epoch total loss 0.285347283\n",
      "Trained batch 438 batch loss 0.284326494 epoch total loss 0.285344958\n",
      "Trained batch 439 batch loss 0.274247766 epoch total loss 0.285319656\n",
      "Trained batch 440 batch loss 0.299087644 epoch total loss 0.285350949\n",
      "Trained batch 441 batch loss 0.337266177 epoch total loss 0.285468668\n",
      "Trained batch 442 batch loss 0.278385937 epoch total loss 0.285452664\n",
      "Trained batch 443 batch loss 0.26647523 epoch total loss 0.285409808\n",
      "Trained batch 444 batch loss 0.304131567 epoch total loss 0.285451978\n",
      "Trained batch 445 batch loss 0.286292493 epoch total loss 0.285453856\n",
      "Trained batch 446 batch loss 0.272666544 epoch total loss 0.285425186\n",
      "Trained batch 447 batch loss 0.338793397 epoch total loss 0.285544574\n",
      "Trained batch 448 batch loss 0.327165782 epoch total loss 0.285637468\n",
      "Trained batch 449 batch loss 0.307943046 epoch total loss 0.285687149\n",
      "Trained batch 450 batch loss 0.283991277 epoch total loss 0.285683393\n",
      "Trained batch 451 batch loss 0.29070282 epoch total loss 0.28569454\n",
      "Trained batch 452 batch loss 0.320816129 epoch total loss 0.285772234\n",
      "Trained batch 453 batch loss 0.333509386 epoch total loss 0.285877615\n",
      "Trained batch 454 batch loss 0.296298772 epoch total loss 0.285900563\n",
      "Trained batch 455 batch loss 0.268747181 epoch total loss 0.285862893\n",
      "Trained batch 456 batch loss 0.275433123 epoch total loss 0.28584\n",
      "Trained batch 457 batch loss 0.281263143 epoch total loss 0.285830021\n",
      "Trained batch 458 batch loss 0.305425256 epoch total loss 0.285872787\n",
      "Trained batch 459 batch loss 0.28784582 epoch total loss 0.285877079\n",
      "Trained batch 460 batch loss 0.308489263 epoch total loss 0.285926223\n",
      "Trained batch 461 batch loss 0.311917961 epoch total loss 0.285982609\n",
      "Trained batch 462 batch loss 0.276406348 epoch total loss 0.285961896\n",
      "Trained batch 463 batch loss 0.293540597 epoch total loss 0.285978258\n",
      "Trained batch 464 batch loss 0.28129077 epoch total loss 0.285968155\n",
      "Trained batch 465 batch loss 0.277413577 epoch total loss 0.285949767\n",
      "Trained batch 466 batch loss 0.254878 epoch total loss 0.285883099\n",
      "Trained batch 467 batch loss 0.285751879 epoch total loss 0.285882831\n",
      "Trained batch 468 batch loss 0.277767956 epoch total loss 0.285865486\n",
      "Trained batch 469 batch loss 0.260217816 epoch total loss 0.285810828\n",
      "Trained batch 470 batch loss 0.263780951 epoch total loss 0.285763949\n",
      "Trained batch 471 batch loss 0.23446402 epoch total loss 0.285655022\n",
      "Trained batch 472 batch loss 0.260001421 epoch total loss 0.285600662\n",
      "Trained batch 473 batch loss 0.285615474 epoch total loss 0.285600692\n",
      "Trained batch 474 batch loss 0.276645869 epoch total loss 0.285581797\n",
      "Trained batch 475 batch loss 0.261908859 epoch total loss 0.285531938\n",
      "Trained batch 476 batch loss 0.318921953 epoch total loss 0.285602093\n",
      "Trained batch 477 batch loss 0.275623262 epoch total loss 0.285581172\n",
      "Trained batch 478 batch loss 0.283418328 epoch total loss 0.285576642\n",
      "Trained batch 479 batch loss 0.239971071 epoch total loss 0.285481423\n",
      "Trained batch 480 batch loss 0.2783494 epoch total loss 0.285466582\n",
      "Trained batch 481 batch loss 0.277313113 epoch total loss 0.285449624\n",
      "Trained batch 482 batch loss 0.268139362 epoch total loss 0.285413712\n",
      "Trained batch 483 batch loss 0.265912205 epoch total loss 0.28537336\n",
      "Trained batch 484 batch loss 0.298219979 epoch total loss 0.285399884\n",
      "Trained batch 485 batch loss 0.313446224 epoch total loss 0.2854577\n",
      "Trained batch 486 batch loss 0.308434963 epoch total loss 0.285505\n",
      "Trained batch 487 batch loss 0.283956081 epoch total loss 0.285501808\n",
      "Trained batch 488 batch loss 0.28532359 epoch total loss 0.28550145\n",
      "Trained batch 489 batch loss 0.26277107 epoch total loss 0.285454959\n",
      "Trained batch 490 batch loss 0.239000902 epoch total loss 0.285360157\n",
      "Trained batch 491 batch loss 0.262680501 epoch total loss 0.285313964\n",
      "Trained batch 492 batch loss 0.296561062 epoch total loss 0.285336822\n",
      "Trained batch 493 batch loss 0.306311935 epoch total loss 0.28537935\n",
      "Trained batch 494 batch loss 0.294157714 epoch total loss 0.285397112\n",
      "Trained batch 495 batch loss 0.291271329 epoch total loss 0.285409\n",
      "Trained batch 496 batch loss 0.284445077 epoch total loss 0.285407037\n",
      "Trained batch 497 batch loss 0.298718423 epoch total loss 0.285433829\n",
      "Trained batch 498 batch loss 0.241329968 epoch total loss 0.285345256\n",
      "Trained batch 499 batch loss 0.260407805 epoch total loss 0.285295278\n",
      "Trained batch 500 batch loss 0.257152766 epoch total loss 0.285239\n",
      "Trained batch 501 batch loss 0.284864902 epoch total loss 0.285238266\n",
      "Trained batch 502 batch loss 0.256870091 epoch total loss 0.285181761\n",
      "Trained batch 503 batch loss 0.306553 epoch total loss 0.285224229\n",
      "Trained batch 504 batch loss 0.293331921 epoch total loss 0.285240322\n",
      "Trained batch 505 batch loss 0.30200544 epoch total loss 0.285273522\n",
      "Trained batch 506 batch loss 0.286887854 epoch total loss 0.285276681\n",
      "Trained batch 507 batch loss 0.305020571 epoch total loss 0.285315633\n",
      "Trained batch 508 batch loss 0.304310411 epoch total loss 0.285353035\n",
      "Trained batch 509 batch loss 0.325468183 epoch total loss 0.285431832\n",
      "Trained batch 510 batch loss 0.30170244 epoch total loss 0.285463721\n",
      "Trained batch 511 batch loss 0.297702283 epoch total loss 0.285487682\n",
      "Trained batch 512 batch loss 0.273332357 epoch total loss 0.285463929\n",
      "Trained batch 513 batch loss 0.25553444 epoch total loss 0.285405606\n",
      "Trained batch 514 batch loss 0.297425479 epoch total loss 0.285428971\n",
      "Trained batch 515 batch loss 0.292724282 epoch total loss 0.285443157\n",
      "Trained batch 516 batch loss 0.327486366 epoch total loss 0.285524607\n",
      "Trained batch 517 batch loss 0.309503496 epoch total loss 0.285571\n",
      "Trained batch 518 batch loss 0.303423733 epoch total loss 0.28560546\n",
      "Trained batch 519 batch loss 0.256293654 epoch total loss 0.285548985\n",
      "Trained batch 520 batch loss 0.291859686 epoch total loss 0.285561115\n",
      "Trained batch 521 batch loss 0.286611378 epoch total loss 0.285563111\n",
      "Trained batch 522 batch loss 0.258069575 epoch total loss 0.285510451\n",
      "Trained batch 523 batch loss 0.277878433 epoch total loss 0.285495847\n",
      "Trained batch 524 batch loss 0.265755087 epoch total loss 0.285458207\n",
      "Trained batch 525 batch loss 0.272087693 epoch total loss 0.285432726\n",
      "Trained batch 526 batch loss 0.278863221 epoch total loss 0.285420269\n",
      "Trained batch 527 batch loss 0.296029627 epoch total loss 0.285440415\n",
      "Trained batch 528 batch loss 0.252321154 epoch total loss 0.285377681\n",
      "Trained batch 529 batch loss 0.278368 epoch total loss 0.285364419\n",
      "Trained batch 530 batch loss 0.263050228 epoch total loss 0.285322309\n",
      "Trained batch 531 batch loss 0.266499698 epoch total loss 0.285286844\n",
      "Trained batch 532 batch loss 0.257204562 epoch total loss 0.285234064\n",
      "Trained batch 533 batch loss 0.252145052 epoch total loss 0.285172\n",
      "Trained batch 534 batch loss 0.270371854 epoch total loss 0.285144269\n",
      "Trained batch 535 batch loss 0.281767368 epoch total loss 0.285137981\n",
      "Trained batch 536 batch loss 0.28176707 epoch total loss 0.285131693\n",
      "Trained batch 537 batch loss 0.273862511 epoch total loss 0.285110712\n",
      "Trained batch 538 batch loss 0.307462692 epoch total loss 0.285152256\n",
      "Trained batch 539 batch loss 0.308577776 epoch total loss 0.285195708\n",
      "Trained batch 540 batch loss 0.307192564 epoch total loss 0.285236448\n",
      "Trained batch 541 batch loss 0.303566247 epoch total loss 0.285270333\n",
      "Trained batch 542 batch loss 0.298314273 epoch total loss 0.285294384\n",
      "Trained batch 543 batch loss 0.306637198 epoch total loss 0.285333693\n",
      "Trained batch 544 batch loss 0.305291474 epoch total loss 0.285370409\n",
      "Trained batch 545 batch loss 0.275898784 epoch total loss 0.285353\n",
      "Trained batch 546 batch loss 0.259678721 epoch total loss 0.285305977\n",
      "Trained batch 547 batch loss 0.273556978 epoch total loss 0.285284519\n",
      "Trained batch 548 batch loss 0.267643511 epoch total loss 0.285252303\n",
      "Trained batch 549 batch loss 0.277764291 epoch total loss 0.285238683\n",
      "Trained batch 550 batch loss 0.24803704 epoch total loss 0.285171032\n",
      "Trained batch 551 batch loss 0.297160864 epoch total loss 0.285192817\n",
      "Trained batch 552 batch loss 0.274065495 epoch total loss 0.285172641\n",
      "Trained batch 553 batch loss 0.282598853 epoch total loss 0.285167962\n",
      "Trained batch 554 batch loss 0.300691962 epoch total loss 0.285196\n",
      "Trained batch 555 batch loss 0.311394155 epoch total loss 0.285243213\n",
      "Trained batch 556 batch loss 0.326531827 epoch total loss 0.285317481\n",
      "Trained batch 557 batch loss 0.350766897 epoch total loss 0.285435\n",
      "Trained batch 558 batch loss 0.336447448 epoch total loss 0.285526395\n",
      "Trained batch 559 batch loss 0.310957 epoch total loss 0.285571903\n",
      "Trained batch 560 batch loss 0.250862062 epoch total loss 0.285509914\n",
      "Trained batch 561 batch loss 0.312276185 epoch total loss 0.285557598\n",
      "Trained batch 562 batch loss 0.324404836 epoch total loss 0.285626709\n",
      "Trained batch 563 batch loss 0.321276575 epoch total loss 0.285690039\n",
      "Trained batch 564 batch loss 0.283613473 epoch total loss 0.285686344\n",
      "Trained batch 565 batch loss 0.28922078 epoch total loss 0.285692602\n",
      "Trained batch 566 batch loss 0.314771116 epoch total loss 0.285743982\n",
      "Trained batch 567 batch loss 0.341195107 epoch total loss 0.285841793\n",
      "Trained batch 568 batch loss 0.275753438 epoch total loss 0.285824031\n",
      "Trained batch 569 batch loss 0.269097149 epoch total loss 0.285794646\n",
      "Trained batch 570 batch loss 0.254708111 epoch total loss 0.285740137\n",
      "Trained batch 571 batch loss 0.255610526 epoch total loss 0.285687357\n",
      "Trained batch 572 batch loss 0.306580275 epoch total loss 0.285723895\n",
      "Trained batch 573 batch loss 0.322529018 epoch total loss 0.285788119\n",
      "Trained batch 574 batch loss 0.293781966 epoch total loss 0.285802037\n",
      "Trained batch 575 batch loss 0.293229461 epoch total loss 0.285814941\n",
      "Trained batch 576 batch loss 0.282476336 epoch total loss 0.285809159\n",
      "Trained batch 577 batch loss 0.280670077 epoch total loss 0.285800248\n",
      "Trained batch 578 batch loss 0.279350907 epoch total loss 0.285789102\n",
      "Trained batch 579 batch loss 0.274630219 epoch total loss 0.28576982\n",
      "Trained batch 580 batch loss 0.325895727 epoch total loss 0.285839\n",
      "Trained batch 581 batch loss 0.308621287 epoch total loss 0.285878211\n",
      "Trained batch 582 batch loss 0.270586193 epoch total loss 0.285851955\n",
      "Trained batch 583 batch loss 0.261079192 epoch total loss 0.285809457\n",
      "Trained batch 584 batch loss 0.24080047 epoch total loss 0.285732388\n",
      "Trained batch 585 batch loss 0.280813754 epoch total loss 0.285723954\n",
      "Trained batch 586 batch loss 0.34754777 epoch total loss 0.285829455\n",
      "Trained batch 587 batch loss 0.364415169 epoch total loss 0.285963327\n",
      "Trained batch 588 batch loss 0.325015962 epoch total loss 0.286029726\n",
      "Trained batch 589 batch loss 0.282407343 epoch total loss 0.286023587\n",
      "Trained batch 590 batch loss 0.282988936 epoch total loss 0.286018461\n",
      "Trained batch 591 batch loss 0.282294661 epoch total loss 0.286012143\n",
      "Trained batch 592 batch loss 0.297958016 epoch total loss 0.286032319\n",
      "Trained batch 593 batch loss 0.288502097 epoch total loss 0.286036462\n",
      "Trained batch 594 batch loss 0.293192595 epoch total loss 0.286048532\n",
      "Trained batch 595 batch loss 0.331018865 epoch total loss 0.28612411\n",
      "Trained batch 596 batch loss 0.325530529 epoch total loss 0.286190242\n",
      "Trained batch 597 batch loss 0.333615214 epoch total loss 0.286269695\n",
      "Trained batch 598 batch loss 0.306328654 epoch total loss 0.286303222\n",
      "Trained batch 599 batch loss 0.310165375 epoch total loss 0.286343068\n",
      "Trained batch 600 batch loss 0.288978249 epoch total loss 0.286347449\n",
      "Trained batch 601 batch loss 0.290664911 epoch total loss 0.286354631\n",
      "Trained batch 602 batch loss 0.306692868 epoch total loss 0.286388397\n",
      "Trained batch 603 batch loss 0.313117862 epoch total loss 0.286432713\n",
      "Trained batch 604 batch loss 0.287015498 epoch total loss 0.286433697\n",
      "Trained batch 605 batch loss 0.270300567 epoch total loss 0.286407024\n",
      "Trained batch 606 batch loss 0.266164631 epoch total loss 0.286373615\n",
      "Trained batch 607 batch loss 0.271303654 epoch total loss 0.28634876\n",
      "Trained batch 608 batch loss 0.230388299 epoch total loss 0.286256731\n",
      "Trained batch 609 batch loss 0.224857807 epoch total loss 0.286155909\n",
      "Trained batch 610 batch loss 0.279011756 epoch total loss 0.286144197\n",
      "Trained batch 611 batch loss 0.291512132 epoch total loss 0.286153\n",
      "Trained batch 612 batch loss 0.316601515 epoch total loss 0.286202759\n",
      "Trained batch 613 batch loss 0.334722161 epoch total loss 0.286281884\n",
      "Trained batch 614 batch loss 0.287765324 epoch total loss 0.286284298\n",
      "Trained batch 615 batch loss 0.260039777 epoch total loss 0.286241621\n",
      "Trained batch 616 batch loss 0.310464203 epoch total loss 0.28628096\n",
      "Trained batch 617 batch loss 0.307632834 epoch total loss 0.28631556\n",
      "Trained batch 618 batch loss 0.316926897 epoch total loss 0.286365092\n",
      "Trained batch 619 batch loss 0.288693964 epoch total loss 0.286368877\n",
      "Trained batch 620 batch loss 0.287639737 epoch total loss 0.286370933\n",
      "Trained batch 621 batch loss 0.302904129 epoch total loss 0.286397547\n",
      "Trained batch 622 batch loss 0.286446691 epoch total loss 0.286397636\n",
      "Trained batch 623 batch loss 0.261314601 epoch total loss 0.286357373\n",
      "Trained batch 624 batch loss 0.271806061 epoch total loss 0.286334068\n",
      "Trained batch 625 batch loss 0.282606661 epoch total loss 0.286328107\n",
      "Trained batch 626 batch loss 0.284149945 epoch total loss 0.28632462\n",
      "Trained batch 627 batch loss 0.288969636 epoch total loss 0.286328852\n",
      "Trained batch 628 batch loss 0.239275545 epoch total loss 0.286253899\n",
      "Trained batch 629 batch loss 0.248526856 epoch total loss 0.286193907\n",
      "Trained batch 630 batch loss 0.29000628 epoch total loss 0.2862\n",
      "Trained batch 631 batch loss 0.242620245 epoch total loss 0.286130905\n",
      "Trained batch 632 batch loss 0.245082974 epoch total loss 0.286065966\n",
      "Trained batch 633 batch loss 0.261280924 epoch total loss 0.286026806\n",
      "Trained batch 634 batch loss 0.266265363 epoch total loss 0.285995632\n",
      "Trained batch 635 batch loss 0.298637688 epoch total loss 0.28601554\n",
      "Trained batch 636 batch loss 0.278862834 epoch total loss 0.286004305\n",
      "Trained batch 637 batch loss 0.283720225 epoch total loss 0.286000729\n",
      "Trained batch 638 batch loss 0.318433106 epoch total loss 0.286051571\n",
      "Trained batch 639 batch loss 0.303802341 epoch total loss 0.286079347\n",
      "Trained batch 640 batch loss 0.253131747 epoch total loss 0.286027849\n",
      "Trained batch 641 batch loss 0.284157127 epoch total loss 0.286024958\n",
      "Trained batch 642 batch loss 0.282137871 epoch total loss 0.286018908\n",
      "Trained batch 643 batch loss 0.290036857 epoch total loss 0.286025137\n",
      "Trained batch 644 batch loss 0.252600521 epoch total loss 0.285973221\n",
      "Trained batch 645 batch loss 0.215809837 epoch total loss 0.285864443\n",
      "Trained batch 646 batch loss 0.255478859 epoch total loss 0.285817415\n",
      "Trained batch 647 batch loss 0.291651517 epoch total loss 0.285826445\n",
      "Trained batch 648 batch loss 0.301711857 epoch total loss 0.285850942\n",
      "Trained batch 649 batch loss 0.331119776 epoch total loss 0.28592068\n",
      "Trained batch 650 batch loss 0.306860596 epoch total loss 0.285952896\n",
      "Trained batch 651 batch loss 0.321040928 epoch total loss 0.286006808\n",
      "Trained batch 652 batch loss 0.293716103 epoch total loss 0.28601864\n",
      "Trained batch 653 batch loss 0.283045352 epoch total loss 0.28601408\n",
      "Trained batch 654 batch loss 0.271795511 epoch total loss 0.285992324\n",
      "Trained batch 655 batch loss 0.246942744 epoch total loss 0.28593272\n",
      "Trained batch 656 batch loss 0.232865885 epoch total loss 0.285851836\n",
      "Trained batch 657 batch loss 0.261669606 epoch total loss 0.28581503\n",
      "Trained batch 658 batch loss 0.303713858 epoch total loss 0.28584221\n",
      "Trained batch 659 batch loss 0.313396364 epoch total loss 0.285884053\n",
      "Trained batch 660 batch loss 0.334557563 epoch total loss 0.285957813\n",
      "Trained batch 661 batch loss 0.332193881 epoch total loss 0.286027759\n",
      "Trained batch 662 batch loss 0.314326495 epoch total loss 0.286070496\n",
      "Trained batch 663 batch loss 0.311711609 epoch total loss 0.286109179\n",
      "Trained batch 664 batch loss 0.278849751 epoch total loss 0.286098242\n",
      "Trained batch 665 batch loss 0.255726248 epoch total loss 0.286052585\n",
      "Trained batch 666 batch loss 0.313302457 epoch total loss 0.286093503\n",
      "Trained batch 667 batch loss 0.272942722 epoch total loss 0.286073804\n",
      "Trained batch 668 batch loss 0.281437367 epoch total loss 0.28606683\n",
      "Trained batch 669 batch loss 0.287177682 epoch total loss 0.286068499\n",
      "Trained batch 670 batch loss 0.293671608 epoch total loss 0.286079854\n",
      "Trained batch 671 batch loss 0.300610244 epoch total loss 0.28610149\n",
      "Trained batch 672 batch loss 0.277291656 epoch total loss 0.286088407\n",
      "Trained batch 673 batch loss 0.31575796 epoch total loss 0.286132485\n",
      "Trained batch 674 batch loss 0.282335848 epoch total loss 0.286126852\n",
      "Trained batch 675 batch loss 0.304017454 epoch total loss 0.286153346\n",
      "Trained batch 676 batch loss 0.322155684 epoch total loss 0.286206633\n",
      "Trained batch 677 batch loss 0.283946425 epoch total loss 0.286203295\n",
      "Trained batch 678 batch loss 0.252562612 epoch total loss 0.286153674\n",
      "Trained batch 679 batch loss 0.291725039 epoch total loss 0.28616187\n",
      "Trained batch 680 batch loss 0.285668314 epoch total loss 0.286161155\n",
      "Trained batch 681 batch loss 0.307615489 epoch total loss 0.286192656\n",
      "Trained batch 682 batch loss 0.260696411 epoch total loss 0.286155283\n",
      "Trained batch 683 batch loss 0.270024389 epoch total loss 0.28613165\n",
      "Trained batch 684 batch loss 0.311289072 epoch total loss 0.286168426\n",
      "Trained batch 685 batch loss 0.279665828 epoch total loss 0.286158949\n",
      "Trained batch 686 batch loss 0.273001045 epoch total loss 0.286139756\n",
      "Trained batch 687 batch loss 0.285591632 epoch total loss 0.286138952\n",
      "Trained batch 688 batch loss 0.262583733 epoch total loss 0.286104739\n",
      "Trained batch 689 batch loss 0.308205128 epoch total loss 0.286136836\n",
      "Trained batch 690 batch loss 0.32492283 epoch total loss 0.286193043\n",
      "Trained batch 691 batch loss 0.261988819 epoch total loss 0.286158\n",
      "Trained batch 692 batch loss 0.266661525 epoch total loss 0.286129832\n",
      "Trained batch 693 batch loss 0.283889174 epoch total loss 0.286126614\n",
      "Trained batch 694 batch loss 0.290330917 epoch total loss 0.286132663\n",
      "Trained batch 695 batch loss 0.293978453 epoch total loss 0.286143959\n",
      "Trained batch 696 batch loss 0.294063509 epoch total loss 0.286155313\n",
      "Trained batch 697 batch loss 0.304631144 epoch total loss 0.286181837\n",
      "Trained batch 698 batch loss 0.278508663 epoch total loss 0.28617084\n",
      "Trained batch 699 batch loss 0.319496214 epoch total loss 0.286218524\n",
      "Trained batch 700 batch loss 0.269764632 epoch total loss 0.286195\n",
      "Trained batch 701 batch loss 0.292260319 epoch total loss 0.286203653\n",
      "Trained batch 702 batch loss 0.285604924 epoch total loss 0.286202788\n",
      "Trained batch 703 batch loss 0.31820479 epoch total loss 0.286248326\n",
      "Trained batch 704 batch loss 0.236386701 epoch total loss 0.286177516\n",
      "Trained batch 705 batch loss 0.241386384 epoch total loss 0.286113948\n",
      "Trained batch 706 batch loss 0.28173 epoch total loss 0.286107749\n",
      "Trained batch 707 batch loss 0.256931692 epoch total loss 0.286066473\n",
      "Trained batch 708 batch loss 0.269385338 epoch total loss 0.286042899\n",
      "Trained batch 709 batch loss 0.277656227 epoch total loss 0.286031067\n",
      "Trained batch 710 batch loss 0.286519051 epoch total loss 0.286031753\n",
      "Trained batch 711 batch loss 0.295809835 epoch total loss 0.286045492\n",
      "Trained batch 712 batch loss 0.316688985 epoch total loss 0.286088526\n",
      "Trained batch 713 batch loss 0.28406918 epoch total loss 0.286085695\n",
      "Trained batch 714 batch loss 0.331767917 epoch total loss 0.286149681\n",
      "Trained batch 715 batch loss 0.324040771 epoch total loss 0.286202669\n",
      "Trained batch 716 batch loss 0.29840064 epoch total loss 0.286219716\n",
      "Trained batch 717 batch loss 0.294881403 epoch total loss 0.286231786\n",
      "Trained batch 718 batch loss 0.325313866 epoch total loss 0.286286235\n",
      "Trained batch 719 batch loss 0.289132684 epoch total loss 0.286290199\n",
      "Trained batch 720 batch loss 0.278262675 epoch total loss 0.286279052\n",
      "Trained batch 721 batch loss 0.313808948 epoch total loss 0.286317229\n",
      "Trained batch 722 batch loss 0.299519241 epoch total loss 0.286335498\n",
      "Trained batch 723 batch loss 0.308363 epoch total loss 0.286366\n",
      "Trained batch 724 batch loss 0.297449082 epoch total loss 0.286381304\n",
      "Trained batch 725 batch loss 0.345196843 epoch total loss 0.286462426\n",
      "Trained batch 726 batch loss 0.287309 epoch total loss 0.286463588\n",
      "Trained batch 727 batch loss 0.308487296 epoch total loss 0.286493868\n",
      "Trained batch 728 batch loss 0.299625397 epoch total loss 0.286511928\n",
      "Trained batch 729 batch loss 0.271756202 epoch total loss 0.286491662\n",
      "Trained batch 730 batch loss 0.300287724 epoch total loss 0.286510587\n",
      "Trained batch 731 batch loss 0.287578523 epoch total loss 0.286512047\n",
      "Trained batch 732 batch loss 0.276214868 epoch total loss 0.28649798\n",
      "Trained batch 733 batch loss 0.283293188 epoch total loss 0.286493599\n",
      "Trained batch 734 batch loss 0.26551041 epoch total loss 0.286465019\n",
      "Trained batch 735 batch loss 0.31981492 epoch total loss 0.286510378\n",
      "Trained batch 736 batch loss 0.307149738 epoch total loss 0.286538422\n",
      "Trained batch 737 batch loss 0.281584561 epoch total loss 0.286531687\n",
      "Trained batch 738 batch loss 0.26608339 epoch total loss 0.286504\n",
      "Trained batch 739 batch loss 0.286977232 epoch total loss 0.286504626\n",
      "Trained batch 740 batch loss 0.270242184 epoch total loss 0.286482662\n",
      "Trained batch 741 batch loss 0.27879405 epoch total loss 0.286472261\n",
      "Trained batch 742 batch loss 0.253943324 epoch total loss 0.286428422\n",
      "Trained batch 743 batch loss 0.261915714 epoch total loss 0.286395431\n",
      "Trained batch 744 batch loss 0.256871164 epoch total loss 0.286355734\n",
      "Trained batch 745 batch loss 0.251023978 epoch total loss 0.286308318\n",
      "Trained batch 746 batch loss 0.264989644 epoch total loss 0.286279738\n",
      "Trained batch 747 batch loss 0.301588982 epoch total loss 0.286300242\n",
      "Trained batch 748 batch loss 0.280448616 epoch total loss 0.286292404\n",
      "Trained batch 749 batch loss 0.254648507 epoch total loss 0.286250144\n",
      "Trained batch 750 batch loss 0.247359782 epoch total loss 0.286198318\n",
      "Trained batch 751 batch loss 0.299077243 epoch total loss 0.286215454\n",
      "Trained batch 752 batch loss 0.289286345 epoch total loss 0.286219537\n",
      "Trained batch 753 batch loss 0.313521236 epoch total loss 0.286255807\n",
      "Trained batch 754 batch loss 0.297191709 epoch total loss 0.286270291\n",
      "Trained batch 755 batch loss 0.278921306 epoch total loss 0.286260575\n",
      "Trained batch 756 batch loss 0.287097573 epoch total loss 0.286261678\n",
      "Trained batch 757 batch loss 0.269694746 epoch total loss 0.286239773\n",
      "Trained batch 758 batch loss 0.286821067 epoch total loss 0.286240548\n",
      "Trained batch 759 batch loss 0.261813462 epoch total loss 0.286208361\n",
      "Trained batch 760 batch loss 0.25311631 epoch total loss 0.28616482\n",
      "Trained batch 761 batch loss 0.252689809 epoch total loss 0.286120832\n",
      "Trained batch 762 batch loss 0.310397983 epoch total loss 0.286152691\n",
      "Trained batch 763 batch loss 0.275790691 epoch total loss 0.286139101\n",
      "Trained batch 764 batch loss 0.28046754 epoch total loss 0.28613168\n",
      "Trained batch 765 batch loss 0.276485205 epoch total loss 0.286119074\n",
      "Trained batch 766 batch loss 0.265679032 epoch total loss 0.286092401\n",
      "Trained batch 767 batch loss 0.287545383 epoch total loss 0.286094308\n",
      "Trained batch 768 batch loss 0.28565976 epoch total loss 0.286093742\n",
      "Trained batch 769 batch loss 0.280549169 epoch total loss 0.286086529\n",
      "Trained batch 770 batch loss 0.255588323 epoch total loss 0.286046922\n",
      "Trained batch 771 batch loss 0.260583967 epoch total loss 0.286013901\n",
      "Trained batch 772 batch loss 0.2987 epoch total loss 0.286030322\n",
      "Trained batch 773 batch loss 0.284779668 epoch total loss 0.286028713\n",
      "Trained batch 774 batch loss 0.264651239 epoch total loss 0.286001086\n",
      "Trained batch 775 batch loss 0.288129538 epoch total loss 0.286003828\n",
      "Trained batch 776 batch loss 0.264911205 epoch total loss 0.285976648\n",
      "Trained batch 777 batch loss 0.233569741 epoch total loss 0.285909206\n",
      "Trained batch 778 batch loss 0.220069498 epoch total loss 0.285824567\n",
      "Trained batch 779 batch loss 0.225716665 epoch total loss 0.285747409\n",
      "Trained batch 780 batch loss 0.231128022 epoch total loss 0.285677373\n",
      "Trained batch 781 batch loss 0.243382096 epoch total loss 0.285623223\n",
      "Trained batch 782 batch loss 0.258622587 epoch total loss 0.285588682\n",
      "Trained batch 783 batch loss 0.257959187 epoch total loss 0.285553396\n",
      "Trained batch 784 batch loss 0.253642708 epoch total loss 0.285512716\n",
      "Trained batch 785 batch loss 0.248608634 epoch total loss 0.285465688\n",
      "Trained batch 786 batch loss 0.244786054 epoch total loss 0.285413951\n",
      "Trained batch 787 batch loss 0.249166504 epoch total loss 0.285367876\n",
      "Trained batch 788 batch loss 0.255534023 epoch total loss 0.285330027\n",
      "Trained batch 789 batch loss 0.265889972 epoch total loss 0.285305381\n",
      "Trained batch 790 batch loss 0.234824389 epoch total loss 0.285241455\n",
      "Trained batch 791 batch loss 0.250495464 epoch total loss 0.285197526\n",
      "Trained batch 792 batch loss 0.252769619 epoch total loss 0.285156608\n",
      "Trained batch 793 batch loss 0.255948663 epoch total loss 0.285119772\n",
      "Trained batch 794 batch loss 0.314310789 epoch total loss 0.285156548\n",
      "Trained batch 795 batch loss 0.325340927 epoch total loss 0.285207093\n",
      "Trained batch 796 batch loss 0.279931217 epoch total loss 0.285200477\n",
      "Trained batch 797 batch loss 0.298777342 epoch total loss 0.285217524\n",
      "Trained batch 798 batch loss 0.320240319 epoch total loss 0.285261393\n",
      "Trained batch 799 batch loss 0.278267324 epoch total loss 0.285252661\n",
      "Trained batch 800 batch loss 0.284725755 epoch total loss 0.285252\n",
      "Trained batch 801 batch loss 0.288591504 epoch total loss 0.285256177\n",
      "Trained batch 802 batch loss 0.273851633 epoch total loss 0.285241932\n",
      "Trained batch 803 batch loss 0.272758484 epoch total loss 0.285226405\n",
      "Trained batch 804 batch loss 0.316527247 epoch total loss 0.285265326\n",
      "Trained batch 805 batch loss 0.286662251 epoch total loss 0.285267085\n",
      "Trained batch 806 batch loss 0.292059779 epoch total loss 0.285275489\n",
      "Trained batch 807 batch loss 0.29308778 epoch total loss 0.285285175\n",
      "Trained batch 808 batch loss 0.324699402 epoch total loss 0.285333961\n",
      "Trained batch 809 batch loss 0.286976576 epoch total loss 0.285336\n",
      "Trained batch 810 batch loss 0.268791199 epoch total loss 0.285315543\n",
      "Trained batch 811 batch loss 0.286564171 epoch total loss 0.285317093\n",
      "Trained batch 812 batch loss 0.262032121 epoch total loss 0.285288423\n",
      "Trained batch 813 batch loss 0.312074631 epoch total loss 0.285321355\n",
      "Trained batch 814 batch loss 0.293470085 epoch total loss 0.285331368\n",
      "Trained batch 815 batch loss 0.311150789 epoch total loss 0.285363048\n",
      "Trained batch 816 batch loss 0.282094419 epoch total loss 0.285359055\n",
      "Trained batch 817 batch loss 0.29319191 epoch total loss 0.285368651\n",
      "Trained batch 818 batch loss 0.287827462 epoch total loss 0.285371631\n",
      "Trained batch 819 batch loss 0.263572961 epoch total loss 0.285345048\n",
      "Trained batch 820 batch loss 0.24552539 epoch total loss 0.28529647\n",
      "Trained batch 821 batch loss 0.275143713 epoch total loss 0.285284132\n",
      "Trained batch 822 batch loss 0.325872242 epoch total loss 0.285333484\n",
      "Trained batch 823 batch loss 0.314318508 epoch total loss 0.285368711\n",
      "Trained batch 824 batch loss 0.314767838 epoch total loss 0.285404384\n",
      "Trained batch 825 batch loss 0.314139098 epoch total loss 0.285439223\n",
      "Trained batch 826 batch loss 0.295795828 epoch total loss 0.28545174\n",
      "Trained batch 827 batch loss 0.30103153 epoch total loss 0.285470575\n",
      "Trained batch 828 batch loss 0.314333856 epoch total loss 0.285505444\n",
      "Trained batch 829 batch loss 0.350227 epoch total loss 0.285583496\n",
      "Trained batch 830 batch loss 0.303689659 epoch total loss 0.285605311\n",
      "Trained batch 831 batch loss 0.276959509 epoch total loss 0.28559491\n",
      "Trained batch 832 batch loss 0.302647412 epoch total loss 0.285615414\n",
      "Trained batch 833 batch loss 0.300139427 epoch total loss 0.285632849\n",
      "Trained batch 834 batch loss 0.279229969 epoch total loss 0.28562516\n",
      "Trained batch 835 batch loss 0.278792113 epoch total loss 0.285617\n",
      "Trained batch 836 batch loss 0.29907155 epoch total loss 0.285633087\n",
      "Trained batch 837 batch loss 0.300714254 epoch total loss 0.285651118\n",
      "Trained batch 838 batch loss 0.308430463 epoch total loss 0.285678297\n",
      "Trained batch 839 batch loss 0.343480259 epoch total loss 0.28574717\n",
      "Trained batch 840 batch loss 0.255339801 epoch total loss 0.285711\n",
      "Trained batch 841 batch loss 0.247929409 epoch total loss 0.285666049\n",
      "Trained batch 842 batch loss 0.274679363 epoch total loss 0.285653\n",
      "Trained batch 843 batch loss 0.274605632 epoch total loss 0.285639912\n",
      "Trained batch 844 batch loss 0.304429054 epoch total loss 0.285662144\n",
      "Trained batch 845 batch loss 0.289138 epoch total loss 0.285666287\n",
      "Trained batch 846 batch loss 0.316348553 epoch total loss 0.285702527\n",
      "Trained batch 847 batch loss 0.276167214 epoch total loss 0.285691291\n",
      "Trained batch 848 batch loss 0.282024503 epoch total loss 0.28568697\n",
      "Trained batch 849 batch loss 0.29107818 epoch total loss 0.285693318\n",
      "Trained batch 850 batch loss 0.297374666 epoch total loss 0.285707057\n",
      "Trained batch 851 batch loss 0.339743853 epoch total loss 0.285770535\n",
      "Trained batch 852 batch loss 0.345354617 epoch total loss 0.285840482\n",
      "Trained batch 853 batch loss 0.270066351 epoch total loss 0.285821974\n",
      "Trained batch 854 batch loss 0.300040841 epoch total loss 0.285838634\n",
      "Trained batch 855 batch loss 0.282006025 epoch total loss 0.285834163\n",
      "Trained batch 856 batch loss 0.297958 epoch total loss 0.28584832\n",
      "Trained batch 857 batch loss 0.276337057 epoch total loss 0.285837203\n",
      "Trained batch 858 batch loss 0.313627958 epoch total loss 0.285869598\n",
      "Trained batch 859 batch loss 0.312518358 epoch total loss 0.285900623\n",
      "Trained batch 860 batch loss 0.320550174 epoch total loss 0.285940915\n",
      "Trained batch 861 batch loss 0.339941442 epoch total loss 0.286003649\n",
      "Trained batch 862 batch loss 0.330825418 epoch total loss 0.286055624\n",
      "Trained batch 863 batch loss 0.31671527 epoch total loss 0.286091149\n",
      "Trained batch 864 batch loss 0.333303541 epoch total loss 0.286145806\n",
      "Trained batch 865 batch loss 0.310329199 epoch total loss 0.286173761\n",
      "Trained batch 866 batch loss 0.304920077 epoch total loss 0.286195397\n",
      "Trained batch 867 batch loss 0.301568776 epoch total loss 0.28621313\n",
      "Trained batch 868 batch loss 0.297040164 epoch total loss 0.286225617\n",
      "Trained batch 869 batch loss 0.290424913 epoch total loss 0.286230445\n",
      "Trained batch 870 batch loss 0.296565175 epoch total loss 0.286242336\n",
      "Trained batch 871 batch loss 0.300783843 epoch total loss 0.286259025\n",
      "Trained batch 872 batch loss 0.304067731 epoch total loss 0.28627944\n",
      "Trained batch 873 batch loss 0.297534913 epoch total loss 0.286292315\n",
      "Trained batch 874 batch loss 0.278365 epoch total loss 0.286283255\n",
      "Trained batch 875 batch loss 0.271531045 epoch total loss 0.286266387\n",
      "Trained batch 876 batch loss 0.261346102 epoch total loss 0.286237955\n",
      "Trained batch 877 batch loss 0.247767866 epoch total loss 0.286194086\n",
      "Trained batch 878 batch loss 0.257022977 epoch total loss 0.286160856\n",
      "Trained batch 879 batch loss 0.250975668 epoch total loss 0.286120832\n",
      "Trained batch 880 batch loss 0.267297655 epoch total loss 0.286099464\n",
      "Trained batch 881 batch loss 0.275104702 epoch total loss 0.286086977\n",
      "Trained batch 882 batch loss 0.269877136 epoch total loss 0.286068588\n",
      "Trained batch 883 batch loss 0.28340593 epoch total loss 0.286065578\n",
      "Trained batch 884 batch loss 0.248388976 epoch total loss 0.286022931\n",
      "Trained batch 885 batch loss 0.274154603 epoch total loss 0.28600955\n",
      "Trained batch 886 batch loss 0.309461087 epoch total loss 0.286036\n",
      "Trained batch 887 batch loss 0.296050608 epoch total loss 0.28604731\n",
      "Trained batch 888 batch loss 0.307596684 epoch total loss 0.286071569\n",
      "Trained batch 889 batch loss 0.253063411 epoch total loss 0.286034435\n",
      "Trained batch 890 batch loss 0.30945015 epoch total loss 0.28606075\n",
      "Trained batch 891 batch loss 0.285782635 epoch total loss 0.286060452\n",
      "Trained batch 892 batch loss 0.317806154 epoch total loss 0.286096036\n",
      "Trained batch 893 batch loss 0.297316134 epoch total loss 0.286108613\n",
      "Trained batch 894 batch loss 0.304074347 epoch total loss 0.2861287\n",
      "Trained batch 895 batch loss 0.317836076 epoch total loss 0.286164105\n",
      "Trained batch 896 batch loss 0.296703041 epoch total loss 0.286175877\n",
      "Trained batch 897 batch loss 0.283545792 epoch total loss 0.286172926\n",
      "Trained batch 898 batch loss 0.320008 epoch total loss 0.286210597\n",
      "Trained batch 899 batch loss 0.289697677 epoch total loss 0.286214501\n",
      "Trained batch 900 batch loss 0.287078261 epoch total loss 0.286215454\n",
      "Trained batch 901 batch loss 0.319131732 epoch total loss 0.286251962\n",
      "Trained batch 902 batch loss 0.322016567 epoch total loss 0.286291629\n",
      "Trained batch 903 batch loss 0.293685406 epoch total loss 0.286299795\n",
      "Trained batch 904 batch loss 0.294486523 epoch total loss 0.286308855\n",
      "Trained batch 905 batch loss 0.230760977 epoch total loss 0.286247492\n",
      "Trained batch 906 batch loss 0.243344218 epoch total loss 0.286200136\n",
      "Trained batch 907 batch loss 0.267079532 epoch total loss 0.286179066\n",
      "Trained batch 908 batch loss 0.286996782 epoch total loss 0.28617996\n",
      "Trained batch 909 batch loss 0.285195678 epoch total loss 0.286178887\n",
      "Trained batch 910 batch loss 0.324518532 epoch total loss 0.286221\n",
      "Trained batch 911 batch loss 0.305405676 epoch total loss 0.286242098\n",
      "Trained batch 912 batch loss 0.314565241 epoch total loss 0.286273152\n",
      "Trained batch 913 batch loss 0.294758052 epoch total loss 0.28628245\n",
      "Trained batch 914 batch loss 0.274224728 epoch total loss 0.286269277\n",
      "Trained batch 915 batch loss 0.246733889 epoch total loss 0.286226064\n",
      "Trained batch 916 batch loss 0.255894333 epoch total loss 0.286192954\n",
      "Trained batch 917 batch loss 0.345207036 epoch total loss 0.286257327\n",
      "Trained batch 918 batch loss 0.309603751 epoch total loss 0.286282748\n",
      "Trained batch 919 batch loss 0.298591316 epoch total loss 0.286296129\n",
      "Trained batch 920 batch loss 0.285902828 epoch total loss 0.286295682\n",
      "Trained batch 921 batch loss 0.281139702 epoch total loss 0.286290079\n",
      "Trained batch 922 batch loss 0.292483479 epoch total loss 0.286296785\n",
      "Trained batch 923 batch loss 0.25864172 epoch total loss 0.286266834\n",
      "Trained batch 924 batch loss 0.268876821 epoch total loss 0.286248\n",
      "Trained batch 925 batch loss 0.265047848 epoch total loss 0.28622508\n",
      "Trained batch 926 batch loss 0.29696852 epoch total loss 0.286236703\n",
      "Trained batch 927 batch loss 0.293202847 epoch total loss 0.286244214\n",
      "Trained batch 928 batch loss 0.297563314 epoch total loss 0.286256433\n",
      "Trained batch 929 batch loss 0.274729967 epoch total loss 0.286244\n",
      "Trained batch 930 batch loss 0.275590956 epoch total loss 0.286232561\n",
      "Trained batch 931 batch loss 0.286682636 epoch total loss 0.286233038\n",
      "Trained batch 932 batch loss 0.289908826 epoch total loss 0.286237\n",
      "Trained batch 933 batch loss 0.320068598 epoch total loss 0.286273271\n",
      "Trained batch 934 batch loss 0.311149627 epoch total loss 0.286299914\n",
      "Trained batch 935 batch loss 0.305622339 epoch total loss 0.286320597\n",
      "Trained batch 936 batch loss 0.318847239 epoch total loss 0.286355346\n",
      "Trained batch 937 batch loss 0.26228717 epoch total loss 0.286329657\n",
      "Trained batch 938 batch loss 0.306552 epoch total loss 0.286351204\n",
      "Trained batch 939 batch loss 0.28127709 epoch total loss 0.28634581\n",
      "Trained batch 940 batch loss 0.257291675 epoch total loss 0.286314905\n",
      "Trained batch 941 batch loss 0.265865326 epoch total loss 0.286293179\n",
      "Trained batch 942 batch loss 0.245169237 epoch total loss 0.286249548\n",
      "Trained batch 943 batch loss 0.258145 epoch total loss 0.286219746\n",
      "Trained batch 944 batch loss 0.281168908 epoch total loss 0.286214381\n",
      "Trained batch 945 batch loss 0.260863721 epoch total loss 0.286187559\n",
      "Trained batch 946 batch loss 0.262414128 epoch total loss 0.286162436\n",
      "Trained batch 947 batch loss 0.268191785 epoch total loss 0.286143452\n",
      "Trained batch 948 batch loss 0.280933857 epoch total loss 0.286137968\n",
      "Trained batch 949 batch loss 0.289525777 epoch total loss 0.286141515\n",
      "Trained batch 950 batch loss 0.287491143 epoch total loss 0.286142975\n",
      "Trained batch 951 batch loss 0.276867479 epoch total loss 0.2861332\n",
      "Trained batch 952 batch loss 0.307052761 epoch total loss 0.286155194\n",
      "Trained batch 953 batch loss 0.306002021 epoch total loss 0.286176026\n",
      "Trained batch 954 batch loss 0.300088972 epoch total loss 0.286190599\n",
      "Trained batch 955 batch loss 0.292680025 epoch total loss 0.286197394\n",
      "Trained batch 956 batch loss 0.31050539 epoch total loss 0.286222845\n",
      "Trained batch 957 batch loss 0.284089476 epoch total loss 0.28622061\n",
      "Trained batch 958 batch loss 0.286835968 epoch total loss 0.286221236\n",
      "Trained batch 959 batch loss 0.318403125 epoch total loss 0.286254793\n",
      "Trained batch 960 batch loss 0.278278768 epoch total loss 0.286246479\n",
      "Trained batch 961 batch loss 0.315501511 epoch total loss 0.286276907\n",
      "Trained batch 962 batch loss 0.263481915 epoch total loss 0.286253244\n",
      "Trained batch 963 batch loss 0.271036267 epoch total loss 0.286237419\n",
      "Trained batch 964 batch loss 0.295771241 epoch total loss 0.286247313\n",
      "Trained batch 965 batch loss 0.26837495 epoch total loss 0.286228806\n",
      "Trained batch 966 batch loss 0.26507917 epoch total loss 0.286206901\n",
      "Trained batch 967 batch loss 0.309981525 epoch total loss 0.286231458\n",
      "Trained batch 968 batch loss 0.334681034 epoch total loss 0.286281526\n",
      "Trained batch 969 batch loss 0.319511652 epoch total loss 0.286315829\n",
      "Trained batch 970 batch loss 0.322832912 epoch total loss 0.286353469\n",
      "Trained batch 971 batch loss 0.315495372 epoch total loss 0.28638348\n",
      "Trained batch 972 batch loss 0.262266099 epoch total loss 0.286358684\n",
      "Trained batch 973 batch loss 0.251276493 epoch total loss 0.286322623\n",
      "Trained batch 974 batch loss 0.225200891 epoch total loss 0.28625986\n",
      "Trained batch 975 batch loss 0.21765919 epoch total loss 0.286189497\n",
      "Trained batch 976 batch loss 0.24535042 epoch total loss 0.286147654\n",
      "Trained batch 977 batch loss 0.259695798 epoch total loss 0.286120594\n",
      "Trained batch 978 batch loss 0.270807266 epoch total loss 0.286104947\n",
      "Trained batch 979 batch loss 0.244640887 epoch total loss 0.286062568\n",
      "Trained batch 980 batch loss 0.279007554 epoch total loss 0.286055386\n",
      "Trained batch 981 batch loss 0.299420595 epoch total loss 0.286069\n",
      "Trained batch 982 batch loss 0.288939118 epoch total loss 0.286071926\n",
      "Trained batch 983 batch loss 0.323604792 epoch total loss 0.286110133\n",
      "Trained batch 984 batch loss 0.341967642 epoch total loss 0.286166906\n",
      "Trained batch 985 batch loss 0.305786669 epoch total loss 0.286186814\n",
      "Trained batch 986 batch loss 0.305962145 epoch total loss 0.286206871\n",
      "Trained batch 987 batch loss 0.304774493 epoch total loss 0.286225706\n",
      "Trained batch 988 batch loss 0.286180884 epoch total loss 0.286225677\n",
      "Trained batch 989 batch loss 0.297916561 epoch total loss 0.286237478\n",
      "Trained batch 990 batch loss 0.282805145 epoch total loss 0.286234021\n",
      "Trained batch 991 batch loss 0.283403039 epoch total loss 0.28623116\n",
      "Trained batch 992 batch loss 0.275308073 epoch total loss 0.286220163\n",
      "Trained batch 993 batch loss 0.296332806 epoch total loss 0.286230326\n",
      "Trained batch 994 batch loss 0.29486528 epoch total loss 0.286239\n",
      "Trained batch 995 batch loss 0.264233768 epoch total loss 0.286216885\n",
      "Trained batch 996 batch loss 0.270715415 epoch total loss 0.286201328\n",
      "Trained batch 997 batch loss 0.25133723 epoch total loss 0.28616637\n",
      "Trained batch 998 batch loss 0.266583234 epoch total loss 0.28614673\n",
      "Trained batch 999 batch loss 0.278861 epoch total loss 0.286139429\n",
      "Trained batch 1000 batch loss 0.31778118 epoch total loss 0.286171079\n",
      "Trained batch 1001 batch loss 0.309987217 epoch total loss 0.286194891\n",
      "Trained batch 1002 batch loss 0.277969748 epoch total loss 0.286186695\n",
      "Trained batch 1003 batch loss 0.281914592 epoch total loss 0.286182433\n",
      "Trained batch 1004 batch loss 0.259911925 epoch total loss 0.286156267\n",
      "Trained batch 1005 batch loss 0.247782171 epoch total loss 0.28611809\n",
      "Trained batch 1006 batch loss 0.288246632 epoch total loss 0.286120206\n",
      "Trained batch 1007 batch loss 0.267269254 epoch total loss 0.28610149\n",
      "Trained batch 1008 batch loss 0.274047643 epoch total loss 0.28608951\n",
      "Trained batch 1009 batch loss 0.292930067 epoch total loss 0.286096305\n",
      "Trained batch 1010 batch loss 0.267479897 epoch total loss 0.286077887\n",
      "Trained batch 1011 batch loss 0.26963371 epoch total loss 0.286061615\n",
      "Trained batch 1012 batch loss 0.280410081 epoch total loss 0.286056\n",
      "Trained batch 1013 batch loss 0.265698195 epoch total loss 0.286035895\n",
      "Trained batch 1014 batch loss 0.283482045 epoch total loss 0.286033362\n",
      "Trained batch 1015 batch loss 0.272444546 epoch total loss 0.286019981\n",
      "Trained batch 1016 batch loss 0.287521601 epoch total loss 0.286021471\n",
      "Trained batch 1017 batch loss 0.264489651 epoch total loss 0.286000311\n",
      "Trained batch 1018 batch loss 0.31091845 epoch total loss 0.286024779\n",
      "Trained batch 1019 batch loss 0.303792685 epoch total loss 0.286042213\n",
      "Trained batch 1020 batch loss 0.326105297 epoch total loss 0.286081493\n",
      "Trained batch 1021 batch loss 0.270926833 epoch total loss 0.286066651\n",
      "Trained batch 1022 batch loss 0.280257136 epoch total loss 0.286060959\n",
      "Trained batch 1023 batch loss 0.312647551 epoch total loss 0.286086947\n",
      "Trained batch 1024 batch loss 0.288069487 epoch total loss 0.286088884\n",
      "Trained batch 1025 batch loss 0.297756582 epoch total loss 0.286100268\n",
      "Trained batch 1026 batch loss 0.324395418 epoch total loss 0.286137611\n",
      "Trained batch 1027 batch loss 0.307174176 epoch total loss 0.286158085\n",
      "Trained batch 1028 batch loss 0.293994904 epoch total loss 0.286165714\n",
      "Trained batch 1029 batch loss 0.281203061 epoch total loss 0.286160856\n",
      "Trained batch 1030 batch loss 0.308627069 epoch total loss 0.286182672\n",
      "Trained batch 1031 batch loss 0.279204518 epoch total loss 0.286175907\n",
      "Trained batch 1032 batch loss 0.287741452 epoch total loss 0.286177427\n",
      "Trained batch 1033 batch loss 0.296767116 epoch total loss 0.286187679\n",
      "Trained batch 1034 batch loss 0.303883821 epoch total loss 0.286204785\n",
      "Trained batch 1035 batch loss 0.298825711 epoch total loss 0.286217\n",
      "Trained batch 1036 batch loss 0.301761061 epoch total loss 0.286232\n",
      "Trained batch 1037 batch loss 0.314744473 epoch total loss 0.286259502\n",
      "Trained batch 1038 batch loss 0.309066534 epoch total loss 0.286281466\n",
      "Trained batch 1039 batch loss 0.338053405 epoch total loss 0.286331266\n",
      "Trained batch 1040 batch loss 0.278770626 epoch total loss 0.286324024\n",
      "Trained batch 1041 batch loss 0.269971848 epoch total loss 0.286308289\n",
      "Trained batch 1042 batch loss 0.283492714 epoch total loss 0.286305577\n",
      "Trained batch 1043 batch loss 0.271680981 epoch total loss 0.28629154\n",
      "Trained batch 1044 batch loss 0.264865637 epoch total loss 0.286271\n",
      "Trained batch 1045 batch loss 0.289843947 epoch total loss 0.286274463\n",
      "Trained batch 1046 batch loss 0.307305396 epoch total loss 0.28629455\n",
      "Trained batch 1047 batch loss 0.304033518 epoch total loss 0.286311507\n",
      "Trained batch 1048 batch loss 0.293931 epoch total loss 0.286318809\n",
      "Trained batch 1049 batch loss 0.298556983 epoch total loss 0.286330462\n",
      "Trained batch 1050 batch loss 0.310239375 epoch total loss 0.28635323\n",
      "Trained batch 1051 batch loss 0.30163464 epoch total loss 0.286367774\n",
      "Trained batch 1052 batch loss 0.283573598 epoch total loss 0.286365122\n",
      "Trained batch 1053 batch loss 0.254451275 epoch total loss 0.286334813\n",
      "Trained batch 1054 batch loss 0.284117579 epoch total loss 0.286332697\n",
      "Trained batch 1055 batch loss 0.289300591 epoch total loss 0.286335528\n",
      "Trained batch 1056 batch loss 0.238642514 epoch total loss 0.286290377\n",
      "Trained batch 1057 batch loss 0.279402882 epoch total loss 0.286283851\n",
      "Trained batch 1058 batch loss 0.26374954 epoch total loss 0.286262542\n",
      "Trained batch 1059 batch loss 0.271042466 epoch total loss 0.286248207\n",
      "Trained batch 1060 batch loss 0.267957747 epoch total loss 0.286230922\n",
      "Trained batch 1061 batch loss 0.263465762 epoch total loss 0.286209464\n",
      "Trained batch 1062 batch loss 0.260650188 epoch total loss 0.286185414\n",
      "Trained batch 1063 batch loss 0.284810662 epoch total loss 0.286184102\n",
      "Trained batch 1064 batch loss 0.307883471 epoch total loss 0.286204517\n",
      "Trained batch 1065 batch loss 0.234646678 epoch total loss 0.286156118\n",
      "Trained batch 1066 batch loss 0.248983607 epoch total loss 0.286121249\n",
      "Trained batch 1067 batch loss 0.239996597 epoch total loss 0.286078\n",
      "Trained batch 1068 batch loss 0.236418396 epoch total loss 0.286031514\n",
      "Trained batch 1069 batch loss 0.30760321 epoch total loss 0.28605172\n",
      "Trained batch 1070 batch loss 0.303882062 epoch total loss 0.28606838\n",
      "Trained batch 1071 batch loss 0.31725204 epoch total loss 0.286097497\n",
      "Trained batch 1072 batch loss 0.295728952 epoch total loss 0.286106467\n",
      "Trained batch 1073 batch loss 0.258917451 epoch total loss 0.286081135\n",
      "Trained batch 1074 batch loss 0.266225815 epoch total loss 0.286062658\n",
      "Trained batch 1075 batch loss 0.278935641 epoch total loss 0.286056\n",
      "Trained batch 1076 batch loss 0.296365201 epoch total loss 0.286065608\n",
      "Trained batch 1077 batch loss 0.306847811 epoch total loss 0.28608489\n",
      "Trained batch 1078 batch loss 0.284649581 epoch total loss 0.286083549\n",
      "Trained batch 1079 batch loss 0.322020769 epoch total loss 0.286116868\n",
      "Trained batch 1080 batch loss 0.298961729 epoch total loss 0.28612873\n",
      "Trained batch 1081 batch loss 0.309653729 epoch total loss 0.286150515\n",
      "Trained batch 1082 batch loss 0.297418386 epoch total loss 0.286160946\n",
      "Trained batch 1083 batch loss 0.263060749 epoch total loss 0.286139607\n",
      "Trained batch 1084 batch loss 0.250968456 epoch total loss 0.286107153\n",
      "Trained batch 1085 batch loss 0.267161071 epoch total loss 0.286089689\n",
      "Trained batch 1086 batch loss 0.260341167 epoch total loss 0.286066\n",
      "Trained batch 1087 batch loss 0.260778069 epoch total loss 0.28604272\n",
      "Trained batch 1088 batch loss 0.287342429 epoch total loss 0.286043912\n",
      "Trained batch 1089 batch loss 0.276127249 epoch total loss 0.286034822\n",
      "Trained batch 1090 batch loss 0.302435488 epoch total loss 0.286049843\n",
      "Trained batch 1091 batch loss 0.309968799 epoch total loss 0.286071777\n",
      "Trained batch 1092 batch loss 0.327192903 epoch total loss 0.286109418\n",
      "Trained batch 1093 batch loss 0.34202683 epoch total loss 0.286160588\n",
      "Trained batch 1094 batch loss 0.331520438 epoch total loss 0.286202043\n",
      "Trained batch 1095 batch loss 0.312403649 epoch total loss 0.286225975\n",
      "Trained batch 1096 batch loss 0.263018101 epoch total loss 0.286204815\n",
      "Trained batch 1097 batch loss 0.289367229 epoch total loss 0.286207706\n",
      "Trained batch 1098 batch loss 0.324704081 epoch total loss 0.286242753\n",
      "Trained batch 1099 batch loss 0.305357397 epoch total loss 0.286260158\n",
      "Trained batch 1100 batch loss 0.266103923 epoch total loss 0.286241829\n",
      "Trained batch 1101 batch loss 0.276587 epoch total loss 0.286233068\n",
      "Trained batch 1102 batch loss 0.285749316 epoch total loss 0.28623262\n",
      "Trained batch 1103 batch loss 0.265994221 epoch total loss 0.286214262\n",
      "Trained batch 1104 batch loss 0.259680241 epoch total loss 0.286190212\n",
      "Trained batch 1105 batch loss 0.28130275 epoch total loss 0.286185801\n",
      "Trained batch 1106 batch loss 0.281907409 epoch total loss 0.286181957\n",
      "Trained batch 1107 batch loss 0.296257138 epoch total loss 0.286191076\n",
      "Trained batch 1108 batch loss 0.286166966 epoch total loss 0.286191046\n",
      "Trained batch 1109 batch loss 0.298269093 epoch total loss 0.286201924\n",
      "Trained batch 1110 batch loss 0.298130512 epoch total loss 0.286212683\n",
      "Trained batch 1111 batch loss 0.286221683 epoch total loss 0.286212683\n",
      "Trained batch 1112 batch loss 0.297645569 epoch total loss 0.286222965\n",
      "Trained batch 1113 batch loss 0.264269769 epoch total loss 0.286203265\n",
      "Trained batch 1114 batch loss 0.276142359 epoch total loss 0.286194235\n",
      "Trained batch 1115 batch loss 0.262518 epoch total loss 0.286173\n",
      "Trained batch 1116 batch loss 0.26724866 epoch total loss 0.286156029\n",
      "Trained batch 1117 batch loss 0.31918928 epoch total loss 0.286185592\n",
      "Trained batch 1118 batch loss 0.300150245 epoch total loss 0.28619808\n",
      "Trained batch 1119 batch loss 0.310426652 epoch total loss 0.286219716\n",
      "Trained batch 1120 batch loss 0.280571461 epoch total loss 0.286214679\n",
      "Trained batch 1121 batch loss 0.290415615 epoch total loss 0.286218435\n",
      "Trained batch 1122 batch loss 0.304482907 epoch total loss 0.286234707\n",
      "Trained batch 1123 batch loss 0.286039233 epoch total loss 0.286234528\n",
      "Trained batch 1124 batch loss 0.256315917 epoch total loss 0.286207914\n",
      "Trained batch 1125 batch loss 0.260840267 epoch total loss 0.286185354\n",
      "Trained batch 1126 batch loss 0.273733318 epoch total loss 0.286174297\n",
      "Trained batch 1127 batch loss 0.256102324 epoch total loss 0.286147624\n",
      "Trained batch 1128 batch loss 0.303266168 epoch total loss 0.286162794\n",
      "Trained batch 1129 batch loss 0.295791388 epoch total loss 0.286171317\n",
      "Trained batch 1130 batch loss 0.303259313 epoch total loss 0.286186427\n",
      "Trained batch 1131 batch loss 0.27664414 epoch total loss 0.286178\n",
      "Trained batch 1132 batch loss 0.274250358 epoch total loss 0.286167443\n",
      "Trained batch 1133 batch loss 0.267111033 epoch total loss 0.286150634\n",
      "Trained batch 1134 batch loss 0.2758452 epoch total loss 0.286141545\n",
      "Trained batch 1135 batch loss 0.283211291 epoch total loss 0.286138982\n",
      "Trained batch 1136 batch loss 0.280722916 epoch total loss 0.286134213\n",
      "Trained batch 1137 batch loss 0.30389756 epoch total loss 0.28614983\n",
      "Trained batch 1138 batch loss 0.284494817 epoch total loss 0.286148369\n",
      "Trained batch 1139 batch loss 0.326769412 epoch total loss 0.286184043\n",
      "Trained batch 1140 batch loss 0.32670182 epoch total loss 0.286219567\n",
      "Trained batch 1141 batch loss 0.297790408 epoch total loss 0.2862297\n",
      "Trained batch 1142 batch loss 0.312850416 epoch total loss 0.286253\n",
      "Trained batch 1143 batch loss 0.312985569 epoch total loss 0.2862764\n",
      "Trained batch 1144 batch loss 0.293581843 epoch total loss 0.286282778\n",
      "Trained batch 1145 batch loss 0.275628448 epoch total loss 0.286273479\n",
      "Trained batch 1146 batch loss 0.28507483 epoch total loss 0.286272436\n",
      "Trained batch 1147 batch loss 0.264656246 epoch total loss 0.286253572\n",
      "Trained batch 1148 batch loss 0.259432942 epoch total loss 0.286230206\n",
      "Trained batch 1149 batch loss 0.261732459 epoch total loss 0.286208868\n",
      "Trained batch 1150 batch loss 0.277457982 epoch total loss 0.286201268\n",
      "Trained batch 1151 batch loss 0.299288064 epoch total loss 0.286212653\n",
      "Trained batch 1152 batch loss 0.287726372 epoch total loss 0.286213964\n",
      "Trained batch 1153 batch loss 0.298491418 epoch total loss 0.286224604\n",
      "Trained batch 1154 batch loss 0.306048214 epoch total loss 0.2862418\n",
      "Trained batch 1155 batch loss 0.242321044 epoch total loss 0.286203742\n",
      "Trained batch 1156 batch loss 0.239292875 epoch total loss 0.286163181\n",
      "Trained batch 1157 batch loss 0.279924423 epoch total loss 0.286157787\n",
      "Trained batch 1158 batch loss 0.298680663 epoch total loss 0.286168605\n",
      "Trained batch 1159 batch loss 0.316454 epoch total loss 0.286194742\n",
      "Trained batch 1160 batch loss 0.310494632 epoch total loss 0.286215693\n",
      "Trained batch 1161 batch loss 0.307017624 epoch total loss 0.286233604\n",
      "Trained batch 1162 batch loss 0.315603226 epoch total loss 0.286258876\n",
      "Trained batch 1163 batch loss 0.293976724 epoch total loss 0.286265522\n",
      "Trained batch 1164 batch loss 0.301062644 epoch total loss 0.286278218\n",
      "Trained batch 1165 batch loss 0.284377784 epoch total loss 0.286276579\n",
      "Trained batch 1166 batch loss 0.298965842 epoch total loss 0.286287457\n",
      "Trained batch 1167 batch loss 0.322587132 epoch total loss 0.2863186\n",
      "Trained batch 1168 batch loss 0.308339775 epoch total loss 0.286337435\n",
      "Trained batch 1169 batch loss 0.308398187 epoch total loss 0.28635633\n",
      "Trained batch 1170 batch loss 0.290423214 epoch total loss 0.286359817\n",
      "Trained batch 1171 batch loss 0.297986209 epoch total loss 0.286369741\n",
      "Trained batch 1172 batch loss 0.287214428 epoch total loss 0.286370456\n",
      "Trained batch 1173 batch loss 0.269684464 epoch total loss 0.286356211\n",
      "Trained batch 1174 batch loss 0.309362561 epoch total loss 0.286375821\n",
      "Trained batch 1175 batch loss 0.309860259 epoch total loss 0.286395818\n",
      "Trained batch 1176 batch loss 0.28534615 epoch total loss 0.286394924\n",
      "Trained batch 1177 batch loss 0.272989959 epoch total loss 0.28638351\n",
      "Trained batch 1178 batch loss 0.269322246 epoch total loss 0.286369026\n",
      "Trained batch 1179 batch loss 0.244665056 epoch total loss 0.28633365\n",
      "Trained batch 1180 batch loss 0.280575842 epoch total loss 0.286328763\n",
      "Trained batch 1181 batch loss 0.283063918 epoch total loss 0.286326\n",
      "Trained batch 1182 batch loss 0.276576579 epoch total loss 0.286317766\n",
      "Trained batch 1183 batch loss 0.24953948 epoch total loss 0.286286652\n",
      "Trained batch 1184 batch loss 0.274730504 epoch total loss 0.286276907\n",
      "Trained batch 1185 batch loss 0.257700086 epoch total loss 0.286252767\n",
      "Trained batch 1186 batch loss 0.310878068 epoch total loss 0.286273539\n",
      "Trained batch 1187 batch loss 0.319474339 epoch total loss 0.286301523\n",
      "Trained batch 1188 batch loss 0.277368695 epoch total loss 0.286294\n",
      "Trained batch 1189 batch loss 0.254006058 epoch total loss 0.286266834\n",
      "Trained batch 1190 batch loss 0.228000015 epoch total loss 0.286217868\n",
      "Trained batch 1191 batch loss 0.213165417 epoch total loss 0.286156535\n",
      "Trained batch 1192 batch loss 0.20148395 epoch total loss 0.286085486\n",
      "Trained batch 1193 batch loss 0.258784413 epoch total loss 0.286062628\n",
      "Trained batch 1194 batch loss 0.296344876 epoch total loss 0.286071241\n",
      "Trained batch 1195 batch loss 0.278332293 epoch total loss 0.286064744\n",
      "Trained batch 1196 batch loss 0.29161644 epoch total loss 0.286069393\n",
      "Trained batch 1197 batch loss 0.226634 epoch total loss 0.286019742\n",
      "Trained batch 1198 batch loss 0.284119904 epoch total loss 0.286018163\n",
      "Trained batch 1199 batch loss 0.282844961 epoch total loss 0.286015511\n",
      "Trained batch 1200 batch loss 0.286426216 epoch total loss 0.286015868\n",
      "Trained batch 1201 batch loss 0.308798671 epoch total loss 0.286034822\n",
      "Trained batch 1202 batch loss 0.301984102 epoch total loss 0.286048084\n",
      "Trained batch 1203 batch loss 0.272790849 epoch total loss 0.286037087\n",
      "Trained batch 1204 batch loss 0.292340696 epoch total loss 0.286042303\n",
      "Trained batch 1205 batch loss 0.298340738 epoch total loss 0.286052495\n",
      "Trained batch 1206 batch loss 0.296677619 epoch total loss 0.286061317\n",
      "Trained batch 1207 batch loss 0.287560046 epoch total loss 0.286062568\n",
      "Trained batch 1208 batch loss 0.298458308 epoch total loss 0.28607285\n",
      "Trained batch 1209 batch loss 0.282739341 epoch total loss 0.286070079\n",
      "Trained batch 1210 batch loss 0.277554333 epoch total loss 0.286063045\n",
      "Trained batch 1211 batch loss 0.245930612 epoch total loss 0.286029905\n",
      "Trained batch 1212 batch loss 0.304411054 epoch total loss 0.286045074\n",
      "Trained batch 1213 batch loss 0.298506796 epoch total loss 0.286055356\n",
      "Trained batch 1214 batch loss 0.285119772 epoch total loss 0.286054581\n",
      "Trained batch 1215 batch loss 0.287784874 epoch total loss 0.286056\n",
      "Trained batch 1216 batch loss 0.305496126 epoch total loss 0.286072\n",
      "Trained batch 1217 batch loss 0.285296828 epoch total loss 0.28607136\n",
      "Trained batch 1218 batch loss 0.282657802 epoch total loss 0.286068559\n",
      "Trained batch 1219 batch loss 0.302343816 epoch total loss 0.28608188\n",
      "Trained batch 1220 batch loss 0.293058813 epoch total loss 0.286087602\n",
      "Trained batch 1221 batch loss 0.282929838 epoch total loss 0.286085\n",
      "Trained batch 1222 batch loss 0.292933464 epoch total loss 0.286090642\n",
      "Trained batch 1223 batch loss 0.339386374 epoch total loss 0.286134213\n",
      "Trained batch 1224 batch loss 0.315833718 epoch total loss 0.286158472\n",
      "Trained batch 1225 batch loss 0.309181184 epoch total loss 0.286177248\n",
      "Trained batch 1226 batch loss 0.304425418 epoch total loss 0.286192119\n",
      "Trained batch 1227 batch loss 0.27998209 epoch total loss 0.286187053\n",
      "Trained batch 1228 batch loss 0.300848573 epoch total loss 0.286199\n",
      "Trained batch 1229 batch loss 0.290897787 epoch total loss 0.286202818\n",
      "Trained batch 1230 batch loss 0.270818084 epoch total loss 0.286190301\n",
      "Trained batch 1231 batch loss 0.303327 epoch total loss 0.286204219\n",
      "Trained batch 1232 batch loss 0.28689459 epoch total loss 0.286204785\n",
      "Trained batch 1233 batch loss 0.31996569 epoch total loss 0.286232173\n",
      "Trained batch 1234 batch loss 0.278842777 epoch total loss 0.286226183\n",
      "Trained batch 1235 batch loss 0.294875354 epoch total loss 0.286233157\n",
      "Trained batch 1236 batch loss 0.276818 epoch total loss 0.286225557\n",
      "Trained batch 1237 batch loss 0.288551271 epoch total loss 0.286227435\n",
      "Trained batch 1238 batch loss 0.298212767 epoch total loss 0.286237121\n",
      "Trained batch 1239 batch loss 0.292697519 epoch total loss 0.286242306\n",
      "Trained batch 1240 batch loss 0.298914135 epoch total loss 0.286252558\n",
      "Trained batch 1241 batch loss 0.339659 epoch total loss 0.286295593\n",
      "Trained batch 1242 batch loss 0.344511926 epoch total loss 0.286342442\n",
      "Trained batch 1243 batch loss 0.365898699 epoch total loss 0.286406457\n",
      "Trained batch 1244 batch loss 0.296439648 epoch total loss 0.286414534\n",
      "Trained batch 1245 batch loss 0.271017641 epoch total loss 0.286402166\n",
      "Trained batch 1246 batch loss 0.279458642 epoch total loss 0.286396593\n",
      "Trained batch 1247 batch loss 0.289183289 epoch total loss 0.286398828\n",
      "Trained batch 1248 batch loss 0.271692455 epoch total loss 0.286387056\n",
      "Trained batch 1249 batch loss 0.249333113 epoch total loss 0.286357373\n",
      "Trained batch 1250 batch loss 0.232980981 epoch total loss 0.286314666\n",
      "Trained batch 1251 batch loss 0.261140049 epoch total loss 0.28629455\n",
      "Trained batch 1252 batch loss 0.231642425 epoch total loss 0.286250889\n",
      "Trained batch 1253 batch loss 0.252173036 epoch total loss 0.28622368\n",
      "Trained batch 1254 batch loss 0.260958 epoch total loss 0.286203533\n",
      "Trained batch 1255 batch loss 0.31179294 epoch total loss 0.286223918\n",
      "Trained batch 1256 batch loss 0.247301489 epoch total loss 0.286192954\n",
      "Trained batch 1257 batch loss 0.2525675 epoch total loss 0.286166191\n",
      "Trained batch 1258 batch loss 0.271143377 epoch total loss 0.28615427\n",
      "Trained batch 1259 batch loss 0.260912478 epoch total loss 0.286134213\n",
      "Trained batch 1260 batch loss 0.320342749 epoch total loss 0.286161363\n",
      "Trained batch 1261 batch loss 0.303608239 epoch total loss 0.286175221\n",
      "Trained batch 1262 batch loss 0.305569738 epoch total loss 0.286190569\n",
      "Trained batch 1263 batch loss 0.300377131 epoch total loss 0.286201835\n",
      "Trained batch 1264 batch loss 0.291049719 epoch total loss 0.286205649\n",
      "Trained batch 1265 batch loss 0.278483808 epoch total loss 0.28619954\n",
      "Trained batch 1266 batch loss 0.273509383 epoch total loss 0.286189497\n",
      "Trained batch 1267 batch loss 0.289377 epoch total loss 0.28619203\n",
      "Trained batch 1268 batch loss 0.313716322 epoch total loss 0.286213726\n",
      "Trained batch 1269 batch loss 0.299449921 epoch total loss 0.286224157\n",
      "Trained batch 1270 batch loss 0.296752274 epoch total loss 0.286232442\n",
      "Trained batch 1271 batch loss 0.275106817 epoch total loss 0.28622368\n",
      "Trained batch 1272 batch loss 0.31287539 epoch total loss 0.286244631\n",
      "Trained batch 1273 batch loss 0.280756295 epoch total loss 0.286240339\n",
      "Trained batch 1274 batch loss 0.291194826 epoch total loss 0.286244214\n",
      "Trained batch 1275 batch loss 0.318499237 epoch total loss 0.286269546\n",
      "Trained batch 1276 batch loss 0.324207067 epoch total loss 0.286299258\n",
      "Trained batch 1277 batch loss 0.298707 epoch total loss 0.286308974\n",
      "Trained batch 1278 batch loss 0.267656416 epoch total loss 0.286294401\n",
      "Trained batch 1279 batch loss 0.254561216 epoch total loss 0.286269575\n",
      "Trained batch 1280 batch loss 0.264575273 epoch total loss 0.286252648\n",
      "Trained batch 1281 batch loss 0.283002436 epoch total loss 0.286250085\n",
      "Trained batch 1282 batch loss 0.275667101 epoch total loss 0.286241829\n",
      "Trained batch 1283 batch loss 0.287532061 epoch total loss 0.286242843\n",
      "Trained batch 1284 batch loss 0.289938331 epoch total loss 0.286245733\n",
      "Trained batch 1285 batch loss 0.268979222 epoch total loss 0.286232293\n",
      "Trained batch 1286 batch loss 0.262773156 epoch total loss 0.286214054\n",
      "Trained batch 1287 batch loss 0.287743062 epoch total loss 0.286215246\n",
      "Trained batch 1288 batch loss 0.275641948 epoch total loss 0.28620705\n",
      "Trained batch 1289 batch loss 0.28380239 epoch total loss 0.286205202\n",
      "Trained batch 1290 batch loss 0.285654068 epoch total loss 0.286204755\n",
      "Trained batch 1291 batch loss 0.283466518 epoch total loss 0.286202639\n",
      "Trained batch 1292 batch loss 0.264026791 epoch total loss 0.286185473\n",
      "Trained batch 1293 batch loss 0.277892441 epoch total loss 0.286179066\n",
      "Trained batch 1294 batch loss 0.28469032 epoch total loss 0.286177933\n",
      "Trained batch 1295 batch loss 0.266869634 epoch total loss 0.286163032\n",
      "Trained batch 1296 batch loss 0.306967 epoch total loss 0.286179096\n",
      "Trained batch 1297 batch loss 0.282714486 epoch total loss 0.286176413\n",
      "Trained batch 1298 batch loss 0.247259468 epoch total loss 0.286146432\n",
      "Trained batch 1299 batch loss 0.257017493 epoch total loss 0.286124\n",
      "Trained batch 1300 batch loss 0.272502184 epoch total loss 0.28611353\n",
      "Trained batch 1301 batch loss 0.252403438 epoch total loss 0.286087602\n",
      "Trained batch 1302 batch loss 0.301196933 epoch total loss 0.286099225\n",
      "Trained batch 1303 batch loss 0.277926117 epoch total loss 0.286092937\n",
      "Trained batch 1304 batch loss 0.258624434 epoch total loss 0.286071897\n",
      "Trained batch 1305 batch loss 0.305534631 epoch total loss 0.286086828\n",
      "Trained batch 1306 batch loss 0.24777098 epoch total loss 0.286057472\n",
      "Trained batch 1307 batch loss 0.272117794 epoch total loss 0.286046803\n",
      "Trained batch 1308 batch loss 0.31769675 epoch total loss 0.286071\n",
      "Trained batch 1309 batch loss 0.326106668 epoch total loss 0.286101609\n",
      "Trained batch 1310 batch loss 0.318119705 epoch total loss 0.286126047\n",
      "Trained batch 1311 batch loss 0.239444345 epoch total loss 0.286090434\n",
      "Trained batch 1312 batch loss 0.242481068 epoch total loss 0.286057204\n",
      "Trained batch 1313 batch loss 0.271568924 epoch total loss 0.286046177\n",
      "Trained batch 1314 batch loss 0.236087903 epoch total loss 0.286008149\n",
      "Trained batch 1315 batch loss 0.241010591 epoch total loss 0.285973907\n",
      "Trained batch 1316 batch loss 0.224240407 epoch total loss 0.285927\n",
      "Trained batch 1317 batch loss 0.263016135 epoch total loss 0.285909623\n",
      "Trained batch 1318 batch loss 0.267403066 epoch total loss 0.285895586\n",
      "Trained batch 1319 batch loss 0.275921 epoch total loss 0.285888\n",
      "Trained batch 1320 batch loss 0.286287 epoch total loss 0.285888314\n",
      "Trained batch 1321 batch loss 0.27392292 epoch total loss 0.285879254\n",
      "Trained batch 1322 batch loss 0.286789566 epoch total loss 0.28587994\n",
      "Trained batch 1323 batch loss 0.242358476 epoch total loss 0.285847068\n",
      "Trained batch 1324 batch loss 0.22560674 epoch total loss 0.28580156\n",
      "Trained batch 1325 batch loss 0.248736 epoch total loss 0.285773605\n",
      "Trained batch 1326 batch loss 0.278922617 epoch total loss 0.285768449\n",
      "Trained batch 1327 batch loss 0.257326424 epoch total loss 0.285747021\n",
      "Trained batch 1328 batch loss 0.275478631 epoch total loss 0.285739273\n",
      "Trained batch 1329 batch loss 0.26633963 epoch total loss 0.28572467\n",
      "Trained batch 1330 batch loss 0.23895821 epoch total loss 0.285689503\n",
      "Trained batch 1331 batch loss 0.29355 epoch total loss 0.285695404\n",
      "Trained batch 1332 batch loss 0.278898 epoch total loss 0.285690308\n",
      "Trained batch 1333 batch loss 0.271037161 epoch total loss 0.285679311\n",
      "Trained batch 1334 batch loss 0.2487299 epoch total loss 0.285651594\n",
      "Trained batch 1335 batch loss 0.247324094 epoch total loss 0.285622895\n",
      "Trained batch 1336 batch loss 0.260330617 epoch total loss 0.28560397\n",
      "Trained batch 1337 batch loss 0.290398598 epoch total loss 0.285607547\n",
      "Trained batch 1338 batch loss 0.28677702 epoch total loss 0.285608411\n",
      "Trained batch 1339 batch loss 0.288925976 epoch total loss 0.285610914\n",
      "Trained batch 1340 batch loss 0.35560596 epoch total loss 0.285663128\n",
      "Trained batch 1341 batch loss 0.338929862 epoch total loss 0.285702854\n",
      "Trained batch 1342 batch loss 0.267371833 epoch total loss 0.285689205\n",
      "Trained batch 1343 batch loss 0.274766058 epoch total loss 0.285681069\n",
      "Trained batch 1344 batch loss 0.283010423 epoch total loss 0.285679102\n",
      "Trained batch 1345 batch loss 0.290441513 epoch total loss 0.285682619\n",
      "Trained batch 1346 batch loss 0.270913333 epoch total loss 0.285671651\n",
      "Trained batch 1347 batch loss 0.254630119 epoch total loss 0.285648614\n",
      "Trained batch 1348 batch loss 0.266928703 epoch total loss 0.285634726\n",
      "Trained batch 1349 batch loss 0.279456 epoch total loss 0.285630137\n",
      "Trained batch 1350 batch loss 0.264747441 epoch total loss 0.285614669\n",
      "Trained batch 1351 batch loss 0.294101179 epoch total loss 0.285620958\n",
      "Trained batch 1352 batch loss 0.26766336 epoch total loss 0.285607666\n",
      "Trained batch 1353 batch loss 0.246417373 epoch total loss 0.285578728\n",
      "Trained batch 1354 batch loss 0.225127369 epoch total loss 0.285534054\n",
      "Trained batch 1355 batch loss 0.231519669 epoch total loss 0.285494208\n",
      "Trained batch 1356 batch loss 0.297588438 epoch total loss 0.285503119\n",
      "Trained batch 1357 batch loss 0.289433599 epoch total loss 0.285506\n",
      "Trained batch 1358 batch loss 0.296773911 epoch total loss 0.285514295\n",
      "Trained batch 1359 batch loss 0.264472067 epoch total loss 0.285498828\n",
      "Trained batch 1360 batch loss 0.270014077 epoch total loss 0.285487443\n",
      "Trained batch 1361 batch loss 0.242072463 epoch total loss 0.285455525\n",
      "Trained batch 1362 batch loss 0.258968323 epoch total loss 0.285436094\n",
      "Trained batch 1363 batch loss 0.268520206 epoch total loss 0.285423666\n",
      "Trained batch 1364 batch loss 0.270584881 epoch total loss 0.285412818\n",
      "Trained batch 1365 batch loss 0.284392834 epoch total loss 0.285412073\n",
      "Trained batch 1366 batch loss 0.294096112 epoch total loss 0.285418421\n",
      "Trained batch 1367 batch loss 0.272807747 epoch total loss 0.285409182\n",
      "Trained batch 1368 batch loss 0.254492909 epoch total loss 0.285386592\n",
      "Trained batch 1369 batch loss 0.237829298 epoch total loss 0.285351843\n",
      "Trained batch 1370 batch loss 0.261301398 epoch total loss 0.285334289\n",
      "Trained batch 1371 batch loss 0.289280713 epoch total loss 0.28533715\n",
      "Trained batch 1372 batch loss 0.276885241 epoch total loss 0.285330981\n",
      "Trained batch 1373 batch loss 0.289461941 epoch total loss 0.285334\n",
      "Trained batch 1374 batch loss 0.272057146 epoch total loss 0.285324335\n",
      "Trained batch 1375 batch loss 0.232589111 epoch total loss 0.28528598\n",
      "Trained batch 1376 batch loss 0.260559142 epoch total loss 0.285268\n",
      "Trained batch 1377 batch loss 0.283484936 epoch total loss 0.285266697\n",
      "Trained batch 1378 batch loss 0.274636686 epoch total loss 0.285258979\n",
      "Trained batch 1379 batch loss 0.285785049 epoch total loss 0.285259366\n",
      "Trained batch 1380 batch loss 0.302800924 epoch total loss 0.285272092\n",
      "Trained batch 1381 batch loss 0.287452728 epoch total loss 0.285273671\n",
      "Trained batch 1382 batch loss 0.258344293 epoch total loss 0.285254151\n",
      "Trained batch 1383 batch loss 0.297247052 epoch total loss 0.285262823\n",
      "Trained batch 1384 batch loss 0.28664571 epoch total loss 0.285263836\n",
      "Trained batch 1385 batch loss 0.300476551 epoch total loss 0.285274804\n",
      "Trained batch 1386 batch loss 0.262717426 epoch total loss 0.285258561\n",
      "Trained batch 1387 batch loss 0.280434459 epoch total loss 0.285255075\n",
      "Trained batch 1388 batch loss 0.27883783 epoch total loss 0.285250455\n",
      "Epoch 4 train loss 0.2852504551410675\n",
      "Validated batch 1 batch loss 0.308689445\n",
      "Validated batch 2 batch loss 0.296487361\n",
      "Validated batch 3 batch loss 0.288480461\n",
      "Validated batch 4 batch loss 0.284855545\n",
      "Validated batch 5 batch loss 0.326408952\n",
      "Validated batch 6 batch loss 0.327732891\n",
      "Validated batch 7 batch loss 0.293235838\n",
      "Validated batch 8 batch loss 0.296521217\n",
      "Validated batch 9 batch loss 0.284834862\n",
      "Validated batch 10 batch loss 0.31013447\n",
      "Validated batch 11 batch loss 0.314412534\n",
      "Validated batch 12 batch loss 0.267009079\n",
      "Validated batch 13 batch loss 0.337661982\n",
      "Validated batch 14 batch loss 0.279295892\n",
      "Validated batch 15 batch loss 0.322170913\n",
      "Validated batch 16 batch loss 0.312957287\n",
      "Validated batch 17 batch loss 0.320734173\n",
      "Validated batch 18 batch loss 0.261701941\n",
      "Validated batch 19 batch loss 0.321343571\n",
      "Validated batch 20 batch loss 0.286356956\n",
      "Validated batch 21 batch loss 0.307349652\n",
      "Validated batch 22 batch loss 0.292485327\n",
      "Validated batch 23 batch loss 0.299142689\n",
      "Validated batch 24 batch loss 0.281272352\n",
      "Validated batch 25 batch loss 0.272840142\n",
      "Validated batch 26 batch loss 0.283853084\n",
      "Validated batch 27 batch loss 0.293390512\n",
      "Validated batch 28 batch loss 0.279729038\n",
      "Validated batch 29 batch loss 0.311688095\n",
      "Validated batch 30 batch loss 0.278496236\n",
      "Validated batch 31 batch loss 0.242261484\n",
      "Validated batch 32 batch loss 0.2620942\n",
      "Validated batch 33 batch loss 0.282515228\n",
      "Validated batch 34 batch loss 0.275593221\n",
      "Validated batch 35 batch loss 0.282037318\n",
      "Validated batch 36 batch loss 0.27238065\n",
      "Validated batch 37 batch loss 0.289428294\n",
      "Validated batch 38 batch loss 0.30792281\n",
      "Validated batch 39 batch loss 0.300314188\n",
      "Validated batch 40 batch loss 0.287777185\n",
      "Validated batch 41 batch loss 0.310866892\n",
      "Validated batch 42 batch loss 0.24302116\n",
      "Validated batch 43 batch loss 0.271149039\n",
      "Validated batch 44 batch loss 0.248835\n",
      "Validated batch 45 batch loss 0.297056437\n",
      "Validated batch 46 batch loss 0.332308233\n",
      "Validated batch 47 batch loss 0.28588438\n",
      "Validated batch 48 batch loss 0.287389606\n",
      "Validated batch 49 batch loss 0.300448507\n",
      "Validated batch 50 batch loss 0.268981397\n",
      "Validated batch 51 batch loss 0.293433517\n",
      "Validated batch 52 batch loss 0.304808676\n",
      "Validated batch 53 batch loss 0.293801367\n",
      "Validated batch 54 batch loss 0.312390357\n",
      "Validated batch 55 batch loss 0.310023785\n",
      "Validated batch 56 batch loss 0.295558542\n",
      "Validated batch 57 batch loss 0.307975471\n",
      "Validated batch 58 batch loss 0.331823319\n",
      "Validated batch 59 batch loss 0.323411107\n",
      "Validated batch 60 batch loss 0.313989222\n",
      "Validated batch 61 batch loss 0.316878796\n",
      "Validated batch 62 batch loss 0.322919\n",
      "Validated batch 63 batch loss 0.337943077\n",
      "Validated batch 64 batch loss 0.274531066\n",
      "Validated batch 65 batch loss 0.311534256\n",
      "Validated batch 66 batch loss 0.327379942\n",
      "Validated batch 67 batch loss 0.310583532\n",
      "Validated batch 68 batch loss 0.292000294\n",
      "Validated batch 69 batch loss 0.304854691\n",
      "Validated batch 70 batch loss 0.293726534\n",
      "Validated batch 71 batch loss 0.302847028\n",
      "Validated batch 72 batch loss 0.281220824\n",
      "Validated batch 73 batch loss 0.282215357\n",
      "Validated batch 74 batch loss 0.300480068\n",
      "Validated batch 75 batch loss 0.306061089\n",
      "Validated batch 76 batch loss 0.309346169\n",
      "Validated batch 77 batch loss 0.317780703\n",
      "Validated batch 78 batch loss 0.298488975\n",
      "Validated batch 79 batch loss 0.283492506\n",
      "Validated batch 80 batch loss 0.296133518\n",
      "Validated batch 81 batch loss 0.284872711\n",
      "Validated batch 82 batch loss 0.301002175\n",
      "Validated batch 83 batch loss 0.340041429\n",
      "Validated batch 84 batch loss 0.316477299\n",
      "Validated batch 85 batch loss 0.307597786\n",
      "Validated batch 86 batch loss 0.335348785\n",
      "Validated batch 87 batch loss 0.265198857\n",
      "Validated batch 88 batch loss 0.303412974\n",
      "Validated batch 89 batch loss 0.264507949\n",
      "Validated batch 90 batch loss 0.278571546\n",
      "Validated batch 91 batch loss 0.318334073\n",
      "Validated batch 92 batch loss 0.27183944\n",
      "Validated batch 93 batch loss 0.283473492\n",
      "Validated batch 94 batch loss 0.310058475\n",
      "Validated batch 95 batch loss 0.279083073\n",
      "Validated batch 96 batch loss 0.298436046\n",
      "Validated batch 97 batch loss 0.286707163\n",
      "Validated batch 98 batch loss 0.294910133\n",
      "Validated batch 99 batch loss 0.305366099\n",
      "Validated batch 100 batch loss 0.29326275\n",
      "Validated batch 101 batch loss 0.276756525\n",
      "Validated batch 102 batch loss 0.314555079\n",
      "Validated batch 103 batch loss 0.279227912\n",
      "Validated batch 104 batch loss 0.263899\n",
      "Validated batch 105 batch loss 0.277861655\n",
      "Validated batch 106 batch loss 0.317299\n",
      "Validated batch 107 batch loss 0.326930881\n",
      "Validated batch 108 batch loss 0.322938412\n",
      "Validated batch 109 batch loss 0.293771058\n",
      "Validated batch 110 batch loss 0.33159256\n",
      "Validated batch 111 batch loss 0.290211529\n",
      "Validated batch 112 batch loss 0.313711286\n",
      "Validated batch 113 batch loss 0.295757413\n",
      "Validated batch 114 batch loss 0.220095307\n",
      "Validated batch 115 batch loss 0.281684756\n",
      "Validated batch 116 batch loss 0.270242572\n",
      "Validated batch 117 batch loss 0.275453627\n",
      "Validated batch 118 batch loss 0.306090266\n",
      "Validated batch 119 batch loss 0.277452439\n",
      "Validated batch 120 batch loss 0.312149644\n",
      "Validated batch 121 batch loss 0.348737925\n",
      "Validated batch 122 batch loss 0.282620907\n",
      "Validated batch 123 batch loss 0.292783201\n",
      "Validated batch 124 batch loss 0.305634558\n",
      "Validated batch 125 batch loss 0.313918322\n",
      "Validated batch 126 batch loss 0.304599941\n",
      "Validated batch 127 batch loss 0.274702966\n",
      "Validated batch 128 batch loss 0.233481586\n",
      "Validated batch 129 batch loss 0.29860726\n",
      "Validated batch 130 batch loss 0.277306795\n",
      "Validated batch 131 batch loss 0.296701342\n",
      "Validated batch 132 batch loss 0.310399681\n",
      "Validated batch 133 batch loss 0.250470281\n",
      "Validated batch 134 batch loss 0.303495347\n",
      "Validated batch 135 batch loss 0.319942415\n",
      "Validated batch 136 batch loss 0.314294577\n",
      "Validated batch 137 batch loss 0.30224216\n",
      "Validated batch 138 batch loss 0.269536197\n",
      "Validated batch 139 batch loss 0.287710279\n",
      "Validated batch 140 batch loss 0.263113409\n",
      "Validated batch 141 batch loss 0.280639082\n",
      "Validated batch 142 batch loss 0.290398598\n",
      "Validated batch 143 batch loss 0.278425485\n",
      "Validated batch 144 batch loss 0.29817304\n",
      "Validated batch 145 batch loss 0.293292969\n",
      "Validated batch 146 batch loss 0.298681796\n",
      "Validated batch 147 batch loss 0.313011646\n",
      "Validated batch 148 batch loss 0.25423941\n",
      "Validated batch 149 batch loss 0.308094919\n",
      "Validated batch 150 batch loss 0.307097405\n",
      "Validated batch 151 batch loss 0.266218871\n",
      "Validated batch 152 batch loss 0.304044574\n",
      "Validated batch 153 batch loss 0.296929926\n",
      "Validated batch 154 batch loss 0.270077735\n",
      "Validated batch 155 batch loss 0.327572227\n",
      "Validated batch 156 batch loss 0.283976138\n",
      "Validated batch 157 batch loss 0.303665966\n",
      "Validated batch 158 batch loss 0.273606241\n",
      "Validated batch 159 batch loss 0.300074369\n",
      "Validated batch 160 batch loss 0.291241854\n",
      "Validated batch 161 batch loss 0.272015095\n",
      "Validated batch 162 batch loss 0.312340528\n",
      "Validated batch 163 batch loss 0.288552046\n",
      "Validated batch 164 batch loss 0.300937057\n",
      "Validated batch 165 batch loss 0.291398257\n",
      "Validated batch 166 batch loss 0.273435295\n",
      "Validated batch 167 batch loss 0.293731928\n",
      "Validated batch 168 batch loss 0.322512388\n",
      "Validated batch 169 batch loss 0.28080973\n",
      "Validated batch 170 batch loss 0.288431168\n",
      "Validated batch 171 batch loss 0.322472692\n",
      "Validated batch 172 batch loss 0.312495559\n",
      "Validated batch 173 batch loss 0.324053138\n",
      "Validated batch 174 batch loss 0.303496569\n",
      "Validated batch 175 batch loss 0.266884476\n",
      "Validated batch 176 batch loss 0.290723115\n",
      "Validated batch 177 batch loss 0.29386127\n",
      "Validated batch 178 batch loss 0.297757804\n",
      "Validated batch 179 batch loss 0.302926153\n",
      "Validated batch 180 batch loss 0.299541652\n",
      "Validated batch 181 batch loss 0.329592705\n",
      "Validated batch 182 batch loss 0.330260575\n",
      "Validated batch 183 batch loss 0.305765241\n",
      "Validated batch 184 batch loss 0.276505172\n",
      "Validated batch 185 batch loss 0.270495266\n",
      "Epoch 4 val loss 0.2955356538295746\n",
      "Model /aiffel/aiffel/mpii/models2/model-epoch-4-loss-0.2955.h5 saved.\n",
      "Start epoch 5 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 0.297379017 epoch total loss 0.297379017\n",
      "Trained batch 2 batch loss 0.295376599 epoch total loss 0.296377808\n",
      "Trained batch 3 batch loss 0.292715818 epoch total loss 0.295157164\n",
      "Trained batch 4 batch loss 0.312617362 epoch total loss 0.299522221\n",
      "Trained batch 5 batch loss 0.301304936 epoch total loss 0.299878776\n",
      "Trained batch 6 batch loss 0.297530472 epoch total loss 0.299487382\n",
      "Trained batch 7 batch loss 0.284218103 epoch total loss 0.297306061\n",
      "Trained batch 8 batch loss 0.266566426 epoch total loss 0.293463618\n",
      "Trained batch 9 batch loss 0.293671101 epoch total loss 0.293486685\n",
      "Trained batch 10 batch loss 0.259424269 epoch total loss 0.290080428\n",
      "Trained batch 11 batch loss 0.25968504 epoch total loss 0.287317216\n",
      "Trained batch 12 batch loss 0.271621346 epoch total loss 0.286009222\n",
      "Trained batch 13 batch loss 0.25695309 epoch total loss 0.283774137\n",
      "Trained batch 14 batch loss 0.258409292 epoch total loss 0.281962365\n",
      "Trained batch 15 batch loss 0.254765809 epoch total loss 0.280149281\n",
      "Trained batch 16 batch loss 0.243788868 epoch total loss 0.277876735\n",
      "Trained batch 17 batch loss 0.28052932 epoch total loss 0.27803278\n",
      "Trained batch 18 batch loss 0.268063933 epoch total loss 0.277478963\n",
      "Trained batch 19 batch loss 0.2803455 epoch total loss 0.277629822\n",
      "Trained batch 20 batch loss 0.297721148 epoch total loss 0.278634399\n",
      "Trained batch 21 batch loss 0.269572556 epoch total loss 0.278202891\n",
      "Trained batch 22 batch loss 0.269523144 epoch total loss 0.277808368\n",
      "Trained batch 23 batch loss 0.306642443 epoch total loss 0.279062033\n",
      "Trained batch 24 batch loss 0.265042722 epoch total loss 0.278477877\n",
      "Trained batch 25 batch loss 0.252292395 epoch total loss 0.277430445\n",
      "Trained batch 26 batch loss 0.231898695 epoch total loss 0.275679231\n",
      "Trained batch 27 batch loss 0.259219646 epoch total loss 0.275069624\n",
      "Trained batch 28 batch loss 0.272771329 epoch total loss 0.274987549\n",
      "Trained batch 29 batch loss 0.271235615 epoch total loss 0.274858177\n",
      "Trained batch 30 batch loss 0.255703449 epoch total loss 0.274219662\n",
      "Trained batch 31 batch loss 0.271109402 epoch total loss 0.274119347\n",
      "Trained batch 32 batch loss 0.30136466 epoch total loss 0.27497077\n",
      "Trained batch 33 batch loss 0.298568517 epoch total loss 0.275685847\n",
      "Trained batch 34 batch loss 0.305751711 epoch total loss 0.276570141\n",
      "Trained batch 35 batch loss 0.274342269 epoch total loss 0.276506513\n",
      "Trained batch 36 batch loss 0.239573643 epoch total loss 0.275480598\n",
      "Trained batch 37 batch loss 0.267842144 epoch total loss 0.275274158\n",
      "Trained batch 38 batch loss 0.278949678 epoch total loss 0.275370866\n",
      "Trained batch 39 batch loss 0.308310479 epoch total loss 0.276215494\n",
      "Trained batch 40 batch loss 0.306698948 epoch total loss 0.276977569\n",
      "Trained batch 41 batch loss 0.297249317 epoch total loss 0.277472019\n",
      "Trained batch 42 batch loss 0.285167187 epoch total loss 0.277655214\n",
      "Trained batch 43 batch loss 0.269905627 epoch total loss 0.277475\n",
      "Trained batch 44 batch loss 0.288926572 epoch total loss 0.277735263\n",
      "Trained batch 45 batch loss 0.255699188 epoch total loss 0.277245551\n",
      "Trained batch 46 batch loss 0.260866851 epoch total loss 0.276889503\n",
      "Trained batch 47 batch loss 0.258931249 epoch total loss 0.276507407\n",
      "Trained batch 48 batch loss 0.271914691 epoch total loss 0.276411742\n",
      "Trained batch 49 batch loss 0.243501604 epoch total loss 0.275740087\n",
      "Trained batch 50 batch loss 0.238632098 epoch total loss 0.27499795\n",
      "Trained batch 51 batch loss 0.279654086 epoch total loss 0.275089234\n",
      "Trained batch 52 batch loss 0.248802334 epoch total loss 0.274583727\n",
      "Trained batch 53 batch loss 0.249982461 epoch total loss 0.274119556\n",
      "Trained batch 54 batch loss 0.24289389 epoch total loss 0.273541301\n",
      "Trained batch 55 batch loss 0.245306835 epoch total loss 0.273027956\n",
      "Trained batch 56 batch loss 0.256466925 epoch total loss 0.272732228\n",
      "Trained batch 57 batch loss 0.311268121 epoch total loss 0.273408294\n",
      "Trained batch 58 batch loss 0.268346786 epoch total loss 0.273321033\n",
      "Trained batch 59 batch loss 0.247101694 epoch total loss 0.27287662\n",
      "Trained batch 60 batch loss 0.281131864 epoch total loss 0.273014188\n",
      "Trained batch 61 batch loss 0.272621334 epoch total loss 0.273007751\n",
      "Trained batch 62 batch loss 0.268984467 epoch total loss 0.272942841\n",
      "Trained batch 63 batch loss 0.286881149 epoch total loss 0.273164093\n",
      "Trained batch 64 batch loss 0.269763112 epoch total loss 0.273110956\n",
      "Trained batch 65 batch loss 0.310946584 epoch total loss 0.273693055\n",
      "Trained batch 66 batch loss 0.293876648 epoch total loss 0.273998857\n",
      "Trained batch 67 batch loss 0.279201418 epoch total loss 0.274076521\n",
      "Trained batch 68 batch loss 0.267660648 epoch total loss 0.273982167\n",
      "Trained batch 69 batch loss 0.279138356 epoch total loss 0.274056882\n",
      "Trained batch 70 batch loss 0.311829776 epoch total loss 0.274596512\n",
      "Trained batch 71 batch loss 0.264836252 epoch total loss 0.274459034\n",
      "Trained batch 72 batch loss 0.281981707 epoch total loss 0.274563521\n",
      "Trained batch 73 batch loss 0.268850744 epoch total loss 0.27448526\n",
      "Trained batch 74 batch loss 0.262972236 epoch total loss 0.274329662\n",
      "Trained batch 75 batch loss 0.254968792 epoch total loss 0.274071515\n",
      "Trained batch 76 batch loss 0.273688674 epoch total loss 0.274066508\n",
      "Trained batch 77 batch loss 0.267719358 epoch total loss 0.273984075\n",
      "Trained batch 78 batch loss 0.294007093 epoch total loss 0.274240762\n",
      "Trained batch 79 batch loss 0.300838649 epoch total loss 0.274577439\n",
      "Trained batch 80 batch loss 0.336365521 epoch total loss 0.275349796\n",
      "Trained batch 81 batch loss 0.292712271 epoch total loss 0.275564134\n",
      "Trained batch 82 batch loss 0.304214954 epoch total loss 0.275913537\n",
      "Trained batch 83 batch loss 0.231174588 epoch total loss 0.275374502\n",
      "Trained batch 84 batch loss 0.258594126 epoch total loss 0.275174767\n",
      "Trained batch 85 batch loss 0.19926554 epoch total loss 0.27428171\n",
      "Trained batch 86 batch loss 0.226663068 epoch total loss 0.273728\n",
      "Trained batch 87 batch loss 0.282063365 epoch total loss 0.273823828\n",
      "Trained batch 88 batch loss 0.31658262 epoch total loss 0.274309695\n",
      "Trained batch 89 batch loss 0.327694148 epoch total loss 0.274909526\n",
      "Trained batch 90 batch loss 0.275617361 epoch total loss 0.274917394\n",
      "Trained batch 91 batch loss 0.275976211 epoch total loss 0.274929017\n",
      "Trained batch 92 batch loss 0.275963 epoch total loss 0.274940252\n",
      "Trained batch 93 batch loss 0.264061391 epoch total loss 0.274823278\n",
      "Trained batch 94 batch loss 0.31747961 epoch total loss 0.275277078\n",
      "Trained batch 95 batch loss 0.290416896 epoch total loss 0.275436431\n",
      "Trained batch 96 batch loss 0.274663299 epoch total loss 0.275428385\n",
      "Trained batch 97 batch loss 0.291238755 epoch total loss 0.275591373\n",
      "Trained batch 98 batch loss 0.363964379 epoch total loss 0.276493162\n",
      "Trained batch 99 batch loss 0.327822268 epoch total loss 0.277011633\n",
      "Trained batch 100 batch loss 0.293100893 epoch total loss 0.277172506\n",
      "Trained batch 101 batch loss 0.294278324 epoch total loss 0.277341872\n",
      "Trained batch 102 batch loss 0.274462193 epoch total loss 0.27731365\n",
      "Trained batch 103 batch loss 0.302243114 epoch total loss 0.277555674\n",
      "Trained batch 104 batch loss 0.30677712 epoch total loss 0.277836651\n",
      "Trained batch 105 batch loss 0.282929838 epoch total loss 0.277885169\n",
      "Trained batch 106 batch loss 0.275682271 epoch total loss 0.277864397\n",
      "Trained batch 107 batch loss 0.256646514 epoch total loss 0.277666092\n",
      "Trained batch 108 batch loss 0.267536879 epoch total loss 0.277572304\n",
      "Trained batch 109 batch loss 0.271541059 epoch total loss 0.277516961\n",
      "Trained batch 110 batch loss 0.256770372 epoch total loss 0.277328372\n",
      "Trained batch 111 batch loss 0.278229326 epoch total loss 0.277336478\n",
      "Trained batch 112 batch loss 0.265513301 epoch total loss 0.277230918\n",
      "Trained batch 113 batch loss 0.25292182 epoch total loss 0.277015775\n",
      "Trained batch 114 batch loss 0.237050802 epoch total loss 0.276665211\n",
      "Trained batch 115 batch loss 0.267214954 epoch total loss 0.276583046\n",
      "Trained batch 116 batch loss 0.256448507 epoch total loss 0.276409477\n",
      "Trained batch 117 batch loss 0.263717681 epoch total loss 0.276301\n",
      "Trained batch 118 batch loss 0.200680137 epoch total loss 0.275660157\n",
      "Trained batch 119 batch loss 0.220116496 epoch total loss 0.275193393\n",
      "Trained batch 120 batch loss 0.282960832 epoch total loss 0.275258094\n",
      "Trained batch 121 batch loss 0.263258547 epoch total loss 0.275158942\n",
      "Trained batch 122 batch loss 0.268208385 epoch total loss 0.27510196\n",
      "Trained batch 123 batch loss 0.25519681 epoch total loss 0.274940133\n",
      "Trained batch 124 batch loss 0.249786288 epoch total loss 0.274737269\n",
      "Trained batch 125 batch loss 0.248306736 epoch total loss 0.274525821\n",
      "Trained batch 126 batch loss 0.216749966 epoch total loss 0.274067283\n",
      "Trained batch 127 batch loss 0.269049585 epoch total loss 0.274027795\n",
      "Trained batch 128 batch loss 0.259226859 epoch total loss 0.273912162\n",
      "Trained batch 129 batch loss 0.249053985 epoch total loss 0.27371946\n",
      "Trained batch 130 batch loss 0.24551028 epoch total loss 0.273502469\n",
      "Trained batch 131 batch loss 0.257125646 epoch total loss 0.273377448\n",
      "Trained batch 132 batch loss 0.241387367 epoch total loss 0.273135096\n",
      "Trained batch 133 batch loss 0.272798628 epoch total loss 0.273132592\n",
      "Trained batch 134 batch loss 0.238821566 epoch total loss 0.272876531\n",
      "Trained batch 135 batch loss 0.258107424 epoch total loss 0.272767127\n",
      "Trained batch 136 batch loss 0.305840343 epoch total loss 0.273010314\n",
      "Trained batch 137 batch loss 0.302693307 epoch total loss 0.273226976\n",
      "Trained batch 138 batch loss 0.30071941 epoch total loss 0.273426205\n",
      "Trained batch 139 batch loss 0.276856452 epoch total loss 0.273450851\n",
      "Trained batch 140 batch loss 0.291153938 epoch total loss 0.273577303\n",
      "Trained batch 141 batch loss 0.264482439 epoch total loss 0.273512781\n",
      "Trained batch 142 batch loss 0.272483647 epoch total loss 0.273505539\n",
      "Trained batch 143 batch loss 0.293337166 epoch total loss 0.273644239\n",
      "Trained batch 144 batch loss 0.294476092 epoch total loss 0.273788899\n",
      "Trained batch 145 batch loss 0.300593 epoch total loss 0.273973763\n",
      "Trained batch 146 batch loss 0.262558401 epoch total loss 0.273895591\n",
      "Trained batch 147 batch loss 0.276837975 epoch total loss 0.273915589\n",
      "Trained batch 148 batch loss 0.315779716 epoch total loss 0.274198443\n",
      "Trained batch 149 batch loss 0.307154834 epoch total loss 0.274419636\n",
      "Trained batch 150 batch loss 0.279788971 epoch total loss 0.274455428\n",
      "Trained batch 151 batch loss 0.281677425 epoch total loss 0.274503261\n",
      "Trained batch 152 batch loss 0.27223745 epoch total loss 0.27448836\n",
      "Trained batch 153 batch loss 0.298031718 epoch total loss 0.274642229\n",
      "Trained batch 154 batch loss 0.236380741 epoch total loss 0.274393767\n",
      "Trained batch 155 batch loss 0.233675182 epoch total loss 0.274131089\n",
      "Trained batch 156 batch loss 0.215824157 epoch total loss 0.273757309\n",
      "Trained batch 157 batch loss 0.229129821 epoch total loss 0.273473084\n",
      "Trained batch 158 batch loss 0.278543711 epoch total loss 0.273505181\n",
      "Trained batch 159 batch loss 0.302469373 epoch total loss 0.273687363\n",
      "Trained batch 160 batch loss 0.293932855 epoch total loss 0.273813903\n",
      "Trained batch 161 batch loss 0.261969745 epoch total loss 0.273740321\n",
      "Trained batch 162 batch loss 0.260928452 epoch total loss 0.273661256\n",
      "Trained batch 163 batch loss 0.268693328 epoch total loss 0.273630768\n",
      "Trained batch 164 batch loss 0.267332 epoch total loss 0.273592353\n",
      "Trained batch 165 batch loss 0.279663235 epoch total loss 0.273629129\n",
      "Trained batch 166 batch loss 0.282676 epoch total loss 0.273683637\n",
      "Trained batch 167 batch loss 0.274810284 epoch total loss 0.273690403\n",
      "Trained batch 168 batch loss 0.302196264 epoch total loss 0.273860067\n",
      "Trained batch 169 batch loss 0.309727669 epoch total loss 0.274072289\n",
      "Trained batch 170 batch loss 0.28226921 epoch total loss 0.27412051\n",
      "Trained batch 171 batch loss 0.29010433 epoch total loss 0.27421397\n",
      "Trained batch 172 batch loss 0.245684043 epoch total loss 0.27404812\n",
      "Trained batch 173 batch loss 0.235798985 epoch total loss 0.273827016\n",
      "Trained batch 174 batch loss 0.261760741 epoch total loss 0.273757666\n",
      "Trained batch 175 batch loss 0.275277823 epoch total loss 0.273766339\n",
      "Trained batch 176 batch loss 0.275597274 epoch total loss 0.27377674\n",
      "Trained batch 177 batch loss 0.284294397 epoch total loss 0.273836166\n",
      "Trained batch 178 batch loss 0.305034131 epoch total loss 0.274011433\n",
      "Trained batch 179 batch loss 0.217921406 epoch total loss 0.273698092\n",
      "Trained batch 180 batch loss 0.285444468 epoch total loss 0.273763359\n",
      "Trained batch 181 batch loss 0.324127436 epoch total loss 0.274041623\n",
      "Trained batch 182 batch loss 0.294787288 epoch total loss 0.274155617\n",
      "Trained batch 183 batch loss 0.257878393 epoch total loss 0.274066657\n",
      "Trained batch 184 batch loss 0.219105914 epoch total loss 0.273767948\n",
      "Trained batch 185 batch loss 0.239675298 epoch total loss 0.273583651\n",
      "Trained batch 186 batch loss 0.238439411 epoch total loss 0.273394704\n",
      "Trained batch 187 batch loss 0.251897246 epoch total loss 0.273279727\n",
      "Trained batch 188 batch loss 0.228734642 epoch total loss 0.273042768\n",
      "Trained batch 189 batch loss 0.244027764 epoch total loss 0.272889256\n",
      "Trained batch 190 batch loss 0.238416851 epoch total loss 0.27270782\n",
      "Trained batch 191 batch loss 0.25700742 epoch total loss 0.272625625\n",
      "Trained batch 192 batch loss 0.273845643 epoch total loss 0.272631973\n",
      "Trained batch 193 batch loss 0.267528027 epoch total loss 0.272605538\n",
      "Trained batch 194 batch loss 0.267167747 epoch total loss 0.272577494\n",
      "Trained batch 195 batch loss 0.284947276 epoch total loss 0.272640944\n",
      "Trained batch 196 batch loss 0.277831584 epoch total loss 0.272667408\n",
      "Trained batch 197 batch loss 0.290705562 epoch total loss 0.272759\n",
      "Trained batch 198 batch loss 0.30952251 epoch total loss 0.272944659\n",
      "Trained batch 199 batch loss 0.283035696 epoch total loss 0.272995353\n",
      "Trained batch 200 batch loss 0.313159525 epoch total loss 0.273196191\n",
      "Trained batch 201 batch loss 0.283042073 epoch total loss 0.273245186\n",
      "Trained batch 202 batch loss 0.248252749 epoch total loss 0.273121446\n",
      "Trained batch 203 batch loss 0.273438752 epoch total loss 0.273123\n",
      "Trained batch 204 batch loss 0.26394096 epoch total loss 0.273078\n",
      "Trained batch 205 batch loss 0.227010116 epoch total loss 0.272853285\n",
      "Trained batch 206 batch loss 0.241199225 epoch total loss 0.272699624\n",
      "Trained batch 207 batch loss 0.235182866 epoch total loss 0.272518367\n",
      "Trained batch 208 batch loss 0.238276109 epoch total loss 0.272353768\n",
      "Trained batch 209 batch loss 0.202883691 epoch total loss 0.272021383\n",
      "Trained batch 210 batch loss 0.210262313 epoch total loss 0.271727294\n",
      "Trained batch 211 batch loss 0.195498407 epoch total loss 0.271366\n",
      "Trained batch 212 batch loss 0.278764576 epoch total loss 0.271400899\n",
      "Trained batch 213 batch loss 0.259907067 epoch total loss 0.271346927\n",
      "Trained batch 214 batch loss 0.236380681 epoch total loss 0.27118355\n",
      "Trained batch 215 batch loss 0.265399486 epoch total loss 0.271156639\n",
      "Trained batch 216 batch loss 0.269156188 epoch total loss 0.2711474\n",
      "Trained batch 217 batch loss 0.282287538 epoch total loss 0.27119872\n",
      "Trained batch 218 batch loss 0.266516238 epoch total loss 0.271177262\n",
      "Trained batch 219 batch loss 0.271584392 epoch total loss 0.27117911\n",
      "Trained batch 220 batch loss 0.276200444 epoch total loss 0.271201938\n",
      "Trained batch 221 batch loss 0.264881641 epoch total loss 0.271173328\n",
      "Trained batch 222 batch loss 0.267234534 epoch total loss 0.271155596\n",
      "Trained batch 223 batch loss 0.264079243 epoch total loss 0.271123856\n",
      "Trained batch 224 batch loss 0.269194484 epoch total loss 0.271115243\n",
      "Trained batch 225 batch loss 0.246327206 epoch total loss 0.271005094\n",
      "Trained batch 226 batch loss 0.283225477 epoch total loss 0.271059155\n",
      "Trained batch 227 batch loss 0.270388514 epoch total loss 0.271056205\n",
      "Trained batch 228 batch loss 0.278170228 epoch total loss 0.271087408\n",
      "Trained batch 229 batch loss 0.285705686 epoch total loss 0.271151245\n",
      "Trained batch 230 batch loss 0.250479579 epoch total loss 0.271061361\n",
      "Trained batch 231 batch loss 0.256018251 epoch total loss 0.270996273\n",
      "Trained batch 232 batch loss 0.255790025 epoch total loss 0.270930707\n",
      "Trained batch 233 batch loss 0.317156613 epoch total loss 0.271129131\n",
      "Trained batch 234 batch loss 0.315607 epoch total loss 0.271319181\n",
      "Trained batch 235 batch loss 0.285726428 epoch total loss 0.271380484\n",
      "Trained batch 236 batch loss 0.260072649 epoch total loss 0.271332562\n",
      "Trained batch 237 batch loss 0.266079217 epoch total loss 0.271310419\n",
      "Trained batch 238 batch loss 0.282549948 epoch total loss 0.271357626\n",
      "Trained batch 239 batch loss 0.293369412 epoch total loss 0.271449745\n",
      "Trained batch 240 batch loss 0.27784133 epoch total loss 0.271476358\n",
      "Trained batch 241 batch loss 0.285667419 epoch total loss 0.271535248\n",
      "Trained batch 242 batch loss 0.269312233 epoch total loss 0.271526039\n",
      "Trained batch 243 batch loss 0.280941278 epoch total loss 0.271564811\n",
      "Trained batch 244 batch loss 0.298021019 epoch total loss 0.271673232\n",
      "Trained batch 245 batch loss 0.303113 epoch total loss 0.271801561\n",
      "Trained batch 246 batch loss 0.323772132 epoch total loss 0.27201283\n",
      "Trained batch 247 batch loss 0.252192944 epoch total loss 0.271932572\n",
      "Trained batch 248 batch loss 0.289674491 epoch total loss 0.272004098\n",
      "Trained batch 249 batch loss 0.299571306 epoch total loss 0.272114784\n",
      "Trained batch 250 batch loss 0.290415108 epoch total loss 0.272187978\n",
      "Trained batch 251 batch loss 0.284443319 epoch total loss 0.272236824\n",
      "Trained batch 252 batch loss 0.280323923 epoch total loss 0.272268921\n",
      "Trained batch 253 batch loss 0.288713574 epoch total loss 0.27233392\n",
      "Trained batch 254 batch loss 0.280963182 epoch total loss 0.272367895\n",
      "Trained batch 255 batch loss 0.325240582 epoch total loss 0.272575229\n",
      "Trained batch 256 batch loss 0.297711819 epoch total loss 0.272673428\n",
      "Trained batch 257 batch loss 0.313586503 epoch total loss 0.272832602\n",
      "Trained batch 258 batch loss 0.284787416 epoch total loss 0.272878945\n",
      "Trained batch 259 batch loss 0.297332078 epoch total loss 0.272973388\n",
      "Trained batch 260 batch loss 0.275023192 epoch total loss 0.272981256\n",
      "Trained batch 261 batch loss 0.329248667 epoch total loss 0.273196846\n",
      "Trained batch 262 batch loss 0.306590915 epoch total loss 0.273324281\n",
      "Trained batch 263 batch loss 0.285117954 epoch total loss 0.273369133\n",
      "Trained batch 264 batch loss 0.267279208 epoch total loss 0.273346066\n",
      "Trained batch 265 batch loss 0.301094681 epoch total loss 0.273450762\n",
      "Trained batch 266 batch loss 0.257493913 epoch total loss 0.27339077\n",
      "Trained batch 267 batch loss 0.275331289 epoch total loss 0.273398042\n",
      "Trained batch 268 batch loss 0.260165274 epoch total loss 0.273348659\n",
      "Trained batch 269 batch loss 0.225715071 epoch total loss 0.273171574\n",
      "Trained batch 270 batch loss 0.227734983 epoch total loss 0.27300331\n",
      "Trained batch 271 batch loss 0.272852272 epoch total loss 0.273002744\n",
      "Trained batch 272 batch loss 0.254622161 epoch total loss 0.272935152\n",
      "Trained batch 273 batch loss 0.250878394 epoch total loss 0.272854358\n",
      "Trained batch 274 batch loss 0.256726205 epoch total loss 0.272795528\n",
      "Trained batch 275 batch loss 0.267853647 epoch total loss 0.272777557\n",
      "Trained batch 276 batch loss 0.301321656 epoch total loss 0.272880971\n",
      "Trained batch 277 batch loss 0.260507941 epoch total loss 0.272836298\n",
      "Trained batch 278 batch loss 0.254338801 epoch total loss 0.272769749\n",
      "Trained batch 279 batch loss 0.29772827 epoch total loss 0.272859216\n",
      "Trained batch 280 batch loss 0.29847753 epoch total loss 0.272950709\n",
      "Trained batch 281 batch loss 0.282942832 epoch total loss 0.272986293\n",
      "Trained batch 282 batch loss 0.296364635 epoch total loss 0.273069173\n",
      "Trained batch 283 batch loss 0.291009039 epoch total loss 0.273132563\n",
      "Trained batch 284 batch loss 0.257949 epoch total loss 0.273079097\n",
      "Trained batch 285 batch loss 0.310105264 epoch total loss 0.273209\n",
      "Trained batch 286 batch loss 0.289774656 epoch total loss 0.273266941\n",
      "Trained batch 287 batch loss 0.284902781 epoch total loss 0.273307472\n",
      "Trained batch 288 batch loss 0.265791863 epoch total loss 0.273281395\n",
      "Trained batch 289 batch loss 0.2793383 epoch total loss 0.273302346\n",
      "Trained batch 290 batch loss 0.265645057 epoch total loss 0.273275942\n",
      "Trained batch 291 batch loss 0.250275612 epoch total loss 0.273196906\n",
      "Trained batch 292 batch loss 0.268985122 epoch total loss 0.273182452\n",
      "Trained batch 293 batch loss 0.288088083 epoch total loss 0.273233324\n",
      "Trained batch 294 batch loss 0.278500795 epoch total loss 0.273251265\n",
      "Trained batch 295 batch loss 0.28637132 epoch total loss 0.27329573\n",
      "Trained batch 296 batch loss 0.290781736 epoch total loss 0.273354799\n",
      "Trained batch 297 batch loss 0.301077336 epoch total loss 0.273448139\n",
      "Trained batch 298 batch loss 0.288337976 epoch total loss 0.273498088\n",
      "Trained batch 299 batch loss 0.251419336 epoch total loss 0.273424268\n",
      "Trained batch 300 batch loss 0.266216069 epoch total loss 0.273400217\n",
      "Trained batch 301 batch loss 0.271333426 epoch total loss 0.273393333\n",
      "Trained batch 302 batch loss 0.234295368 epoch total loss 0.273263901\n",
      "Trained batch 303 batch loss 0.274778455 epoch total loss 0.273268908\n",
      "Trained batch 304 batch loss 0.27248767 epoch total loss 0.273266345\n",
      "Trained batch 305 batch loss 0.264263868 epoch total loss 0.273236841\n",
      "Trained batch 306 batch loss 0.246282935 epoch total loss 0.273148745\n",
      "Trained batch 307 batch loss 0.286555916 epoch total loss 0.273192406\n",
      "Trained batch 308 batch loss 0.245677248 epoch total loss 0.273103058\n",
      "Trained batch 309 batch loss 0.283750743 epoch total loss 0.27313754\n",
      "Trained batch 310 batch loss 0.306923538 epoch total loss 0.273246527\n",
      "Trained batch 311 batch loss 0.290224791 epoch total loss 0.273301095\n",
      "Trained batch 312 batch loss 0.329744637 epoch total loss 0.273482\n",
      "Trained batch 313 batch loss 0.297477096 epoch total loss 0.273558676\n",
      "Trained batch 314 batch loss 0.275587827 epoch total loss 0.273565143\n",
      "Trained batch 315 batch loss 0.26983276 epoch total loss 0.273553312\n",
      "Trained batch 316 batch loss 0.232587457 epoch total loss 0.273423672\n",
      "Trained batch 317 batch loss 0.251160473 epoch total loss 0.273353428\n",
      "Trained batch 318 batch loss 0.268643677 epoch total loss 0.273338616\n",
      "Trained batch 319 batch loss 0.316056669 epoch total loss 0.273472548\n",
      "Trained batch 320 batch loss 0.277897477 epoch total loss 0.273486376\n",
      "Trained batch 321 batch loss 0.290684581 epoch total loss 0.27353996\n",
      "Trained batch 322 batch loss 0.279310703 epoch total loss 0.273557901\n",
      "Trained batch 323 batch loss 0.276236773 epoch total loss 0.273566186\n",
      "Trained batch 324 batch loss 0.263225228 epoch total loss 0.273534268\n",
      "Trained batch 325 batch loss 0.242240012 epoch total loss 0.273437977\n",
      "Trained batch 326 batch loss 0.282620072 epoch total loss 0.27346614\n",
      "Trained batch 327 batch loss 0.276213348 epoch total loss 0.273474544\n",
      "Trained batch 328 batch loss 0.278826356 epoch total loss 0.273490846\n",
      "Trained batch 329 batch loss 0.30273205 epoch total loss 0.273579746\n",
      "Trained batch 330 batch loss 0.260194302 epoch total loss 0.273539186\n",
      "Trained batch 331 batch loss 0.263435543 epoch total loss 0.273508668\n",
      "Trained batch 332 batch loss 0.279009551 epoch total loss 0.273525208\n",
      "Trained batch 333 batch loss 0.295459837 epoch total loss 0.273591101\n",
      "Trained batch 334 batch loss 0.270291954 epoch total loss 0.273581237\n",
      "Trained batch 335 batch loss 0.275038123 epoch total loss 0.273585588\n",
      "Trained batch 336 batch loss 0.282450736 epoch total loss 0.273611963\n",
      "Trained batch 337 batch loss 0.306955814 epoch total loss 0.273710877\n",
      "Trained batch 338 batch loss 0.278996676 epoch total loss 0.273726523\n",
      "Trained batch 339 batch loss 0.257079512 epoch total loss 0.273677438\n",
      "Trained batch 340 batch loss 0.288054287 epoch total loss 0.273719728\n",
      "Trained batch 341 batch loss 0.286681116 epoch total loss 0.273757726\n",
      "Trained batch 342 batch loss 0.290556848 epoch total loss 0.27380687\n",
      "Trained batch 343 batch loss 0.283780903 epoch total loss 0.273835927\n",
      "Trained batch 344 batch loss 0.280477524 epoch total loss 0.273855239\n",
      "Trained batch 345 batch loss 0.240043193 epoch total loss 0.273757249\n",
      "Trained batch 346 batch loss 0.290706664 epoch total loss 0.273806244\n",
      "Trained batch 347 batch loss 0.28781116 epoch total loss 0.273846596\n",
      "Trained batch 348 batch loss 0.283690631 epoch total loss 0.273874909\n",
      "Trained batch 349 batch loss 0.256531984 epoch total loss 0.273825198\n",
      "Trained batch 350 batch loss 0.257039875 epoch total loss 0.273777246\n",
      "Trained batch 351 batch loss 0.24798581 epoch total loss 0.273703754\n",
      "Trained batch 352 batch loss 0.270323843 epoch total loss 0.273694158\n",
      "Trained batch 353 batch loss 0.288422644 epoch total loss 0.273735881\n",
      "Trained batch 354 batch loss 0.295753509 epoch total loss 0.273798078\n",
      "Trained batch 355 batch loss 0.292441 epoch total loss 0.27385059\n",
      "Trained batch 356 batch loss 0.289871484 epoch total loss 0.273895621\n",
      "Trained batch 357 batch loss 0.27673316 epoch total loss 0.273903549\n",
      "Trained batch 358 batch loss 0.27891925 epoch total loss 0.273917586\n",
      "Trained batch 359 batch loss 0.264341027 epoch total loss 0.273890913\n",
      "Trained batch 360 batch loss 0.281445682 epoch total loss 0.273911893\n",
      "Trained batch 361 batch loss 0.322848648 epoch total loss 0.274047464\n",
      "Trained batch 362 batch loss 0.239812508 epoch total loss 0.273952872\n",
      "Trained batch 363 batch loss 0.203397647 epoch total loss 0.273758531\n",
      "Trained batch 364 batch loss 0.225871295 epoch total loss 0.273626953\n",
      "Trained batch 365 batch loss 0.27559942 epoch total loss 0.273632348\n",
      "Trained batch 366 batch loss 0.2983284 epoch total loss 0.27369982\n",
      "Trained batch 367 batch loss 0.322387844 epoch total loss 0.27383247\n",
      "Trained batch 368 batch loss 0.308611542 epoch total loss 0.273926973\n",
      "Trained batch 369 batch loss 0.29582423 epoch total loss 0.27398631\n",
      "Trained batch 370 batch loss 0.296754748 epoch total loss 0.274047852\n",
      "Trained batch 371 batch loss 0.291249126 epoch total loss 0.274094224\n",
      "Trained batch 372 batch loss 0.324760795 epoch total loss 0.274230421\n",
      "Trained batch 373 batch loss 0.268822968 epoch total loss 0.274215937\n",
      "Trained batch 374 batch loss 0.292480737 epoch total loss 0.274264753\n",
      "Trained batch 375 batch loss 0.273419291 epoch total loss 0.274262518\n",
      "Trained batch 376 batch loss 0.298220873 epoch total loss 0.274326235\n",
      "Trained batch 377 batch loss 0.317194402 epoch total loss 0.274439931\n",
      "Trained batch 378 batch loss 0.246465564 epoch total loss 0.274365932\n",
      "Trained batch 379 batch loss 0.227896199 epoch total loss 0.274243325\n",
      "Trained batch 380 batch loss 0.274572521 epoch total loss 0.274244189\n",
      "Trained batch 381 batch loss 0.281606287 epoch total loss 0.274263531\n",
      "Trained batch 382 batch loss 0.260741174 epoch total loss 0.274228126\n",
      "Trained batch 383 batch loss 0.269700259 epoch total loss 0.274216294\n",
      "Trained batch 384 batch loss 0.273329586 epoch total loss 0.274214\n",
      "Trained batch 385 batch loss 0.270139962 epoch total loss 0.27420342\n",
      "Trained batch 386 batch loss 0.293067038 epoch total loss 0.274252295\n",
      "Trained batch 387 batch loss 0.300196797 epoch total loss 0.274319321\n",
      "Trained batch 388 batch loss 0.28475967 epoch total loss 0.274346232\n",
      "Trained batch 389 batch loss 0.305773199 epoch total loss 0.274427\n",
      "Trained batch 390 batch loss 0.338968247 epoch total loss 0.274592489\n",
      "Trained batch 391 batch loss 0.352459192 epoch total loss 0.274791658\n",
      "Trained batch 392 batch loss 0.312984 epoch total loss 0.274889082\n",
      "Trained batch 393 batch loss 0.260027677 epoch total loss 0.274851263\n",
      "Trained batch 394 batch loss 0.242714852 epoch total loss 0.274769694\n",
      "Trained batch 395 batch loss 0.309149235 epoch total loss 0.274856716\n",
      "Trained batch 396 batch loss 0.298567533 epoch total loss 0.274916589\n",
      "Trained batch 397 batch loss 0.313583076 epoch total loss 0.275013983\n",
      "Trained batch 398 batch loss 0.289048851 epoch total loss 0.275049269\n",
      "Trained batch 399 batch loss 0.305578172 epoch total loss 0.275125772\n",
      "Trained batch 400 batch loss 0.316242576 epoch total loss 0.27522859\n",
      "Trained batch 401 batch loss 0.280072391 epoch total loss 0.27524066\n",
      "Trained batch 402 batch loss 0.297014832 epoch total loss 0.275294811\n",
      "Trained batch 403 batch loss 0.251976967 epoch total loss 0.275236964\n",
      "Trained batch 404 batch loss 0.273386866 epoch total loss 0.275232375\n",
      "Trained batch 405 batch loss 0.290982425 epoch total loss 0.275271267\n",
      "Trained batch 406 batch loss 0.289495677 epoch total loss 0.275306314\n",
      "Trained batch 407 batch loss 0.290616214 epoch total loss 0.275343925\n",
      "Trained batch 408 batch loss 0.304629147 epoch total loss 0.275415689\n",
      "Trained batch 409 batch loss 0.294520855 epoch total loss 0.275462419\n",
      "Trained batch 410 batch loss 0.289585054 epoch total loss 0.27549684\n",
      "Trained batch 411 batch loss 0.32327944 epoch total loss 0.275613099\n",
      "Trained batch 412 batch loss 0.278998375 epoch total loss 0.275621325\n",
      "Trained batch 413 batch loss 0.276051402 epoch total loss 0.275622368\n",
      "Trained batch 414 batch loss 0.308307528 epoch total loss 0.275701314\n",
      "Trained batch 415 batch loss 0.312525064 epoch total loss 0.275790036\n",
      "Trained batch 416 batch loss 0.273525655 epoch total loss 0.275784612\n",
      "Trained batch 417 batch loss 0.274550289 epoch total loss 0.275781631\n",
      "Trained batch 418 batch loss 0.278638691 epoch total loss 0.275788486\n",
      "Trained batch 419 batch loss 0.287647218 epoch total loss 0.275816768\n",
      "Trained batch 420 batch loss 0.293943822 epoch total loss 0.275859952\n",
      "Trained batch 421 batch loss 0.320422947 epoch total loss 0.27596578\n",
      "Trained batch 422 batch loss 0.314131886 epoch total loss 0.27605623\n",
      "Trained batch 423 batch loss 0.252817273 epoch total loss 0.276001275\n",
      "Trained batch 424 batch loss 0.291126847 epoch total loss 0.276036978\n",
      "Trained batch 425 batch loss 0.283507437 epoch total loss 0.276054531\n",
      "Trained batch 426 batch loss 0.294346124 epoch total loss 0.276097476\n",
      "Trained batch 427 batch loss 0.284302771 epoch total loss 0.276116699\n",
      "Trained batch 428 batch loss 0.270058304 epoch total loss 0.276102543\n",
      "Trained batch 429 batch loss 0.274273753 epoch total loss 0.276098281\n",
      "Trained batch 430 batch loss 0.262663871 epoch total loss 0.276067048\n",
      "Trained batch 431 batch loss 0.300959 epoch total loss 0.276124805\n",
      "Trained batch 432 batch loss 0.295290768 epoch total loss 0.276169151\n",
      "Trained batch 433 batch loss 0.286099762 epoch total loss 0.276192099\n",
      "Trained batch 434 batch loss 0.24957177 epoch total loss 0.276130766\n",
      "Trained batch 435 batch loss 0.277712047 epoch total loss 0.276134402\n",
      "Trained batch 436 batch loss 0.294879138 epoch total loss 0.276177377\n",
      "Trained batch 437 batch loss 0.28042078 epoch total loss 0.276187092\n",
      "Trained batch 438 batch loss 0.280711353 epoch total loss 0.276197404\n",
      "Trained batch 439 batch loss 0.339937299 epoch total loss 0.276342601\n",
      "Trained batch 440 batch loss 0.340772957 epoch total loss 0.276489019\n",
      "Trained batch 441 batch loss 0.27817136 epoch total loss 0.276492834\n",
      "Trained batch 442 batch loss 0.274738669 epoch total loss 0.27648887\n",
      "Trained batch 443 batch loss 0.230451316 epoch total loss 0.27638495\n",
      "Trained batch 444 batch loss 0.219155982 epoch total loss 0.276256055\n",
      "Trained batch 445 batch loss 0.25388822 epoch total loss 0.276205808\n",
      "Trained batch 446 batch loss 0.237586573 epoch total loss 0.276119202\n",
      "Trained batch 447 batch loss 0.205210939 epoch total loss 0.275960565\n",
      "Trained batch 448 batch loss 0.202948764 epoch total loss 0.275797606\n",
      "Trained batch 449 batch loss 0.229611337 epoch total loss 0.275694758\n",
      "Trained batch 450 batch loss 0.247647777 epoch total loss 0.275632411\n",
      "Trained batch 451 batch loss 0.265748382 epoch total loss 0.275610507\n",
      "Trained batch 452 batch loss 0.265794635 epoch total loss 0.275588781\n",
      "Trained batch 453 batch loss 0.27270022 epoch total loss 0.275582403\n",
      "Trained batch 454 batch loss 0.298286408 epoch total loss 0.275632411\n",
      "Trained batch 455 batch loss 0.268059313 epoch total loss 0.275615782\n",
      "Trained batch 456 batch loss 0.265839398 epoch total loss 0.275594324\n",
      "Trained batch 457 batch loss 0.285912782 epoch total loss 0.275616914\n",
      "Trained batch 458 batch loss 0.254762471 epoch total loss 0.275571376\n",
      "Trained batch 459 batch loss 0.253151178 epoch total loss 0.27552253\n",
      "Trained batch 460 batch loss 0.265624672 epoch total loss 0.275501\n",
      "Trained batch 461 batch loss 0.241483957 epoch total loss 0.275427222\n",
      "Trained batch 462 batch loss 0.233602926 epoch total loss 0.275336683\n",
      "Trained batch 463 batch loss 0.26000607 epoch total loss 0.275303572\n",
      "Trained batch 464 batch loss 0.242495731 epoch total loss 0.275232881\n",
      "Trained batch 465 batch loss 0.291288704 epoch total loss 0.275267392\n",
      "Trained batch 466 batch loss 0.279934645 epoch total loss 0.275277436\n",
      "Trained batch 467 batch loss 0.237630591 epoch total loss 0.275196791\n",
      "Trained batch 468 batch loss 0.273613572 epoch total loss 0.275193423\n",
      "Trained batch 469 batch loss 0.270804465 epoch total loss 0.275184065\n",
      "Trained batch 470 batch loss 0.277727842 epoch total loss 0.275189459\n",
      "Trained batch 471 batch loss 0.2999672 epoch total loss 0.27524209\n",
      "Trained batch 472 batch loss 0.296390414 epoch total loss 0.275286883\n",
      "Trained batch 473 batch loss 0.270563215 epoch total loss 0.275276899\n",
      "Trained batch 474 batch loss 0.271790028 epoch total loss 0.275269538\n",
      "Trained batch 475 batch loss 0.252745926 epoch total loss 0.275222123\n",
      "Trained batch 476 batch loss 0.251888126 epoch total loss 0.275173128\n",
      "Trained batch 477 batch loss 0.252514333 epoch total loss 0.275125623\n",
      "Trained batch 478 batch loss 0.260962605 epoch total loss 0.275095969\n",
      "Trained batch 479 batch loss 0.294644088 epoch total loss 0.275136799\n",
      "Trained batch 480 batch loss 0.333873272 epoch total loss 0.275259167\n",
      "Trained batch 481 batch loss 0.290988028 epoch total loss 0.27529186\n",
      "Trained batch 482 batch loss 0.238090843 epoch total loss 0.275214702\n",
      "Trained batch 483 batch loss 0.257724196 epoch total loss 0.275178492\n",
      "Trained batch 484 batch loss 0.252326459 epoch total loss 0.275131255\n",
      "Trained batch 485 batch loss 0.268086433 epoch total loss 0.275116712\n",
      "Trained batch 486 batch loss 0.316531062 epoch total loss 0.275201917\n",
      "Trained batch 487 batch loss 0.282358825 epoch total loss 0.275216639\n",
      "Trained batch 488 batch loss 0.275152892 epoch total loss 0.27521649\n",
      "Trained batch 489 batch loss 0.29245466 epoch total loss 0.275251746\n",
      "Trained batch 490 batch loss 0.272967517 epoch total loss 0.275247067\n",
      "Trained batch 491 batch loss 0.258508205 epoch total loss 0.275213\n",
      "Trained batch 492 batch loss 0.2931467 epoch total loss 0.275249451\n",
      "Trained batch 493 batch loss 0.291894227 epoch total loss 0.275283217\n",
      "Trained batch 494 batch loss 0.271792769 epoch total loss 0.275276154\n",
      "Trained batch 495 batch loss 0.285188735 epoch total loss 0.275296181\n",
      "Trained batch 496 batch loss 0.24383904 epoch total loss 0.275232732\n",
      "Trained batch 497 batch loss 0.228552923 epoch total loss 0.275138795\n",
      "Trained batch 498 batch loss 0.249075949 epoch total loss 0.275086462\n",
      "Trained batch 499 batch loss 0.282218575 epoch total loss 0.275100738\n",
      "Trained batch 500 batch loss 0.266079068 epoch total loss 0.275082707\n",
      "Trained batch 501 batch loss 0.279826552 epoch total loss 0.275092185\n",
      "Trained batch 502 batch loss 0.304472059 epoch total loss 0.275150716\n",
      "Trained batch 503 batch loss 0.287312061 epoch total loss 0.275174886\n",
      "Trained batch 504 batch loss 0.248401 epoch total loss 0.275121748\n",
      "Trained batch 505 batch loss 0.242982924 epoch total loss 0.275058091\n",
      "Trained batch 506 batch loss 0.26291883 epoch total loss 0.27503413\n",
      "Trained batch 507 batch loss 0.294699311 epoch total loss 0.275072902\n",
      "Trained batch 508 batch loss 0.289878249 epoch total loss 0.275102019\n",
      "Trained batch 509 batch loss 0.302121103 epoch total loss 0.275155127\n",
      "Trained batch 510 batch loss 0.298174202 epoch total loss 0.275200248\n",
      "Trained batch 511 batch loss 0.328661978 epoch total loss 0.275304854\n",
      "Trained batch 512 batch loss 0.29248327 epoch total loss 0.275338411\n",
      "Trained batch 513 batch loss 0.296145886 epoch total loss 0.275378972\n",
      "Trained batch 514 batch loss 0.279388189 epoch total loss 0.275386781\n",
      "Trained batch 515 batch loss 0.291030943 epoch total loss 0.275417149\n",
      "Trained batch 516 batch loss 0.295122296 epoch total loss 0.275455326\n",
      "Trained batch 517 batch loss 0.308191 epoch total loss 0.275518656\n",
      "Trained batch 518 batch loss 0.31858319 epoch total loss 0.275601804\n",
      "Trained batch 519 batch loss 0.29083842 epoch total loss 0.27563116\n",
      "Trained batch 520 batch loss 0.273297429 epoch total loss 0.275626659\n",
      "Trained batch 521 batch loss 0.246250972 epoch total loss 0.275570273\n",
      "Trained batch 522 batch loss 0.236698806 epoch total loss 0.275495797\n",
      "Trained batch 523 batch loss 0.286437809 epoch total loss 0.275516719\n",
      "Trained batch 524 batch loss 0.290811062 epoch total loss 0.275545925\n",
      "Trained batch 525 batch loss 0.291144639 epoch total loss 0.275575608\n",
      "Trained batch 526 batch loss 0.29047367 epoch total loss 0.27560392\n",
      "Trained batch 527 batch loss 0.306359291 epoch total loss 0.275662303\n",
      "Trained batch 528 batch loss 0.261984587 epoch total loss 0.275636375\n",
      "Trained batch 529 batch loss 0.236779 epoch total loss 0.275562942\n",
      "Trained batch 530 batch loss 0.253665566 epoch total loss 0.275521606\n",
      "Trained batch 531 batch loss 0.266213953 epoch total loss 0.275504112\n",
      "Trained batch 532 batch loss 0.293134898 epoch total loss 0.275537252\n",
      "Trained batch 533 batch loss 0.260289043 epoch total loss 0.275508642\n",
      "Trained batch 534 batch loss 0.312118202 epoch total loss 0.275577188\n",
      "Trained batch 535 batch loss 0.294922113 epoch total loss 0.275613338\n",
      "Trained batch 536 batch loss 0.31247735 epoch total loss 0.275682122\n",
      "Trained batch 537 batch loss 0.299173445 epoch total loss 0.275725901\n",
      "Trained batch 538 batch loss 0.325421542 epoch total loss 0.275818259\n",
      "Trained batch 539 batch loss 0.285552442 epoch total loss 0.275836319\n",
      "Trained batch 540 batch loss 0.334403396 epoch total loss 0.275944769\n",
      "Trained batch 541 batch loss 0.309030682 epoch total loss 0.276005954\n",
      "Trained batch 542 batch loss 0.286685169 epoch total loss 0.276025653\n",
      "Trained batch 543 batch loss 0.227718234 epoch total loss 0.275936693\n",
      "Trained batch 544 batch loss 0.223477453 epoch total loss 0.275840253\n",
      "Trained batch 545 batch loss 0.242658287 epoch total loss 0.275779366\n",
      "Trained batch 546 batch loss 0.310891688 epoch total loss 0.27584368\n",
      "Trained batch 547 batch loss 0.328995585 epoch total loss 0.275940865\n",
      "Trained batch 548 batch loss 0.314898372 epoch total loss 0.276011944\n",
      "Trained batch 549 batch loss 0.284568727 epoch total loss 0.27602753\n",
      "Trained batch 550 batch loss 0.273582846 epoch total loss 0.27602309\n",
      "Trained batch 551 batch loss 0.267788529 epoch total loss 0.276008159\n",
      "Trained batch 552 batch loss 0.292079568 epoch total loss 0.276037276\n",
      "Trained batch 553 batch loss 0.293215513 epoch total loss 0.27606833\n",
      "Trained batch 554 batch loss 0.287065804 epoch total loss 0.276088178\n",
      "Trained batch 555 batch loss 0.284953892 epoch total loss 0.276104152\n",
      "Trained batch 556 batch loss 0.308575422 epoch total loss 0.276162565\n",
      "Trained batch 557 batch loss 0.261501968 epoch total loss 0.276136249\n",
      "Trained batch 558 batch loss 0.279635787 epoch total loss 0.276142508\n",
      "Trained batch 559 batch loss 0.240084022 epoch total loss 0.276078016\n",
      "Trained batch 560 batch loss 0.270265341 epoch total loss 0.276067615\n",
      "Trained batch 561 batch loss 0.264522165 epoch total loss 0.276047051\n",
      "Trained batch 562 batch loss 0.274405658 epoch total loss 0.27604413\n",
      "Trained batch 563 batch loss 0.251447082 epoch total loss 0.27600044\n",
      "Trained batch 564 batch loss 0.228672788 epoch total loss 0.275916517\n",
      "Trained batch 565 batch loss 0.264192551 epoch total loss 0.275895745\n",
      "Trained batch 566 batch loss 0.283185 epoch total loss 0.275908649\n",
      "Trained batch 567 batch loss 0.269556612 epoch total loss 0.275897443\n",
      "Trained batch 568 batch loss 0.249068439 epoch total loss 0.275850207\n",
      "Trained batch 569 batch loss 0.266137362 epoch total loss 0.27583316\n",
      "Trained batch 570 batch loss 0.26901567 epoch total loss 0.275821179\n",
      "Trained batch 571 batch loss 0.281040192 epoch total loss 0.275830328\n",
      "Trained batch 572 batch loss 0.281525582 epoch total loss 0.275840282\n",
      "Trained batch 573 batch loss 0.282537758 epoch total loss 0.275851965\n",
      "Trained batch 574 batch loss 0.269634426 epoch total loss 0.275841117\n",
      "Trained batch 575 batch loss 0.292005301 epoch total loss 0.27586925\n",
      "Trained batch 576 batch loss 0.287954032 epoch total loss 0.275890231\n",
      "Trained batch 577 batch loss 0.277585119 epoch total loss 0.275893152\n",
      "Trained batch 578 batch loss 0.286930859 epoch total loss 0.275912255\n",
      "Trained batch 579 batch loss 0.278654456 epoch total loss 0.275917\n",
      "Trained batch 580 batch loss 0.265278578 epoch total loss 0.275898635\n",
      "Trained batch 581 batch loss 0.254686445 epoch total loss 0.275862128\n",
      "Trained batch 582 batch loss 0.264299601 epoch total loss 0.275842249\n",
      "Trained batch 583 batch loss 0.304092 epoch total loss 0.275890708\n",
      "Trained batch 584 batch loss 0.268493354 epoch total loss 0.275878042\n",
      "Trained batch 585 batch loss 0.293073177 epoch total loss 0.275907427\n",
      "Trained batch 586 batch loss 0.304466069 epoch total loss 0.275956154\n",
      "Trained batch 587 batch loss 0.267419696 epoch total loss 0.27594164\n",
      "Trained batch 588 batch loss 0.241966397 epoch total loss 0.275883853\n",
      "Trained batch 589 batch loss 0.278701156 epoch total loss 0.275888652\n",
      "Trained batch 590 batch loss 0.282709718 epoch total loss 0.275900215\n",
      "Trained batch 591 batch loss 0.270105064 epoch total loss 0.27589041\n",
      "Trained batch 592 batch loss 0.251206636 epoch total loss 0.275848716\n",
      "Trained batch 593 batch loss 0.261470884 epoch total loss 0.275824487\n",
      "Trained batch 594 batch loss 0.277800858 epoch total loss 0.275827825\n",
      "Trained batch 595 batch loss 0.275285602 epoch total loss 0.275826901\n",
      "Trained batch 596 batch loss 0.294334084 epoch total loss 0.275857925\n",
      "Trained batch 597 batch loss 0.250499725 epoch total loss 0.275815457\n",
      "Trained batch 598 batch loss 0.247805551 epoch total loss 0.275768638\n",
      "Trained batch 599 batch loss 0.253753155 epoch total loss 0.275731862\n",
      "Trained batch 600 batch loss 0.271405876 epoch total loss 0.275724679\n",
      "Trained batch 601 batch loss 0.282131881 epoch total loss 0.275735319\n",
      "Trained batch 602 batch loss 0.275554061 epoch total loss 0.27573505\n",
      "Trained batch 603 batch loss 0.270652562 epoch total loss 0.275726587\n",
      "Trained batch 604 batch loss 0.24849005 epoch total loss 0.275681496\n",
      "Trained batch 605 batch loss 0.269241244 epoch total loss 0.275670856\n",
      "Trained batch 606 batch loss 0.258251578 epoch total loss 0.275642127\n",
      "Trained batch 607 batch loss 0.242600158 epoch total loss 0.275587678\n",
      "Trained batch 608 batch loss 0.259348691 epoch total loss 0.275560975\n",
      "Trained batch 609 batch loss 0.257833093 epoch total loss 0.275531858\n",
      "Trained batch 610 batch loss 0.287941962 epoch total loss 0.275552213\n",
      "Trained batch 611 batch loss 0.29273057 epoch total loss 0.275580317\n",
      "Trained batch 612 batch loss 0.281347483 epoch total loss 0.275589734\n",
      "Trained batch 613 batch loss 0.277687788 epoch total loss 0.275593162\n",
      "Trained batch 614 batch loss 0.299704403 epoch total loss 0.275632441\n",
      "Trained batch 615 batch loss 0.300511956 epoch total loss 0.275672883\n",
      "Trained batch 616 batch loss 0.329438031 epoch total loss 0.275760144\n",
      "Trained batch 617 batch loss 0.324531496 epoch total loss 0.27583918\n",
      "Trained batch 618 batch loss 0.293208599 epoch total loss 0.275867313\n",
      "Trained batch 619 batch loss 0.26874432 epoch total loss 0.27585578\n",
      "Trained batch 620 batch loss 0.295075178 epoch total loss 0.275886774\n",
      "Trained batch 621 batch loss 0.277151674 epoch total loss 0.275888801\n",
      "Trained batch 622 batch loss 0.296542168 epoch total loss 0.275922\n",
      "Trained batch 623 batch loss 0.268778473 epoch total loss 0.275910556\n",
      "Trained batch 624 batch loss 0.26458326 epoch total loss 0.275892407\n",
      "Trained batch 625 batch loss 0.243763775 epoch total loss 0.275841\n",
      "Trained batch 626 batch loss 0.261031091 epoch total loss 0.275817335\n",
      "Trained batch 627 batch loss 0.262761801 epoch total loss 0.275796503\n",
      "Trained batch 628 batch loss 0.254140168 epoch total loss 0.275762022\n",
      "Trained batch 629 batch loss 0.26996249 epoch total loss 0.275752783\n",
      "Trained batch 630 batch loss 0.298861504 epoch total loss 0.275789469\n",
      "Trained batch 631 batch loss 0.335666955 epoch total loss 0.27588436\n",
      "Trained batch 632 batch loss 0.310531557 epoch total loss 0.275939167\n",
      "Trained batch 633 batch loss 0.335350245 epoch total loss 0.276033044\n",
      "Trained batch 634 batch loss 0.321216941 epoch total loss 0.276104301\n",
      "Trained batch 635 batch loss 0.278551519 epoch total loss 0.276108146\n",
      "Trained batch 636 batch loss 0.285003424 epoch total loss 0.276122123\n",
      "Trained batch 637 batch loss 0.304128557 epoch total loss 0.276166081\n",
      "Trained batch 638 batch loss 0.285927892 epoch total loss 0.2761814\n",
      "Trained batch 639 batch loss 0.307229787 epoch total loss 0.27623\n",
      "Trained batch 640 batch loss 0.271384209 epoch total loss 0.276222408\n",
      "Trained batch 641 batch loss 0.306785464 epoch total loss 0.276270092\n",
      "Trained batch 642 batch loss 0.269230306 epoch total loss 0.276259124\n",
      "Trained batch 643 batch loss 0.27423203 epoch total loss 0.276255965\n",
      "Trained batch 644 batch loss 0.254084587 epoch total loss 0.276221544\n",
      "Trained batch 645 batch loss 0.223030508 epoch total loss 0.276139081\n",
      "Trained batch 646 batch loss 0.234271407 epoch total loss 0.27607426\n",
      "Trained batch 647 batch loss 0.269420505 epoch total loss 0.276063979\n",
      "Trained batch 648 batch loss 0.296103716 epoch total loss 0.276094913\n",
      "Trained batch 649 batch loss 0.326034248 epoch total loss 0.276171863\n",
      "Trained batch 650 batch loss 0.303954691 epoch total loss 0.2762146\n",
      "Trained batch 651 batch loss 0.299713194 epoch total loss 0.27625069\n",
      "Trained batch 652 batch loss 0.287569255 epoch total loss 0.276268065\n",
      "Trained batch 653 batch loss 0.301492542 epoch total loss 0.276306689\n",
      "Trained batch 654 batch loss 0.24194248 epoch total loss 0.276254147\n",
      "Trained batch 655 batch loss 0.237938136 epoch total loss 0.276195645\n",
      "Trained batch 656 batch loss 0.254820794 epoch total loss 0.276163071\n",
      "Trained batch 657 batch loss 0.339816093 epoch total loss 0.276259959\n",
      "Trained batch 658 batch loss 0.289688 epoch total loss 0.276280373\n",
      "Trained batch 659 batch loss 0.284837872 epoch total loss 0.276293337\n",
      "Trained batch 660 batch loss 0.259642333 epoch total loss 0.276268125\n",
      "Trained batch 661 batch loss 0.299090147 epoch total loss 0.276302636\n",
      "Trained batch 662 batch loss 0.261333615 epoch total loss 0.276280046\n",
      "Trained batch 663 batch loss 0.266899824 epoch total loss 0.276265889\n",
      "Trained batch 664 batch loss 0.262606442 epoch total loss 0.276245326\n",
      "Trained batch 665 batch loss 0.285674572 epoch total loss 0.276259512\n",
      "Trained batch 666 batch loss 0.277773857 epoch total loss 0.276261777\n",
      "Trained batch 667 batch loss 0.281499892 epoch total loss 0.276269615\n",
      "Trained batch 668 batch loss 0.284101367 epoch total loss 0.276281357\n",
      "Trained batch 669 batch loss 0.264361143 epoch total loss 0.276263535\n",
      "Trained batch 670 batch loss 0.243569463 epoch total loss 0.276214749\n",
      "Trained batch 671 batch loss 0.264669359 epoch total loss 0.276197523\n",
      "Trained batch 672 batch loss 0.287926316 epoch total loss 0.276215\n",
      "Trained batch 673 batch loss 0.336345643 epoch total loss 0.276304334\n",
      "Trained batch 674 batch loss 0.273271382 epoch total loss 0.276299834\n",
      "Trained batch 675 batch loss 0.318403363 epoch total loss 0.276362211\n",
      "Trained batch 676 batch loss 0.259014964 epoch total loss 0.276336551\n",
      "Trained batch 677 batch loss 0.262929082 epoch total loss 0.276316732\n",
      "Trained batch 678 batch loss 0.274666488 epoch total loss 0.276314318\n",
      "Trained batch 679 batch loss 0.25127393 epoch total loss 0.276277423\n",
      "Trained batch 680 batch loss 0.266642869 epoch total loss 0.276263267\n",
      "Trained batch 681 batch loss 0.279386967 epoch total loss 0.276267856\n",
      "Trained batch 682 batch loss 0.284905881 epoch total loss 0.276280522\n",
      "Trained batch 683 batch loss 0.267535537 epoch total loss 0.276267737\n",
      "Trained batch 684 batch loss 0.295811534 epoch total loss 0.276296288\n",
      "Trained batch 685 batch loss 0.26844582 epoch total loss 0.276284844\n",
      "Trained batch 686 batch loss 0.277360588 epoch total loss 0.276286393\n",
      "Trained batch 687 batch loss 0.260431945 epoch total loss 0.276263326\n",
      "Trained batch 688 batch loss 0.248523146 epoch total loss 0.276223\n",
      "Trained batch 689 batch loss 0.289403349 epoch total loss 0.276242137\n",
      "Trained batch 690 batch loss 0.275136083 epoch total loss 0.276240528\n",
      "Trained batch 691 batch loss 0.284834683 epoch total loss 0.276252955\n",
      "Trained batch 692 batch loss 0.268658727 epoch total loss 0.276242\n",
      "Trained batch 693 batch loss 0.242525041 epoch total loss 0.276193321\n",
      "Trained batch 694 batch loss 0.226995662 epoch total loss 0.276122421\n",
      "Trained batch 695 batch loss 0.273860067 epoch total loss 0.276119173\n",
      "Trained batch 696 batch loss 0.252451479 epoch total loss 0.276085198\n",
      "Trained batch 697 batch loss 0.258889377 epoch total loss 0.276060522\n",
      "Trained batch 698 batch loss 0.255029649 epoch total loss 0.276030391\n",
      "Trained batch 699 batch loss 0.295454144 epoch total loss 0.276058197\n",
      "Trained batch 700 batch loss 0.287868708 epoch total loss 0.276075065\n",
      "Trained batch 701 batch loss 0.292039305 epoch total loss 0.276097834\n",
      "Trained batch 702 batch loss 0.301392257 epoch total loss 0.276133865\n",
      "Trained batch 703 batch loss 0.299636096 epoch total loss 0.276167303\n",
      "Trained batch 704 batch loss 0.283740371 epoch total loss 0.276178062\n",
      "Trained batch 705 batch loss 0.317728072 epoch total loss 0.276237\n",
      "Trained batch 706 batch loss 0.28373915 epoch total loss 0.276247621\n",
      "Trained batch 707 batch loss 0.249924153 epoch total loss 0.276210397\n",
      "Trained batch 708 batch loss 0.266812354 epoch total loss 0.276197135\n",
      "Trained batch 709 batch loss 0.294049531 epoch total loss 0.276222318\n",
      "Trained batch 710 batch loss 0.27241981 epoch total loss 0.276216954\n",
      "Trained batch 711 batch loss 0.315995634 epoch total loss 0.276272893\n",
      "Trained batch 712 batch loss 0.307907462 epoch total loss 0.276317328\n",
      "Trained batch 713 batch loss 0.29717648 epoch total loss 0.276346564\n",
      "Trained batch 714 batch loss 0.227594107 epoch total loss 0.276278317\n",
      "Trained batch 715 batch loss 0.289846122 epoch total loss 0.276297271\n",
      "Trained batch 716 batch loss 0.292391896 epoch total loss 0.276319742\n",
      "Trained batch 717 batch loss 0.274770021 epoch total loss 0.276317567\n",
      "Trained batch 718 batch loss 0.299194366 epoch total loss 0.276349455\n",
      "Trained batch 719 batch loss 0.308101147 epoch total loss 0.276393622\n",
      "Trained batch 720 batch loss 0.270371199 epoch total loss 0.276385248\n",
      "Trained batch 721 batch loss 0.261180133 epoch total loss 0.276364148\n",
      "Trained batch 722 batch loss 0.264257699 epoch total loss 0.276347399\n",
      "Trained batch 723 batch loss 0.270375371 epoch total loss 0.276339114\n",
      "Trained batch 724 batch loss 0.262491256 epoch total loss 0.27632\n",
      "Trained batch 725 batch loss 0.267055064 epoch total loss 0.276307225\n",
      "Trained batch 726 batch loss 0.25311321 epoch total loss 0.276275277\n",
      "Trained batch 727 batch loss 0.259420246 epoch total loss 0.276252091\n",
      "Trained batch 728 batch loss 0.275056064 epoch total loss 0.276250452\n",
      "Trained batch 729 batch loss 0.26130724 epoch total loss 0.276229948\n",
      "Trained batch 730 batch loss 0.240600824 epoch total loss 0.276181132\n",
      "Trained batch 731 batch loss 0.274887085 epoch total loss 0.276179373\n",
      "Trained batch 732 batch loss 0.268957525 epoch total loss 0.276169479\n",
      "Trained batch 733 batch loss 0.268990934 epoch total loss 0.276159704\n",
      "Trained batch 734 batch loss 0.264876395 epoch total loss 0.276144326\n",
      "Trained batch 735 batch loss 0.256561488 epoch total loss 0.276117682\n",
      "Trained batch 736 batch loss 0.279556453 epoch total loss 0.276122361\n",
      "Trained batch 737 batch loss 0.269493818 epoch total loss 0.276113391\n",
      "Trained batch 738 batch loss 0.271708846 epoch total loss 0.27610743\n",
      "Trained batch 739 batch loss 0.273948431 epoch total loss 0.27610448\n",
      "Trained batch 740 batch loss 0.315934777 epoch total loss 0.276158303\n",
      "Trained batch 741 batch loss 0.311698556 epoch total loss 0.276206255\n",
      "Trained batch 742 batch loss 0.324063241 epoch total loss 0.276270747\n",
      "Trained batch 743 batch loss 0.302195638 epoch total loss 0.276305646\n",
      "Trained batch 744 batch loss 0.321200877 epoch total loss 0.276366\n",
      "Trained batch 745 batch loss 0.285480678 epoch total loss 0.276378214\n",
      "Trained batch 746 batch loss 0.272059798 epoch total loss 0.276372433\n",
      "Trained batch 747 batch loss 0.243683636 epoch total loss 0.276328683\n",
      "Trained batch 748 batch loss 0.288998753 epoch total loss 0.276345611\n",
      "Trained batch 749 batch loss 0.30669263 epoch total loss 0.276386142\n",
      "Trained batch 750 batch loss 0.302464694 epoch total loss 0.276420891\n",
      "Trained batch 751 batch loss 0.275614023 epoch total loss 0.276419818\n",
      "Trained batch 752 batch loss 0.257019877 epoch total loss 0.276394039\n",
      "Trained batch 753 batch loss 0.255058438 epoch total loss 0.276365697\n",
      "Trained batch 754 batch loss 0.220942512 epoch total loss 0.276292205\n",
      "Trained batch 755 batch loss 0.229987144 epoch total loss 0.276230872\n",
      "Trained batch 756 batch loss 0.277764112 epoch total loss 0.276232898\n",
      "Trained batch 757 batch loss 0.247312516 epoch total loss 0.276194692\n",
      "Trained batch 758 batch loss 0.258361697 epoch total loss 0.276171178\n",
      "Trained batch 759 batch loss 0.271407962 epoch total loss 0.276164889\n",
      "Trained batch 760 batch loss 0.271340817 epoch total loss 0.276158571\n",
      "Trained batch 761 batch loss 0.310264915 epoch total loss 0.276203394\n",
      "Trained batch 762 batch loss 0.330127209 epoch total loss 0.276274145\n",
      "Trained batch 763 batch loss 0.282356322 epoch total loss 0.276282132\n",
      "Trained batch 764 batch loss 0.302546442 epoch total loss 0.276316524\n",
      "Trained batch 765 batch loss 0.274161756 epoch total loss 0.276313692\n",
      "Trained batch 766 batch loss 0.286562771 epoch total loss 0.276327074\n",
      "Trained batch 767 batch loss 0.250014752 epoch total loss 0.276292771\n",
      "Trained batch 768 batch loss 0.289718509 epoch total loss 0.276310235\n",
      "Trained batch 769 batch loss 0.283569396 epoch total loss 0.276319683\n",
      "Trained batch 770 batch loss 0.249344558 epoch total loss 0.276284665\n",
      "Trained batch 771 batch loss 0.271076053 epoch total loss 0.2762779\n",
      "Trained batch 772 batch loss 0.226199523 epoch total loss 0.27621302\n",
      "Trained batch 773 batch loss 0.226854652 epoch total loss 0.276149154\n",
      "Trained batch 774 batch loss 0.259912878 epoch total loss 0.276128203\n",
      "Trained batch 775 batch loss 0.292198628 epoch total loss 0.276148945\n",
      "Trained batch 776 batch loss 0.334625632 epoch total loss 0.276224285\n",
      "Trained batch 777 batch loss 0.337343901 epoch total loss 0.276302963\n",
      "Trained batch 778 batch loss 0.299342 epoch total loss 0.276332557\n",
      "Trained batch 779 batch loss 0.312875271 epoch total loss 0.276379496\n",
      "Trained batch 780 batch loss 0.345019579 epoch total loss 0.276467472\n",
      "Trained batch 781 batch loss 0.29189226 epoch total loss 0.276487231\n",
      "Trained batch 782 batch loss 0.280447125 epoch total loss 0.276492268\n",
      "Trained batch 783 batch loss 0.301620901 epoch total loss 0.276524365\n",
      "Trained batch 784 batch loss 0.310179204 epoch total loss 0.27656731\n",
      "Trained batch 785 batch loss 0.313996255 epoch total loss 0.276615\n",
      "Trained batch 786 batch loss 0.339172095 epoch total loss 0.276694566\n",
      "Trained batch 787 batch loss 0.334798694 epoch total loss 0.276768386\n",
      "Trained batch 788 batch loss 0.339024812 epoch total loss 0.276847392\n",
      "Trained batch 789 batch loss 0.268758357 epoch total loss 0.27683714\n",
      "Trained batch 790 batch loss 0.270832479 epoch total loss 0.276829541\n",
      "Trained batch 791 batch loss 0.2765674 epoch total loss 0.276829183\n",
      "Trained batch 792 batch loss 0.270423055 epoch total loss 0.276821107\n",
      "Trained batch 793 batch loss 0.229611695 epoch total loss 0.276761562\n",
      "Trained batch 794 batch loss 0.259913236 epoch total loss 0.276740342\n",
      "Trained batch 795 batch loss 0.252349257 epoch total loss 0.276709676\n",
      "Trained batch 796 batch loss 0.269239426 epoch total loss 0.276700288\n",
      "Trained batch 797 batch loss 0.227283582 epoch total loss 0.276638299\n",
      "Trained batch 798 batch loss 0.25875324 epoch total loss 0.276615888\n",
      "Trained batch 799 batch loss 0.275607407 epoch total loss 0.276614606\n",
      "Trained batch 800 batch loss 0.282383919 epoch total loss 0.276621819\n",
      "Trained batch 801 batch loss 0.221403241 epoch total loss 0.276552886\n",
      "Trained batch 802 batch loss 0.245066151 epoch total loss 0.276513636\n",
      "Trained batch 803 batch loss 0.256514788 epoch total loss 0.276488721\n",
      "Trained batch 804 batch loss 0.263036191 epoch total loss 0.276471972\n",
      "Trained batch 805 batch loss 0.268644601 epoch total loss 0.276462257\n",
      "Trained batch 806 batch loss 0.262602866 epoch total loss 0.276445061\n",
      "Trained batch 807 batch loss 0.277083337 epoch total loss 0.276445866\n",
      "Trained batch 808 batch loss 0.304813474 epoch total loss 0.276480973\n",
      "Trained batch 809 batch loss 0.306059271 epoch total loss 0.27651754\n",
      "Trained batch 810 batch loss 0.330854982 epoch total loss 0.276584625\n",
      "Trained batch 811 batch loss 0.296629369 epoch total loss 0.276609331\n",
      "Trained batch 812 batch loss 0.288097262 epoch total loss 0.276623487\n",
      "Trained batch 813 batch loss 0.291898489 epoch total loss 0.276642263\n",
      "Trained batch 814 batch loss 0.288330972 epoch total loss 0.276656628\n",
      "Trained batch 815 batch loss 0.276377857 epoch total loss 0.2766563\n",
      "Trained batch 816 batch loss 0.282228976 epoch total loss 0.276663125\n",
      "Trained batch 817 batch loss 0.265844464 epoch total loss 0.276649863\n",
      "Trained batch 818 batch loss 0.254130065 epoch total loss 0.276622355\n",
      "Trained batch 819 batch loss 0.301184028 epoch total loss 0.276652336\n",
      "Trained batch 820 batch loss 0.278899401 epoch total loss 0.276655078\n",
      "Trained batch 821 batch loss 0.263266474 epoch total loss 0.276638746\n",
      "Trained batch 822 batch loss 0.243901819 epoch total loss 0.27659893\n",
      "Trained batch 823 batch loss 0.285872877 epoch total loss 0.276610196\n",
      "Trained batch 824 batch loss 0.284139305 epoch total loss 0.276619315\n",
      "Trained batch 825 batch loss 0.3193717 epoch total loss 0.276671141\n",
      "Trained batch 826 batch loss 0.309044421 epoch total loss 0.276710331\n",
      "Trained batch 827 batch loss 0.276767224 epoch total loss 0.276710421\n",
      "Trained batch 828 batch loss 0.311704934 epoch total loss 0.276752681\n",
      "Trained batch 829 batch loss 0.32204324 epoch total loss 0.276807308\n",
      "Trained batch 830 batch loss 0.294241339 epoch total loss 0.276828289\n",
      "Trained batch 831 batch loss 0.283788264 epoch total loss 0.276836663\n",
      "Trained batch 832 batch loss 0.293706924 epoch total loss 0.276856929\n",
      "Trained batch 833 batch loss 0.261926204 epoch total loss 0.276839018\n",
      "Trained batch 834 batch loss 0.29480198 epoch total loss 0.276860565\n",
      "Trained batch 835 batch loss 0.309085131 epoch total loss 0.276899129\n",
      "Trained batch 836 batch loss 0.275838077 epoch total loss 0.276897877\n",
      "Trained batch 837 batch loss 0.303740799 epoch total loss 0.276929945\n",
      "Trained batch 838 batch loss 0.269039929 epoch total loss 0.276920527\n",
      "Trained batch 839 batch loss 0.313188046 epoch total loss 0.276963741\n",
      "Trained batch 840 batch loss 0.286088586 epoch total loss 0.276974618\n",
      "Trained batch 841 batch loss 0.247707218 epoch total loss 0.276939809\n",
      "Trained batch 842 batch loss 0.264539659 epoch total loss 0.276925087\n",
      "Trained batch 843 batch loss 0.272938967 epoch total loss 0.276920348\n",
      "Trained batch 844 batch loss 0.276958287 epoch total loss 0.276920408\n",
      "Trained batch 845 batch loss 0.299779713 epoch total loss 0.276947469\n",
      "Trained batch 846 batch loss 0.290161848 epoch total loss 0.276963085\n",
      "Trained batch 847 batch loss 0.308561355 epoch total loss 0.277000368\n",
      "Trained batch 848 batch loss 0.267778575 epoch total loss 0.27698952\n",
      "Trained batch 849 batch loss 0.256197959 epoch total loss 0.276965022\n",
      "Trained batch 850 batch loss 0.31106782 epoch total loss 0.277005136\n",
      "Trained batch 851 batch loss 0.307419777 epoch total loss 0.277040869\n",
      "Trained batch 852 batch loss 0.310594618 epoch total loss 0.277080238\n",
      "Trained batch 853 batch loss 0.290691108 epoch total loss 0.277096212\n",
      "Trained batch 854 batch loss 0.279689431 epoch total loss 0.277099252\n",
      "Trained batch 855 batch loss 0.26099211 epoch total loss 0.277080417\n",
      "Trained batch 856 batch loss 0.277045429 epoch total loss 0.277080357\n",
      "Trained batch 857 batch loss 0.315359831 epoch total loss 0.277125031\n",
      "Trained batch 858 batch loss 0.298241854 epoch total loss 0.277149647\n",
      "Trained batch 859 batch loss 0.337451309 epoch total loss 0.277219832\n",
      "Trained batch 860 batch loss 0.32126525 epoch total loss 0.277271032\n",
      "Trained batch 861 batch loss 0.270188302 epoch total loss 0.277262807\n",
      "Trained batch 862 batch loss 0.294566482 epoch total loss 0.277282894\n",
      "Trained batch 863 batch loss 0.271449447 epoch total loss 0.277276129\n",
      "Trained batch 864 batch loss 0.292073101 epoch total loss 0.277293265\n",
      "Trained batch 865 batch loss 0.330510885 epoch total loss 0.277354777\n",
      "Trained batch 866 batch loss 0.264000475 epoch total loss 0.277339369\n",
      "Trained batch 867 batch loss 0.245308 epoch total loss 0.277302414\n",
      "Trained batch 868 batch loss 0.24517262 epoch total loss 0.277265429\n",
      "Trained batch 869 batch loss 0.259921908 epoch total loss 0.277245462\n",
      "Trained batch 870 batch loss 0.232432052 epoch total loss 0.277193964\n",
      "Trained batch 871 batch loss 0.252859175 epoch total loss 0.277166\n",
      "Trained batch 872 batch loss 0.299485862 epoch total loss 0.277191609\n",
      "Trained batch 873 batch loss 0.278384119 epoch total loss 0.27719295\n",
      "Trained batch 874 batch loss 0.276370674 epoch total loss 0.277192026\n",
      "Trained batch 875 batch loss 0.273914397 epoch total loss 0.277188271\n",
      "Trained batch 876 batch loss 0.252093256 epoch total loss 0.277159631\n",
      "Trained batch 877 batch loss 0.246575519 epoch total loss 0.277124763\n",
      "Trained batch 878 batch loss 0.250632256 epoch total loss 0.277094573\n",
      "Trained batch 879 batch loss 0.274693191 epoch total loss 0.277091831\n",
      "Trained batch 880 batch loss 0.301278561 epoch total loss 0.277119339\n",
      "Trained batch 881 batch loss 0.281558484 epoch total loss 0.277124345\n",
      "Trained batch 882 batch loss 0.306416661 epoch total loss 0.277157575\n",
      "Trained batch 883 batch loss 0.275349826 epoch total loss 0.277155519\n",
      "Trained batch 884 batch loss 0.270064861 epoch total loss 0.277147502\n",
      "Trained batch 885 batch loss 0.284010142 epoch total loss 0.27715525\n",
      "Trained batch 886 batch loss 0.278607905 epoch total loss 0.277156889\n",
      "Trained batch 887 batch loss 0.270066828 epoch total loss 0.277148902\n",
      "Trained batch 888 batch loss 0.269542843 epoch total loss 0.277140319\n",
      "Trained batch 889 batch loss 0.300131202 epoch total loss 0.277166188\n",
      "Trained batch 890 batch loss 0.329215229 epoch total loss 0.27722466\n",
      "Trained batch 891 batch loss 0.284336418 epoch total loss 0.277232647\n",
      "Trained batch 892 batch loss 0.266117096 epoch total loss 0.27722016\n",
      "Trained batch 893 batch loss 0.291570604 epoch total loss 0.277236223\n",
      "Trained batch 894 batch loss 0.292044163 epoch total loss 0.277252793\n",
      "Trained batch 895 batch loss 0.273910135 epoch total loss 0.277249068\n",
      "Trained batch 896 batch loss 0.305731058 epoch total loss 0.277280837\n",
      "Trained batch 897 batch loss 0.28352356 epoch total loss 0.277287811\n",
      "Trained batch 898 batch loss 0.295641661 epoch total loss 0.277308226\n",
      "Trained batch 899 batch loss 0.3041372 epoch total loss 0.277338088\n",
      "Trained batch 900 batch loss 0.304147393 epoch total loss 0.27736789\n",
      "Trained batch 901 batch loss 0.304965883 epoch total loss 0.277398497\n",
      "Trained batch 902 batch loss 0.283764392 epoch total loss 0.27740556\n",
      "Trained batch 903 batch loss 0.259428352 epoch total loss 0.277385652\n",
      "Trained batch 904 batch loss 0.30036816 epoch total loss 0.277411073\n",
      "Trained batch 905 batch loss 0.266710103 epoch total loss 0.277399242\n",
      "Trained batch 906 batch loss 0.279943347 epoch total loss 0.277402043\n",
      "Trained batch 907 batch loss 0.285395026 epoch total loss 0.277410865\n",
      "Trained batch 908 batch loss 0.298210144 epoch total loss 0.277433783\n",
      "Trained batch 909 batch loss 0.272312284 epoch total loss 0.27742815\n",
      "Trained batch 910 batch loss 0.274186492 epoch total loss 0.277424574\n",
      "Trained batch 911 batch loss 0.276259 epoch total loss 0.277423322\n",
      "Trained batch 912 batch loss 0.289199859 epoch total loss 0.277436227\n",
      "Trained batch 913 batch loss 0.312424064 epoch total loss 0.277474552\n",
      "Trained batch 914 batch loss 0.301034153 epoch total loss 0.277500331\n",
      "Trained batch 915 batch loss 0.286204189 epoch total loss 0.277509838\n",
      "Trained batch 916 batch loss 0.290825546 epoch total loss 0.277524382\n",
      "Trained batch 917 batch loss 0.302606404 epoch total loss 0.27755174\n",
      "Trained batch 918 batch loss 0.296689153 epoch total loss 0.277572602\n",
      "Trained batch 919 batch loss 0.27947256 epoch total loss 0.277574688\n",
      "Trained batch 920 batch loss 0.30180642 epoch total loss 0.277601\n",
      "Trained batch 921 batch loss 0.277179867 epoch total loss 0.277600557\n",
      "Trained batch 922 batch loss 0.278014481 epoch total loss 0.277601\n",
      "Trained batch 923 batch loss 0.302674323 epoch total loss 0.277628154\n",
      "Trained batch 924 batch loss 0.304376662 epoch total loss 0.277657121\n",
      "Trained batch 925 batch loss 0.270911723 epoch total loss 0.27764982\n",
      "Trained batch 926 batch loss 0.300346822 epoch total loss 0.277674347\n",
      "Trained batch 927 batch loss 0.222426862 epoch total loss 0.277614713\n",
      "Trained batch 928 batch loss 0.252487242 epoch total loss 0.277587652\n",
      "Trained batch 929 batch loss 0.248580009 epoch total loss 0.277556419\n",
      "Trained batch 930 batch loss 0.269369513 epoch total loss 0.277547628\n",
      "Trained batch 931 batch loss 0.288230687 epoch total loss 0.277559102\n",
      "Trained batch 932 batch loss 0.306762964 epoch total loss 0.277590454\n",
      "Trained batch 933 batch loss 0.294082701 epoch total loss 0.277608126\n",
      "Trained batch 934 batch loss 0.290431023 epoch total loss 0.277621865\n",
      "Trained batch 935 batch loss 0.314871639 epoch total loss 0.277661711\n",
      "Trained batch 936 batch loss 0.305192232 epoch total loss 0.277691156\n",
      "Trained batch 937 batch loss 0.293376952 epoch total loss 0.277707875\n",
      "Trained batch 938 batch loss 0.31472075 epoch total loss 0.277747333\n",
      "Trained batch 939 batch loss 0.291194886 epoch total loss 0.277761668\n",
      "Trained batch 940 batch loss 0.289077431 epoch total loss 0.277773678\n",
      "Trained batch 941 batch loss 0.263698339 epoch total loss 0.277758747\n",
      "Trained batch 942 batch loss 0.300473928 epoch total loss 0.277782857\n",
      "Trained batch 943 batch loss 0.313935727 epoch total loss 0.277821183\n",
      "Trained batch 944 batch loss 0.300685525 epoch total loss 0.277845412\n",
      "Trained batch 945 batch loss 0.288360178 epoch total loss 0.277856529\n",
      "Trained batch 946 batch loss 0.293800414 epoch total loss 0.277873397\n",
      "Trained batch 947 batch loss 0.286322474 epoch total loss 0.277882308\n",
      "Trained batch 948 batch loss 0.281143457 epoch total loss 0.277885765\n",
      "Trained batch 949 batch loss 0.314570636 epoch total loss 0.277924418\n",
      "Trained batch 950 batch loss 0.315695 epoch total loss 0.277964175\n",
      "Trained batch 951 batch loss 0.295264155 epoch total loss 0.277982384\n",
      "Trained batch 952 batch loss 0.287442476 epoch total loss 0.277992308\n",
      "Trained batch 953 batch loss 0.259256601 epoch total loss 0.277972639\n",
      "Trained batch 954 batch loss 0.244175419 epoch total loss 0.277937204\n",
      "Trained batch 955 batch loss 0.265931606 epoch total loss 0.277924627\n",
      "Trained batch 956 batch loss 0.270926625 epoch total loss 0.277917325\n",
      "Trained batch 957 batch loss 0.26555863 epoch total loss 0.277904421\n",
      "Trained batch 958 batch loss 0.298323035 epoch total loss 0.27792573\n",
      "Trained batch 959 batch loss 0.24808234 epoch total loss 0.277894586\n",
      "Trained batch 960 batch loss 0.27074036 epoch total loss 0.277887166\n",
      "Trained batch 961 batch loss 0.250837386 epoch total loss 0.277859\n",
      "Trained batch 962 batch loss 0.271066338 epoch total loss 0.277851909\n",
      "Trained batch 963 batch loss 0.257780492 epoch total loss 0.277831078\n",
      "Trained batch 964 batch loss 0.228298604 epoch total loss 0.277779698\n",
      "Trained batch 965 batch loss 0.2162752 epoch total loss 0.277715981\n",
      "Trained batch 966 batch loss 0.249858394 epoch total loss 0.277687132\n",
      "Trained batch 967 batch loss 0.249890372 epoch total loss 0.277658373\n",
      "Trained batch 968 batch loss 0.24684158 epoch total loss 0.277626544\n",
      "Trained batch 969 batch loss 0.274889529 epoch total loss 0.277623743\n",
      "Trained batch 970 batch loss 0.233292878 epoch total loss 0.277578056\n",
      "Trained batch 971 batch loss 0.27884835 epoch total loss 0.277579337\n",
      "Trained batch 972 batch loss 0.280846357 epoch total loss 0.277582705\n",
      "Trained batch 973 batch loss 0.301657081 epoch total loss 0.277607471\n",
      "Trained batch 974 batch loss 0.281731516 epoch total loss 0.277611703\n",
      "Trained batch 975 batch loss 0.307670653 epoch total loss 0.277642548\n",
      "Trained batch 976 batch loss 0.291889369 epoch total loss 0.277657151\n",
      "Trained batch 977 batch loss 0.272389561 epoch total loss 0.277651757\n",
      "Trained batch 978 batch loss 0.29104206 epoch total loss 0.277665466\n",
      "Trained batch 979 batch loss 0.26044789 epoch total loss 0.277647853\n",
      "Trained batch 980 batch loss 0.258739054 epoch total loss 0.277628571\n",
      "Trained batch 981 batch loss 0.263716161 epoch total loss 0.277614355\n",
      "Trained batch 982 batch loss 0.300061285 epoch total loss 0.277637213\n",
      "Trained batch 983 batch loss 0.284145892 epoch total loss 0.27764383\n",
      "Trained batch 984 batch loss 0.286310494 epoch total loss 0.277652651\n",
      "Trained batch 985 batch loss 0.28653124 epoch total loss 0.277661651\n",
      "Trained batch 986 batch loss 0.293309033 epoch total loss 0.277677536\n",
      "Trained batch 987 batch loss 0.301278293 epoch total loss 0.277701437\n",
      "Trained batch 988 batch loss 0.316679746 epoch total loss 0.277740866\n",
      "Trained batch 989 batch loss 0.30029434 epoch total loss 0.277763695\n",
      "Trained batch 990 batch loss 0.316502124 epoch total loss 0.277802795\n",
      "Trained batch 991 batch loss 0.269287765 epoch total loss 0.277794212\n",
      "Trained batch 992 batch loss 0.266106725 epoch total loss 0.27778244\n",
      "Trained batch 993 batch loss 0.307341307 epoch total loss 0.277812213\n",
      "Trained batch 994 batch loss 0.264152795 epoch total loss 0.277798474\n",
      "Trained batch 995 batch loss 0.260031521 epoch total loss 0.277780622\n",
      "Trained batch 996 batch loss 0.254752517 epoch total loss 0.277757525\n",
      "Trained batch 997 batch loss 0.259073168 epoch total loss 0.27773875\n",
      "Trained batch 998 batch loss 0.284749776 epoch total loss 0.277745813\n",
      "Trained batch 999 batch loss 0.295425713 epoch total loss 0.277763516\n",
      "Trained batch 1000 batch loss 0.29736644 epoch total loss 0.277783126\n",
      "Trained batch 1001 batch loss 0.306812316 epoch total loss 0.277812123\n",
      "Trained batch 1002 batch loss 0.283094227 epoch total loss 0.277817369\n",
      "Trained batch 1003 batch loss 0.35436967 epoch total loss 0.277893692\n",
      "Trained batch 1004 batch loss 0.263466626 epoch total loss 0.277879328\n",
      "Trained batch 1005 batch loss 0.276724488 epoch total loss 0.277878195\n",
      "Trained batch 1006 batch loss 0.323759675 epoch total loss 0.277923793\n",
      "Trained batch 1007 batch loss 0.299406469 epoch total loss 0.277945131\n",
      "Trained batch 1008 batch loss 0.302523464 epoch total loss 0.277969509\n",
      "Trained batch 1009 batch loss 0.296527117 epoch total loss 0.277987927\n",
      "Trained batch 1010 batch loss 0.271421 epoch total loss 0.27798143\n",
      "Trained batch 1011 batch loss 0.254899234 epoch total loss 0.277958602\n",
      "Trained batch 1012 batch loss 0.286985606 epoch total loss 0.277967513\n",
      "Trained batch 1013 batch loss 0.289979428 epoch total loss 0.277979374\n",
      "Trained batch 1014 batch loss 0.275738895 epoch total loss 0.277977169\n",
      "Trained batch 1015 batch loss 0.284433 epoch total loss 0.277983516\n",
      "Trained batch 1016 batch loss 0.269266903 epoch total loss 0.277974904\n",
      "Trained batch 1017 batch loss 0.275905669 epoch total loss 0.277972877\n",
      "Trained batch 1018 batch loss 0.288376331 epoch total loss 0.277983129\n",
      "Trained batch 1019 batch loss 0.282799453 epoch total loss 0.277987868\n",
      "Trained batch 1020 batch loss 0.292594522 epoch total loss 0.278002173\n",
      "Trained batch 1021 batch loss 0.24718979 epoch total loss 0.277972\n",
      "Trained batch 1022 batch loss 0.310742259 epoch total loss 0.27800405\n",
      "Trained batch 1023 batch loss 0.283836246 epoch total loss 0.278009772\n",
      "Trained batch 1024 batch loss 0.323978722 epoch total loss 0.278054655\n",
      "Trained batch 1025 batch loss 0.32537806 epoch total loss 0.278100818\n",
      "Trained batch 1026 batch loss 0.284705192 epoch total loss 0.278107256\n",
      "Trained batch 1027 batch loss 0.300622642 epoch total loss 0.27812919\n",
      "Trained batch 1028 batch loss 0.272103786 epoch total loss 0.278123319\n",
      "Trained batch 1029 batch loss 0.273282677 epoch total loss 0.27811861\n",
      "Trained batch 1030 batch loss 0.265822381 epoch total loss 0.27810666\n",
      "Trained batch 1031 batch loss 0.322115958 epoch total loss 0.278149337\n",
      "Trained batch 1032 batch loss 0.285603523 epoch total loss 0.278156579\n",
      "Trained batch 1033 batch loss 0.309223801 epoch total loss 0.278186649\n",
      "Trained batch 1034 batch loss 0.323451161 epoch total loss 0.278230429\n",
      "Trained batch 1035 batch loss 0.31391412 epoch total loss 0.27826491\n",
      "Trained batch 1036 batch loss 0.336210728 epoch total loss 0.278320849\n",
      "Trained batch 1037 batch loss 0.314146668 epoch total loss 0.27835539\n",
      "Trained batch 1038 batch loss 0.311818272 epoch total loss 0.278387636\n",
      "Trained batch 1039 batch loss 0.321079075 epoch total loss 0.278428733\n",
      "Trained batch 1040 batch loss 0.290899515 epoch total loss 0.278440714\n",
      "Trained batch 1041 batch loss 0.276619792 epoch total loss 0.278438956\n",
      "Trained batch 1042 batch loss 0.282584637 epoch total loss 0.278442949\n",
      "Trained batch 1043 batch loss 0.312629402 epoch total loss 0.278475702\n",
      "Trained batch 1044 batch loss 0.276442349 epoch total loss 0.278473735\n",
      "Trained batch 1045 batch loss 0.24899517 epoch total loss 0.278445542\n",
      "Trained batch 1046 batch loss 0.238522679 epoch total loss 0.278407365\n",
      "Trained batch 1047 batch loss 0.253634483 epoch total loss 0.278383702\n",
      "Trained batch 1048 batch loss 0.279289842 epoch total loss 0.278384566\n",
      "Trained batch 1049 batch loss 0.295776486 epoch total loss 0.278401166\n",
      "Trained batch 1050 batch loss 0.321892142 epoch total loss 0.278442591\n",
      "Trained batch 1051 batch loss 0.347051293 epoch total loss 0.278507859\n",
      "Trained batch 1052 batch loss 0.286447644 epoch total loss 0.278515399\n",
      "Trained batch 1053 batch loss 0.290453076 epoch total loss 0.278526753\n",
      "Trained batch 1054 batch loss 0.281074822 epoch total loss 0.278529167\n",
      "Trained batch 1055 batch loss 0.233267009 epoch total loss 0.278486252\n",
      "Trained batch 1056 batch loss 0.261236638 epoch total loss 0.27846992\n",
      "Trained batch 1057 batch loss 0.289972067 epoch total loss 0.278480798\n",
      "Trained batch 1058 batch loss 0.264480025 epoch total loss 0.278467566\n",
      "Trained batch 1059 batch loss 0.286058962 epoch total loss 0.278474748\n",
      "Trained batch 1060 batch loss 0.289419055 epoch total loss 0.27848509\n",
      "Trained batch 1061 batch loss 0.292160094 epoch total loss 0.278498\n",
      "Trained batch 1062 batch loss 0.280296177 epoch total loss 0.278499693\n",
      "Trained batch 1063 batch loss 0.30910486 epoch total loss 0.278528482\n",
      "Trained batch 1064 batch loss 0.302542955 epoch total loss 0.278551072\n",
      "Trained batch 1065 batch loss 0.305807948 epoch total loss 0.278576672\n",
      "Trained batch 1066 batch loss 0.294563651 epoch total loss 0.278591663\n",
      "Trained batch 1067 batch loss 0.281597853 epoch total loss 0.278594464\n",
      "Trained batch 1068 batch loss 0.274321198 epoch total loss 0.278590471\n",
      "Trained batch 1069 batch loss 0.278526425 epoch total loss 0.278590411\n",
      "Trained batch 1070 batch loss 0.279988825 epoch total loss 0.278591722\n",
      "Trained batch 1071 batch loss 0.274961621 epoch total loss 0.278588325\n",
      "Trained batch 1072 batch loss 0.285499752 epoch total loss 0.278594762\n",
      "Trained batch 1073 batch loss 0.298742235 epoch total loss 0.278613538\n",
      "Trained batch 1074 batch loss 0.276995 epoch total loss 0.278612047\n",
      "Trained batch 1075 batch loss 0.288121581 epoch total loss 0.278620899\n",
      "Trained batch 1076 batch loss 0.279975176 epoch total loss 0.27862215\n",
      "Trained batch 1077 batch loss 0.236606568 epoch total loss 0.278583139\n",
      "Trained batch 1078 batch loss 0.280519694 epoch total loss 0.278584927\n",
      "Trained batch 1079 batch loss 0.277705103 epoch total loss 0.278584123\n",
      "Trained batch 1080 batch loss 0.263280272 epoch total loss 0.278569937\n",
      "Trained batch 1081 batch loss 0.245419115 epoch total loss 0.27853927\n",
      "Trained batch 1082 batch loss 0.237741768 epoch total loss 0.27850157\n",
      "Trained batch 1083 batch loss 0.265871614 epoch total loss 0.278489888\n",
      "Trained batch 1084 batch loss 0.288758606 epoch total loss 0.278499365\n",
      "Trained batch 1085 batch loss 0.272103101 epoch total loss 0.278493464\n",
      "Trained batch 1086 batch loss 0.242564008 epoch total loss 0.278460354\n",
      "Trained batch 1087 batch loss 0.288740158 epoch total loss 0.278469801\n",
      "Trained batch 1088 batch loss 0.243723825 epoch total loss 0.278437853\n",
      "Trained batch 1089 batch loss 0.244888932 epoch total loss 0.278407067\n",
      "Trained batch 1090 batch loss 0.283619314 epoch total loss 0.278411865\n",
      "Trained batch 1091 batch loss 0.283358246 epoch total loss 0.278416395\n",
      "Trained batch 1092 batch loss 0.237245321 epoch total loss 0.278378695\n",
      "Trained batch 1093 batch loss 0.258247435 epoch total loss 0.278360277\n",
      "Trained batch 1094 batch loss 0.269410849 epoch total loss 0.278352082\n",
      "Trained batch 1095 batch loss 0.242832884 epoch total loss 0.278319657\n",
      "Trained batch 1096 batch loss 0.245683879 epoch total loss 0.278289884\n",
      "Trained batch 1097 batch loss 0.262184858 epoch total loss 0.278275192\n",
      "Trained batch 1098 batch loss 0.255856037 epoch total loss 0.278254777\n",
      "Trained batch 1099 batch loss 0.29719606 epoch total loss 0.278272033\n",
      "Trained batch 1100 batch loss 0.291480124 epoch total loss 0.278284\n",
      "Trained batch 1101 batch loss 0.270304739 epoch total loss 0.278276771\n",
      "Trained batch 1102 batch loss 0.281563163 epoch total loss 0.278279752\n",
      "Trained batch 1103 batch loss 0.289426416 epoch total loss 0.278289855\n",
      "Trained batch 1104 batch loss 0.308068 epoch total loss 0.278316826\n",
      "Trained batch 1105 batch loss 0.318050146 epoch total loss 0.278352797\n",
      "Trained batch 1106 batch loss 0.291296065 epoch total loss 0.27836448\n",
      "Trained batch 1107 batch loss 0.27196312 epoch total loss 0.278358728\n",
      "Trained batch 1108 batch loss 0.275804162 epoch total loss 0.278356433\n",
      "Trained batch 1109 batch loss 0.299979776 epoch total loss 0.278375924\n",
      "Trained batch 1110 batch loss 0.287426621 epoch total loss 0.27838406\n",
      "Trained batch 1111 batch loss 0.306487262 epoch total loss 0.278409362\n",
      "Trained batch 1112 batch loss 0.273652583 epoch total loss 0.2784051\n",
      "Trained batch 1113 batch loss 0.299699605 epoch total loss 0.278424233\n",
      "Trained batch 1114 batch loss 0.272193313 epoch total loss 0.27841863\n",
      "Trained batch 1115 batch loss 0.263726652 epoch total loss 0.278405458\n",
      "Trained batch 1116 batch loss 0.27254647 epoch total loss 0.278400213\n",
      "Trained batch 1117 batch loss 0.283691913 epoch total loss 0.278404951\n",
      "Trained batch 1118 batch loss 0.305351019 epoch total loss 0.278429061\n",
      "Trained batch 1119 batch loss 0.278505713 epoch total loss 0.278429121\n",
      "Trained batch 1120 batch loss 0.283652 epoch total loss 0.2784338\n",
      "Trained batch 1121 batch loss 0.287718445 epoch total loss 0.278442085\n",
      "Trained batch 1122 batch loss 0.286893487 epoch total loss 0.278449625\n",
      "Trained batch 1123 batch loss 0.25572139 epoch total loss 0.278429359\n",
      "Trained batch 1124 batch loss 0.244873554 epoch total loss 0.278399497\n",
      "Trained batch 1125 batch loss 0.286912143 epoch total loss 0.278407097\n",
      "Trained batch 1126 batch loss 0.298447847 epoch total loss 0.278424889\n",
      "Trained batch 1127 batch loss 0.309603661 epoch total loss 0.278452575\n",
      "Trained batch 1128 batch loss 0.262777239 epoch total loss 0.278438687\n",
      "Trained batch 1129 batch loss 0.25018689 epoch total loss 0.278413653\n",
      "Trained batch 1130 batch loss 0.280362248 epoch total loss 0.278415382\n",
      "Trained batch 1131 batch loss 0.276761889 epoch total loss 0.278413922\n",
      "Trained batch 1132 batch loss 0.275428116 epoch total loss 0.278411269\n",
      "Trained batch 1133 batch loss 0.264851302 epoch total loss 0.278399318\n",
      "Trained batch 1134 batch loss 0.262623608 epoch total loss 0.278385401\n",
      "Trained batch 1135 batch loss 0.275873721 epoch total loss 0.278383195\n",
      "Trained batch 1136 batch loss 0.284171939 epoch total loss 0.278388292\n",
      "Trained batch 1137 batch loss 0.278033644 epoch total loss 0.278388\n",
      "Trained batch 1138 batch loss 0.298072755 epoch total loss 0.278405309\n",
      "Trained batch 1139 batch loss 0.253195435 epoch total loss 0.278383166\n",
      "Trained batch 1140 batch loss 0.284135848 epoch total loss 0.278388232\n",
      "Trained batch 1141 batch loss 0.257434368 epoch total loss 0.278369874\n",
      "Trained batch 1142 batch loss 0.260489881 epoch total loss 0.278354228\n",
      "Trained batch 1143 batch loss 0.311098874 epoch total loss 0.278382868\n",
      "Trained batch 1144 batch loss 0.292731017 epoch total loss 0.278395414\n",
      "Trained batch 1145 batch loss 0.296956301 epoch total loss 0.278411627\n",
      "Trained batch 1146 batch loss 0.316247255 epoch total loss 0.278444648\n",
      "Trained batch 1147 batch loss 0.300093293 epoch total loss 0.278463513\n",
      "Trained batch 1148 batch loss 0.269347429 epoch total loss 0.278455555\n",
      "Trained batch 1149 batch loss 0.275884181 epoch total loss 0.27845332\n",
      "Trained batch 1150 batch loss 0.284052312 epoch total loss 0.278458208\n",
      "Trained batch 1151 batch loss 0.267565221 epoch total loss 0.278448761\n",
      "Trained batch 1152 batch loss 0.286643386 epoch total loss 0.278455853\n",
      "Trained batch 1153 batch loss 0.287639618 epoch total loss 0.278463811\n",
      "Trained batch 1154 batch loss 0.302415669 epoch total loss 0.278484583\n",
      "Trained batch 1155 batch loss 0.269886047 epoch total loss 0.278477162\n",
      "Trained batch 1156 batch loss 0.295179 epoch total loss 0.278491586\n",
      "Trained batch 1157 batch loss 0.28398931 epoch total loss 0.278496355\n",
      "Trained batch 1158 batch loss 0.314404309 epoch total loss 0.278527349\n",
      "Trained batch 1159 batch loss 0.308714181 epoch total loss 0.278553396\n",
      "Trained batch 1160 batch loss 0.302788317 epoch total loss 0.278574288\n",
      "Trained batch 1161 batch loss 0.299187779 epoch total loss 0.27859205\n",
      "Trained batch 1162 batch loss 0.290781558 epoch total loss 0.27860254\n",
      "Trained batch 1163 batch loss 0.303626418 epoch total loss 0.278624058\n",
      "Trained batch 1164 batch loss 0.277948171 epoch total loss 0.278623462\n",
      "Trained batch 1165 batch loss 0.2689946 epoch total loss 0.278615206\n",
      "Trained batch 1166 batch loss 0.271632463 epoch total loss 0.278609216\n",
      "Trained batch 1167 batch loss 0.296264321 epoch total loss 0.278624326\n",
      "Trained batch 1168 batch loss 0.29317981 epoch total loss 0.278636813\n",
      "Trained batch 1169 batch loss 0.265030205 epoch total loss 0.27862516\n",
      "Trained batch 1170 batch loss 0.242026776 epoch total loss 0.278593898\n",
      "Trained batch 1171 batch loss 0.259142399 epoch total loss 0.278577298\n",
      "Trained batch 1172 batch loss 0.231058598 epoch total loss 0.278536737\n",
      "Trained batch 1173 batch loss 0.247742355 epoch total loss 0.278510481\n",
      "Trained batch 1174 batch loss 0.283620954 epoch total loss 0.278514862\n",
      "Trained batch 1175 batch loss 0.28645739 epoch total loss 0.278521627\n",
      "Trained batch 1176 batch loss 0.294376075 epoch total loss 0.278535098\n",
      "Trained batch 1177 batch loss 0.29572612 epoch total loss 0.278549701\n",
      "Trained batch 1178 batch loss 0.30005008 epoch total loss 0.27856794\n",
      "Trained batch 1179 batch loss 0.301034629 epoch total loss 0.278586984\n",
      "Trained batch 1180 batch loss 0.267448455 epoch total loss 0.278577566\n",
      "Trained batch 1181 batch loss 0.301871032 epoch total loss 0.278597295\n",
      "Trained batch 1182 batch loss 0.317956686 epoch total loss 0.278630614\n",
      "Trained batch 1183 batch loss 0.294055223 epoch total loss 0.278643638\n",
      "Trained batch 1184 batch loss 0.246686801 epoch total loss 0.278616637\n",
      "Trained batch 1185 batch loss 0.234474897 epoch total loss 0.278579384\n",
      "Trained batch 1186 batch loss 0.231518567 epoch total loss 0.278539687\n",
      "Trained batch 1187 batch loss 0.247904286 epoch total loss 0.278513879\n",
      "Trained batch 1188 batch loss 0.267312258 epoch total loss 0.278504431\n",
      "Trained batch 1189 batch loss 0.254812956 epoch total loss 0.278484523\n",
      "Trained batch 1190 batch loss 0.288436532 epoch total loss 0.278492868\n",
      "Trained batch 1191 batch loss 0.298043877 epoch total loss 0.278509289\n",
      "Trained batch 1192 batch loss 0.303679526 epoch total loss 0.278530389\n",
      "Trained batch 1193 batch loss 0.3053298 epoch total loss 0.27855286\n",
      "Trained batch 1194 batch loss 0.289685071 epoch total loss 0.278562188\n",
      "Trained batch 1195 batch loss 0.279784 epoch total loss 0.278563201\n",
      "Trained batch 1196 batch loss 0.289156377 epoch total loss 0.278572053\n",
      "Trained batch 1197 batch loss 0.287200212 epoch total loss 0.278579265\n",
      "Trained batch 1198 batch loss 0.271122962 epoch total loss 0.278573036\n",
      "Trained batch 1199 batch loss 0.298100948 epoch total loss 0.278589308\n",
      "Trained batch 1200 batch loss 0.267013073 epoch total loss 0.278579652\n",
      "Trained batch 1201 batch loss 0.290520608 epoch total loss 0.278589606\n",
      "Trained batch 1202 batch loss 0.28763622 epoch total loss 0.278597116\n",
      "Trained batch 1203 batch loss 0.26896894 epoch total loss 0.278589129\n",
      "Trained batch 1204 batch loss 0.283361673 epoch total loss 0.278593093\n",
      "Trained batch 1205 batch loss 0.280801415 epoch total loss 0.278594911\n",
      "Trained batch 1206 batch loss 0.290017903 epoch total loss 0.278604388\n",
      "Trained batch 1207 batch loss 0.251609594 epoch total loss 0.278582036\n",
      "Trained batch 1208 batch loss 0.253929257 epoch total loss 0.278561622\n",
      "Trained batch 1209 batch loss 0.234157607 epoch total loss 0.278524905\n",
      "Trained batch 1210 batch loss 0.256905198 epoch total loss 0.278507024\n",
      "Trained batch 1211 batch loss 0.255703807 epoch total loss 0.278488189\n",
      "Trained batch 1212 batch loss 0.258615524 epoch total loss 0.278471798\n",
      "Trained batch 1213 batch loss 0.235139236 epoch total loss 0.278436065\n",
      "Trained batch 1214 batch loss 0.255382061 epoch total loss 0.278417081\n",
      "Trained batch 1215 batch loss 0.281089664 epoch total loss 0.278419286\n",
      "Trained batch 1216 batch loss 0.296956301 epoch total loss 0.278434515\n",
      "Trained batch 1217 batch loss 0.281430125 epoch total loss 0.278437\n",
      "Trained batch 1218 batch loss 0.234965518 epoch total loss 0.278401285\n",
      "Trained batch 1219 batch loss 0.246657953 epoch total loss 0.278375238\n",
      "Trained batch 1220 batch loss 0.23980464 epoch total loss 0.278343618\n",
      "Trained batch 1221 batch loss 0.257295787 epoch total loss 0.278326392\n",
      "Trained batch 1222 batch loss 0.272840142 epoch total loss 0.278321892\n",
      "Trained batch 1223 batch loss 0.286518037 epoch total loss 0.278328598\n",
      "Trained batch 1224 batch loss 0.269224405 epoch total loss 0.278321147\n",
      "Trained batch 1225 batch loss 0.258303881 epoch total loss 0.278304815\n",
      "Trained batch 1226 batch loss 0.284113944 epoch total loss 0.278309554\n",
      "Trained batch 1227 batch loss 0.299813509 epoch total loss 0.278327078\n",
      "Trained batch 1228 batch loss 0.335639685 epoch total loss 0.278373748\n",
      "Trained batch 1229 batch loss 0.347968847 epoch total loss 0.278430372\n",
      "Trained batch 1230 batch loss 0.349620938 epoch total loss 0.278488219\n",
      "Trained batch 1231 batch loss 0.286631852 epoch total loss 0.278494835\n",
      "Trained batch 1232 batch loss 0.235166281 epoch total loss 0.278459668\n",
      "Trained batch 1233 batch loss 0.291930974 epoch total loss 0.278470606\n",
      "Trained batch 1234 batch loss 0.301096678 epoch total loss 0.278488934\n",
      "Trained batch 1235 batch loss 0.315410763 epoch total loss 0.278518826\n",
      "Trained batch 1236 batch loss 0.290894926 epoch total loss 0.278528839\n",
      "Trained batch 1237 batch loss 0.290296197 epoch total loss 0.278538316\n",
      "Trained batch 1238 batch loss 0.289926857 epoch total loss 0.278547525\n",
      "Trained batch 1239 batch loss 0.320118248 epoch total loss 0.278581083\n",
      "Trained batch 1240 batch loss 0.309139907 epoch total loss 0.278605729\n",
      "Trained batch 1241 batch loss 0.252872646 epoch total loss 0.278585\n",
      "Trained batch 1242 batch loss 0.269122362 epoch total loss 0.278577387\n",
      "Trained batch 1243 batch loss 0.269263834 epoch total loss 0.278569877\n",
      "Trained batch 1244 batch loss 0.232050851 epoch total loss 0.278532475\n",
      "Trained batch 1245 batch loss 0.264503211 epoch total loss 0.27852121\n",
      "Trained batch 1246 batch loss 0.289097905 epoch total loss 0.278529704\n",
      "Trained batch 1247 batch loss 0.273296028 epoch total loss 0.278525501\n",
      "Trained batch 1248 batch loss 0.272230387 epoch total loss 0.278520435\n",
      "Trained batch 1249 batch loss 0.256167769 epoch total loss 0.278502524\n",
      "Trained batch 1250 batch loss 0.238268346 epoch total loss 0.278470367\n",
      "Trained batch 1251 batch loss 0.287142575 epoch total loss 0.278477281\n",
      "Trained batch 1252 batch loss 0.310342818 epoch total loss 0.278502733\n",
      "Trained batch 1253 batch loss 0.288012326 epoch total loss 0.278510332\n",
      "Trained batch 1254 batch loss 0.256916612 epoch total loss 0.278493136\n",
      "Trained batch 1255 batch loss 0.207937524 epoch total loss 0.278436899\n",
      "Trained batch 1256 batch loss 0.20136857 epoch total loss 0.278375536\n",
      "Trained batch 1257 batch loss 0.199778661 epoch total loss 0.278313\n",
      "Trained batch 1258 batch loss 0.25848639 epoch total loss 0.278297246\n",
      "Trained batch 1259 batch loss 0.262820721 epoch total loss 0.278284937\n",
      "Trained batch 1260 batch loss 0.271390736 epoch total loss 0.278279483\n",
      "Trained batch 1261 batch loss 0.260715187 epoch total loss 0.278265536\n",
      "Trained batch 1262 batch loss 0.290676177 epoch total loss 0.278275371\n",
      "Trained batch 1263 batch loss 0.310565054 epoch total loss 0.278300971\n",
      "Trained batch 1264 batch loss 0.270778447 epoch total loss 0.278295\n",
      "Trained batch 1265 batch loss 0.262524724 epoch total loss 0.278282523\n",
      "Trained batch 1266 batch loss 0.256228954 epoch total loss 0.278265119\n",
      "Trained batch 1267 batch loss 0.230638862 epoch total loss 0.278227538\n",
      "Trained batch 1268 batch loss 0.229591116 epoch total loss 0.278189182\n",
      "Trained batch 1269 batch loss 0.268140852 epoch total loss 0.278181225\n",
      "Trained batch 1270 batch loss 0.236867249 epoch total loss 0.278148711\n",
      "Trained batch 1271 batch loss 0.262992322 epoch total loss 0.27813679\n",
      "Trained batch 1272 batch loss 0.269190609 epoch total loss 0.278129756\n",
      "Trained batch 1273 batch loss 0.253070682 epoch total loss 0.278110087\n",
      "Trained batch 1274 batch loss 0.252303571 epoch total loss 0.278089821\n",
      "Trained batch 1275 batch loss 0.260723293 epoch total loss 0.278076202\n",
      "Trained batch 1276 batch loss 0.297167897 epoch total loss 0.278091162\n",
      "Trained batch 1277 batch loss 0.28232494 epoch total loss 0.278094471\n",
      "Trained batch 1278 batch loss 0.305644274 epoch total loss 0.278116018\n",
      "Trained batch 1279 batch loss 0.276872933 epoch total loss 0.278115064\n",
      "Trained batch 1280 batch loss 0.249513179 epoch total loss 0.278092712\n",
      "Trained batch 1281 batch loss 0.253322452 epoch total loss 0.27807337\n",
      "Trained batch 1282 batch loss 0.239525631 epoch total loss 0.27804333\n",
      "Trained batch 1283 batch loss 0.244722 epoch total loss 0.278017342\n",
      "Trained batch 1284 batch loss 0.261507392 epoch total loss 0.278004497\n",
      "Trained batch 1285 batch loss 0.251894 epoch total loss 0.277984172\n",
      "Trained batch 1286 batch loss 0.233392373 epoch total loss 0.277949512\n",
      "Trained batch 1287 batch loss 0.257058203 epoch total loss 0.27793327\n",
      "Trained batch 1288 batch loss 0.246883929 epoch total loss 0.27790916\n",
      "Trained batch 1289 batch loss 0.237739414 epoch total loss 0.277878\n",
      "Trained batch 1290 batch loss 0.235247046 epoch total loss 0.277844936\n",
      "Trained batch 1291 batch loss 0.255346984 epoch total loss 0.277827531\n",
      "Trained batch 1292 batch loss 0.251459181 epoch total loss 0.277807117\n",
      "Trained batch 1293 batch loss 0.297358871 epoch total loss 0.277822226\n",
      "Trained batch 1294 batch loss 0.323996812 epoch total loss 0.277857929\n",
      "Trained batch 1295 batch loss 0.27342841 epoch total loss 0.277854502\n",
      "Trained batch 1296 batch loss 0.293381959 epoch total loss 0.277866513\n",
      "Trained batch 1297 batch loss 0.314103484 epoch total loss 0.277894467\n",
      "Trained batch 1298 batch loss 0.298980772 epoch total loss 0.277910709\n",
      "Trained batch 1299 batch loss 0.295466781 epoch total loss 0.27792421\n",
      "Trained batch 1300 batch loss 0.252895027 epoch total loss 0.277904958\n",
      "Trained batch 1301 batch loss 0.262394488 epoch total loss 0.277893037\n",
      "Trained batch 1302 batch loss 0.314419299 epoch total loss 0.27792111\n",
      "Trained batch 1303 batch loss 0.273095667 epoch total loss 0.277917415\n",
      "Trained batch 1304 batch loss 0.296813816 epoch total loss 0.277931899\n",
      "Trained batch 1305 batch loss 0.254272759 epoch total loss 0.277913749\n",
      "Trained batch 1306 batch loss 0.302112728 epoch total loss 0.277932286\n",
      "Trained batch 1307 batch loss 0.275268584 epoch total loss 0.27793026\n",
      "Trained batch 1308 batch loss 0.26496309 epoch total loss 0.277920336\n",
      "Trained batch 1309 batch loss 0.278728783 epoch total loss 0.277920961\n",
      "Trained batch 1310 batch loss 0.293147236 epoch total loss 0.277932584\n",
      "Trained batch 1311 batch loss 0.297276616 epoch total loss 0.277947336\n",
      "Trained batch 1312 batch loss 0.3171269 epoch total loss 0.277977198\n",
      "Trained batch 1313 batch loss 0.288179219 epoch total loss 0.277984977\n",
      "Trained batch 1314 batch loss 0.312520802 epoch total loss 0.278011262\n",
      "Trained batch 1315 batch loss 0.299418926 epoch total loss 0.278027534\n",
      "Trained batch 1316 batch loss 0.311757624 epoch total loss 0.278053164\n",
      "Trained batch 1317 batch loss 0.273528337 epoch total loss 0.278049737\n",
      "Trained batch 1318 batch loss 0.320541888 epoch total loss 0.278081983\n",
      "Trained batch 1319 batch loss 0.277490526 epoch total loss 0.278081536\n",
      "Trained batch 1320 batch loss 0.278848916 epoch total loss 0.278082103\n",
      "Trained batch 1321 batch loss 0.262777984 epoch total loss 0.278070539\n",
      "Trained batch 1322 batch loss 0.252487928 epoch total loss 0.278051198\n",
      "Trained batch 1323 batch loss 0.231724173 epoch total loss 0.27801618\n",
      "Trained batch 1324 batch loss 0.261146665 epoch total loss 0.278003424\n",
      "Trained batch 1325 batch loss 0.263542831 epoch total loss 0.277992517\n",
      "Trained batch 1326 batch loss 0.287441492 epoch total loss 0.27799964\n",
      "Trained batch 1327 batch loss 0.26823324 epoch total loss 0.277992278\n",
      "Trained batch 1328 batch loss 0.289331079 epoch total loss 0.278000832\n",
      "Trained batch 1329 batch loss 0.28013289 epoch total loss 0.278002411\n",
      "Trained batch 1330 batch loss 0.25430885 epoch total loss 0.277984589\n",
      "Trained batch 1331 batch loss 0.273966 epoch total loss 0.277981579\n",
      "Trained batch 1332 batch loss 0.266889691 epoch total loss 0.277973235\n",
      "Trained batch 1333 batch loss 0.261060059 epoch total loss 0.277960539\n",
      "Trained batch 1334 batch loss 0.266741842 epoch total loss 0.277952135\n",
      "Trained batch 1335 batch loss 0.234851256 epoch total loss 0.277919859\n",
      "Trained batch 1336 batch loss 0.282067716 epoch total loss 0.277922958\n",
      "Trained batch 1337 batch loss 0.26645422 epoch total loss 0.277914375\n",
      "Trained batch 1338 batch loss 0.275776148 epoch total loss 0.277912796\n",
      "Trained batch 1339 batch loss 0.271577239 epoch total loss 0.277908057\n",
      "Trained batch 1340 batch loss 0.238973334 epoch total loss 0.27787903\n",
      "Trained batch 1341 batch loss 0.221265942 epoch total loss 0.2778368\n",
      "Trained batch 1342 batch loss 0.221332461 epoch total loss 0.277794689\n",
      "Trained batch 1343 batch loss 0.217872068 epoch total loss 0.277750075\n",
      "Trained batch 1344 batch loss 0.227306396 epoch total loss 0.277712524\n",
      "Trained batch 1345 batch loss 0.225229457 epoch total loss 0.277673513\n",
      "Trained batch 1346 batch loss 0.228044152 epoch total loss 0.277636647\n",
      "Trained batch 1347 batch loss 0.241690606 epoch total loss 0.277609944\n",
      "Trained batch 1348 batch loss 0.251301557 epoch total loss 0.277590454\n",
      "Trained batch 1349 batch loss 0.219441369 epoch total loss 0.277547359\n",
      "Trained batch 1350 batch loss 0.244398132 epoch total loss 0.277522773\n",
      "Trained batch 1351 batch loss 0.240605101 epoch total loss 0.277495444\n",
      "Trained batch 1352 batch loss 0.224773049 epoch total loss 0.277456462\n",
      "Trained batch 1353 batch loss 0.314441264 epoch total loss 0.277483791\n",
      "Trained batch 1354 batch loss 0.250066429 epoch total loss 0.277463555\n",
      "Trained batch 1355 batch loss 0.256652236 epoch total loss 0.277448177\n",
      "Trained batch 1356 batch loss 0.221137211 epoch total loss 0.277406663\n",
      "Trained batch 1357 batch loss 0.258076787 epoch total loss 0.277392417\n",
      "Trained batch 1358 batch loss 0.254954666 epoch total loss 0.277375877\n",
      "Trained batch 1359 batch loss 0.26282838 epoch total loss 0.277365178\n",
      "Trained batch 1360 batch loss 0.269297123 epoch total loss 0.277359247\n",
      "Trained batch 1361 batch loss 0.298958927 epoch total loss 0.277375102\n",
      "Trained batch 1362 batch loss 0.332092822 epoch total loss 0.277415276\n",
      "Trained batch 1363 batch loss 0.314181417 epoch total loss 0.277442247\n",
      "Trained batch 1364 batch loss 0.275400162 epoch total loss 0.277440727\n",
      "Trained batch 1365 batch loss 0.257754564 epoch total loss 0.277426302\n",
      "Trained batch 1366 batch loss 0.247612983 epoch total loss 0.277404487\n",
      "Trained batch 1367 batch loss 0.277228385 epoch total loss 0.277404368\n",
      "Trained batch 1368 batch loss 0.278303057 epoch total loss 0.277405\n",
      "Trained batch 1369 batch loss 0.248110205 epoch total loss 0.277383596\n",
      "Trained batch 1370 batch loss 0.29264456 epoch total loss 0.277394742\n",
      "Trained batch 1371 batch loss 0.279200941 epoch total loss 0.277396053\n",
      "Trained batch 1372 batch loss 0.288499832 epoch total loss 0.277404159\n",
      "Trained batch 1373 batch loss 0.290392 epoch total loss 0.277413636\n",
      "Trained batch 1374 batch loss 0.290496141 epoch total loss 0.277423143\n",
      "Trained batch 1375 batch loss 0.293748349 epoch total loss 0.277435035\n",
      "Trained batch 1376 batch loss 0.288753718 epoch total loss 0.27744326\n",
      "Trained batch 1377 batch loss 0.303648025 epoch total loss 0.277462304\n",
      "Trained batch 1378 batch loss 0.257965744 epoch total loss 0.277448148\n",
      "Trained batch 1379 batch loss 0.271173328 epoch total loss 0.277443588\n",
      "Trained batch 1380 batch loss 0.262481928 epoch total loss 0.27743277\n",
      "Trained batch 1381 batch loss 0.243195727 epoch total loss 0.277407974\n",
      "Trained batch 1382 batch loss 0.236456618 epoch total loss 0.277378321\n",
      "Trained batch 1383 batch loss 0.279304445 epoch total loss 0.277379721\n",
      "Trained batch 1384 batch loss 0.265219897 epoch total loss 0.27737093\n",
      "Trained batch 1385 batch loss 0.254638225 epoch total loss 0.277354538\n",
      "Trained batch 1386 batch loss 0.262116402 epoch total loss 0.277343541\n",
      "Trained batch 1387 batch loss 0.238789067 epoch total loss 0.277315736\n",
      "Trained batch 1388 batch loss 0.261233777 epoch total loss 0.277304143\n",
      "Epoch 5 train loss 0.27730414271354675\n",
      "Validated batch 1 batch loss 0.266473591\n",
      "Validated batch 2 batch loss 0.268671513\n",
      "Validated batch 3 batch loss 0.273529738\n",
      "Validated batch 4 batch loss 0.293711543\n",
      "Validated batch 5 batch loss 0.273162127\n",
      "Validated batch 6 batch loss 0.306368858\n",
      "Validated batch 7 batch loss 0.285116404\n",
      "Validated batch 8 batch loss 0.227507189\n",
      "Validated batch 9 batch loss 0.255108386\n",
      "Validated batch 10 batch loss 0.276845127\n",
      "Validated batch 11 batch loss 0.268323809\n",
      "Validated batch 12 batch loss 0.272845596\n",
      "Validated batch 13 batch loss 0.275636554\n",
      "Validated batch 14 batch loss 0.274942636\n",
      "Validated batch 15 batch loss 0.299102604\n",
      "Validated batch 16 batch loss 0.30451718\n",
      "Validated batch 17 batch loss 0.280436039\n",
      "Validated batch 18 batch loss 0.307986021\n",
      "Validated batch 19 batch loss 0.232777819\n",
      "Validated batch 20 batch loss 0.266185284\n",
      "Validated batch 21 batch loss 0.243029609\n",
      "Validated batch 22 batch loss 0.292975\n",
      "Validated batch 23 batch loss 0.317924\n",
      "Validated batch 24 batch loss 0.303882778\n",
      "Validated batch 25 batch loss 0.309624195\n",
      "Validated batch 26 batch loss 0.281104922\n",
      "Validated batch 27 batch loss 0.287548\n",
      "Validated batch 28 batch loss 0.306329161\n",
      "Validated batch 29 batch loss 0.33824867\n",
      "Validated batch 30 batch loss 0.280702204\n",
      "Validated batch 31 batch loss 0.308796734\n",
      "Validated batch 32 batch loss 0.282542765\n",
      "Validated batch 33 batch loss 0.306302428\n",
      "Validated batch 34 batch loss 0.29786253\n",
      "Validated batch 35 batch loss 0.265876442\n",
      "Validated batch 36 batch loss 0.335551351\n",
      "Validated batch 37 batch loss 0.272336513\n",
      "Validated batch 38 batch loss 0.313811809\n",
      "Validated batch 39 batch loss 0.298707187\n",
      "Validated batch 40 batch loss 0.317350328\n",
      "Validated batch 41 batch loss 0.268571138\n",
      "Validated batch 42 batch loss 0.308724254\n",
      "Validated batch 43 batch loss 0.278498143\n",
      "Validated batch 44 batch loss 0.308390617\n",
      "Validated batch 45 batch loss 0.297429502\n",
      "Validated batch 46 batch loss 0.29189983\n",
      "Validated batch 47 batch loss 0.30633083\n",
      "Validated batch 48 batch loss 0.287858546\n",
      "Validated batch 49 batch loss 0.272533327\n",
      "Validated batch 50 batch loss 0.275771469\n",
      "Validated batch 51 batch loss 0.288474649\n",
      "Validated batch 52 batch loss 0.297263652\n",
      "Validated batch 53 batch loss 0.289387316\n",
      "Validated batch 54 batch loss 0.289920509\n",
      "Validated batch 55 batch loss 0.296195686\n",
      "Validated batch 56 batch loss 0.308861226\n",
      "Validated batch 57 batch loss 0.259201527\n",
      "Validated batch 58 batch loss 0.245170578\n",
      "Validated batch 59 batch loss 0.306754172\n",
      "Validated batch 60 batch loss 0.299940526\n",
      "Validated batch 61 batch loss 0.332371652\n",
      "Validated batch 62 batch loss 0.312860698\n",
      "Validated batch 63 batch loss 0.287415\n",
      "Validated batch 64 batch loss 0.331158429\n",
      "Validated batch 65 batch loss 0.282458454\n",
      "Validated batch 66 batch loss 0.299515426\n",
      "Validated batch 67 batch loss 0.287955135\n",
      "Validated batch 68 batch loss 0.228312105\n",
      "Validated batch 69 batch loss 0.283717364\n",
      "Validated batch 70 batch loss 0.319771707\n",
      "Validated batch 71 batch loss 0.293440044\n",
      "Validated batch 72 batch loss 0.282118052\n",
      "Validated batch 73 batch loss 0.296094179\n",
      "Validated batch 74 batch loss 0.269970357\n",
      "Validated batch 75 batch loss 0.309238732\n",
      "Validated batch 76 batch loss 0.293121874\n",
      "Validated batch 77 batch loss 0.288080513\n",
      "Validated batch 78 batch loss 0.295398593\n",
      "Validated batch 79 batch loss 0.311902821\n",
      "Validated batch 80 batch loss 0.304529697\n",
      "Validated batch 81 batch loss 0.315986246\n",
      "Validated batch 82 batch loss 0.290833265\n",
      "Validated batch 83 batch loss 0.269354701\n",
      "Validated batch 84 batch loss 0.273059785\n",
      "Validated batch 85 batch loss 0.300927907\n",
      "Validated batch 86 batch loss 0.277718693\n",
      "Validated batch 87 batch loss 0.289126784\n",
      "Validated batch 88 batch loss 0.301375657\n",
      "Validated batch 89 batch loss 0.357919753\n",
      "Validated batch 90 batch loss 0.312521219\n",
      "Validated batch 91 batch loss 0.298072517\n",
      "Validated batch 92 batch loss 0.2654351\n",
      "Validated batch 93 batch loss 0.246873707\n",
      "Validated batch 94 batch loss 0.280960977\n",
      "Validated batch 95 batch loss 0.312009245\n",
      "Validated batch 96 batch loss 0.278051138\n",
      "Validated batch 97 batch loss 0.315817565\n",
      "Validated batch 98 batch loss 0.336208761\n",
      "Validated batch 99 batch loss 0.274328232\n",
      "Validated batch 100 batch loss 0.298835039\n",
      "Validated batch 101 batch loss 0.296096563\n",
      "Validated batch 102 batch loss 0.321900696\n",
      "Validated batch 103 batch loss 0.295391589\n",
      "Validated batch 104 batch loss 0.274241328\n",
      "Validated batch 105 batch loss 0.242884815\n",
      "Validated batch 106 batch loss 0.279310048\n",
      "Validated batch 107 batch loss 0.270614028\n",
      "Validated batch 108 batch loss 0.291170508\n",
      "Validated batch 109 batch loss 0.294001848\n",
      "Validated batch 110 batch loss 0.242574185\n",
      "Validated batch 111 batch loss 0.292624146\n",
      "Validated batch 112 batch loss 0.318580031\n",
      "Validated batch 113 batch loss 0.314359248\n",
      "Validated batch 114 batch loss 0.292136818\n",
      "Validated batch 115 batch loss 0.259535402\n",
      "Validated batch 116 batch loss 0.28999567\n",
      "Validated batch 117 batch loss 0.301169872\n",
      "Validated batch 118 batch loss 0.28709954\n",
      "Validated batch 119 batch loss 0.272980839\n",
      "Validated batch 120 batch loss 0.302423149\n",
      "Validated batch 121 batch loss 0.298246711\n",
      "Validated batch 122 batch loss 0.304641128\n",
      "Validated batch 123 batch loss 0.308547735\n",
      "Validated batch 124 batch loss 0.311459154\n",
      "Validated batch 125 batch loss 0.280808568\n",
      "Validated batch 126 batch loss 0.298234195\n",
      "Validated batch 127 batch loss 0.291068166\n",
      "Validated batch 128 batch loss 0.285716027\n",
      "Validated batch 129 batch loss 0.32830292\n",
      "Validated batch 130 batch loss 0.317221403\n",
      "Validated batch 131 batch loss 0.306303024\n",
      "Validated batch 132 batch loss 0.312510937\n",
      "Validated batch 133 batch loss 0.270534\n",
      "Validated batch 134 batch loss 0.285931498\n",
      "Validated batch 135 batch loss 0.271453798\n",
      "Validated batch 136 batch loss 0.254523\n",
      "Validated batch 137 batch loss 0.301395804\n",
      "Validated batch 138 batch loss 0.274184763\n",
      "Validated batch 139 batch loss 0.28964138\n",
      "Validated batch 140 batch loss 0.25399524\n",
      "Validated batch 141 batch loss 0.281737298\n",
      "Validated batch 142 batch loss 0.272708684\n",
      "Validated batch 143 batch loss 0.252956331\n",
      "Validated batch 144 batch loss 0.292832136\n",
      "Validated batch 145 batch loss 0.286508679\n",
      "Validated batch 146 batch loss 0.299819678\n",
      "Validated batch 147 batch loss 0.307056248\n",
      "Validated batch 148 batch loss 0.250877947\n",
      "Validated batch 149 batch loss 0.305734\n",
      "Validated batch 150 batch loss 0.297892392\n",
      "Validated batch 151 batch loss 0.264621109\n",
      "Validated batch 152 batch loss 0.300503731\n",
      "Validated batch 153 batch loss 0.290040612\n",
      "Validated batch 154 batch loss 0.270067185\n",
      "Validated batch 155 batch loss 0.334468186\n",
      "Validated batch 156 batch loss 0.288485\n",
      "Validated batch 157 batch loss 0.298823744\n",
      "Validated batch 158 batch loss 0.266115\n",
      "Validated batch 159 batch loss 0.289433599\n",
      "Validated batch 160 batch loss 0.267621219\n",
      "Validated batch 161 batch loss 0.269687057\n",
      "Validated batch 162 batch loss 0.293444306\n",
      "Validated batch 163 batch loss 0.280988276\n",
      "Validated batch 164 batch loss 0.280312926\n",
      "Validated batch 165 batch loss 0.273859978\n",
      "Validated batch 166 batch loss 0.276845932\n",
      "Validated batch 167 batch loss 0.297289491\n",
      "Validated batch 168 batch loss 0.286821961\n",
      "Validated batch 169 batch loss 0.305856\n",
      "Validated batch 170 batch loss 0.309272349\n",
      "Validated batch 171 batch loss 0.308002979\n",
      "Validated batch 172 batch loss 0.29885006\n",
      "Validated batch 173 batch loss 0.341584682\n",
      "Validated batch 174 batch loss 0.309384972\n",
      "Validated batch 175 batch loss 0.314718127\n",
      "Validated batch 176 batch loss 0.303714603\n",
      "Validated batch 177 batch loss 0.33105287\n",
      "Validated batch 178 batch loss 0.316742927\n",
      "Validated batch 179 batch loss 0.272493094\n",
      "Validated batch 180 batch loss 0.289216667\n",
      "Validated batch 181 batch loss 0.304866463\n",
      "Validated batch 182 batch loss 0.316535473\n",
      "Validated batch 183 batch loss 0.27901423\n",
      "Validated batch 184 batch loss 0.308247983\n",
      "Validated batch 185 batch loss 0.281109899\n",
      "Epoch 5 val loss 0.2908313572406769\n",
      "Model /aiffel/aiffel/mpii/models2/model-epoch-5-loss-0.2908.h5 saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_simple_model_file = train2(epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplebaseline모델 예측하기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS_PATH = os.path.join(MODEL_PATH2, 'model-epoch-5-loss-0.2908.h5')\n",
    "\n",
    "sbl = Simplebaseline()\n",
    "sbl.load_weights(WEIGHTS_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(sbl, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "STEP 3 : 두 모델의 비교  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackedHourglassNetwork 모델과 Simplebaseline을 구성하여 포즈디텍팅을 해보았다.  \n",
    "Simplebaseline은 분산처리시 에러가 발생했으나, 서버에서는 디버깅이 힘들어 분산 처리코드를 모두 막고 진행했다.  \n",
    "StackedHourglassNetwork모델이 5epoch씩 학습한 경우에 로스가 더 낮게 나왔다 하지만 아주 간단한 Simplebaseline도 비슷한 수준의 결과를 보였다.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6debceb626036820d184549e25d059a55b6b8771e25bc8133db281d329c34fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
